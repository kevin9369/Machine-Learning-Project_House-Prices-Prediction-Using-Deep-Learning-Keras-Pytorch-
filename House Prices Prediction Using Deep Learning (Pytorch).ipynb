{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression using a Neural Network (Pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7FmGucnl4Uk8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = pd.read_csv(\"housing.csv\")\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 10)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing: remove NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude               0\n",
       "latitude                0\n",
       "housing_median_age      0\n",
       "total_rooms             0\n",
       "total_bedrooms        207\n",
       "population              0\n",
       "households              0\n",
       "median_income           0\n",
       "median_house_value      0\n",
       "ocean_proximity         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude             0\n",
       "latitude              0\n",
       "housing_median_age    0\n",
       "total_rooms           0\n",
       "total_bedrooms        0\n",
       "population            0\n",
       "households            0\n",
       "median_income         0\n",
       "median_house_value    0\n",
       "ocean_proximity       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are 207 NaN in the column 'total_bedrooms', remove them\n",
    "# check housing again using housing.isnull().sum()\n",
    "housing['total_bedrooms'].fillna((housing['total_bedrooms'].mean()), inplace=True)\n",
    "housing.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing: Convert categorical data to numerical data - \"ocean_proximity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "colab_type": "code",
    "id": "RXn7GRuM4vgm",
    "outputId": "ebd6f495-12a9-4b2f-8dca-ce694cc5696a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1H OCEAN     9136\n",
       "INLAND        6551\n",
       "NEAR OCEAN    2658\n",
       "NEAR BAY      2290\n",
       "ISLAND           5\n",
       "Name: ocean_proximity, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing[\"ocean_proximity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity_&lt;1H OCEAN</th>\n",
       "      <th>ocean_proximity_INLAND</th>\n",
       "      <th>ocean_proximity_ISLAND</th>\n",
       "      <th>ocean_proximity_NEAR BAY</th>\n",
       "      <th>ocean_proximity_NEAR OCEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value  \\\n",
       "0       322.0       126.0         8.3252            452600.0   \n",
       "1      2401.0      1138.0         8.3014            358500.0   \n",
       "2       496.0       177.0         7.2574            352100.0   \n",
       "3       558.0       219.0         5.6431            341300.0   \n",
       "4       565.0       259.0         3.8462            342200.0   \n",
       "\n",
       "   ocean_proximity_<1H OCEAN  ocean_proximity_INLAND  ocean_proximity_ISLAND  \\\n",
       "0                          0                       0                       0   \n",
       "1                          0                       0                       0   \n",
       "2                          0                       0                       0   \n",
       "3                          0                       0                       0   \n",
       "4                          0                       0                       0   \n",
       "\n",
       "   ocean_proximity_NEAR BAY  ocean_proximity_NEAR OCEAN  \n",
       "0                         1                           0  \n",
       "1                         1                           0  \n",
       "2                         1                           0  \n",
       "3                         1                           0  \n",
       "4                         1                           0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can use one-hot encoding method by calling pd.get_dummies\n",
    "categorical_columns=['ocean_proximity'] # must be a list\n",
    "housing = pd.get_dummies(housing, columns=categorical_columns)\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'median_income')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skimage.io import imread\n",
    "california_img = imread('california.png')\n",
    "x1 = min(housing[\"longitude\"].values)\n",
    "x2 = max(housing[\"longitude\"].values)\n",
    "y1 = min(housing[\"latitude\"].values)\n",
    "y2 = max(housing[\"latitude\"].values)\n",
    "#---------------------------------------------\n",
    "# the parameter c refers to color\n",
    "# thus, median_house_value is color-coded in the left plot\n",
    "fig, ax =plt.subplots(1,2)\n",
    "housing.plot(ax=ax[0], kind=\"scatter\", x=\"longitude\", y=\"latitude\",\n",
    "             s=housing['population']/100, label=\"population\",\n",
    "             c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"),\n",
    "             colorbar=True, alpha=0.4, figsize=(10,7))\n",
    "#---------------------------------------------\n",
    "# the parameter c refers to color\n",
    "# thus, median_income is color-coded in the right plot\n",
    "ax[0].imshow(california_img,extent=[x1,x2,y1,y2])\n",
    "ax[0].set_title('median_house_value')\n",
    "housing.plot(ax=ax[1], kind=\"scatter\", x=\"longitude\", y=\"latitude\",\n",
    "             s=housing['population']/100, label=\"population\",\n",
    "             c=\"median_income\", cmap=plt.get_cmap(\"jet\"),\n",
    "             colorbar=True, alpha=0.4, figsize=(10,7))\n",
    "ax[1].imshow(california_img,extent=[x1,x2,y1,y2])\n",
    "ax[1].set_title('median_income')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Training and Testing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity_&lt;1H OCEAN</th>\n",
       "      <th>ocean_proximity_INLAND</th>\n",
       "      <th>ocean_proximity_ISLAND</th>\n",
       "      <th>ocean_proximity_NEAR BAY</th>\n",
       "      <th>ocean_proximity_NEAR OCEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  ocean_proximity_<1H OCEAN  \\\n",
       "0       322.0       126.0         8.3252                          0   \n",
       "1      2401.0      1138.0         8.3014                          0   \n",
       "2       496.0       177.0         7.2574                          0   \n",
       "3       558.0       219.0         5.6431                          0   \n",
       "4       565.0       259.0         3.8462                          0   \n",
       "\n",
       "   ocean_proximity_INLAND  ocean_proximity_ISLAND  ocean_proximity_NEAR BAY  \\\n",
       "0                       0                       0                         1   \n",
       "1                       0                       0                         1   \n",
       "2                       0                       0                         1   \n",
       "3                       0                       0                         1   \n",
       "4                       0                       0                         1   \n",
       "\n",
       "   ocean_proximity_NEAR OCEAN  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=housing.drop(['median_house_value'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    452600.0\n",
       "1    358500.0\n",
       "2    352100.0\n",
       "3    341300.0\n",
       "4    342200.0\n",
       "Name: median_house_value, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=housing['median_house_value']\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pandas dataframe/series to numpy array\n",
    "# sklearn functions may not work well with pandas data types\n",
    "X_columns=X.columns #store the column names\n",
    "X=X.values.astype('float32')\n",
    "Y=Y.values.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trainnig, validation, testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (14860, 13) (14860,)\n",
      "validation: (1652, 13) (1652,)\n",
      "test: (4128, 13) (4128,)\n"
     ]
    }
   ],
   "source": [
    "#trainnig, validation, testing split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "#split X_train and Y_train into a 'pure' training set and a validation set\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=0)\n",
    "print('train:', X_train.shape, Y_train.shape)\n",
    "print('validation:', X_val.shape, Y_val.shape)\n",
    "print('test:', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply feature normalization to training, validation and test sets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scalerX=MinMaxScaler()\n",
    "scalerX.fit(X_train) # think about why fit to X_train, not X ?\n",
    "X_train=scalerX.transform(X_train)\n",
    "X_val=scalerX.transform(X_val)\n",
    "X_test=scalerX.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5786848 , 0.38044596, 0.19607843, 0.12570114, 0.13671634,\n",
       "       0.00983827, 0.02795593, 0.11055019, 0.        , 1.        ,\n",
       "       0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the output to facilitate convergence\n",
    "Y_train_max=Y_train.max()\n",
    "Y_train/=Y_train_max\n",
    "Y_val/=Y_train_max\n",
    "Y_test/=Y_train_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use LinearRegression as the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step1:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear_model = LinearRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step2:\n",
    "linear_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.52667534, -0.47057638,  0.11070066, -0.31356546,  0.8725247 ,\n",
       "       -2.8026872 ,  1.0090168 ,  1.130492  , -0.04724976, -0.12498008,\n",
       "        0.26538274, -0.05612947, -0.03702466], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54965335"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate model on testing set\n",
      "MSE= 0.018863907\n",
      "MAE= 0.09931182\n",
      "MAPE= 0.28951442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Y_test_pred')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#step3:\n",
    "Y_train_pred = linear_model.predict(X_train)\n",
    "Y_test_pred = linear_model.predict(X_test)\n",
    "print('Evaluate model on testing set')\n",
    "MSE = np.mean((Y_test - Y_test_pred)**2)\n",
    "MAE = np.mean(np.abs(Y_test - Y_test_pred))\n",
    "MAPE =  np.mean(np.abs(Y_test - Y_test_pred)/Y_test)\n",
    "print('MSE=', MSE)\n",
    "print('MAE=', MAE)\n",
    "print('MAPE=', MAPE)\n",
    "#step6: \n",
    "# the red line is the 45-degree line\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Y_test_pred vs Y_test')\n",
    "ax.plot(Y_test, Y_test_pred, '.')\n",
    "ymax=np.max([Y_test.max(), Y_test_pred.max()])\n",
    "ax.plot(np.linspace(0,ymax, 3), np.linspace(0, ymax, 3), '-r')\n",
    "ax.set_xlabel('Y_test')\n",
    "ax.set_ylabel('Y_test_pred')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your work begins here\n",
    "see NN_nonlinear_regression_Pytorch.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define a dataset to hold/represent the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I give you the code here, because it is tricky\n",
    "import torch\n",
    "from torch.utils.data import Dataset as torch_dataset\n",
    "class MyDataset(torch_dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X=X\n",
    "        self.Y=Y.reshape(-1, 1) #this is very important\n",
    "    def __len__(self):\n",
    "        #return the number of data points\n",
    "        return self.X.shape[0]\n",
    "    def __getitem__(self, idx):        \n",
    "        # use the notation DatasetName[idx]\n",
    "        # to get a data point (x,y) by idx\n",
    "        # we need to convert numpy array to torch tensor\n",
    "        x=torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "        y=torch.tensor(self.Y[idx], dtype=torch.float32)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create instance objects of the `MyDataset` class <br>\n",
    "a training dataset `dataset_train` <br>\n",
    "a validation dataset `dataset_val` <br>\n",
    "a testing dataset `dataset_test` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train= MyDataset(X_train,Y_train)\n",
    "dataset_val = MyDataset(X_val, Y_val)\n",
    "dataset_test = MyDataset(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14860"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train) # get the number of data points in the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create dataloaders which will be used to generate minibatches <br>\n",
    "batch_size=N means each minibatch contains N data points  <br>\n",
    "note: the last minibatch may contain less than N data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset as torch_dataset\n",
    "from torch.utils.data import DataLoader as torch_dataloader\n",
    "\n",
    "dataloader_train = torch_dataloader(dataset_train, batch_size=128, shuffle=True, num_workers=0)\n",
    "dataloader_val = torch_dataloader(dataset_val, batch_size=128, shuffle=False, num_workers=0) \n",
    "dataloader_test = torch_dataloader(dataset_test, batch_size=128, shuffle=False, num_workers=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader_train) # get the number of minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "1 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "2 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "3 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "4 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "5 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "6 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "7 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "8 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "9 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "10 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "11 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "12 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "13 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "14 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "15 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "16 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "17 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "18 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "19 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "20 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "21 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "22 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "23 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "24 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "25 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "26 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "27 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "28 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "29 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "30 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "31 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "32 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "33 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "34 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "35 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "36 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "37 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "38 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "39 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "40 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "41 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "42 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "43 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "44 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "45 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "46 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "47 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "48 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "49 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "50 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "51 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "52 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "53 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "54 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "55 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "56 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "57 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "58 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "59 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "60 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "61 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "62 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "63 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "64 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "65 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "66 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "67 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "68 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "69 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "70 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "71 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "72 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "73 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "74 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "75 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "76 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "77 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "78 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "79 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "80 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "81 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "82 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "83 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "84 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "85 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "86 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "87 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "88 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "89 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "90 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "91 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "92 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "93 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "94 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "95 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "96 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "97 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "98 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "99 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "100 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "101 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "102 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "103 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "104 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "105 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "106 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "107 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "108 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "109 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "110 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "111 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "112 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "113 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "114 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "115 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "116 torch.Size([12, 13]) torch.Size([12, 1])\n"
     ]
    }
   ],
   "source": [
    "#verify the shape of each tensor in a batch\n",
    "for batch_idx, (X, Y) in enumerate(dataloader_train):\n",
    "    print(batch_idx, X.size(), Y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let's build a neural network that has many hidden layers and nonlinear activation - softplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnF\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, n_units):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, n_units)\n",
    "        self.layer2 = nn.Linear(n_units, n_units)\n",
    "        self.layer3 = nn.Linear(n_units, output_dim)        \n",
    "    def forward(self, x):\n",
    "        x=self.layer1(x)\n",
    "        x=nnF.softplus(x)\n",
    "        x=self.layer2(x)\n",
    "        x=nnF.softplus(x)\n",
    "        y=self.layer3(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create an instance object of the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Net(input_dim=13, output_dim=1, n_units=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (layer1): Linear(in_features=13, out_features=128, bias=True)\n",
       "  (layer2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (layer3): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#move the model to GPU if you have a GPU\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a function to train the neural network in one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, dataloader, device, epoch):    \n",
    "    model.train()\n",
    "    loss_train=0\n",
    "    for batch_idx, (X, Y) in enumerate(dataloader):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        Yp = model(X)\n",
    "        loss = torch.mean((Yp-Y)**2) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_train+=loss.item()\n",
    "        if batch_idx % 1 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * X.size(0), len(dataloader.dataset),\n",
    "                    100. * batch_idx / len(dataloader), loss.item()))\n",
    "    loss_train/=len(dataloader)\n",
    "    return loss_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a function to evaluate the neural network on the validation set or the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, device):\n",
    "    model.eval()#set model to evaluation mode\n",
    "    loss_test=0\n",
    "    mae_test=0\n",
    "    mape_test=0\n",
    "    sample_count=0\n",
    "    with torch.no_grad(): # tell Pytorch not to build graph in the 'with' section\n",
    "        for batch_idx, (X, Y) in enumerate(dataloader):\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            Yp = model(X)#forward pass\n",
    "            loss_test+=torch.sum((Yp-Y)**2).item()\n",
    "            mae_test+= torch.sum((Yp-Y).abs()).item()\n",
    "            mape_test+= torch.sum(((Yp-Y)/Yp).abs()).item()\n",
    "            sample_count+=X.size(0)\n",
    "    loss_test/=sample_count\n",
    "    mae_test/=sample_count\n",
    "    mape_test/=sample_count\n",
    "    return loss_test, mae_test ,mape_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create an optimizer (e.g. Adam) and send the parameters of the model to the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01,weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the neural network model for many epochs <br>\n",
    "It may need 100 epochs to converge.\n",
    "So, we will not save any model to harddrive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train_list=[]\n",
    "loss_val_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/14860 (0%)]\tLoss: 0.387423\n",
      "Train Epoch: 0 [128/14860 (1%)]\tLoss: 9.189272\n",
      "Train Epoch: 0 [256/14860 (2%)]\tLoss: 0.819736\n",
      "Train Epoch: 0 [384/14860 (3%)]\tLoss: 0.888607\n",
      "Train Epoch: 0 [512/14860 (3%)]\tLoss: 2.572276\n",
      "Train Epoch: 0 [640/14860 (4%)]\tLoss: 2.079280\n",
      "Train Epoch: 0 [768/14860 (5%)]\tLoss: 1.007213\n",
      "Train Epoch: 0 [896/14860 (6%)]\tLoss: 0.422501\n",
      "Train Epoch: 0 [1024/14860 (7%)]\tLoss: 0.159765\n",
      "Train Epoch: 0 [1152/14860 (8%)]\tLoss: 0.095183\n",
      "Train Epoch: 0 [1280/14860 (9%)]\tLoss: 0.056042\n",
      "Train Epoch: 0 [1408/14860 (9%)]\tLoss: 0.052542\n",
      "Train Epoch: 0 [1536/14860 (10%)]\tLoss: 0.048829\n",
      "Train Epoch: 0 [1664/14860 (11%)]\tLoss: 0.062779\n",
      "Train Epoch: 0 [1792/14860 (12%)]\tLoss: 0.072793\n",
      "Train Epoch: 0 [1920/14860 (13%)]\tLoss: 0.076439\n",
      "Train Epoch: 0 [2048/14860 (14%)]\tLoss: 0.078212\n",
      "Train Epoch: 0 [2176/14860 (15%)]\tLoss: 0.072852\n",
      "Train Epoch: 0 [2304/14860 (15%)]\tLoss: 0.065903\n",
      "Train Epoch: 0 [2432/14860 (16%)]\tLoss: 0.070104\n",
      "Train Epoch: 0 [2560/14860 (17%)]\tLoss: 0.062824\n",
      "Train Epoch: 0 [2688/14860 (18%)]\tLoss: 0.058588\n",
      "Train Epoch: 0 [2816/14860 (19%)]\tLoss: 0.058200\n",
      "Train Epoch: 0 [2944/14860 (20%)]\tLoss: 0.051209\n",
      "Train Epoch: 0 [3072/14860 (21%)]\tLoss: 0.057893\n",
      "Train Epoch: 0 [3200/14860 (21%)]\tLoss: 0.060435\n",
      "Train Epoch: 0 [3328/14860 (22%)]\tLoss: 0.054010\n",
      "Train Epoch: 0 [3456/14860 (23%)]\tLoss: 0.051743\n",
      "Train Epoch: 0 [3584/14860 (24%)]\tLoss: 0.034007\n",
      "Train Epoch: 0 [3712/14860 (25%)]\tLoss: 0.048772\n",
      "Train Epoch: 0 [3840/14860 (26%)]\tLoss: 0.045705\n",
      "Train Epoch: 0 [3968/14860 (26%)]\tLoss: 0.056439\n",
      "Train Epoch: 0 [4096/14860 (27%)]\tLoss: 0.060637\n",
      "Train Epoch: 0 [4224/14860 (28%)]\tLoss: 0.056345\n",
      "Train Epoch: 0 [4352/14860 (29%)]\tLoss: 0.074010\n",
      "Train Epoch: 0 [4480/14860 (30%)]\tLoss: 0.035010\n",
      "Train Epoch: 0 [4608/14860 (31%)]\tLoss: 0.064276\n",
      "Train Epoch: 0 [4736/14860 (32%)]\tLoss: 0.047619\n",
      "Train Epoch: 0 [4864/14860 (32%)]\tLoss: 0.055219\n",
      "Train Epoch: 0 [4992/14860 (33%)]\tLoss: 0.043844\n",
      "Train Epoch: 0 [5120/14860 (34%)]\tLoss: 0.047459\n",
      "Train Epoch: 0 [5248/14860 (35%)]\tLoss: 0.043910\n",
      "Train Epoch: 0 [5376/14860 (36%)]\tLoss: 0.051998\n",
      "Train Epoch: 0 [5504/14860 (37%)]\tLoss: 0.051157\n",
      "Train Epoch: 0 [5632/14860 (38%)]\tLoss: 0.047811\n",
      "Train Epoch: 0 [5760/14860 (38%)]\tLoss: 0.062103\n",
      "Train Epoch: 0 [5888/14860 (39%)]\tLoss: 0.052213\n",
      "Train Epoch: 0 [6016/14860 (40%)]\tLoss: 0.057364\n",
      "Train Epoch: 0 [6144/14860 (41%)]\tLoss: 0.055066\n",
      "Train Epoch: 0 [6272/14860 (42%)]\tLoss: 0.069502\n",
      "Train Epoch: 0 [6400/14860 (43%)]\tLoss: 0.053429\n",
      "Train Epoch: 0 [6528/14860 (44%)]\tLoss: 0.039575\n",
      "Train Epoch: 0 [6656/14860 (44%)]\tLoss: 0.057275\n",
      "Train Epoch: 0 [6784/14860 (45%)]\tLoss: 0.049272\n",
      "Train Epoch: 0 [6912/14860 (46%)]\tLoss: 0.054982\n",
      "Train Epoch: 0 [7040/14860 (47%)]\tLoss: 0.052440\n",
      "Train Epoch: 0 [7168/14860 (48%)]\tLoss: 0.054524\n",
      "Train Epoch: 0 [7296/14860 (49%)]\tLoss: 0.051338\n",
      "Train Epoch: 0 [7424/14860 (50%)]\tLoss: 0.051245\n",
      "Train Epoch: 0 [7552/14860 (50%)]\tLoss: 0.051386\n",
      "Train Epoch: 0 [7680/14860 (51%)]\tLoss: 0.057608\n",
      "Train Epoch: 0 [7808/14860 (52%)]\tLoss: 0.053962\n",
      "Train Epoch: 0 [7936/14860 (53%)]\tLoss: 0.050069\n",
      "Train Epoch: 0 [8064/14860 (54%)]\tLoss: 0.053426\n",
      "Train Epoch: 0 [8192/14860 (55%)]\tLoss: 0.045123\n",
      "Train Epoch: 0 [8320/14860 (56%)]\tLoss: 0.061157\n",
      "Train Epoch: 0 [8448/14860 (56%)]\tLoss: 0.048786\n",
      "Train Epoch: 0 [8576/14860 (57%)]\tLoss: 0.054617\n",
      "Train Epoch: 0 [8704/14860 (58%)]\tLoss: 0.051911\n",
      "Train Epoch: 0 [8832/14860 (59%)]\tLoss: 0.043479\n",
      "Train Epoch: 0 [8960/14860 (60%)]\tLoss: 0.048233\n",
      "Train Epoch: 0 [9088/14860 (61%)]\tLoss: 0.055390\n",
      "Train Epoch: 0 [9216/14860 (62%)]\tLoss: 0.062600\n",
      "Train Epoch: 0 [9344/14860 (62%)]\tLoss: 0.043538\n",
      "Train Epoch: 0 [9472/14860 (63%)]\tLoss: 0.047550\n",
      "Train Epoch: 0 [9600/14860 (64%)]\tLoss: 0.051575\n",
      "Train Epoch: 0 [9728/14860 (65%)]\tLoss: 0.048718\n",
      "Train Epoch: 0 [9856/14860 (66%)]\tLoss: 0.045836\n",
      "Train Epoch: 0 [9984/14860 (67%)]\tLoss: 0.039566\n",
      "Train Epoch: 0 [10112/14860 (68%)]\tLoss: 0.056654\n",
      "Train Epoch: 0 [10240/14860 (68%)]\tLoss: 0.050532\n",
      "Train Epoch: 0 [10368/14860 (69%)]\tLoss: 0.049617\n",
      "Train Epoch: 0 [10496/14860 (70%)]\tLoss: 0.047573\n",
      "Train Epoch: 0 [10624/14860 (71%)]\tLoss: 0.060333\n",
      "Train Epoch: 0 [10752/14860 (72%)]\tLoss: 0.047841\n",
      "Train Epoch: 0 [10880/14860 (73%)]\tLoss: 0.043389\n",
      "Train Epoch: 0 [11008/14860 (74%)]\tLoss: 0.049615\n",
      "Train Epoch: 0 [11136/14860 (74%)]\tLoss: 0.063494\n",
      "Train Epoch: 0 [11264/14860 (75%)]\tLoss: 0.041207\n",
      "Train Epoch: 0 [11392/14860 (76%)]\tLoss: 0.055368\n",
      "Train Epoch: 0 [11520/14860 (77%)]\tLoss: 0.045248\n",
      "Train Epoch: 0 [11648/14860 (78%)]\tLoss: 0.060836\n",
      "Train Epoch: 0 [11776/14860 (79%)]\tLoss: 0.032457\n",
      "Train Epoch: 0 [11904/14860 (79%)]\tLoss: 0.049642\n",
      "Train Epoch: 0 [12032/14860 (80%)]\tLoss: 0.039572\n",
      "Train Epoch: 0 [12160/14860 (81%)]\tLoss: 0.058173\n",
      "Train Epoch: 0 [12288/14860 (82%)]\tLoss: 0.041339\n",
      "Train Epoch: 0 [12416/14860 (83%)]\tLoss: 0.043154\n",
      "Train Epoch: 0 [12544/14860 (84%)]\tLoss: 0.037106\n",
      "Train Epoch: 0 [12672/14860 (85%)]\tLoss: 0.042518\n",
      "Train Epoch: 0 [12800/14860 (85%)]\tLoss: 0.053790\n",
      "Train Epoch: 0 [12928/14860 (86%)]\tLoss: 0.047599\n",
      "Train Epoch: 0 [13056/14860 (87%)]\tLoss: 0.042060\n",
      "Train Epoch: 0 [13184/14860 (88%)]\tLoss: 0.038178\n",
      "Train Epoch: 0 [13312/14860 (89%)]\tLoss: 0.050771\n",
      "Train Epoch: 0 [13440/14860 (90%)]\tLoss: 0.059793\n",
      "Train Epoch: 0 [13568/14860 (91%)]\tLoss: 0.032970\n",
      "Train Epoch: 0 [13696/14860 (91%)]\tLoss: 0.048042\n",
      "Train Epoch: 0 [13824/14860 (92%)]\tLoss: 0.049093\n",
      "Train Epoch: 0 [13952/14860 (93%)]\tLoss: 0.038232\n",
      "Train Epoch: 0 [14080/14860 (94%)]\tLoss: 0.050709\n",
      "Train Epoch: 0 [14208/14860 (95%)]\tLoss: 0.041343\n",
      "Train Epoch: 0 [14336/14860 (96%)]\tLoss: 0.050223\n",
      "Train Epoch: 0 [14464/14860 (97%)]\tLoss: 0.043877\n",
      "Train Epoch: 0 [14592/14860 (97%)]\tLoss: 0.031940\n",
      "Train Epoch: 0 [14720/14860 (98%)]\tLoss: 0.047989\n",
      "Train Epoch: 0 [1392/14860 (99%)]\tLoss: 0.021014\n",
      "epoch 0 training loss: 0.1977352280742847\n",
      "epoch 0 validation loss: 0.046540774675604794\n",
      "Train Epoch: 1 [0/14860 (0%)]\tLoss: 0.050074\n",
      "Train Epoch: 1 [128/14860 (1%)]\tLoss: 0.045002\n",
      "Train Epoch: 1 [256/14860 (2%)]\tLoss: 0.053225\n",
      "Train Epoch: 1 [384/14860 (3%)]\tLoss: 0.044026\n",
      "Train Epoch: 1 [512/14860 (3%)]\tLoss: 0.046843\n",
      "Train Epoch: 1 [640/14860 (4%)]\tLoss: 0.051254\n",
      "Train Epoch: 1 [768/14860 (5%)]\tLoss: 0.054934\n",
      "Train Epoch: 1 [896/14860 (6%)]\tLoss: 0.051788\n",
      "Train Epoch: 1 [1024/14860 (7%)]\tLoss: 0.042280\n",
      "Train Epoch: 1 [1152/14860 (8%)]\tLoss: 0.046113\n",
      "Train Epoch: 1 [1280/14860 (9%)]\tLoss: 0.039737\n",
      "Train Epoch: 1 [1408/14860 (9%)]\tLoss: 0.044610\n",
      "Train Epoch: 1 [1536/14860 (10%)]\tLoss: 0.049584\n",
      "Train Epoch: 1 [1664/14860 (11%)]\tLoss: 0.043540\n",
      "Train Epoch: 1 [1792/14860 (12%)]\tLoss: 0.047657\n",
      "Train Epoch: 1 [1920/14860 (13%)]\tLoss: 0.054386\n",
      "Train Epoch: 1 [2048/14860 (14%)]\tLoss: 0.057678\n",
      "Train Epoch: 1 [2176/14860 (15%)]\tLoss: 0.047756\n",
      "Train Epoch: 1 [2304/14860 (15%)]\tLoss: 0.036891\n",
      "Train Epoch: 1 [2432/14860 (16%)]\tLoss: 0.042063\n",
      "Train Epoch: 1 [2560/14860 (17%)]\tLoss: 0.035937\n",
      "Train Epoch: 1 [2688/14860 (18%)]\tLoss: 0.027059\n",
      "Train Epoch: 1 [2816/14860 (19%)]\tLoss: 0.039587\n",
      "Train Epoch: 1 [2944/14860 (20%)]\tLoss: 0.046967\n",
      "Train Epoch: 1 [3072/14860 (21%)]\tLoss: 0.047873\n",
      "Train Epoch: 1 [3200/14860 (21%)]\tLoss: 0.042702\n",
      "Train Epoch: 1 [3328/14860 (22%)]\tLoss: 0.046339\n",
      "Train Epoch: 1 [3456/14860 (23%)]\tLoss: 0.053882\n",
      "Train Epoch: 1 [3584/14860 (24%)]\tLoss: 0.039970\n",
      "Train Epoch: 1 [3712/14860 (25%)]\tLoss: 0.053719\n",
      "Train Epoch: 1 [3840/14860 (26%)]\tLoss: 0.053745\n",
      "Train Epoch: 1 [3968/14860 (26%)]\tLoss: 0.047067\n",
      "Train Epoch: 1 [4096/14860 (27%)]\tLoss: 0.052077\n",
      "Train Epoch: 1 [4224/14860 (28%)]\tLoss: 0.044311\n",
      "Train Epoch: 1 [4352/14860 (29%)]\tLoss: 0.043207\n",
      "Train Epoch: 1 [4480/14860 (30%)]\tLoss: 0.053772\n",
      "Train Epoch: 1 [4608/14860 (31%)]\tLoss: 0.048266\n",
      "Train Epoch: 1 [4736/14860 (32%)]\tLoss: 0.040604\n",
      "Train Epoch: 1 [4864/14860 (32%)]\tLoss: 0.041782\n",
      "Train Epoch: 1 [4992/14860 (33%)]\tLoss: 0.037305\n",
      "Train Epoch: 1 [5120/14860 (34%)]\tLoss: 0.039582\n",
      "Train Epoch: 1 [5248/14860 (35%)]\tLoss: 0.042728\n",
      "Train Epoch: 1 [5376/14860 (36%)]\tLoss: 0.048093\n",
      "Train Epoch: 1 [5504/14860 (37%)]\tLoss: 0.039142\n",
      "Train Epoch: 1 [5632/14860 (38%)]\tLoss: 0.041908\n",
      "Train Epoch: 1 [5760/14860 (38%)]\tLoss: 0.042671\n",
      "Train Epoch: 1 [5888/14860 (39%)]\tLoss: 0.037843\n",
      "Train Epoch: 1 [6016/14860 (40%)]\tLoss: 0.042611\n",
      "Train Epoch: 1 [6144/14860 (41%)]\tLoss: 0.047978\n",
      "Train Epoch: 1 [6272/14860 (42%)]\tLoss: 0.046644\n",
      "Train Epoch: 1 [6400/14860 (43%)]\tLoss: 0.039337\n",
      "Train Epoch: 1 [6528/14860 (44%)]\tLoss: 0.042598\n",
      "Train Epoch: 1 [6656/14860 (44%)]\tLoss: 0.038497\n",
      "Train Epoch: 1 [6784/14860 (45%)]\tLoss: 0.031985\n",
      "Train Epoch: 1 [6912/14860 (46%)]\tLoss: 0.045475\n",
      "Train Epoch: 1 [7040/14860 (47%)]\tLoss: 0.039608\n",
      "Train Epoch: 1 [7168/14860 (48%)]\tLoss: 0.047246\n",
      "Train Epoch: 1 [7296/14860 (49%)]\tLoss: 0.040731\n",
      "Train Epoch: 1 [7424/14860 (50%)]\tLoss: 0.036631\n",
      "Train Epoch: 1 [7552/14860 (50%)]\tLoss: 0.062326\n",
      "Train Epoch: 1 [7680/14860 (51%)]\tLoss: 0.045628\n",
      "Train Epoch: 1 [7808/14860 (52%)]\tLoss: 0.037913\n",
      "Train Epoch: 1 [7936/14860 (53%)]\tLoss: 0.037750\n",
      "Train Epoch: 1 [8064/14860 (54%)]\tLoss: 0.039731\n",
      "Train Epoch: 1 [8192/14860 (55%)]\tLoss: 0.042381\n",
      "Train Epoch: 1 [8320/14860 (56%)]\tLoss: 0.033229\n",
      "Train Epoch: 1 [8448/14860 (56%)]\tLoss: 0.026573\n",
      "Train Epoch: 1 [8576/14860 (57%)]\tLoss: 0.041930\n",
      "Train Epoch: 1 [8704/14860 (58%)]\tLoss: 0.050548\n",
      "Train Epoch: 1 [8832/14860 (59%)]\tLoss: 0.036251\n",
      "Train Epoch: 1 [8960/14860 (60%)]\tLoss: 0.043456\n",
      "Train Epoch: 1 [9088/14860 (61%)]\tLoss: 0.034984\n",
      "Train Epoch: 1 [9216/14860 (62%)]\tLoss: 0.040435\n",
      "Train Epoch: 1 [9344/14860 (62%)]\tLoss: 0.039854\n",
      "Train Epoch: 1 [9472/14860 (63%)]\tLoss: 0.042066\n",
      "Train Epoch: 1 [9600/14860 (64%)]\tLoss: 0.045824\n",
      "Train Epoch: 1 [9728/14860 (65%)]\tLoss: 0.041583\n",
      "Train Epoch: 1 [9856/14860 (66%)]\tLoss: 0.046484\n",
      "Train Epoch: 1 [9984/14860 (67%)]\tLoss: 0.057965\n",
      "Train Epoch: 1 [10112/14860 (68%)]\tLoss: 0.031075\n",
      "Train Epoch: 1 [10240/14860 (68%)]\tLoss: 0.043188\n",
      "Train Epoch: 1 [10368/14860 (69%)]\tLoss: 0.040762\n",
      "Train Epoch: 1 [10496/14860 (70%)]\tLoss: 0.035457\n",
      "Train Epoch: 1 [10624/14860 (71%)]\tLoss: 0.039084\n",
      "Train Epoch: 1 [10752/14860 (72%)]\tLoss: 0.035946\n",
      "Train Epoch: 1 [10880/14860 (73%)]\tLoss: 0.044792\n",
      "Train Epoch: 1 [11008/14860 (74%)]\tLoss: 0.029709\n",
      "Train Epoch: 1 [11136/14860 (74%)]\tLoss: 0.038233\n",
      "Train Epoch: 1 [11264/14860 (75%)]\tLoss: 0.028422\n",
      "Train Epoch: 1 [11392/14860 (76%)]\tLoss: 0.028161\n",
      "Train Epoch: 1 [11520/14860 (77%)]\tLoss: 0.035087\n",
      "Train Epoch: 1 [11648/14860 (78%)]\tLoss: 0.040131\n",
      "Train Epoch: 1 [11776/14860 (79%)]\tLoss: 0.040962\n",
      "Train Epoch: 1 [11904/14860 (79%)]\tLoss: 0.027586\n",
      "Train Epoch: 1 [12032/14860 (80%)]\tLoss: 0.039586\n",
      "Train Epoch: 1 [12160/14860 (81%)]\tLoss: 0.038949\n",
      "Train Epoch: 1 [12288/14860 (82%)]\tLoss: 0.033832\n",
      "Train Epoch: 1 [12416/14860 (83%)]\tLoss: 0.034520\n",
      "Train Epoch: 1 [12544/14860 (84%)]\tLoss: 0.039761\n",
      "Train Epoch: 1 [12672/14860 (85%)]\tLoss: 0.035291\n",
      "Train Epoch: 1 [12800/14860 (85%)]\tLoss: 0.039066\n",
      "Train Epoch: 1 [12928/14860 (86%)]\tLoss: 0.038102\n",
      "Train Epoch: 1 [13056/14860 (87%)]\tLoss: 0.032118\n",
      "Train Epoch: 1 [13184/14860 (88%)]\tLoss: 0.041431\n",
      "Train Epoch: 1 [13312/14860 (89%)]\tLoss: 0.034312\n",
      "Train Epoch: 1 [13440/14860 (90%)]\tLoss: 0.030778\n",
      "Train Epoch: 1 [13568/14860 (91%)]\tLoss: 0.030345\n",
      "Train Epoch: 1 [13696/14860 (91%)]\tLoss: 0.040242\n",
      "Train Epoch: 1 [13824/14860 (92%)]\tLoss: 0.045934\n",
      "Train Epoch: 1 [13952/14860 (93%)]\tLoss: 0.032527\n",
      "Train Epoch: 1 [14080/14860 (94%)]\tLoss: 0.047677\n",
      "Train Epoch: 1 [14208/14860 (95%)]\tLoss: 0.039462\n",
      "Train Epoch: 1 [14336/14860 (96%)]\tLoss: 0.045992\n",
      "Train Epoch: 1 [14464/14860 (97%)]\tLoss: 0.029855\n",
      "Train Epoch: 1 [14592/14860 (97%)]\tLoss: 0.042388\n",
      "Train Epoch: 1 [14720/14860 (98%)]\tLoss: 0.031789\n",
      "Train Epoch: 1 [1392/14860 (99%)]\tLoss: 0.030718\n",
      "epoch 1 training loss: 0.041684638390429\n",
      "epoch 1 validation loss: 0.038353806546467556\n",
      "Train Epoch: 2 [0/14860 (0%)]\tLoss: 0.037829\n",
      "Train Epoch: 2 [128/14860 (1%)]\tLoss: 0.033141\n",
      "Train Epoch: 2 [256/14860 (2%)]\tLoss: 0.036706\n",
      "Train Epoch: 2 [384/14860 (3%)]\tLoss: 0.052512\n",
      "Train Epoch: 2 [512/14860 (3%)]\tLoss: 0.030549\n",
      "Train Epoch: 2 [640/14860 (4%)]\tLoss: 0.031902\n",
      "Train Epoch: 2 [768/14860 (5%)]\tLoss: 0.026475\n",
      "Train Epoch: 2 [896/14860 (6%)]\tLoss: 0.042097\n",
      "Train Epoch: 2 [1024/14860 (7%)]\tLoss: 0.030421\n",
      "Train Epoch: 2 [1152/14860 (8%)]\tLoss: 0.042016\n",
      "Train Epoch: 2 [1280/14860 (9%)]\tLoss: 0.047483\n",
      "Train Epoch: 2 [1408/14860 (9%)]\tLoss: 0.040599\n",
      "Train Epoch: 2 [1536/14860 (10%)]\tLoss: 0.043512\n",
      "Train Epoch: 2 [1664/14860 (11%)]\tLoss: 0.036033\n",
      "Train Epoch: 2 [1792/14860 (12%)]\tLoss: 0.036316\n",
      "Train Epoch: 2 [1920/14860 (13%)]\tLoss: 0.030124\n",
      "Train Epoch: 2 [2048/14860 (14%)]\tLoss: 0.044856\n",
      "Train Epoch: 2 [2176/14860 (15%)]\tLoss: 0.028723\n",
      "Train Epoch: 2 [2304/14860 (15%)]\tLoss: 0.033346\n",
      "Train Epoch: 2 [2432/14860 (16%)]\tLoss: 0.037800\n",
      "Train Epoch: 2 [2560/14860 (17%)]\tLoss: 0.035405\n",
      "Train Epoch: 2 [2688/14860 (18%)]\tLoss: 0.035658\n",
      "Train Epoch: 2 [2816/14860 (19%)]\tLoss: 0.027497\n",
      "Train Epoch: 2 [2944/14860 (20%)]\tLoss: 0.031267\n",
      "Train Epoch: 2 [3072/14860 (21%)]\tLoss: 0.035368\n",
      "Train Epoch: 2 [3200/14860 (21%)]\tLoss: 0.031196\n",
      "Train Epoch: 2 [3328/14860 (22%)]\tLoss: 0.053824\n",
      "Train Epoch: 2 [3456/14860 (23%)]\tLoss: 0.032091\n",
      "Train Epoch: 2 [3584/14860 (24%)]\tLoss: 0.043994\n",
      "Train Epoch: 2 [3712/14860 (25%)]\tLoss: 0.029304\n",
      "Train Epoch: 2 [3840/14860 (26%)]\tLoss: 0.042765\n",
      "Train Epoch: 2 [3968/14860 (26%)]\tLoss: 0.039289\n",
      "Train Epoch: 2 [4096/14860 (27%)]\tLoss: 0.024939\n",
      "Train Epoch: 2 [4224/14860 (28%)]\tLoss: 0.046231\n",
      "Train Epoch: 2 [4352/14860 (29%)]\tLoss: 0.025309\n",
      "Train Epoch: 2 [4480/14860 (30%)]\tLoss: 0.031341\n",
      "Train Epoch: 2 [4608/14860 (31%)]\tLoss: 0.039343\n",
      "Train Epoch: 2 [4736/14860 (32%)]\tLoss: 0.040037\n",
      "Train Epoch: 2 [4864/14860 (32%)]\tLoss: 0.038094\n",
      "Train Epoch: 2 [4992/14860 (33%)]\tLoss: 0.041924\n",
      "Train Epoch: 2 [5120/14860 (34%)]\tLoss: 0.033341\n",
      "Train Epoch: 2 [5248/14860 (35%)]\tLoss: 0.029218\n",
      "Train Epoch: 2 [5376/14860 (36%)]\tLoss: 0.033367\n",
      "Train Epoch: 2 [5504/14860 (37%)]\tLoss: 0.036907\n",
      "Train Epoch: 2 [5632/14860 (38%)]\tLoss: 0.037080\n",
      "Train Epoch: 2 [5760/14860 (38%)]\tLoss: 0.033652\n",
      "Train Epoch: 2 [5888/14860 (39%)]\tLoss: 0.028146\n",
      "Train Epoch: 2 [6016/14860 (40%)]\tLoss: 0.038883\n",
      "Train Epoch: 2 [6144/14860 (41%)]\tLoss: 0.036491\n",
      "Train Epoch: 2 [6272/14860 (42%)]\tLoss: 0.031899\n",
      "Train Epoch: 2 [6400/14860 (43%)]\tLoss: 0.043443\n",
      "Train Epoch: 2 [6528/14860 (44%)]\tLoss: 0.044235\n",
      "Train Epoch: 2 [6656/14860 (44%)]\tLoss: 0.042950\n",
      "Train Epoch: 2 [6784/14860 (45%)]\tLoss: 0.038267\n",
      "Train Epoch: 2 [6912/14860 (46%)]\tLoss: 0.029736\n",
      "Train Epoch: 2 [7040/14860 (47%)]\tLoss: 0.027916\n",
      "Train Epoch: 2 [7168/14860 (48%)]\tLoss: 0.029660\n",
      "Train Epoch: 2 [7296/14860 (49%)]\tLoss: 0.039668\n",
      "Train Epoch: 2 [7424/14860 (50%)]\tLoss: 0.034310\n",
      "Train Epoch: 2 [7552/14860 (50%)]\tLoss: 0.036204\n",
      "Train Epoch: 2 [7680/14860 (51%)]\tLoss: 0.033236\n",
      "Train Epoch: 2 [7808/14860 (52%)]\tLoss: 0.035523\n",
      "Train Epoch: 2 [7936/14860 (53%)]\tLoss: 0.038804\n",
      "Train Epoch: 2 [8064/14860 (54%)]\tLoss: 0.030399\n",
      "Train Epoch: 2 [8192/14860 (55%)]\tLoss: 0.024625\n",
      "Train Epoch: 2 [8320/14860 (56%)]\tLoss: 0.036872\n",
      "Train Epoch: 2 [8448/14860 (56%)]\tLoss: 0.026012\n",
      "Train Epoch: 2 [8576/14860 (57%)]\tLoss: 0.035486\n",
      "Train Epoch: 2 [8704/14860 (58%)]\tLoss: 0.031989\n",
      "Train Epoch: 2 [8832/14860 (59%)]\tLoss: 0.040033\n",
      "Train Epoch: 2 [8960/14860 (60%)]\tLoss: 0.047890\n",
      "Train Epoch: 2 [9088/14860 (61%)]\tLoss: 0.025218\n",
      "Train Epoch: 2 [9216/14860 (62%)]\tLoss: 0.038913\n",
      "Train Epoch: 2 [9344/14860 (62%)]\tLoss: 0.026129\n",
      "Train Epoch: 2 [9472/14860 (63%)]\tLoss: 0.034041\n",
      "Train Epoch: 2 [9600/14860 (64%)]\tLoss: 0.036878\n",
      "Train Epoch: 2 [9728/14860 (65%)]\tLoss: 0.033864\n",
      "Train Epoch: 2 [9856/14860 (66%)]\tLoss: 0.030927\n",
      "Train Epoch: 2 [9984/14860 (67%)]\tLoss: 0.027520\n",
      "Train Epoch: 2 [10112/14860 (68%)]\tLoss: 0.037156\n",
      "Train Epoch: 2 [10240/14860 (68%)]\tLoss: 0.038421\n",
      "Train Epoch: 2 [10368/14860 (69%)]\tLoss: 0.032657\n",
      "Train Epoch: 2 [10496/14860 (70%)]\tLoss: 0.032434\n",
      "Train Epoch: 2 [10624/14860 (71%)]\tLoss: 0.024990\n",
      "Train Epoch: 2 [10752/14860 (72%)]\tLoss: 0.025637\n",
      "Train Epoch: 2 [10880/14860 (73%)]\tLoss: 0.037604\n",
      "Train Epoch: 2 [11008/14860 (74%)]\tLoss: 0.029672\n",
      "Train Epoch: 2 [11136/14860 (74%)]\tLoss: 0.038712\n",
      "Train Epoch: 2 [11264/14860 (75%)]\tLoss: 0.037794\n",
      "Train Epoch: 2 [11392/14860 (76%)]\tLoss: 0.027946\n",
      "Train Epoch: 2 [11520/14860 (77%)]\tLoss: 0.039102\n",
      "Train Epoch: 2 [11648/14860 (78%)]\tLoss: 0.034948\n",
      "Train Epoch: 2 [11776/14860 (79%)]\tLoss: 0.039660\n",
      "Train Epoch: 2 [11904/14860 (79%)]\tLoss: 0.035551\n",
      "Train Epoch: 2 [12032/14860 (80%)]\tLoss: 0.032757\n",
      "Train Epoch: 2 [12160/14860 (81%)]\tLoss: 0.039052\n",
      "Train Epoch: 2 [12288/14860 (82%)]\tLoss: 0.035836\n",
      "Train Epoch: 2 [12416/14860 (83%)]\tLoss: 0.025848\n",
      "Train Epoch: 2 [12544/14860 (84%)]\tLoss: 0.040886\n",
      "Train Epoch: 2 [12672/14860 (85%)]\tLoss: 0.029520\n",
      "Train Epoch: 2 [12800/14860 (85%)]\tLoss: 0.034221\n",
      "Train Epoch: 2 [12928/14860 (86%)]\tLoss: 0.039042\n",
      "Train Epoch: 2 [13056/14860 (87%)]\tLoss: 0.034150\n",
      "Train Epoch: 2 [13184/14860 (88%)]\tLoss: 0.035309\n",
      "Train Epoch: 2 [13312/14860 (89%)]\tLoss: 0.030307\n",
      "Train Epoch: 2 [13440/14860 (90%)]\tLoss: 0.035957\n",
      "Train Epoch: 2 [13568/14860 (91%)]\tLoss: 0.041164\n",
      "Train Epoch: 2 [13696/14860 (91%)]\tLoss: 0.032769\n",
      "Train Epoch: 2 [13824/14860 (92%)]\tLoss: 0.030650\n",
      "Train Epoch: 2 [13952/14860 (93%)]\tLoss: 0.041543\n",
      "Train Epoch: 2 [14080/14860 (94%)]\tLoss: 0.044390\n",
      "Train Epoch: 2 [14208/14860 (95%)]\tLoss: 0.035208\n",
      "Train Epoch: 2 [14336/14860 (96%)]\tLoss: 0.026746\n",
      "Train Epoch: 2 [14464/14860 (97%)]\tLoss: 0.032426\n",
      "Train Epoch: 2 [14592/14860 (97%)]\tLoss: 0.026231\n",
      "Train Epoch: 2 [14720/14860 (98%)]\tLoss: 0.031314\n",
      "Train Epoch: 2 [1392/14860 (99%)]\tLoss: 0.019496\n",
      "epoch 2 training loss: 0.03499276544421147\n",
      "epoch 2 validation loss: 0.03345830085491153\n",
      "Train Epoch: 3 [0/14860 (0%)]\tLoss: 0.031021\n",
      "Train Epoch: 3 [128/14860 (1%)]\tLoss: 0.028534\n",
      "Train Epoch: 3 [256/14860 (2%)]\tLoss: 0.022858\n",
      "Train Epoch: 3 [384/14860 (3%)]\tLoss: 0.040474\n",
      "Train Epoch: 3 [512/14860 (3%)]\tLoss: 0.031875\n",
      "Train Epoch: 3 [640/14860 (4%)]\tLoss: 0.035165\n",
      "Train Epoch: 3 [768/14860 (5%)]\tLoss: 0.028106\n",
      "Train Epoch: 3 [896/14860 (6%)]\tLoss: 0.029827\n",
      "Train Epoch: 3 [1024/14860 (7%)]\tLoss: 0.041311\n",
      "Train Epoch: 3 [1152/14860 (8%)]\tLoss: 0.029916\n",
      "Train Epoch: 3 [1280/14860 (9%)]\tLoss: 0.036149\n",
      "Train Epoch: 3 [1408/14860 (9%)]\tLoss: 0.028648\n",
      "Train Epoch: 3 [1536/14860 (10%)]\tLoss: 0.035843\n",
      "Train Epoch: 3 [1664/14860 (11%)]\tLoss: 0.027953\n",
      "Train Epoch: 3 [1792/14860 (12%)]\tLoss: 0.036784\n",
      "Train Epoch: 3 [1920/14860 (13%)]\tLoss: 0.035358\n",
      "Train Epoch: 3 [2048/14860 (14%)]\tLoss: 0.033970\n",
      "Train Epoch: 3 [2176/14860 (15%)]\tLoss: 0.037416\n",
      "Train Epoch: 3 [2304/14860 (15%)]\tLoss: 0.031396\n",
      "Train Epoch: 3 [2432/14860 (16%)]\tLoss: 0.034419\n",
      "Train Epoch: 3 [2560/14860 (17%)]\tLoss: 0.027519\n",
      "Train Epoch: 3 [2688/14860 (18%)]\tLoss: 0.028358\n",
      "Train Epoch: 3 [2816/14860 (19%)]\tLoss: 0.028440\n",
      "Train Epoch: 3 [2944/14860 (20%)]\tLoss: 0.035594\n",
      "Train Epoch: 3 [3072/14860 (21%)]\tLoss: 0.034433\n",
      "Train Epoch: 3 [3200/14860 (21%)]\tLoss: 0.030289\n",
      "Train Epoch: 3 [3328/14860 (22%)]\tLoss: 0.035386\n",
      "Train Epoch: 3 [3456/14860 (23%)]\tLoss: 0.022712\n",
      "Train Epoch: 3 [3584/14860 (24%)]\tLoss: 0.032877\n",
      "Train Epoch: 3 [3712/14860 (25%)]\tLoss: 0.028977\n",
      "Train Epoch: 3 [3840/14860 (26%)]\tLoss: 0.041339\n",
      "Train Epoch: 3 [3968/14860 (26%)]\tLoss: 0.031178\n",
      "Train Epoch: 3 [4096/14860 (27%)]\tLoss: 0.033586\n",
      "Train Epoch: 3 [4224/14860 (28%)]\tLoss: 0.023066\n",
      "Train Epoch: 3 [4352/14860 (29%)]\tLoss: 0.021227\n",
      "Train Epoch: 3 [4480/14860 (30%)]\tLoss: 0.026187\n",
      "Train Epoch: 3 [4608/14860 (31%)]\tLoss: 0.030481\n",
      "Train Epoch: 3 [4736/14860 (32%)]\tLoss: 0.036196\n",
      "Train Epoch: 3 [4864/14860 (32%)]\tLoss: 0.037309\n",
      "Train Epoch: 3 [4992/14860 (33%)]\tLoss: 0.033234\n",
      "Train Epoch: 3 [5120/14860 (34%)]\tLoss: 0.032019\n",
      "Train Epoch: 3 [5248/14860 (35%)]\tLoss: 0.030924\n",
      "Train Epoch: 3 [5376/14860 (36%)]\tLoss: 0.033826\n",
      "Train Epoch: 3 [5504/14860 (37%)]\tLoss: 0.032387\n",
      "Train Epoch: 3 [5632/14860 (38%)]\tLoss: 0.027888\n",
      "Train Epoch: 3 [5760/14860 (38%)]\tLoss: 0.034309\n",
      "Train Epoch: 3 [5888/14860 (39%)]\tLoss: 0.030051\n",
      "Train Epoch: 3 [6016/14860 (40%)]\tLoss: 0.025261\n",
      "Train Epoch: 3 [6144/14860 (41%)]\tLoss: 0.029647\n",
      "Train Epoch: 3 [6272/14860 (42%)]\tLoss: 0.024730\n",
      "Train Epoch: 3 [6400/14860 (43%)]\tLoss: 0.032515\n",
      "Train Epoch: 3 [6528/14860 (44%)]\tLoss: 0.040449\n",
      "Train Epoch: 3 [6656/14860 (44%)]\tLoss: 0.035021\n",
      "Train Epoch: 3 [6784/14860 (45%)]\tLoss: 0.025344\n",
      "Train Epoch: 3 [6912/14860 (46%)]\tLoss: 0.040252\n",
      "Train Epoch: 3 [7040/14860 (47%)]\tLoss: 0.042719\n",
      "Train Epoch: 3 [7168/14860 (48%)]\tLoss: 0.030948\n",
      "Train Epoch: 3 [7296/14860 (49%)]\tLoss: 0.033182\n",
      "Train Epoch: 3 [7424/14860 (50%)]\tLoss: 0.029266\n",
      "Train Epoch: 3 [7552/14860 (50%)]\tLoss: 0.036289\n",
      "Train Epoch: 3 [7680/14860 (51%)]\tLoss: 0.025775\n",
      "Train Epoch: 3 [7808/14860 (52%)]\tLoss: 0.026301\n",
      "Train Epoch: 3 [7936/14860 (53%)]\tLoss: 0.034671\n",
      "Train Epoch: 3 [8064/14860 (54%)]\tLoss: 0.019575\n",
      "Train Epoch: 3 [8192/14860 (55%)]\tLoss: 0.021971\n",
      "Train Epoch: 3 [8320/14860 (56%)]\tLoss: 0.031983\n",
      "Train Epoch: 3 [8448/14860 (56%)]\tLoss: 0.026448\n",
      "Train Epoch: 3 [8576/14860 (57%)]\tLoss: 0.029896\n",
      "Train Epoch: 3 [8704/14860 (58%)]\tLoss: 0.029285\n",
      "Train Epoch: 3 [8832/14860 (59%)]\tLoss: 0.027231\n",
      "Train Epoch: 3 [8960/14860 (60%)]\tLoss: 0.030813\n",
      "Train Epoch: 3 [9088/14860 (61%)]\tLoss: 0.034058\n",
      "Train Epoch: 3 [9216/14860 (62%)]\tLoss: 0.028425\n",
      "Train Epoch: 3 [9344/14860 (62%)]\tLoss: 0.026493\n",
      "Train Epoch: 3 [9472/14860 (63%)]\tLoss: 0.020788\n",
      "Train Epoch: 3 [9600/14860 (64%)]\tLoss: 0.024712\n",
      "Train Epoch: 3 [9728/14860 (65%)]\tLoss: 0.027756\n",
      "Train Epoch: 3 [9856/14860 (66%)]\tLoss: 0.026670\n",
      "Train Epoch: 3 [9984/14860 (67%)]\tLoss: 0.031576\n",
      "Train Epoch: 3 [10112/14860 (68%)]\tLoss: 0.032735\n",
      "Train Epoch: 3 [10240/14860 (68%)]\tLoss: 0.032745\n",
      "Train Epoch: 3 [10368/14860 (69%)]\tLoss: 0.025553\n",
      "Train Epoch: 3 [10496/14860 (70%)]\tLoss: 0.027826\n",
      "Train Epoch: 3 [10624/14860 (71%)]\tLoss: 0.037194\n",
      "Train Epoch: 3 [10752/14860 (72%)]\tLoss: 0.027847\n",
      "Train Epoch: 3 [10880/14860 (73%)]\tLoss: 0.031700\n",
      "Train Epoch: 3 [11008/14860 (74%)]\tLoss: 0.026771\n",
      "Train Epoch: 3 [11136/14860 (74%)]\tLoss: 0.023238\n",
      "Train Epoch: 3 [11264/14860 (75%)]\tLoss: 0.024427\n",
      "Train Epoch: 3 [11392/14860 (76%)]\tLoss: 0.028790\n",
      "Train Epoch: 3 [11520/14860 (77%)]\tLoss: 0.030577\n",
      "Train Epoch: 3 [11648/14860 (78%)]\tLoss: 0.027827\n",
      "Train Epoch: 3 [11776/14860 (79%)]\tLoss: 0.024972\n",
      "Train Epoch: 3 [11904/14860 (79%)]\tLoss: 0.028786\n",
      "Train Epoch: 3 [12032/14860 (80%)]\tLoss: 0.024077\n",
      "Train Epoch: 3 [12160/14860 (81%)]\tLoss: 0.024498\n",
      "Train Epoch: 3 [12288/14860 (82%)]\tLoss: 0.014679\n",
      "Train Epoch: 3 [12416/14860 (83%)]\tLoss: 0.021718\n",
      "Train Epoch: 3 [12544/14860 (84%)]\tLoss: 0.025914\n",
      "Train Epoch: 3 [12672/14860 (85%)]\tLoss: 0.031361\n",
      "Train Epoch: 3 [12800/14860 (85%)]\tLoss: 0.023961\n",
      "Train Epoch: 3 [12928/14860 (86%)]\tLoss: 0.024969\n",
      "Train Epoch: 3 [13056/14860 (87%)]\tLoss: 0.031227\n",
      "Train Epoch: 3 [13184/14860 (88%)]\tLoss: 0.032858\n",
      "Train Epoch: 3 [13312/14860 (89%)]\tLoss: 0.023078\n",
      "Train Epoch: 3 [13440/14860 (90%)]\tLoss: 0.022274\n",
      "Train Epoch: 3 [13568/14860 (91%)]\tLoss: 0.028357\n",
      "Train Epoch: 3 [13696/14860 (91%)]\tLoss: 0.028635\n",
      "Train Epoch: 3 [13824/14860 (92%)]\tLoss: 0.020379\n",
      "Train Epoch: 3 [13952/14860 (93%)]\tLoss: 0.024046\n",
      "Train Epoch: 3 [14080/14860 (94%)]\tLoss: 0.016494\n",
      "Train Epoch: 3 [14208/14860 (95%)]\tLoss: 0.026548\n",
      "Train Epoch: 3 [14336/14860 (96%)]\tLoss: 0.021235\n",
      "Train Epoch: 3 [14464/14860 (97%)]\tLoss: 0.024553\n",
      "Train Epoch: 3 [14592/14860 (97%)]\tLoss: 0.025542\n",
      "Train Epoch: 3 [14720/14860 (98%)]\tLoss: 0.029283\n",
      "Train Epoch: 3 [1392/14860 (99%)]\tLoss: 0.010737\n",
      "epoch 3 training loss: 0.02935278793780977\n",
      "epoch 3 validation loss: 0.02717389133882869\n",
      "Train Epoch: 4 [0/14860 (0%)]\tLoss: 0.028225\n",
      "Train Epoch: 4 [128/14860 (1%)]\tLoss: 0.025871\n",
      "Train Epoch: 4 [256/14860 (2%)]\tLoss: 0.024752\n",
      "Train Epoch: 4 [384/14860 (3%)]\tLoss: 0.032108\n",
      "Train Epoch: 4 [512/14860 (3%)]\tLoss: 0.017354\n",
      "Train Epoch: 4 [640/14860 (4%)]\tLoss: 0.023267\n",
      "Train Epoch: 4 [768/14860 (5%)]\tLoss: 0.027241\n",
      "Train Epoch: 4 [896/14860 (6%)]\tLoss: 0.021894\n",
      "Train Epoch: 4 [1024/14860 (7%)]\tLoss: 0.036477\n",
      "Train Epoch: 4 [1152/14860 (8%)]\tLoss: 0.028012\n",
      "Train Epoch: 4 [1280/14860 (9%)]\tLoss: 0.024785\n",
      "Train Epoch: 4 [1408/14860 (9%)]\tLoss: 0.023534\n",
      "Train Epoch: 4 [1536/14860 (10%)]\tLoss: 0.019914\n",
      "Train Epoch: 4 [1664/14860 (11%)]\tLoss: 0.030221\n",
      "Train Epoch: 4 [1792/14860 (12%)]\tLoss: 0.022358\n",
      "Train Epoch: 4 [1920/14860 (13%)]\tLoss: 0.019128\n",
      "Train Epoch: 4 [2048/14860 (14%)]\tLoss: 0.019229\n",
      "Train Epoch: 4 [2176/14860 (15%)]\tLoss: 0.030801\n",
      "Train Epoch: 4 [2304/14860 (15%)]\tLoss: 0.023817\n",
      "Train Epoch: 4 [2432/14860 (16%)]\tLoss: 0.020526\n",
      "Train Epoch: 4 [2560/14860 (17%)]\tLoss: 0.019446\n",
      "Train Epoch: 4 [2688/14860 (18%)]\tLoss: 0.014211\n",
      "Train Epoch: 4 [2816/14860 (19%)]\tLoss: 0.026605\n",
      "Train Epoch: 4 [2944/14860 (20%)]\tLoss: 0.020314\n",
      "Train Epoch: 4 [3072/14860 (21%)]\tLoss: 0.022112\n",
      "Train Epoch: 4 [3200/14860 (21%)]\tLoss: 0.020385\n",
      "Train Epoch: 4 [3328/14860 (22%)]\tLoss: 0.027732\n",
      "Train Epoch: 4 [3456/14860 (23%)]\tLoss: 0.021079\n",
      "Train Epoch: 4 [3584/14860 (24%)]\tLoss: 0.023501\n",
      "Train Epoch: 4 [3712/14860 (25%)]\tLoss: 0.029729\n",
      "Train Epoch: 4 [3840/14860 (26%)]\tLoss: 0.027473\n",
      "Train Epoch: 4 [3968/14860 (26%)]\tLoss: 0.027366\n",
      "Train Epoch: 4 [4096/14860 (27%)]\tLoss: 0.023987\n",
      "Train Epoch: 4 [4224/14860 (28%)]\tLoss: 0.019915\n",
      "Train Epoch: 4 [4352/14860 (29%)]\tLoss: 0.024841\n",
      "Train Epoch: 4 [4480/14860 (30%)]\tLoss: 0.027064\n",
      "Train Epoch: 4 [4608/14860 (31%)]\tLoss: 0.019260\n",
      "Train Epoch: 4 [4736/14860 (32%)]\tLoss: 0.026099\n",
      "Train Epoch: 4 [4864/14860 (32%)]\tLoss: 0.026924\n",
      "Train Epoch: 4 [4992/14860 (33%)]\tLoss: 0.024406\n",
      "Train Epoch: 4 [5120/14860 (34%)]\tLoss: 0.026688\n",
      "Train Epoch: 4 [5248/14860 (35%)]\tLoss: 0.022653\n",
      "Train Epoch: 4 [5376/14860 (36%)]\tLoss: 0.016122\n",
      "Train Epoch: 4 [5504/14860 (37%)]\tLoss: 0.015990\n",
      "Train Epoch: 4 [5632/14860 (38%)]\tLoss: 0.020424\n",
      "Train Epoch: 4 [5760/14860 (38%)]\tLoss: 0.015909\n",
      "Train Epoch: 4 [5888/14860 (39%)]\tLoss: 0.014881\n",
      "Train Epoch: 4 [6016/14860 (40%)]\tLoss: 0.024181\n",
      "Train Epoch: 4 [6144/14860 (41%)]\tLoss: 0.018780\n",
      "Train Epoch: 4 [6272/14860 (42%)]\tLoss: 0.024830\n",
      "Train Epoch: 4 [6400/14860 (43%)]\tLoss: 0.015956\n",
      "Train Epoch: 4 [6528/14860 (44%)]\tLoss: 0.017979\n",
      "Train Epoch: 4 [6656/14860 (44%)]\tLoss: 0.030393\n",
      "Train Epoch: 4 [6784/14860 (45%)]\tLoss: 0.020877\n",
      "Train Epoch: 4 [6912/14860 (46%)]\tLoss: 0.020582\n",
      "Train Epoch: 4 [7040/14860 (47%)]\tLoss: 0.028557\n",
      "Train Epoch: 4 [7168/14860 (48%)]\tLoss: 0.023800\n",
      "Train Epoch: 4 [7296/14860 (49%)]\tLoss: 0.023040\n",
      "Train Epoch: 4 [7424/14860 (50%)]\tLoss: 0.019275\n",
      "Train Epoch: 4 [7552/14860 (50%)]\tLoss: 0.018461\n",
      "Train Epoch: 4 [7680/14860 (51%)]\tLoss: 0.016374\n",
      "Train Epoch: 4 [7808/14860 (52%)]\tLoss: 0.020385\n",
      "Train Epoch: 4 [7936/14860 (53%)]\tLoss: 0.021184\n",
      "Train Epoch: 4 [8064/14860 (54%)]\tLoss: 0.016970\n",
      "Train Epoch: 4 [8192/14860 (55%)]\tLoss: 0.028776\n",
      "Train Epoch: 4 [8320/14860 (56%)]\tLoss: 0.017554\n",
      "Train Epoch: 4 [8448/14860 (56%)]\tLoss: 0.019457\n",
      "Train Epoch: 4 [8576/14860 (57%)]\tLoss: 0.020774\n",
      "Train Epoch: 4 [8704/14860 (58%)]\tLoss: 0.026359\n",
      "Train Epoch: 4 [8832/14860 (59%)]\tLoss: 0.020767\n",
      "Train Epoch: 4 [8960/14860 (60%)]\tLoss: 0.026156\n",
      "Train Epoch: 4 [9088/14860 (61%)]\tLoss: 0.023128\n",
      "Train Epoch: 4 [9216/14860 (62%)]\tLoss: 0.019390\n",
      "Train Epoch: 4 [9344/14860 (62%)]\tLoss: 0.020755\n",
      "Train Epoch: 4 [9472/14860 (63%)]\tLoss: 0.021375\n",
      "Train Epoch: 4 [9600/14860 (64%)]\tLoss: 0.015931\n",
      "Train Epoch: 4 [9728/14860 (65%)]\tLoss: 0.018180\n",
      "Train Epoch: 4 [9856/14860 (66%)]\tLoss: 0.016744\n",
      "Train Epoch: 4 [9984/14860 (67%)]\tLoss: 0.022252\n",
      "Train Epoch: 4 [10112/14860 (68%)]\tLoss: 0.017881\n",
      "Train Epoch: 4 [10240/14860 (68%)]\tLoss: 0.019481\n",
      "Train Epoch: 4 [10368/14860 (69%)]\tLoss: 0.013967\n",
      "Train Epoch: 4 [10496/14860 (70%)]\tLoss: 0.016962\n",
      "Train Epoch: 4 [10624/14860 (71%)]\tLoss: 0.028981\n",
      "Train Epoch: 4 [10752/14860 (72%)]\tLoss: 0.024936\n",
      "Train Epoch: 4 [10880/14860 (73%)]\tLoss: 0.020515\n",
      "Train Epoch: 4 [11008/14860 (74%)]\tLoss: 0.016300\n",
      "Train Epoch: 4 [11136/14860 (74%)]\tLoss: 0.020382\n",
      "Train Epoch: 4 [11264/14860 (75%)]\tLoss: 0.014982\n",
      "Train Epoch: 4 [11392/14860 (76%)]\tLoss: 0.023513\n",
      "Train Epoch: 4 [11520/14860 (77%)]\tLoss: 0.018175\n",
      "Train Epoch: 4 [11648/14860 (78%)]\tLoss: 0.019892\n",
      "Train Epoch: 4 [11776/14860 (79%)]\tLoss: 0.020225\n",
      "Train Epoch: 4 [11904/14860 (79%)]\tLoss: 0.022969\n",
      "Train Epoch: 4 [12032/14860 (80%)]\tLoss: 0.027251\n",
      "Train Epoch: 4 [12160/14860 (81%)]\tLoss: 0.027527\n",
      "Train Epoch: 4 [12288/14860 (82%)]\tLoss: 0.020837\n",
      "Train Epoch: 4 [12416/14860 (83%)]\tLoss: 0.021919\n",
      "Train Epoch: 4 [12544/14860 (84%)]\tLoss: 0.022197\n",
      "Train Epoch: 4 [12672/14860 (85%)]\tLoss: 0.026341\n",
      "Train Epoch: 4 [12800/14860 (85%)]\tLoss: 0.027023\n",
      "Train Epoch: 4 [12928/14860 (86%)]\tLoss: 0.022965\n",
      "Train Epoch: 4 [13056/14860 (87%)]\tLoss: 0.028608\n",
      "Train Epoch: 4 [13184/14860 (88%)]\tLoss: 0.017586\n",
      "Train Epoch: 4 [13312/14860 (89%)]\tLoss: 0.021249\n",
      "Train Epoch: 4 [13440/14860 (90%)]\tLoss: 0.025413\n",
      "Train Epoch: 4 [13568/14860 (91%)]\tLoss: 0.028609\n",
      "Train Epoch: 4 [13696/14860 (91%)]\tLoss: 0.019264\n",
      "Train Epoch: 4 [13824/14860 (92%)]\tLoss: 0.015363\n",
      "Train Epoch: 4 [13952/14860 (93%)]\tLoss: 0.013520\n",
      "Train Epoch: 4 [14080/14860 (94%)]\tLoss: 0.017005\n",
      "Train Epoch: 4 [14208/14860 (95%)]\tLoss: 0.025485\n",
      "Train Epoch: 4 [14336/14860 (96%)]\tLoss: 0.022677\n",
      "Train Epoch: 4 [14464/14860 (97%)]\tLoss: 0.025438\n",
      "Train Epoch: 4 [14592/14860 (97%)]\tLoss: 0.028660\n",
      "Train Epoch: 4 [14720/14860 (98%)]\tLoss: 0.024925\n",
      "Train Epoch: 4 [1392/14860 (99%)]\tLoss: 0.018847\n",
      "epoch 4 training loss: 0.02232240478739015\n",
      "epoch 4 validation loss: 0.023717758441952758\n",
      "Train Epoch: 5 [0/14860 (0%)]\tLoss: 0.018747\n",
      "Train Epoch: 5 [128/14860 (1%)]\tLoss: 0.018798\n",
      "Train Epoch: 5 [256/14860 (2%)]\tLoss: 0.019360\n",
      "Train Epoch: 5 [384/14860 (3%)]\tLoss: 0.023157\n",
      "Train Epoch: 5 [512/14860 (3%)]\tLoss: 0.033350\n",
      "Train Epoch: 5 [640/14860 (4%)]\tLoss: 0.018916\n",
      "Train Epoch: 5 [768/14860 (5%)]\tLoss: 0.026060\n",
      "Train Epoch: 5 [896/14860 (6%)]\tLoss: 0.021453\n",
      "Train Epoch: 5 [1024/14860 (7%)]\tLoss: 0.015324\n",
      "Train Epoch: 5 [1152/14860 (8%)]\tLoss: 0.021319\n",
      "Train Epoch: 5 [1280/14860 (9%)]\tLoss: 0.022066\n",
      "Train Epoch: 5 [1408/14860 (9%)]\tLoss: 0.023780\n",
      "Train Epoch: 5 [1536/14860 (10%)]\tLoss: 0.018249\n",
      "Train Epoch: 5 [1664/14860 (11%)]\tLoss: 0.023984\n",
      "Train Epoch: 5 [1792/14860 (12%)]\tLoss: 0.025072\n",
      "Train Epoch: 5 [1920/14860 (13%)]\tLoss: 0.024546\n",
      "Train Epoch: 5 [2048/14860 (14%)]\tLoss: 0.019660\n",
      "Train Epoch: 5 [2176/14860 (15%)]\tLoss: 0.016457\n",
      "Train Epoch: 5 [2304/14860 (15%)]\tLoss: 0.018625\n",
      "Train Epoch: 5 [2432/14860 (16%)]\tLoss: 0.017566\n",
      "Train Epoch: 5 [2560/14860 (17%)]\tLoss: 0.022455\n",
      "Train Epoch: 5 [2688/14860 (18%)]\tLoss: 0.021301\n",
      "Train Epoch: 5 [2816/14860 (19%)]\tLoss: 0.021896\n",
      "Train Epoch: 5 [2944/14860 (20%)]\tLoss: 0.026558\n",
      "Train Epoch: 5 [3072/14860 (21%)]\tLoss: 0.023713\n",
      "Train Epoch: 5 [3200/14860 (21%)]\tLoss: 0.017801\n",
      "Train Epoch: 5 [3328/14860 (22%)]\tLoss: 0.022914\n",
      "Train Epoch: 5 [3456/14860 (23%)]\tLoss: 0.020588\n",
      "Train Epoch: 5 [3584/14860 (24%)]\tLoss: 0.022423\n",
      "Train Epoch: 5 [3712/14860 (25%)]\tLoss: 0.016257\n",
      "Train Epoch: 5 [3840/14860 (26%)]\tLoss: 0.022149\n",
      "Train Epoch: 5 [3968/14860 (26%)]\tLoss: 0.017136\n",
      "Train Epoch: 5 [4096/14860 (27%)]\tLoss: 0.021365\n",
      "Train Epoch: 5 [4224/14860 (28%)]\tLoss: 0.027588\n",
      "Train Epoch: 5 [4352/14860 (29%)]\tLoss: 0.013291\n",
      "Train Epoch: 5 [4480/14860 (30%)]\tLoss: 0.020280\n",
      "Train Epoch: 5 [4608/14860 (31%)]\tLoss: 0.021668\n",
      "Train Epoch: 5 [4736/14860 (32%)]\tLoss: 0.020457\n",
      "Train Epoch: 5 [4864/14860 (32%)]\tLoss: 0.028960\n",
      "Train Epoch: 5 [4992/14860 (33%)]\tLoss: 0.017787\n",
      "Train Epoch: 5 [5120/14860 (34%)]\tLoss: 0.012744\n",
      "Train Epoch: 5 [5248/14860 (35%)]\tLoss: 0.025533\n",
      "Train Epoch: 5 [5376/14860 (36%)]\tLoss: 0.017921\n",
      "Train Epoch: 5 [5504/14860 (37%)]\tLoss: 0.026315\n",
      "Train Epoch: 5 [5632/14860 (38%)]\tLoss: 0.018753\n",
      "Train Epoch: 5 [5760/14860 (38%)]\tLoss: 0.017507\n",
      "Train Epoch: 5 [5888/14860 (39%)]\tLoss: 0.021973\n",
      "Train Epoch: 5 [6016/14860 (40%)]\tLoss: 0.023783\n",
      "Train Epoch: 5 [6144/14860 (41%)]\tLoss: 0.017006\n",
      "Train Epoch: 5 [6272/14860 (42%)]\tLoss: 0.019565\n",
      "Train Epoch: 5 [6400/14860 (43%)]\tLoss: 0.018307\n",
      "Train Epoch: 5 [6528/14860 (44%)]\tLoss: 0.020913\n",
      "Train Epoch: 5 [6656/14860 (44%)]\tLoss: 0.018452\n",
      "Train Epoch: 5 [6784/14860 (45%)]\tLoss: 0.022011\n",
      "Train Epoch: 5 [6912/14860 (46%)]\tLoss: 0.017143\n",
      "Train Epoch: 5 [7040/14860 (47%)]\tLoss: 0.017466\n",
      "Train Epoch: 5 [7168/14860 (48%)]\tLoss: 0.020437\n",
      "Train Epoch: 5 [7296/14860 (49%)]\tLoss: 0.026190\n",
      "Train Epoch: 5 [7424/14860 (50%)]\tLoss: 0.022489\n",
      "Train Epoch: 5 [7552/14860 (50%)]\tLoss: 0.024572\n",
      "Train Epoch: 5 [7680/14860 (51%)]\tLoss: 0.020752\n",
      "Train Epoch: 5 [7808/14860 (52%)]\tLoss: 0.021598\n",
      "Train Epoch: 5 [7936/14860 (53%)]\tLoss: 0.030079\n",
      "Train Epoch: 5 [8064/14860 (54%)]\tLoss: 0.013506\n",
      "Train Epoch: 5 [8192/14860 (55%)]\tLoss: 0.021045\n",
      "Train Epoch: 5 [8320/14860 (56%)]\tLoss: 0.019201\n",
      "Train Epoch: 5 [8448/14860 (56%)]\tLoss: 0.022436\n",
      "Train Epoch: 5 [8576/14860 (57%)]\tLoss: 0.025440\n",
      "Train Epoch: 5 [8704/14860 (58%)]\tLoss: 0.016857\n",
      "Train Epoch: 5 [8832/14860 (59%)]\tLoss: 0.020565\n",
      "Train Epoch: 5 [8960/14860 (60%)]\tLoss: 0.015777\n",
      "Train Epoch: 5 [9088/14860 (61%)]\tLoss: 0.017154\n",
      "Train Epoch: 5 [9216/14860 (62%)]\tLoss: 0.021936\n",
      "Train Epoch: 5 [9344/14860 (62%)]\tLoss: 0.029740\n",
      "Train Epoch: 5 [9472/14860 (63%)]\tLoss: 0.016830\n",
      "Train Epoch: 5 [9600/14860 (64%)]\tLoss: 0.021108\n",
      "Train Epoch: 5 [9728/14860 (65%)]\tLoss: 0.019929\n",
      "Train Epoch: 5 [9856/14860 (66%)]\tLoss: 0.020711\n",
      "Train Epoch: 5 [9984/14860 (67%)]\tLoss: 0.019226\n",
      "Train Epoch: 5 [10112/14860 (68%)]\tLoss: 0.027384\n",
      "Train Epoch: 5 [10240/14860 (68%)]\tLoss: 0.017006\n",
      "Train Epoch: 5 [10368/14860 (69%)]\tLoss: 0.029754\n",
      "Train Epoch: 5 [10496/14860 (70%)]\tLoss: 0.018032\n",
      "Train Epoch: 5 [10624/14860 (71%)]\tLoss: 0.020479\n",
      "Train Epoch: 5 [10752/14860 (72%)]\tLoss: 0.022234\n",
      "Train Epoch: 5 [10880/14860 (73%)]\tLoss: 0.017559\n",
      "Train Epoch: 5 [11008/14860 (74%)]\tLoss: 0.022317\n",
      "Train Epoch: 5 [11136/14860 (74%)]\tLoss: 0.018763\n",
      "Train Epoch: 5 [11264/14860 (75%)]\tLoss: 0.016458\n",
      "Train Epoch: 5 [11392/14860 (76%)]\tLoss: 0.022710\n",
      "Train Epoch: 5 [11520/14860 (77%)]\tLoss: 0.028283\n",
      "Train Epoch: 5 [11648/14860 (78%)]\tLoss: 0.021048\n",
      "Train Epoch: 5 [11776/14860 (79%)]\tLoss: 0.026984\n",
      "Train Epoch: 5 [11904/14860 (79%)]\tLoss: 0.018503\n",
      "Train Epoch: 5 [12032/14860 (80%)]\tLoss: 0.020913\n",
      "Train Epoch: 5 [12160/14860 (81%)]\tLoss: 0.021896\n",
      "Train Epoch: 5 [12288/14860 (82%)]\tLoss: 0.018980\n",
      "Train Epoch: 5 [12416/14860 (83%)]\tLoss: 0.019723\n",
      "Train Epoch: 5 [12544/14860 (84%)]\tLoss: 0.021111\n",
      "Train Epoch: 5 [12672/14860 (85%)]\tLoss: 0.021445\n",
      "Train Epoch: 5 [12800/14860 (85%)]\tLoss: 0.022308\n",
      "Train Epoch: 5 [12928/14860 (86%)]\tLoss: 0.020083\n",
      "Train Epoch: 5 [13056/14860 (87%)]\tLoss: 0.021217\n",
      "Train Epoch: 5 [13184/14860 (88%)]\tLoss: 0.019930\n",
      "Train Epoch: 5 [13312/14860 (89%)]\tLoss: 0.021796\n",
      "Train Epoch: 5 [13440/14860 (90%)]\tLoss: 0.019519\n",
      "Train Epoch: 5 [13568/14860 (91%)]\tLoss: 0.021623\n",
      "Train Epoch: 5 [13696/14860 (91%)]\tLoss: 0.026677\n",
      "Train Epoch: 5 [13824/14860 (92%)]\tLoss: 0.020944\n",
      "Train Epoch: 5 [13952/14860 (93%)]\tLoss: 0.019620\n",
      "Train Epoch: 5 [14080/14860 (94%)]\tLoss: 0.018684\n",
      "Train Epoch: 5 [14208/14860 (95%)]\tLoss: 0.020151\n",
      "Train Epoch: 5 [14336/14860 (96%)]\tLoss: 0.017032\n",
      "Train Epoch: 5 [14464/14860 (97%)]\tLoss: 0.019499\n",
      "Train Epoch: 5 [14592/14860 (97%)]\tLoss: 0.023842\n",
      "Train Epoch: 5 [14720/14860 (98%)]\tLoss: 0.022135\n",
      "Train Epoch: 5 [1392/14860 (99%)]\tLoss: 0.057249\n",
      "epoch 5 training loss: 0.021367006083456878\n",
      "epoch 5 validation loss: 0.0227044817899099\n",
      "Train Epoch: 6 [0/14860 (0%)]\tLoss: 0.021862\n",
      "Train Epoch: 6 [128/14860 (1%)]\tLoss: 0.021803\n",
      "Train Epoch: 6 [256/14860 (2%)]\tLoss: 0.024602\n",
      "Train Epoch: 6 [384/14860 (3%)]\tLoss: 0.018699\n",
      "Train Epoch: 6 [512/14860 (3%)]\tLoss: 0.022606\n",
      "Train Epoch: 6 [640/14860 (4%)]\tLoss: 0.017638\n",
      "Train Epoch: 6 [768/14860 (5%)]\tLoss: 0.021678\n",
      "Train Epoch: 6 [896/14860 (6%)]\tLoss: 0.020430\n",
      "Train Epoch: 6 [1024/14860 (7%)]\tLoss: 0.014680\n",
      "Train Epoch: 6 [1152/14860 (8%)]\tLoss: 0.030806\n",
      "Train Epoch: 6 [1280/14860 (9%)]\tLoss: 0.020142\n",
      "Train Epoch: 6 [1408/14860 (9%)]\tLoss: 0.014270\n",
      "Train Epoch: 6 [1536/14860 (10%)]\tLoss: 0.021474\n",
      "Train Epoch: 6 [1664/14860 (11%)]\tLoss: 0.018271\n",
      "Train Epoch: 6 [1792/14860 (12%)]\tLoss: 0.016758\n",
      "Train Epoch: 6 [1920/14860 (13%)]\tLoss: 0.019320\n",
      "Train Epoch: 6 [2048/14860 (14%)]\tLoss: 0.020316\n",
      "Train Epoch: 6 [2176/14860 (15%)]\tLoss: 0.015909\n",
      "Train Epoch: 6 [2304/14860 (15%)]\tLoss: 0.013890\n",
      "Train Epoch: 6 [2432/14860 (16%)]\tLoss: 0.028924\n",
      "Train Epoch: 6 [2560/14860 (17%)]\tLoss: 0.027772\n",
      "Train Epoch: 6 [2688/14860 (18%)]\tLoss: 0.021814\n",
      "Train Epoch: 6 [2816/14860 (19%)]\tLoss: 0.030663\n",
      "Train Epoch: 6 [2944/14860 (20%)]\tLoss: 0.023977\n",
      "Train Epoch: 6 [3072/14860 (21%)]\tLoss: 0.021622\n",
      "Train Epoch: 6 [3200/14860 (21%)]\tLoss: 0.017783\n",
      "Train Epoch: 6 [3328/14860 (22%)]\tLoss: 0.019073\n",
      "Train Epoch: 6 [3456/14860 (23%)]\tLoss: 0.022687\n",
      "Train Epoch: 6 [3584/14860 (24%)]\tLoss: 0.023075\n",
      "Train Epoch: 6 [3712/14860 (25%)]\tLoss: 0.025128\n",
      "Train Epoch: 6 [3840/14860 (26%)]\tLoss: 0.017281\n",
      "Train Epoch: 6 [3968/14860 (26%)]\tLoss: 0.024121\n",
      "Train Epoch: 6 [4096/14860 (27%)]\tLoss: 0.018916\n",
      "Train Epoch: 6 [4224/14860 (28%)]\tLoss: 0.021089\n",
      "Train Epoch: 6 [4352/14860 (29%)]\tLoss: 0.021577\n",
      "Train Epoch: 6 [4480/14860 (30%)]\tLoss: 0.017966\n",
      "Train Epoch: 6 [4608/14860 (31%)]\tLoss: 0.015708\n",
      "Train Epoch: 6 [4736/14860 (32%)]\tLoss: 0.016045\n",
      "Train Epoch: 6 [4864/14860 (32%)]\tLoss: 0.022347\n",
      "Train Epoch: 6 [4992/14860 (33%)]\tLoss: 0.025208\n",
      "Train Epoch: 6 [5120/14860 (34%)]\tLoss: 0.018373\n",
      "Train Epoch: 6 [5248/14860 (35%)]\tLoss: 0.018049\n",
      "Train Epoch: 6 [5376/14860 (36%)]\tLoss: 0.028318\n",
      "Train Epoch: 6 [5504/14860 (37%)]\tLoss: 0.020352\n",
      "Train Epoch: 6 [5632/14860 (38%)]\tLoss: 0.027536\n",
      "Train Epoch: 6 [5760/14860 (38%)]\tLoss: 0.021048\n",
      "Train Epoch: 6 [5888/14860 (39%)]\tLoss: 0.020910\n",
      "Train Epoch: 6 [6016/14860 (40%)]\tLoss: 0.018593\n",
      "Train Epoch: 6 [6144/14860 (41%)]\tLoss: 0.017571\n",
      "Train Epoch: 6 [6272/14860 (42%)]\tLoss: 0.024712\n",
      "Train Epoch: 6 [6400/14860 (43%)]\tLoss: 0.020151\n",
      "Train Epoch: 6 [6528/14860 (44%)]\tLoss: 0.021194\n",
      "Train Epoch: 6 [6656/14860 (44%)]\tLoss: 0.022761\n",
      "Train Epoch: 6 [6784/14860 (45%)]\tLoss: 0.014714\n",
      "Train Epoch: 6 [6912/14860 (46%)]\tLoss: 0.018577\n",
      "Train Epoch: 6 [7040/14860 (47%)]\tLoss: 0.018657\n",
      "Train Epoch: 6 [7168/14860 (48%)]\tLoss: 0.023993\n",
      "Train Epoch: 6 [7296/14860 (49%)]\tLoss: 0.024544\n",
      "Train Epoch: 6 [7424/14860 (50%)]\tLoss: 0.017245\n",
      "Train Epoch: 6 [7552/14860 (50%)]\tLoss: 0.014850\n",
      "Train Epoch: 6 [7680/14860 (51%)]\tLoss: 0.017331\n",
      "Train Epoch: 6 [7808/14860 (52%)]\tLoss: 0.017708\n",
      "Train Epoch: 6 [7936/14860 (53%)]\tLoss: 0.021297\n",
      "Train Epoch: 6 [8064/14860 (54%)]\tLoss: 0.025086\n",
      "Train Epoch: 6 [8192/14860 (55%)]\tLoss: 0.022367\n",
      "Train Epoch: 6 [8320/14860 (56%)]\tLoss: 0.027437\n",
      "Train Epoch: 6 [8448/14860 (56%)]\tLoss: 0.022828\n",
      "Train Epoch: 6 [8576/14860 (57%)]\tLoss: 0.022368\n",
      "Train Epoch: 6 [8704/14860 (58%)]\tLoss: 0.013583\n",
      "Train Epoch: 6 [8832/14860 (59%)]\tLoss: 0.021942\n",
      "Train Epoch: 6 [8960/14860 (60%)]\tLoss: 0.023785\n",
      "Train Epoch: 6 [9088/14860 (61%)]\tLoss: 0.022548\n",
      "Train Epoch: 6 [9216/14860 (62%)]\tLoss: 0.018359\n",
      "Train Epoch: 6 [9344/14860 (62%)]\tLoss: 0.022692\n",
      "Train Epoch: 6 [9472/14860 (63%)]\tLoss: 0.015658\n",
      "Train Epoch: 6 [9600/14860 (64%)]\tLoss: 0.013697\n",
      "Train Epoch: 6 [9728/14860 (65%)]\tLoss: 0.024719\n",
      "Train Epoch: 6 [9856/14860 (66%)]\tLoss: 0.027779\n",
      "Train Epoch: 6 [9984/14860 (67%)]\tLoss: 0.021618\n",
      "Train Epoch: 6 [10112/14860 (68%)]\tLoss: 0.027156\n",
      "Train Epoch: 6 [10240/14860 (68%)]\tLoss: 0.023283\n",
      "Train Epoch: 6 [10368/14860 (69%)]\tLoss: 0.022419\n",
      "Train Epoch: 6 [10496/14860 (70%)]\tLoss: 0.015829\n",
      "Train Epoch: 6 [10624/14860 (71%)]\tLoss: 0.014022\n",
      "Train Epoch: 6 [10752/14860 (72%)]\tLoss: 0.024515\n",
      "Train Epoch: 6 [10880/14860 (73%)]\tLoss: 0.016805\n",
      "Train Epoch: 6 [11008/14860 (74%)]\tLoss: 0.022477\n",
      "Train Epoch: 6 [11136/14860 (74%)]\tLoss: 0.024750\n",
      "Train Epoch: 6 [11264/14860 (75%)]\tLoss: 0.022359\n",
      "Train Epoch: 6 [11392/14860 (76%)]\tLoss: 0.021489\n",
      "Train Epoch: 6 [11520/14860 (77%)]\tLoss: 0.026667\n",
      "Train Epoch: 6 [11648/14860 (78%)]\tLoss: 0.020396\n",
      "Train Epoch: 6 [11776/14860 (79%)]\tLoss: 0.024179\n",
      "Train Epoch: 6 [11904/14860 (79%)]\tLoss: 0.031582\n",
      "Train Epoch: 6 [12032/14860 (80%)]\tLoss: 0.019535\n",
      "Train Epoch: 6 [12160/14860 (81%)]\tLoss: 0.022622\n",
      "Train Epoch: 6 [12288/14860 (82%)]\tLoss: 0.024217\n",
      "Train Epoch: 6 [12416/14860 (83%)]\tLoss: 0.021483\n",
      "Train Epoch: 6 [12544/14860 (84%)]\tLoss: 0.024284\n",
      "Train Epoch: 6 [12672/14860 (85%)]\tLoss: 0.022707\n",
      "Train Epoch: 6 [12800/14860 (85%)]\tLoss: 0.016400\n",
      "Train Epoch: 6 [12928/14860 (86%)]\tLoss: 0.021100\n",
      "Train Epoch: 6 [13056/14860 (87%)]\tLoss: 0.019078\n",
      "Train Epoch: 6 [13184/14860 (88%)]\tLoss: 0.019057\n",
      "Train Epoch: 6 [13312/14860 (89%)]\tLoss: 0.017288\n",
      "Train Epoch: 6 [13440/14860 (90%)]\tLoss: 0.018505\n",
      "Train Epoch: 6 [13568/14860 (91%)]\tLoss: 0.020448\n",
      "Train Epoch: 6 [13696/14860 (91%)]\tLoss: 0.021343\n",
      "Train Epoch: 6 [13824/14860 (92%)]\tLoss: 0.017906\n",
      "Train Epoch: 6 [13952/14860 (93%)]\tLoss: 0.021050\n",
      "Train Epoch: 6 [14080/14860 (94%)]\tLoss: 0.016963\n",
      "Train Epoch: 6 [14208/14860 (95%)]\tLoss: 0.025068\n",
      "Train Epoch: 6 [14336/14860 (96%)]\tLoss: 0.017951\n",
      "Train Epoch: 6 [14464/14860 (97%)]\tLoss: 0.023562\n",
      "Train Epoch: 6 [14592/14860 (97%)]\tLoss: 0.021297\n",
      "Train Epoch: 6 [14720/14860 (98%)]\tLoss: 0.018991\n",
      "Train Epoch: 6 [1392/14860 (99%)]\tLoss: 0.006963\n",
      "epoch 6 training loss: 0.020928445773629043\n",
      "epoch 6 validation loss: 0.021794955609208445\n",
      "Train Epoch: 7 [0/14860 (0%)]\tLoss: 0.021665\n",
      "Train Epoch: 7 [128/14860 (1%)]\tLoss: 0.027822\n",
      "Train Epoch: 7 [256/14860 (2%)]\tLoss: 0.019091\n",
      "Train Epoch: 7 [384/14860 (3%)]\tLoss: 0.024037\n",
      "Train Epoch: 7 [512/14860 (3%)]\tLoss: 0.021206\n",
      "Train Epoch: 7 [640/14860 (4%)]\tLoss: 0.022297\n",
      "Train Epoch: 7 [768/14860 (5%)]\tLoss: 0.019505\n",
      "Train Epoch: 7 [896/14860 (6%)]\tLoss: 0.019238\n",
      "Train Epoch: 7 [1024/14860 (7%)]\tLoss: 0.019203\n",
      "Train Epoch: 7 [1152/14860 (8%)]\tLoss: 0.014320\n",
      "Train Epoch: 7 [1280/14860 (9%)]\tLoss: 0.020500\n",
      "Train Epoch: 7 [1408/14860 (9%)]\tLoss: 0.021259\n",
      "Train Epoch: 7 [1536/14860 (10%)]\tLoss: 0.019566\n",
      "Train Epoch: 7 [1664/14860 (11%)]\tLoss: 0.024261\n",
      "Train Epoch: 7 [1792/14860 (12%)]\tLoss: 0.016153\n",
      "Train Epoch: 7 [1920/14860 (13%)]\tLoss: 0.018409\n",
      "Train Epoch: 7 [2048/14860 (14%)]\tLoss: 0.012258\n",
      "Train Epoch: 7 [2176/14860 (15%)]\tLoss: 0.023475\n",
      "Train Epoch: 7 [2304/14860 (15%)]\tLoss: 0.020952\n",
      "Train Epoch: 7 [2432/14860 (16%)]\tLoss: 0.019810\n",
      "Train Epoch: 7 [2560/14860 (17%)]\tLoss: 0.018734\n",
      "Train Epoch: 7 [2688/14860 (18%)]\tLoss: 0.022914\n",
      "Train Epoch: 7 [2816/14860 (19%)]\tLoss: 0.019665\n",
      "Train Epoch: 7 [2944/14860 (20%)]\tLoss: 0.022239\n",
      "Train Epoch: 7 [3072/14860 (21%)]\tLoss: 0.019987\n",
      "Train Epoch: 7 [3200/14860 (21%)]\tLoss: 0.017218\n",
      "Train Epoch: 7 [3328/14860 (22%)]\tLoss: 0.020865\n",
      "Train Epoch: 7 [3456/14860 (23%)]\tLoss: 0.017642\n",
      "Train Epoch: 7 [3584/14860 (24%)]\tLoss: 0.020456\n",
      "Train Epoch: 7 [3712/14860 (25%)]\tLoss: 0.016030\n",
      "Train Epoch: 7 [3840/14860 (26%)]\tLoss: 0.027356\n",
      "Train Epoch: 7 [3968/14860 (26%)]\tLoss: 0.016541\n",
      "Train Epoch: 7 [4096/14860 (27%)]\tLoss: 0.023782\n",
      "Train Epoch: 7 [4224/14860 (28%)]\tLoss: 0.018100\n",
      "Train Epoch: 7 [4352/14860 (29%)]\tLoss: 0.018218\n",
      "Train Epoch: 7 [4480/14860 (30%)]\tLoss: 0.024719\n",
      "Train Epoch: 7 [4608/14860 (31%)]\tLoss: 0.019501\n",
      "Train Epoch: 7 [4736/14860 (32%)]\tLoss: 0.020099\n",
      "Train Epoch: 7 [4864/14860 (32%)]\tLoss: 0.019519\n",
      "Train Epoch: 7 [4992/14860 (33%)]\tLoss: 0.021115\n",
      "Train Epoch: 7 [5120/14860 (34%)]\tLoss: 0.021872\n",
      "Train Epoch: 7 [5248/14860 (35%)]\tLoss: 0.019010\n",
      "Train Epoch: 7 [5376/14860 (36%)]\tLoss: 0.018186\n",
      "Train Epoch: 7 [5504/14860 (37%)]\tLoss: 0.022026\n",
      "Train Epoch: 7 [5632/14860 (38%)]\tLoss: 0.019711\n",
      "Train Epoch: 7 [5760/14860 (38%)]\tLoss: 0.029018\n",
      "Train Epoch: 7 [5888/14860 (39%)]\tLoss: 0.023137\n",
      "Train Epoch: 7 [6016/14860 (40%)]\tLoss: 0.020242\n",
      "Train Epoch: 7 [6144/14860 (41%)]\tLoss: 0.015694\n",
      "Train Epoch: 7 [6272/14860 (42%)]\tLoss: 0.030035\n",
      "Train Epoch: 7 [6400/14860 (43%)]\tLoss: 0.019035\n",
      "Train Epoch: 7 [6528/14860 (44%)]\tLoss: 0.019994\n",
      "Train Epoch: 7 [6656/14860 (44%)]\tLoss: 0.020591\n",
      "Train Epoch: 7 [6784/14860 (45%)]\tLoss: 0.019092\n",
      "Train Epoch: 7 [6912/14860 (46%)]\tLoss: 0.027094\n",
      "Train Epoch: 7 [7040/14860 (47%)]\tLoss: 0.014241\n",
      "Train Epoch: 7 [7168/14860 (48%)]\tLoss: 0.020663\n",
      "Train Epoch: 7 [7296/14860 (49%)]\tLoss: 0.014061\n",
      "Train Epoch: 7 [7424/14860 (50%)]\tLoss: 0.028444\n",
      "Train Epoch: 7 [7552/14860 (50%)]\tLoss: 0.016756\n",
      "Train Epoch: 7 [7680/14860 (51%)]\tLoss: 0.020857\n",
      "Train Epoch: 7 [7808/14860 (52%)]\tLoss: 0.023053\n",
      "Train Epoch: 7 [7936/14860 (53%)]\tLoss: 0.019253\n",
      "Train Epoch: 7 [8064/14860 (54%)]\tLoss: 0.020480\n",
      "Train Epoch: 7 [8192/14860 (55%)]\tLoss: 0.022564\n",
      "Train Epoch: 7 [8320/14860 (56%)]\tLoss: 0.023899\n",
      "Train Epoch: 7 [8448/14860 (56%)]\tLoss: 0.023558\n",
      "Train Epoch: 7 [8576/14860 (57%)]\tLoss: 0.018649\n",
      "Train Epoch: 7 [8704/14860 (58%)]\tLoss: 0.020628\n",
      "Train Epoch: 7 [8832/14860 (59%)]\tLoss: 0.019539\n",
      "Train Epoch: 7 [8960/14860 (60%)]\tLoss: 0.024037\n",
      "Train Epoch: 7 [9088/14860 (61%)]\tLoss: 0.020322\n",
      "Train Epoch: 7 [9216/14860 (62%)]\tLoss: 0.018381\n",
      "Train Epoch: 7 [9344/14860 (62%)]\tLoss: 0.017131\n",
      "Train Epoch: 7 [9472/14860 (63%)]\tLoss: 0.020583\n",
      "Train Epoch: 7 [9600/14860 (64%)]\tLoss: 0.021605\n",
      "Train Epoch: 7 [9728/14860 (65%)]\tLoss: 0.023061\n",
      "Train Epoch: 7 [9856/14860 (66%)]\tLoss: 0.019160\n",
      "Train Epoch: 7 [9984/14860 (67%)]\tLoss: 0.015350\n",
      "Train Epoch: 7 [10112/14860 (68%)]\tLoss: 0.025774\n",
      "Train Epoch: 7 [10240/14860 (68%)]\tLoss: 0.025541\n",
      "Train Epoch: 7 [10368/14860 (69%)]\tLoss: 0.027390\n",
      "Train Epoch: 7 [10496/14860 (70%)]\tLoss: 0.022019\n",
      "Train Epoch: 7 [10624/14860 (71%)]\tLoss: 0.022908\n",
      "Train Epoch: 7 [10752/14860 (72%)]\tLoss: 0.020031\n",
      "Train Epoch: 7 [10880/14860 (73%)]\tLoss: 0.017991\n",
      "Train Epoch: 7 [11008/14860 (74%)]\tLoss: 0.017785\n",
      "Train Epoch: 7 [11136/14860 (74%)]\tLoss: 0.016451\n",
      "Train Epoch: 7 [11264/14860 (75%)]\tLoss: 0.025290\n",
      "Train Epoch: 7 [11392/14860 (76%)]\tLoss: 0.024305\n",
      "Train Epoch: 7 [11520/14860 (77%)]\tLoss: 0.028252\n",
      "Train Epoch: 7 [11648/14860 (78%)]\tLoss: 0.023802\n",
      "Train Epoch: 7 [11776/14860 (79%)]\tLoss: 0.026148\n",
      "Train Epoch: 7 [11904/14860 (79%)]\tLoss: 0.030236\n",
      "Train Epoch: 7 [12032/14860 (80%)]\tLoss: 0.021112\n",
      "Train Epoch: 7 [12160/14860 (81%)]\tLoss: 0.016348\n",
      "Train Epoch: 7 [12288/14860 (82%)]\tLoss: 0.018886\n",
      "Train Epoch: 7 [12416/14860 (83%)]\tLoss: 0.016013\n",
      "Train Epoch: 7 [12544/14860 (84%)]\tLoss: 0.017858\n",
      "Train Epoch: 7 [12672/14860 (85%)]\tLoss: 0.017353\n",
      "Train Epoch: 7 [12800/14860 (85%)]\tLoss: 0.015441\n",
      "Train Epoch: 7 [12928/14860 (86%)]\tLoss: 0.019984\n",
      "Train Epoch: 7 [13056/14860 (87%)]\tLoss: 0.018796\n",
      "Train Epoch: 7 [13184/14860 (88%)]\tLoss: 0.020420\n",
      "Train Epoch: 7 [13312/14860 (89%)]\tLoss: 0.018485\n",
      "Train Epoch: 7 [13440/14860 (90%)]\tLoss: 0.021753\n",
      "Train Epoch: 7 [13568/14860 (91%)]\tLoss: 0.013543\n",
      "Train Epoch: 7 [13696/14860 (91%)]\tLoss: 0.018110\n",
      "Train Epoch: 7 [13824/14860 (92%)]\tLoss: 0.024855\n",
      "Train Epoch: 7 [13952/14860 (93%)]\tLoss: 0.026313\n",
      "Train Epoch: 7 [14080/14860 (94%)]\tLoss: 0.017399\n",
      "Train Epoch: 7 [14208/14860 (95%)]\tLoss: 0.019516\n",
      "Train Epoch: 7 [14336/14860 (96%)]\tLoss: 0.015893\n",
      "Train Epoch: 7 [14464/14860 (97%)]\tLoss: 0.020770\n",
      "Train Epoch: 7 [14592/14860 (97%)]\tLoss: 0.021545\n",
      "Train Epoch: 7 [14720/14860 (98%)]\tLoss: 0.015679\n",
      "Train Epoch: 7 [1392/14860 (99%)]\tLoss: 0.055742\n",
      "epoch 7 training loss: 0.020910062198328156\n",
      "epoch 7 validation loss: 0.029093057999599357\n",
      "Train Epoch: 8 [0/14860 (0%)]\tLoss: 0.035978\n",
      "Train Epoch: 8 [128/14860 (1%)]\tLoss: 0.014603\n",
      "Train Epoch: 8 [256/14860 (2%)]\tLoss: 0.029047\n",
      "Train Epoch: 8 [384/14860 (3%)]\tLoss: 0.021671\n",
      "Train Epoch: 8 [512/14860 (3%)]\tLoss: 0.016116\n",
      "Train Epoch: 8 [640/14860 (4%)]\tLoss: 0.021503\n",
      "Train Epoch: 8 [768/14860 (5%)]\tLoss: 0.029522\n",
      "Train Epoch: 8 [896/14860 (6%)]\tLoss: 0.025740\n",
      "Train Epoch: 8 [1024/14860 (7%)]\tLoss: 0.022380\n",
      "Train Epoch: 8 [1152/14860 (8%)]\tLoss: 0.033387\n",
      "Train Epoch: 8 [1280/14860 (9%)]\tLoss: 0.023769\n",
      "Train Epoch: 8 [1408/14860 (9%)]\tLoss: 0.023154\n",
      "Train Epoch: 8 [1536/14860 (10%)]\tLoss: 0.024828\n",
      "Train Epoch: 8 [1664/14860 (11%)]\tLoss: 0.021188\n",
      "Train Epoch: 8 [1792/14860 (12%)]\tLoss: 0.020122\n",
      "Train Epoch: 8 [1920/14860 (13%)]\tLoss: 0.015478\n",
      "Train Epoch: 8 [2048/14860 (14%)]\tLoss: 0.018564\n",
      "Train Epoch: 8 [2176/14860 (15%)]\tLoss: 0.014777\n",
      "Train Epoch: 8 [2304/14860 (15%)]\tLoss: 0.025713\n",
      "Train Epoch: 8 [2432/14860 (16%)]\tLoss: 0.012815\n",
      "Train Epoch: 8 [2560/14860 (17%)]\tLoss: 0.026687\n",
      "Train Epoch: 8 [2688/14860 (18%)]\tLoss: 0.023174\n",
      "Train Epoch: 8 [2816/14860 (19%)]\tLoss: 0.018726\n",
      "Train Epoch: 8 [2944/14860 (20%)]\tLoss: 0.018755\n",
      "Train Epoch: 8 [3072/14860 (21%)]\tLoss: 0.023474\n",
      "Train Epoch: 8 [3200/14860 (21%)]\tLoss: 0.015642\n",
      "Train Epoch: 8 [3328/14860 (22%)]\tLoss: 0.020886\n",
      "Train Epoch: 8 [3456/14860 (23%)]\tLoss: 0.026879\n",
      "Train Epoch: 8 [3584/14860 (24%)]\tLoss: 0.018780\n",
      "Train Epoch: 8 [3712/14860 (25%)]\tLoss: 0.016265\n",
      "Train Epoch: 8 [3840/14860 (26%)]\tLoss: 0.019276\n",
      "Train Epoch: 8 [3968/14860 (26%)]\tLoss: 0.019283\n",
      "Train Epoch: 8 [4096/14860 (27%)]\tLoss: 0.016461\n",
      "Train Epoch: 8 [4224/14860 (28%)]\tLoss: 0.018546\n",
      "Train Epoch: 8 [4352/14860 (29%)]\tLoss: 0.023252\n",
      "Train Epoch: 8 [4480/14860 (30%)]\tLoss: 0.017223\n",
      "Train Epoch: 8 [4608/14860 (31%)]\tLoss: 0.018380\n",
      "Train Epoch: 8 [4736/14860 (32%)]\tLoss: 0.018704\n",
      "Train Epoch: 8 [4864/14860 (32%)]\tLoss: 0.024226\n",
      "Train Epoch: 8 [4992/14860 (33%)]\tLoss: 0.029659\n",
      "Train Epoch: 8 [5120/14860 (34%)]\tLoss: 0.015886\n",
      "Train Epoch: 8 [5248/14860 (35%)]\tLoss: 0.014779\n",
      "Train Epoch: 8 [5376/14860 (36%)]\tLoss: 0.013559\n",
      "Train Epoch: 8 [5504/14860 (37%)]\tLoss: 0.019010\n",
      "Train Epoch: 8 [5632/14860 (38%)]\tLoss: 0.015495\n",
      "Train Epoch: 8 [5760/14860 (38%)]\tLoss: 0.021826\n",
      "Train Epoch: 8 [5888/14860 (39%)]\tLoss: 0.016229\n",
      "Train Epoch: 8 [6016/14860 (40%)]\tLoss: 0.014642\n",
      "Train Epoch: 8 [6144/14860 (41%)]\tLoss: 0.016697\n",
      "Train Epoch: 8 [6272/14860 (42%)]\tLoss: 0.016585\n",
      "Train Epoch: 8 [6400/14860 (43%)]\tLoss: 0.018005\n",
      "Train Epoch: 8 [6528/14860 (44%)]\tLoss: 0.019797\n",
      "Train Epoch: 8 [6656/14860 (44%)]\tLoss: 0.013908\n",
      "Train Epoch: 8 [6784/14860 (45%)]\tLoss: 0.021092\n",
      "Train Epoch: 8 [6912/14860 (46%)]\tLoss: 0.021042\n",
      "Train Epoch: 8 [7040/14860 (47%)]\tLoss: 0.024771\n",
      "Train Epoch: 8 [7168/14860 (48%)]\tLoss: 0.017086\n",
      "Train Epoch: 8 [7296/14860 (49%)]\tLoss: 0.016694\n",
      "Train Epoch: 8 [7424/14860 (50%)]\tLoss: 0.022733\n",
      "Train Epoch: 8 [7552/14860 (50%)]\tLoss: 0.017049\n",
      "Train Epoch: 8 [7680/14860 (51%)]\tLoss: 0.020459\n",
      "Train Epoch: 8 [7808/14860 (52%)]\tLoss: 0.021654\n",
      "Train Epoch: 8 [7936/14860 (53%)]\tLoss: 0.021360\n",
      "Train Epoch: 8 [8064/14860 (54%)]\tLoss: 0.025196\n",
      "Train Epoch: 8 [8192/14860 (55%)]\tLoss: 0.021450\n",
      "Train Epoch: 8 [8320/14860 (56%)]\tLoss: 0.018177\n",
      "Train Epoch: 8 [8448/14860 (56%)]\tLoss: 0.016208\n",
      "Train Epoch: 8 [8576/14860 (57%)]\tLoss: 0.016574\n",
      "Train Epoch: 8 [8704/14860 (58%)]\tLoss: 0.017688\n",
      "Train Epoch: 8 [8832/14860 (59%)]\tLoss: 0.016351\n",
      "Train Epoch: 8 [8960/14860 (60%)]\tLoss: 0.017919\n",
      "Train Epoch: 8 [9088/14860 (61%)]\tLoss: 0.015625\n",
      "Train Epoch: 8 [9216/14860 (62%)]\tLoss: 0.025661\n",
      "Train Epoch: 8 [9344/14860 (62%)]\tLoss: 0.022927\n",
      "Train Epoch: 8 [9472/14860 (63%)]\tLoss: 0.019394\n",
      "Train Epoch: 8 [9600/14860 (64%)]\tLoss: 0.021274\n",
      "Train Epoch: 8 [9728/14860 (65%)]\tLoss: 0.020975\n",
      "Train Epoch: 8 [9856/14860 (66%)]\tLoss: 0.022430\n",
      "Train Epoch: 8 [9984/14860 (67%)]\tLoss: 0.018656\n",
      "Train Epoch: 8 [10112/14860 (68%)]\tLoss: 0.017975\n",
      "Train Epoch: 8 [10240/14860 (68%)]\tLoss: 0.021854\n",
      "Train Epoch: 8 [10368/14860 (69%)]\tLoss: 0.026728\n",
      "Train Epoch: 8 [10496/14860 (70%)]\tLoss: 0.023250\n",
      "Train Epoch: 8 [10624/14860 (71%)]\tLoss: 0.020865\n",
      "Train Epoch: 8 [10752/14860 (72%)]\tLoss: 0.021484\n",
      "Train Epoch: 8 [10880/14860 (73%)]\tLoss: 0.019432\n",
      "Train Epoch: 8 [11008/14860 (74%)]\tLoss: 0.022892\n",
      "Train Epoch: 8 [11136/14860 (74%)]\tLoss: 0.018632\n",
      "Train Epoch: 8 [11264/14860 (75%)]\tLoss: 0.020985\n",
      "Train Epoch: 8 [11392/14860 (76%)]\tLoss: 0.023253\n",
      "Train Epoch: 8 [11520/14860 (77%)]\tLoss: 0.020823\n",
      "Train Epoch: 8 [11648/14860 (78%)]\tLoss: 0.019978\n",
      "Train Epoch: 8 [11776/14860 (79%)]\tLoss: 0.020780\n",
      "Train Epoch: 8 [11904/14860 (79%)]\tLoss: 0.027409\n",
      "Train Epoch: 8 [12032/14860 (80%)]\tLoss: 0.027536\n",
      "Train Epoch: 8 [12160/14860 (81%)]\tLoss: 0.017791\n",
      "Train Epoch: 8 [12288/14860 (82%)]\tLoss: 0.018439\n",
      "Train Epoch: 8 [12416/14860 (83%)]\tLoss: 0.017823\n",
      "Train Epoch: 8 [12544/14860 (84%)]\tLoss: 0.026039\n",
      "Train Epoch: 8 [12672/14860 (85%)]\tLoss: 0.018812\n",
      "Train Epoch: 8 [12800/14860 (85%)]\tLoss: 0.018843\n",
      "Train Epoch: 8 [12928/14860 (86%)]\tLoss: 0.028034\n",
      "Train Epoch: 8 [13056/14860 (87%)]\tLoss: 0.027574\n",
      "Train Epoch: 8 [13184/14860 (88%)]\tLoss: 0.018859\n",
      "Train Epoch: 8 [13312/14860 (89%)]\tLoss: 0.024224\n",
      "Train Epoch: 8 [13440/14860 (90%)]\tLoss: 0.028314\n",
      "Train Epoch: 8 [13568/14860 (91%)]\tLoss: 0.022123\n",
      "Train Epoch: 8 [13696/14860 (91%)]\tLoss: 0.024516\n",
      "Train Epoch: 8 [13824/14860 (92%)]\tLoss: 0.025095\n",
      "Train Epoch: 8 [13952/14860 (93%)]\tLoss: 0.023856\n",
      "Train Epoch: 8 [14080/14860 (94%)]\tLoss: 0.016935\n",
      "Train Epoch: 8 [14208/14860 (95%)]\tLoss: 0.018493\n",
      "Train Epoch: 8 [14336/14860 (96%)]\tLoss: 0.026723\n",
      "Train Epoch: 8 [14464/14860 (97%)]\tLoss: 0.029720\n",
      "Train Epoch: 8 [14592/14860 (97%)]\tLoss: 0.022848\n",
      "Train Epoch: 8 [14720/14860 (98%)]\tLoss: 0.015972\n",
      "Train Epoch: 8 [1392/14860 (99%)]\tLoss: 0.072039\n",
      "epoch 8 training loss: 0.021354246637823746\n",
      "epoch 8 validation loss: 0.021791743885806916\n",
      "Train Epoch: 9 [0/14860 (0%)]\tLoss: 0.026579\n",
      "Train Epoch: 9 [128/14860 (1%)]\tLoss: 0.020489\n",
      "Train Epoch: 9 [256/14860 (2%)]\tLoss: 0.021157\n",
      "Train Epoch: 9 [384/14860 (3%)]\tLoss: 0.022448\n",
      "Train Epoch: 9 [512/14860 (3%)]\tLoss: 0.023525\n",
      "Train Epoch: 9 [640/14860 (4%)]\tLoss: 0.027380\n",
      "Train Epoch: 9 [768/14860 (5%)]\tLoss: 0.030019\n",
      "Train Epoch: 9 [896/14860 (6%)]\tLoss: 0.017437\n",
      "Train Epoch: 9 [1024/14860 (7%)]\tLoss: 0.028469\n",
      "Train Epoch: 9 [1152/14860 (8%)]\tLoss: 0.030819\n",
      "Train Epoch: 9 [1280/14860 (9%)]\tLoss: 0.020695\n",
      "Train Epoch: 9 [1408/14860 (9%)]\tLoss: 0.026769\n",
      "Train Epoch: 9 [1536/14860 (10%)]\tLoss: 0.022393\n",
      "Train Epoch: 9 [1664/14860 (11%)]\tLoss: 0.021645\n",
      "Train Epoch: 9 [1792/14860 (12%)]\tLoss: 0.031242\n",
      "Train Epoch: 9 [1920/14860 (13%)]\tLoss: 0.023471\n",
      "Train Epoch: 9 [2048/14860 (14%)]\tLoss: 0.022156\n",
      "Train Epoch: 9 [2176/14860 (15%)]\tLoss: 0.023263\n",
      "Train Epoch: 9 [2304/14860 (15%)]\tLoss: 0.018909\n",
      "Train Epoch: 9 [2432/14860 (16%)]\tLoss: 0.020942\n",
      "Train Epoch: 9 [2560/14860 (17%)]\tLoss: 0.017632\n",
      "Train Epoch: 9 [2688/14860 (18%)]\tLoss: 0.020420\n",
      "Train Epoch: 9 [2816/14860 (19%)]\tLoss: 0.026736\n",
      "Train Epoch: 9 [2944/14860 (20%)]\tLoss: 0.022798\n",
      "Train Epoch: 9 [3072/14860 (21%)]\tLoss: 0.017144\n",
      "Train Epoch: 9 [3200/14860 (21%)]\tLoss: 0.022878\n",
      "Train Epoch: 9 [3328/14860 (22%)]\tLoss: 0.015868\n",
      "Train Epoch: 9 [3456/14860 (23%)]\tLoss: 0.024780\n",
      "Train Epoch: 9 [3584/14860 (24%)]\tLoss: 0.012841\n",
      "Train Epoch: 9 [3712/14860 (25%)]\tLoss: 0.023578\n",
      "Train Epoch: 9 [3840/14860 (26%)]\tLoss: 0.018950\n",
      "Train Epoch: 9 [3968/14860 (26%)]\tLoss: 0.018924\n",
      "Train Epoch: 9 [4096/14860 (27%)]\tLoss: 0.021381\n",
      "Train Epoch: 9 [4224/14860 (28%)]\tLoss: 0.024252\n",
      "Train Epoch: 9 [4352/14860 (29%)]\tLoss: 0.015950\n",
      "Train Epoch: 9 [4480/14860 (30%)]\tLoss: 0.024488\n",
      "Train Epoch: 9 [4608/14860 (31%)]\tLoss: 0.021727\n",
      "Train Epoch: 9 [4736/14860 (32%)]\tLoss: 0.015614\n",
      "Train Epoch: 9 [4864/14860 (32%)]\tLoss: 0.025104\n",
      "Train Epoch: 9 [4992/14860 (33%)]\tLoss: 0.022192\n",
      "Train Epoch: 9 [5120/14860 (34%)]\tLoss: 0.019723\n",
      "Train Epoch: 9 [5248/14860 (35%)]\tLoss: 0.020377\n",
      "Train Epoch: 9 [5376/14860 (36%)]\tLoss: 0.023703\n",
      "Train Epoch: 9 [5504/14860 (37%)]\tLoss: 0.015039\n",
      "Train Epoch: 9 [5632/14860 (38%)]\tLoss: 0.021838\n",
      "Train Epoch: 9 [5760/14860 (38%)]\tLoss: 0.027964\n",
      "Train Epoch: 9 [5888/14860 (39%)]\tLoss: 0.012071\n",
      "Train Epoch: 9 [6016/14860 (40%)]\tLoss: 0.019411\n",
      "Train Epoch: 9 [6144/14860 (41%)]\tLoss: 0.026088\n",
      "Train Epoch: 9 [6272/14860 (42%)]\tLoss: 0.020902\n",
      "Train Epoch: 9 [6400/14860 (43%)]\tLoss: 0.014538\n",
      "Train Epoch: 9 [6528/14860 (44%)]\tLoss: 0.015342\n",
      "Train Epoch: 9 [6656/14860 (44%)]\tLoss: 0.025350\n",
      "Train Epoch: 9 [6784/14860 (45%)]\tLoss: 0.013488\n",
      "Train Epoch: 9 [6912/14860 (46%)]\tLoss: 0.020045\n",
      "Train Epoch: 9 [7040/14860 (47%)]\tLoss: 0.014173\n",
      "Train Epoch: 9 [7168/14860 (48%)]\tLoss: 0.017756\n",
      "Train Epoch: 9 [7296/14860 (49%)]\tLoss: 0.018871\n",
      "Train Epoch: 9 [7424/14860 (50%)]\tLoss: 0.016297\n",
      "Train Epoch: 9 [7552/14860 (50%)]\tLoss: 0.022624\n",
      "Train Epoch: 9 [7680/14860 (51%)]\tLoss: 0.018271\n",
      "Train Epoch: 9 [7808/14860 (52%)]\tLoss: 0.024657\n",
      "Train Epoch: 9 [7936/14860 (53%)]\tLoss: 0.022247\n",
      "Train Epoch: 9 [8064/14860 (54%)]\tLoss: 0.018499\n",
      "Train Epoch: 9 [8192/14860 (55%)]\tLoss: 0.021536\n",
      "Train Epoch: 9 [8320/14860 (56%)]\tLoss: 0.016753\n",
      "Train Epoch: 9 [8448/14860 (56%)]\tLoss: 0.018609\n",
      "Train Epoch: 9 [8576/14860 (57%)]\tLoss: 0.023282\n",
      "Train Epoch: 9 [8704/14860 (58%)]\tLoss: 0.015293\n",
      "Train Epoch: 9 [8832/14860 (59%)]\tLoss: 0.018496\n",
      "Train Epoch: 9 [8960/14860 (60%)]\tLoss: 0.021754\n",
      "Train Epoch: 9 [9088/14860 (61%)]\tLoss: 0.023301\n",
      "Train Epoch: 9 [9216/14860 (62%)]\tLoss: 0.022368\n",
      "Train Epoch: 9 [9344/14860 (62%)]\tLoss: 0.023687\n",
      "Train Epoch: 9 [9472/14860 (63%)]\tLoss: 0.019575\n",
      "Train Epoch: 9 [9600/14860 (64%)]\tLoss: 0.018138\n",
      "Train Epoch: 9 [9728/14860 (65%)]\tLoss: 0.016987\n",
      "Train Epoch: 9 [9856/14860 (66%)]\tLoss: 0.020221\n",
      "Train Epoch: 9 [9984/14860 (67%)]\tLoss: 0.020164\n",
      "Train Epoch: 9 [10112/14860 (68%)]\tLoss: 0.024582\n",
      "Train Epoch: 9 [10240/14860 (68%)]\tLoss: 0.021078\n",
      "Train Epoch: 9 [10368/14860 (69%)]\tLoss: 0.015433\n",
      "Train Epoch: 9 [10496/14860 (70%)]\tLoss: 0.019882\n",
      "Train Epoch: 9 [10624/14860 (71%)]\tLoss: 0.022819\n",
      "Train Epoch: 9 [10752/14860 (72%)]\tLoss: 0.020111\n",
      "Train Epoch: 9 [10880/14860 (73%)]\tLoss: 0.018319\n",
      "Train Epoch: 9 [11008/14860 (74%)]\tLoss: 0.026352\n",
      "Train Epoch: 9 [11136/14860 (74%)]\tLoss: 0.023751\n",
      "Train Epoch: 9 [11264/14860 (75%)]\tLoss: 0.027759\n",
      "Train Epoch: 9 [11392/14860 (76%)]\tLoss: 0.024873\n",
      "Train Epoch: 9 [11520/14860 (77%)]\tLoss: 0.022048\n",
      "Train Epoch: 9 [11648/14860 (78%)]\tLoss: 0.022410\n",
      "Train Epoch: 9 [11776/14860 (79%)]\tLoss: 0.026500\n",
      "Train Epoch: 9 [11904/14860 (79%)]\tLoss: 0.020823\n",
      "Train Epoch: 9 [12032/14860 (80%)]\tLoss: 0.023479\n",
      "Train Epoch: 9 [12160/14860 (81%)]\tLoss: 0.020041\n",
      "Train Epoch: 9 [12288/14860 (82%)]\tLoss: 0.023081\n",
      "Train Epoch: 9 [12416/14860 (83%)]\tLoss: 0.029195\n",
      "Train Epoch: 9 [12544/14860 (84%)]\tLoss: 0.015997\n",
      "Train Epoch: 9 [12672/14860 (85%)]\tLoss: 0.019142\n",
      "Train Epoch: 9 [12800/14860 (85%)]\tLoss: 0.023370\n",
      "Train Epoch: 9 [12928/14860 (86%)]\tLoss: 0.017757\n",
      "Train Epoch: 9 [13056/14860 (87%)]\tLoss: 0.025858\n",
      "Train Epoch: 9 [13184/14860 (88%)]\tLoss: 0.013078\n",
      "Train Epoch: 9 [13312/14860 (89%)]\tLoss: 0.020973\n",
      "Train Epoch: 9 [13440/14860 (90%)]\tLoss: 0.018883\n",
      "Train Epoch: 9 [13568/14860 (91%)]\tLoss: 0.017794\n",
      "Train Epoch: 9 [13696/14860 (91%)]\tLoss: 0.016445\n",
      "Train Epoch: 9 [13824/14860 (92%)]\tLoss: 0.025577\n",
      "Train Epoch: 9 [13952/14860 (93%)]\tLoss: 0.013978\n",
      "Train Epoch: 9 [14080/14860 (94%)]\tLoss: 0.019345\n",
      "Train Epoch: 9 [14208/14860 (95%)]\tLoss: 0.019295\n",
      "Train Epoch: 9 [14336/14860 (96%)]\tLoss: 0.022009\n",
      "Train Epoch: 9 [14464/14860 (97%)]\tLoss: 0.017614\n",
      "Train Epoch: 9 [14592/14860 (97%)]\tLoss: 0.023857\n",
      "Train Epoch: 9 [14720/14860 (98%)]\tLoss: 0.012524\n",
      "Train Epoch: 9 [1392/14860 (99%)]\tLoss: 0.034025\n",
      "epoch 9 training loss: 0.02113297710625025\n",
      "epoch 9 validation loss: 0.026124668034745186\n",
      "Train Epoch: 10 [0/14860 (0%)]\tLoss: 0.027104\n",
      "Train Epoch: 10 [128/14860 (1%)]\tLoss: 0.028003\n",
      "Train Epoch: 10 [256/14860 (2%)]\tLoss: 0.018613\n",
      "Train Epoch: 10 [384/14860 (3%)]\tLoss: 0.019070\n",
      "Train Epoch: 10 [512/14860 (3%)]\tLoss: 0.023077\n",
      "Train Epoch: 10 [640/14860 (4%)]\tLoss: 0.019029\n",
      "Train Epoch: 10 [768/14860 (5%)]\tLoss: 0.018000\n",
      "Train Epoch: 10 [896/14860 (6%)]\tLoss: 0.024600\n",
      "Train Epoch: 10 [1024/14860 (7%)]\tLoss: 0.014127\n",
      "Train Epoch: 10 [1152/14860 (8%)]\tLoss: 0.012499\n",
      "Train Epoch: 10 [1280/14860 (9%)]\tLoss: 0.021236\n",
      "Train Epoch: 10 [1408/14860 (9%)]\tLoss: 0.023270\n",
      "Train Epoch: 10 [1536/14860 (10%)]\tLoss: 0.023961\n",
      "Train Epoch: 10 [1664/14860 (11%)]\tLoss: 0.028511\n",
      "Train Epoch: 10 [1792/14860 (12%)]\tLoss: 0.020642\n",
      "Train Epoch: 10 [1920/14860 (13%)]\tLoss: 0.018852\n",
      "Train Epoch: 10 [2048/14860 (14%)]\tLoss: 0.019681\n",
      "Train Epoch: 10 [2176/14860 (15%)]\tLoss: 0.023248\n",
      "Train Epoch: 10 [2304/14860 (15%)]\tLoss: 0.017824\n",
      "Train Epoch: 10 [2432/14860 (16%)]\tLoss: 0.019620\n",
      "Train Epoch: 10 [2560/14860 (17%)]\tLoss: 0.018270\n",
      "Train Epoch: 10 [2688/14860 (18%)]\tLoss: 0.019956\n",
      "Train Epoch: 10 [2816/14860 (19%)]\tLoss: 0.021847\n",
      "Train Epoch: 10 [2944/14860 (20%)]\tLoss: 0.026875\n",
      "Train Epoch: 10 [3072/14860 (21%)]\tLoss: 0.017236\n",
      "Train Epoch: 10 [3200/14860 (21%)]\tLoss: 0.030383\n",
      "Train Epoch: 10 [3328/14860 (22%)]\tLoss: 0.019957\n",
      "Train Epoch: 10 [3456/14860 (23%)]\tLoss: 0.021915\n",
      "Train Epoch: 10 [3584/14860 (24%)]\tLoss: 0.026003\n",
      "Train Epoch: 10 [3712/14860 (25%)]\tLoss: 0.018721\n",
      "Train Epoch: 10 [3840/14860 (26%)]\tLoss: 0.016306\n",
      "Train Epoch: 10 [3968/14860 (26%)]\tLoss: 0.022736\n",
      "Train Epoch: 10 [4096/14860 (27%)]\tLoss: 0.024877\n",
      "Train Epoch: 10 [4224/14860 (28%)]\tLoss: 0.019567\n",
      "Train Epoch: 10 [4352/14860 (29%)]\tLoss: 0.015843\n",
      "Train Epoch: 10 [4480/14860 (30%)]\tLoss: 0.018347\n",
      "Train Epoch: 10 [4608/14860 (31%)]\tLoss: 0.015481\n",
      "Train Epoch: 10 [4736/14860 (32%)]\tLoss: 0.027164\n",
      "Train Epoch: 10 [4864/14860 (32%)]\tLoss: 0.016306\n",
      "Train Epoch: 10 [4992/14860 (33%)]\tLoss: 0.017228\n",
      "Train Epoch: 10 [5120/14860 (34%)]\tLoss: 0.024054\n",
      "Train Epoch: 10 [5248/14860 (35%)]\tLoss: 0.019275\n",
      "Train Epoch: 10 [5376/14860 (36%)]\tLoss: 0.020988\n",
      "Train Epoch: 10 [5504/14860 (37%)]\tLoss: 0.019227\n",
      "Train Epoch: 10 [5632/14860 (38%)]\tLoss: 0.017710\n",
      "Train Epoch: 10 [5760/14860 (38%)]\tLoss: 0.022184\n",
      "Train Epoch: 10 [5888/14860 (39%)]\tLoss: 0.019817\n",
      "Train Epoch: 10 [6016/14860 (40%)]\tLoss: 0.019019\n",
      "Train Epoch: 10 [6144/14860 (41%)]\tLoss: 0.026836\n",
      "Train Epoch: 10 [6272/14860 (42%)]\tLoss: 0.017014\n",
      "Train Epoch: 10 [6400/14860 (43%)]\tLoss: 0.013780\n",
      "Train Epoch: 10 [6528/14860 (44%)]\tLoss: 0.024155\n",
      "Train Epoch: 10 [6656/14860 (44%)]\tLoss: 0.013188\n",
      "Train Epoch: 10 [6784/14860 (45%)]\tLoss: 0.019859\n",
      "Train Epoch: 10 [6912/14860 (46%)]\tLoss: 0.018270\n",
      "Train Epoch: 10 [7040/14860 (47%)]\tLoss: 0.019509\n",
      "Train Epoch: 10 [7168/14860 (48%)]\tLoss: 0.023430\n",
      "Train Epoch: 10 [7296/14860 (49%)]\tLoss: 0.016643\n",
      "Train Epoch: 10 [7424/14860 (50%)]\tLoss: 0.016669\n",
      "Train Epoch: 10 [7552/14860 (50%)]\tLoss: 0.020094\n",
      "Train Epoch: 10 [7680/14860 (51%)]\tLoss: 0.030921\n",
      "Train Epoch: 10 [7808/14860 (52%)]\tLoss: 0.021201\n",
      "Train Epoch: 10 [7936/14860 (53%)]\tLoss: 0.030597\n",
      "Train Epoch: 10 [8064/14860 (54%)]\tLoss: 0.027557\n",
      "Train Epoch: 10 [8192/14860 (55%)]\tLoss: 0.019089\n",
      "Train Epoch: 10 [8320/14860 (56%)]\tLoss: 0.023328\n",
      "Train Epoch: 10 [8448/14860 (56%)]\tLoss: 0.021941\n",
      "Train Epoch: 10 [8576/14860 (57%)]\tLoss: 0.016337\n",
      "Train Epoch: 10 [8704/14860 (58%)]\tLoss: 0.017903\n",
      "Train Epoch: 10 [8832/14860 (59%)]\tLoss: 0.021057\n",
      "Train Epoch: 10 [8960/14860 (60%)]\tLoss: 0.019798\n",
      "Train Epoch: 10 [9088/14860 (61%)]\tLoss: 0.022210\n",
      "Train Epoch: 10 [9216/14860 (62%)]\tLoss: 0.023254\n",
      "Train Epoch: 10 [9344/14860 (62%)]\tLoss: 0.018657\n",
      "Train Epoch: 10 [9472/14860 (63%)]\tLoss: 0.019697\n",
      "Train Epoch: 10 [9600/14860 (64%)]\tLoss: 0.025048\n",
      "Train Epoch: 10 [9728/14860 (65%)]\tLoss: 0.031628\n",
      "Train Epoch: 10 [9856/14860 (66%)]\tLoss: 0.020402\n",
      "Train Epoch: 10 [9984/14860 (67%)]\tLoss: 0.017111\n",
      "Train Epoch: 10 [10112/14860 (68%)]\tLoss: 0.016116\n",
      "Train Epoch: 10 [10240/14860 (68%)]\tLoss: 0.017232\n",
      "Train Epoch: 10 [10368/14860 (69%)]\tLoss: 0.021689\n",
      "Train Epoch: 10 [10496/14860 (70%)]\tLoss: 0.022399\n",
      "Train Epoch: 10 [10624/14860 (71%)]\tLoss: 0.018764\n",
      "Train Epoch: 10 [10752/14860 (72%)]\tLoss: 0.019197\n",
      "Train Epoch: 10 [10880/14860 (73%)]\tLoss: 0.020562\n",
      "Train Epoch: 10 [11008/14860 (74%)]\tLoss: 0.022931\n",
      "Train Epoch: 10 [11136/14860 (74%)]\tLoss: 0.015061\n",
      "Train Epoch: 10 [11264/14860 (75%)]\tLoss: 0.015521\n",
      "Train Epoch: 10 [11392/14860 (76%)]\tLoss: 0.020708\n",
      "Train Epoch: 10 [11520/14860 (77%)]\tLoss: 0.021840\n",
      "Train Epoch: 10 [11648/14860 (78%)]\tLoss: 0.018515\n",
      "Train Epoch: 10 [11776/14860 (79%)]\tLoss: 0.024088\n",
      "Train Epoch: 10 [11904/14860 (79%)]\tLoss: 0.016457\n",
      "Train Epoch: 10 [12032/14860 (80%)]\tLoss: 0.014528\n",
      "Train Epoch: 10 [12160/14860 (81%)]\tLoss: 0.024140\n",
      "Train Epoch: 10 [12288/14860 (82%)]\tLoss: 0.019014\n",
      "Train Epoch: 10 [12416/14860 (83%)]\tLoss: 0.015499\n",
      "Train Epoch: 10 [12544/14860 (84%)]\tLoss: 0.019857\n",
      "Train Epoch: 10 [12672/14860 (85%)]\tLoss: 0.013792\n",
      "Train Epoch: 10 [12800/14860 (85%)]\tLoss: 0.016033\n",
      "Train Epoch: 10 [12928/14860 (86%)]\tLoss: 0.014862\n",
      "Train Epoch: 10 [13056/14860 (87%)]\tLoss: 0.024063\n",
      "Train Epoch: 10 [13184/14860 (88%)]\tLoss: 0.019275\n",
      "Train Epoch: 10 [13312/14860 (89%)]\tLoss: 0.016253\n",
      "Train Epoch: 10 [13440/14860 (90%)]\tLoss: 0.017051\n",
      "Train Epoch: 10 [13568/14860 (91%)]\tLoss: 0.016019\n",
      "Train Epoch: 10 [13696/14860 (91%)]\tLoss: 0.017245\n",
      "Train Epoch: 10 [13824/14860 (92%)]\tLoss: 0.019537\n",
      "Train Epoch: 10 [13952/14860 (93%)]\tLoss: 0.018632\n",
      "Train Epoch: 10 [14080/14860 (94%)]\tLoss: 0.017639\n",
      "Train Epoch: 10 [14208/14860 (95%)]\tLoss: 0.024210\n",
      "Train Epoch: 10 [14336/14860 (96%)]\tLoss: 0.015374\n",
      "Train Epoch: 10 [14464/14860 (97%)]\tLoss: 0.019587\n",
      "Train Epoch: 10 [14592/14860 (97%)]\tLoss: 0.030892\n",
      "Train Epoch: 10 [14720/14860 (98%)]\tLoss: 0.023665\n",
      "Train Epoch: 10 [1392/14860 (99%)]\tLoss: 0.021628\n",
      "epoch 10 training loss: 0.02038731750769493\n",
      "epoch 10 validation loss: 0.021471471821136106\n",
      "Train Epoch: 11 [0/14860 (0%)]\tLoss: 0.017313\n",
      "Train Epoch: 11 [128/14860 (1%)]\tLoss: 0.019588\n",
      "Train Epoch: 11 [256/14860 (2%)]\tLoss: 0.019126\n",
      "Train Epoch: 11 [384/14860 (3%)]\tLoss: 0.020421\n",
      "Train Epoch: 11 [512/14860 (3%)]\tLoss: 0.016870\n",
      "Train Epoch: 11 [640/14860 (4%)]\tLoss: 0.024345\n",
      "Train Epoch: 11 [768/14860 (5%)]\tLoss: 0.025090\n",
      "Train Epoch: 11 [896/14860 (6%)]\tLoss: 0.019200\n",
      "Train Epoch: 11 [1024/14860 (7%)]\tLoss: 0.025885\n",
      "Train Epoch: 11 [1152/14860 (8%)]\tLoss: 0.026939\n",
      "Train Epoch: 11 [1280/14860 (9%)]\tLoss: 0.027636\n",
      "Train Epoch: 11 [1408/14860 (9%)]\tLoss: 0.026212\n",
      "Train Epoch: 11 [1536/14860 (10%)]\tLoss: 0.018647\n",
      "Train Epoch: 11 [1664/14860 (11%)]\tLoss: 0.018771\n",
      "Train Epoch: 11 [1792/14860 (12%)]\tLoss: 0.012455\n",
      "Train Epoch: 11 [1920/14860 (13%)]\tLoss: 0.015841\n",
      "Train Epoch: 11 [2048/14860 (14%)]\tLoss: 0.019366\n",
      "Train Epoch: 11 [2176/14860 (15%)]\tLoss: 0.019254\n",
      "Train Epoch: 11 [2304/14860 (15%)]\tLoss: 0.016753\n",
      "Train Epoch: 11 [2432/14860 (16%)]\tLoss: 0.015955\n",
      "Train Epoch: 11 [2560/14860 (17%)]\tLoss: 0.016699\n",
      "Train Epoch: 11 [2688/14860 (18%)]\tLoss: 0.021341\n",
      "Train Epoch: 11 [2816/14860 (19%)]\tLoss: 0.015084\n",
      "Train Epoch: 11 [2944/14860 (20%)]\tLoss: 0.024141\n",
      "Train Epoch: 11 [3072/14860 (21%)]\tLoss: 0.012358\n",
      "Train Epoch: 11 [3200/14860 (21%)]\tLoss: 0.015946\n",
      "Train Epoch: 11 [3328/14860 (22%)]\tLoss: 0.029561\n",
      "Train Epoch: 11 [3456/14860 (23%)]\tLoss: 0.021299\n",
      "Train Epoch: 11 [3584/14860 (24%)]\tLoss: 0.026717\n",
      "Train Epoch: 11 [3712/14860 (25%)]\tLoss: 0.018882\n",
      "Train Epoch: 11 [3840/14860 (26%)]\tLoss: 0.024654\n",
      "Train Epoch: 11 [3968/14860 (26%)]\tLoss: 0.020296\n",
      "Train Epoch: 11 [4096/14860 (27%)]\tLoss: 0.021109\n",
      "Train Epoch: 11 [4224/14860 (28%)]\tLoss: 0.032052\n",
      "Train Epoch: 11 [4352/14860 (29%)]\tLoss: 0.017572\n",
      "Train Epoch: 11 [4480/14860 (30%)]\tLoss: 0.016232\n",
      "Train Epoch: 11 [4608/14860 (31%)]\tLoss: 0.024543\n",
      "Train Epoch: 11 [4736/14860 (32%)]\tLoss: 0.022121\n",
      "Train Epoch: 11 [4864/14860 (32%)]\tLoss: 0.028033\n",
      "Train Epoch: 11 [4992/14860 (33%)]\tLoss: 0.023151\n",
      "Train Epoch: 11 [5120/14860 (34%)]\tLoss: 0.017646\n",
      "Train Epoch: 11 [5248/14860 (35%)]\tLoss: 0.019324\n",
      "Train Epoch: 11 [5376/14860 (36%)]\tLoss: 0.022350\n",
      "Train Epoch: 11 [5504/14860 (37%)]\tLoss: 0.026706\n",
      "Train Epoch: 11 [5632/14860 (38%)]\tLoss: 0.024474\n",
      "Train Epoch: 11 [5760/14860 (38%)]\tLoss: 0.023081\n",
      "Train Epoch: 11 [5888/14860 (39%)]\tLoss: 0.015100\n",
      "Train Epoch: 11 [6016/14860 (40%)]\tLoss: 0.021315\n",
      "Train Epoch: 11 [6144/14860 (41%)]\tLoss: 0.028197\n",
      "Train Epoch: 11 [6272/14860 (42%)]\tLoss: 0.016223\n",
      "Train Epoch: 11 [6400/14860 (43%)]\tLoss: 0.017878\n",
      "Train Epoch: 11 [6528/14860 (44%)]\tLoss: 0.018107\n",
      "Train Epoch: 11 [6656/14860 (44%)]\tLoss: 0.021317\n",
      "Train Epoch: 11 [6784/14860 (45%)]\tLoss: 0.015715\n",
      "Train Epoch: 11 [6912/14860 (46%)]\tLoss: 0.017223\n",
      "Train Epoch: 11 [7040/14860 (47%)]\tLoss: 0.025471\n",
      "Train Epoch: 11 [7168/14860 (48%)]\tLoss: 0.021490\n",
      "Train Epoch: 11 [7296/14860 (49%)]\tLoss: 0.022212\n",
      "Train Epoch: 11 [7424/14860 (50%)]\tLoss: 0.014004\n",
      "Train Epoch: 11 [7552/14860 (50%)]\tLoss: 0.018552\n",
      "Train Epoch: 11 [7680/14860 (51%)]\tLoss: 0.022240\n",
      "Train Epoch: 11 [7808/14860 (52%)]\tLoss: 0.020484\n",
      "Train Epoch: 11 [7936/14860 (53%)]\tLoss: 0.028249\n",
      "Train Epoch: 11 [8064/14860 (54%)]\tLoss: 0.018716\n",
      "Train Epoch: 11 [8192/14860 (55%)]\tLoss: 0.019966\n",
      "Train Epoch: 11 [8320/14860 (56%)]\tLoss: 0.015980\n",
      "Train Epoch: 11 [8448/14860 (56%)]\tLoss: 0.032494\n",
      "Train Epoch: 11 [8576/14860 (57%)]\tLoss: 0.020216\n",
      "Train Epoch: 11 [8704/14860 (58%)]\tLoss: 0.025642\n",
      "Train Epoch: 11 [8832/14860 (59%)]\tLoss: 0.018653\n",
      "Train Epoch: 11 [8960/14860 (60%)]\tLoss: 0.023836\n",
      "Train Epoch: 11 [9088/14860 (61%)]\tLoss: 0.018444\n",
      "Train Epoch: 11 [9216/14860 (62%)]\tLoss: 0.019499\n",
      "Train Epoch: 11 [9344/14860 (62%)]\tLoss: 0.018604\n",
      "Train Epoch: 11 [9472/14860 (63%)]\tLoss: 0.021363\n",
      "Train Epoch: 11 [9600/14860 (64%)]\tLoss: 0.016784\n",
      "Train Epoch: 11 [9728/14860 (65%)]\tLoss: 0.014429\n",
      "Train Epoch: 11 [9856/14860 (66%)]\tLoss: 0.014915\n",
      "Train Epoch: 11 [9984/14860 (67%)]\tLoss: 0.028524\n",
      "Train Epoch: 11 [10112/14860 (68%)]\tLoss: 0.014963\n",
      "Train Epoch: 11 [10240/14860 (68%)]\tLoss: 0.019926\n",
      "Train Epoch: 11 [10368/14860 (69%)]\tLoss: 0.011667\n",
      "Train Epoch: 11 [10496/14860 (70%)]\tLoss: 0.016025\n",
      "Train Epoch: 11 [10624/14860 (71%)]\tLoss: 0.020077\n",
      "Train Epoch: 11 [10752/14860 (72%)]\tLoss: 0.019572\n",
      "Train Epoch: 11 [10880/14860 (73%)]\tLoss: 0.021616\n",
      "Train Epoch: 11 [11008/14860 (74%)]\tLoss: 0.018414\n",
      "Train Epoch: 11 [11136/14860 (74%)]\tLoss: 0.028728\n",
      "Train Epoch: 11 [11264/14860 (75%)]\tLoss: 0.022619\n",
      "Train Epoch: 11 [11392/14860 (76%)]\tLoss: 0.014755\n",
      "Train Epoch: 11 [11520/14860 (77%)]\tLoss: 0.021546\n",
      "Train Epoch: 11 [11648/14860 (78%)]\tLoss: 0.019013\n",
      "Train Epoch: 11 [11776/14860 (79%)]\tLoss: 0.017063\n",
      "Train Epoch: 11 [11904/14860 (79%)]\tLoss: 0.024671\n",
      "Train Epoch: 11 [12032/14860 (80%)]\tLoss: 0.016688\n",
      "Train Epoch: 11 [12160/14860 (81%)]\tLoss: 0.014646\n",
      "Train Epoch: 11 [12288/14860 (82%)]\tLoss: 0.019283\n",
      "Train Epoch: 11 [12416/14860 (83%)]\tLoss: 0.018331\n",
      "Train Epoch: 11 [12544/14860 (84%)]\tLoss: 0.015063\n",
      "Train Epoch: 11 [12672/14860 (85%)]\tLoss: 0.028190\n",
      "Train Epoch: 11 [12800/14860 (85%)]\tLoss: 0.016862\n",
      "Train Epoch: 11 [12928/14860 (86%)]\tLoss: 0.021258\n",
      "Train Epoch: 11 [13056/14860 (87%)]\tLoss: 0.024303\n",
      "Train Epoch: 11 [13184/14860 (88%)]\tLoss: 0.027235\n",
      "Train Epoch: 11 [13312/14860 (89%)]\tLoss: 0.012978\n",
      "Train Epoch: 11 [13440/14860 (90%)]\tLoss: 0.027745\n",
      "Train Epoch: 11 [13568/14860 (91%)]\tLoss: 0.018185\n",
      "Train Epoch: 11 [13696/14860 (91%)]\tLoss: 0.025155\n",
      "Train Epoch: 11 [13824/14860 (92%)]\tLoss: 0.017089\n",
      "Train Epoch: 11 [13952/14860 (93%)]\tLoss: 0.019513\n",
      "Train Epoch: 11 [14080/14860 (94%)]\tLoss: 0.019552\n",
      "Train Epoch: 11 [14208/14860 (95%)]\tLoss: 0.025277\n",
      "Train Epoch: 11 [14336/14860 (96%)]\tLoss: 0.021445\n",
      "Train Epoch: 11 [14464/14860 (97%)]\tLoss: 0.018530\n",
      "Train Epoch: 11 [14592/14860 (97%)]\tLoss: 0.016278\n",
      "Train Epoch: 11 [14720/14860 (98%)]\tLoss: 0.014567\n",
      "Train Epoch: 11 [1392/14860 (99%)]\tLoss: 0.014893\n",
      "epoch 11 training loss: 0.020398279779359825\n",
      "epoch 11 validation loss: 0.022472548427073778\n",
      "Train Epoch: 12 [0/14860 (0%)]\tLoss: 0.014722\n",
      "Train Epoch: 12 [128/14860 (1%)]\tLoss: 0.018157\n",
      "Train Epoch: 12 [256/14860 (2%)]\tLoss: 0.019995\n",
      "Train Epoch: 12 [384/14860 (3%)]\tLoss: 0.031669\n",
      "Train Epoch: 12 [512/14860 (3%)]\tLoss: 0.023292\n",
      "Train Epoch: 12 [640/14860 (4%)]\tLoss: 0.028632\n",
      "Train Epoch: 12 [768/14860 (5%)]\tLoss: 0.025025\n",
      "Train Epoch: 12 [896/14860 (6%)]\tLoss: 0.030730\n",
      "Train Epoch: 12 [1024/14860 (7%)]\tLoss: 0.021133\n",
      "Train Epoch: 12 [1152/14860 (8%)]\tLoss: 0.022719\n",
      "Train Epoch: 12 [1280/14860 (9%)]\tLoss: 0.022236\n",
      "Train Epoch: 12 [1408/14860 (9%)]\tLoss: 0.020720\n",
      "Train Epoch: 12 [1536/14860 (10%)]\tLoss: 0.023557\n",
      "Train Epoch: 12 [1664/14860 (11%)]\tLoss: 0.022076\n",
      "Train Epoch: 12 [1792/14860 (12%)]\tLoss: 0.022960\n",
      "Train Epoch: 12 [1920/14860 (13%)]\tLoss: 0.028464\n",
      "Train Epoch: 12 [2048/14860 (14%)]\tLoss: 0.022612\n",
      "Train Epoch: 12 [2176/14860 (15%)]\tLoss: 0.020633\n",
      "Train Epoch: 12 [2304/14860 (15%)]\tLoss: 0.024309\n",
      "Train Epoch: 12 [2432/14860 (16%)]\tLoss: 0.017370\n",
      "Train Epoch: 12 [2560/14860 (17%)]\tLoss: 0.025458\n",
      "Train Epoch: 12 [2688/14860 (18%)]\tLoss: 0.020670\n",
      "Train Epoch: 12 [2816/14860 (19%)]\tLoss: 0.022122\n",
      "Train Epoch: 12 [2944/14860 (20%)]\tLoss: 0.019918\n",
      "Train Epoch: 12 [3072/14860 (21%)]\tLoss: 0.020496\n",
      "Train Epoch: 12 [3200/14860 (21%)]\tLoss: 0.022673\n",
      "Train Epoch: 12 [3328/14860 (22%)]\tLoss: 0.015073\n",
      "Train Epoch: 12 [3456/14860 (23%)]\tLoss: 0.017405\n",
      "Train Epoch: 12 [3584/14860 (24%)]\tLoss: 0.021181\n",
      "Train Epoch: 12 [3712/14860 (25%)]\tLoss: 0.017528\n",
      "Train Epoch: 12 [3840/14860 (26%)]\tLoss: 0.018849\n",
      "Train Epoch: 12 [3968/14860 (26%)]\tLoss: 0.027633\n",
      "Train Epoch: 12 [4096/14860 (27%)]\tLoss: 0.024116\n",
      "Train Epoch: 12 [4224/14860 (28%)]\tLoss: 0.018370\n",
      "Train Epoch: 12 [4352/14860 (29%)]\tLoss: 0.014256\n",
      "Train Epoch: 12 [4480/14860 (30%)]\tLoss: 0.023193\n",
      "Train Epoch: 12 [4608/14860 (31%)]\tLoss: 0.016898\n",
      "Train Epoch: 12 [4736/14860 (32%)]\tLoss: 0.013350\n",
      "Train Epoch: 12 [4864/14860 (32%)]\tLoss: 0.018416\n",
      "Train Epoch: 12 [4992/14860 (33%)]\tLoss: 0.024767\n",
      "Train Epoch: 12 [5120/14860 (34%)]\tLoss: 0.020050\n",
      "Train Epoch: 12 [5248/14860 (35%)]\tLoss: 0.018557\n",
      "Train Epoch: 12 [5376/14860 (36%)]\tLoss: 0.021682\n",
      "Train Epoch: 12 [5504/14860 (37%)]\tLoss: 0.013845\n",
      "Train Epoch: 12 [5632/14860 (38%)]\tLoss: 0.015141\n",
      "Train Epoch: 12 [5760/14860 (38%)]\tLoss: 0.023260\n",
      "Train Epoch: 12 [5888/14860 (39%)]\tLoss: 0.021951\n",
      "Train Epoch: 12 [6016/14860 (40%)]\tLoss: 0.022301\n",
      "Train Epoch: 12 [6144/14860 (41%)]\tLoss: 0.019001\n",
      "Train Epoch: 12 [6272/14860 (42%)]\tLoss: 0.021171\n",
      "Train Epoch: 12 [6400/14860 (43%)]\tLoss: 0.028738\n",
      "Train Epoch: 12 [6528/14860 (44%)]\tLoss: 0.016149\n",
      "Train Epoch: 12 [6656/14860 (44%)]\tLoss: 0.016797\n",
      "Train Epoch: 12 [6784/14860 (45%)]\tLoss: 0.024728\n",
      "Train Epoch: 12 [6912/14860 (46%)]\tLoss: 0.012987\n",
      "Train Epoch: 12 [7040/14860 (47%)]\tLoss: 0.018374\n",
      "Train Epoch: 12 [7168/14860 (48%)]\tLoss: 0.024646\n",
      "Train Epoch: 12 [7296/14860 (49%)]\tLoss: 0.015615\n",
      "Train Epoch: 12 [7424/14860 (50%)]\tLoss: 0.024302\n",
      "Train Epoch: 12 [7552/14860 (50%)]\tLoss: 0.021275\n",
      "Train Epoch: 12 [7680/14860 (51%)]\tLoss: 0.023315\n",
      "Train Epoch: 12 [7808/14860 (52%)]\tLoss: 0.016336\n",
      "Train Epoch: 12 [7936/14860 (53%)]\tLoss: 0.021721\n",
      "Train Epoch: 12 [8064/14860 (54%)]\tLoss: 0.016605\n",
      "Train Epoch: 12 [8192/14860 (55%)]\tLoss: 0.015814\n",
      "Train Epoch: 12 [8320/14860 (56%)]\tLoss: 0.021710\n",
      "Train Epoch: 12 [8448/14860 (56%)]\tLoss: 0.019497\n",
      "Train Epoch: 12 [8576/14860 (57%)]\tLoss: 0.015848\n",
      "Train Epoch: 12 [8704/14860 (58%)]\tLoss: 0.021515\n",
      "Train Epoch: 12 [8832/14860 (59%)]\tLoss: 0.025533\n",
      "Train Epoch: 12 [8960/14860 (60%)]\tLoss: 0.021021\n",
      "Train Epoch: 12 [9088/14860 (61%)]\tLoss: 0.013584\n",
      "Train Epoch: 12 [9216/14860 (62%)]\tLoss: 0.023939\n",
      "Train Epoch: 12 [9344/14860 (62%)]\tLoss: 0.025415\n",
      "Train Epoch: 12 [9472/14860 (63%)]\tLoss: 0.016917\n",
      "Train Epoch: 12 [9600/14860 (64%)]\tLoss: 0.016296\n",
      "Train Epoch: 12 [9728/14860 (65%)]\tLoss: 0.019611\n",
      "Train Epoch: 12 [9856/14860 (66%)]\tLoss: 0.018956\n",
      "Train Epoch: 12 [9984/14860 (67%)]\tLoss: 0.015417\n",
      "Train Epoch: 12 [10112/14860 (68%)]\tLoss: 0.022530\n",
      "Train Epoch: 12 [10240/14860 (68%)]\tLoss: 0.023093\n",
      "Train Epoch: 12 [10368/14860 (69%)]\tLoss: 0.023982\n",
      "Train Epoch: 12 [10496/14860 (70%)]\tLoss: 0.012899\n",
      "Train Epoch: 12 [10624/14860 (71%)]\tLoss: 0.024323\n",
      "Train Epoch: 12 [10752/14860 (72%)]\tLoss: 0.022943\n",
      "Train Epoch: 12 [10880/14860 (73%)]\tLoss: 0.020127\n",
      "Train Epoch: 12 [11008/14860 (74%)]\tLoss: 0.019874\n",
      "Train Epoch: 12 [11136/14860 (74%)]\tLoss: 0.018835\n",
      "Train Epoch: 12 [11264/14860 (75%)]\tLoss: 0.022009\n",
      "Train Epoch: 12 [11392/14860 (76%)]\tLoss: 0.016953\n",
      "Train Epoch: 12 [11520/14860 (77%)]\tLoss: 0.019561\n",
      "Train Epoch: 12 [11648/14860 (78%)]\tLoss: 0.026479\n",
      "Train Epoch: 12 [11776/14860 (79%)]\tLoss: 0.017103\n",
      "Train Epoch: 12 [11904/14860 (79%)]\tLoss: 0.020984\n",
      "Train Epoch: 12 [12032/14860 (80%)]\tLoss: 0.026513\n",
      "Train Epoch: 12 [12160/14860 (81%)]\tLoss: 0.014075\n",
      "Train Epoch: 12 [12288/14860 (82%)]\tLoss: 0.021111\n",
      "Train Epoch: 12 [12416/14860 (83%)]\tLoss: 0.022337\n",
      "Train Epoch: 12 [12544/14860 (84%)]\tLoss: 0.020947\n",
      "Train Epoch: 12 [12672/14860 (85%)]\tLoss: 0.023250\n",
      "Train Epoch: 12 [12800/14860 (85%)]\tLoss: 0.017495\n",
      "Train Epoch: 12 [12928/14860 (86%)]\tLoss: 0.026031\n",
      "Train Epoch: 12 [13056/14860 (87%)]\tLoss: 0.022947\n",
      "Train Epoch: 12 [13184/14860 (88%)]\tLoss: 0.018957\n",
      "Train Epoch: 12 [13312/14860 (89%)]\tLoss: 0.018356\n",
      "Train Epoch: 12 [13440/14860 (90%)]\tLoss: 0.018736\n",
      "Train Epoch: 12 [13568/14860 (91%)]\tLoss: 0.024080\n",
      "Train Epoch: 12 [13696/14860 (91%)]\tLoss: 0.020203\n",
      "Train Epoch: 12 [13824/14860 (92%)]\tLoss: 0.024755\n",
      "Train Epoch: 12 [13952/14860 (93%)]\tLoss: 0.025280\n",
      "Train Epoch: 12 [14080/14860 (94%)]\tLoss: 0.025634\n",
      "Train Epoch: 12 [14208/14860 (95%)]\tLoss: 0.020990\n",
      "Train Epoch: 12 [14336/14860 (96%)]\tLoss: 0.019907\n",
      "Train Epoch: 12 [14464/14860 (97%)]\tLoss: 0.026263\n",
      "Train Epoch: 12 [14592/14860 (97%)]\tLoss: 0.022020\n",
      "Train Epoch: 12 [14720/14860 (98%)]\tLoss: 0.020532\n",
      "Train Epoch: 12 [1392/14860 (99%)]\tLoss: 0.025232\n",
      "epoch 12 training loss: 0.020943140810053062\n",
      "epoch 12 validation loss: 0.024698170564942442\n",
      "Train Epoch: 13 [0/14860 (0%)]\tLoss: 0.026866\n",
      "Train Epoch: 13 [128/14860 (1%)]\tLoss: 0.022140\n",
      "Train Epoch: 13 [256/14860 (2%)]\tLoss: 0.018776\n",
      "Train Epoch: 13 [384/14860 (3%)]\tLoss: 0.030329\n",
      "Train Epoch: 13 [512/14860 (3%)]\tLoss: 0.019230\n",
      "Train Epoch: 13 [640/14860 (4%)]\tLoss: 0.020423\n",
      "Train Epoch: 13 [768/14860 (5%)]\tLoss: 0.024480\n",
      "Train Epoch: 13 [896/14860 (6%)]\tLoss: 0.023703\n",
      "Train Epoch: 13 [1024/14860 (7%)]\tLoss: 0.017107\n",
      "Train Epoch: 13 [1152/14860 (8%)]\tLoss: 0.034227\n",
      "Train Epoch: 13 [1280/14860 (9%)]\tLoss: 0.018377\n",
      "Train Epoch: 13 [1408/14860 (9%)]\tLoss: 0.030190\n",
      "Train Epoch: 13 [1536/14860 (10%)]\tLoss: 0.019598\n",
      "Train Epoch: 13 [1664/14860 (11%)]\tLoss: 0.022377\n",
      "Train Epoch: 13 [1792/14860 (12%)]\tLoss: 0.019799\n",
      "Train Epoch: 13 [1920/14860 (13%)]\tLoss: 0.018328\n",
      "Train Epoch: 13 [2048/14860 (14%)]\tLoss: 0.021767\n",
      "Train Epoch: 13 [2176/14860 (15%)]\tLoss: 0.028108\n",
      "Train Epoch: 13 [2304/14860 (15%)]\tLoss: 0.024939\n",
      "Train Epoch: 13 [2432/14860 (16%)]\tLoss: 0.027756\n",
      "Train Epoch: 13 [2560/14860 (17%)]\tLoss: 0.023240\n",
      "Train Epoch: 13 [2688/14860 (18%)]\tLoss: 0.016246\n",
      "Train Epoch: 13 [2816/14860 (19%)]\tLoss: 0.021815\n",
      "Train Epoch: 13 [2944/14860 (20%)]\tLoss: 0.025026\n",
      "Train Epoch: 13 [3072/14860 (21%)]\tLoss: 0.019490\n",
      "Train Epoch: 13 [3200/14860 (21%)]\tLoss: 0.022002\n",
      "Train Epoch: 13 [3328/14860 (22%)]\tLoss: 0.022202\n",
      "Train Epoch: 13 [3456/14860 (23%)]\tLoss: 0.018749\n",
      "Train Epoch: 13 [3584/14860 (24%)]\tLoss: 0.019744\n",
      "Train Epoch: 13 [3712/14860 (25%)]\tLoss: 0.017648\n",
      "Train Epoch: 13 [3840/14860 (26%)]\tLoss: 0.024895\n",
      "Train Epoch: 13 [3968/14860 (26%)]\tLoss: 0.015352\n",
      "Train Epoch: 13 [4096/14860 (27%)]\tLoss: 0.019083\n",
      "Train Epoch: 13 [4224/14860 (28%)]\tLoss: 0.021442\n",
      "Train Epoch: 13 [4352/14860 (29%)]\tLoss: 0.022298\n",
      "Train Epoch: 13 [4480/14860 (30%)]\tLoss: 0.016087\n",
      "Train Epoch: 13 [4608/14860 (31%)]\tLoss: 0.019380\n",
      "Train Epoch: 13 [4736/14860 (32%)]\tLoss: 0.013881\n",
      "Train Epoch: 13 [4864/14860 (32%)]\tLoss: 0.015709\n",
      "Train Epoch: 13 [4992/14860 (33%)]\tLoss: 0.015306\n",
      "Train Epoch: 13 [5120/14860 (34%)]\tLoss: 0.018945\n",
      "Train Epoch: 13 [5248/14860 (35%)]\tLoss: 0.018341\n",
      "Train Epoch: 13 [5376/14860 (36%)]\tLoss: 0.022860\n",
      "Train Epoch: 13 [5504/14860 (37%)]\tLoss: 0.021582\n",
      "Train Epoch: 13 [5632/14860 (38%)]\tLoss: 0.018905\n",
      "Train Epoch: 13 [5760/14860 (38%)]\tLoss: 0.025844\n",
      "Train Epoch: 13 [5888/14860 (39%)]\tLoss: 0.026885\n",
      "Train Epoch: 13 [6016/14860 (40%)]\tLoss: 0.018806\n",
      "Train Epoch: 13 [6144/14860 (41%)]\tLoss: 0.022345\n",
      "Train Epoch: 13 [6272/14860 (42%)]\tLoss: 0.019737\n",
      "Train Epoch: 13 [6400/14860 (43%)]\tLoss: 0.019670\n",
      "Train Epoch: 13 [6528/14860 (44%)]\tLoss: 0.021579\n",
      "Train Epoch: 13 [6656/14860 (44%)]\tLoss: 0.020812\n",
      "Train Epoch: 13 [6784/14860 (45%)]\tLoss: 0.020867\n",
      "Train Epoch: 13 [6912/14860 (46%)]\tLoss: 0.016332\n",
      "Train Epoch: 13 [7040/14860 (47%)]\tLoss: 0.022544\n",
      "Train Epoch: 13 [7168/14860 (48%)]\tLoss: 0.017139\n",
      "Train Epoch: 13 [7296/14860 (49%)]\tLoss: 0.019119\n",
      "Train Epoch: 13 [7424/14860 (50%)]\tLoss: 0.020502\n",
      "Train Epoch: 13 [7552/14860 (50%)]\tLoss: 0.014040\n",
      "Train Epoch: 13 [7680/14860 (51%)]\tLoss: 0.017238\n",
      "Train Epoch: 13 [7808/14860 (52%)]\tLoss: 0.027785\n",
      "Train Epoch: 13 [7936/14860 (53%)]\tLoss: 0.019599\n",
      "Train Epoch: 13 [8064/14860 (54%)]\tLoss: 0.018921\n",
      "Train Epoch: 13 [8192/14860 (55%)]\tLoss: 0.016108\n",
      "Train Epoch: 13 [8320/14860 (56%)]\tLoss: 0.020418\n",
      "Train Epoch: 13 [8448/14860 (56%)]\tLoss: 0.016713\n",
      "Train Epoch: 13 [8576/14860 (57%)]\tLoss: 0.016738\n",
      "Train Epoch: 13 [8704/14860 (58%)]\tLoss: 0.014371\n",
      "Train Epoch: 13 [8832/14860 (59%)]\tLoss: 0.015827\n",
      "Train Epoch: 13 [8960/14860 (60%)]\tLoss: 0.016627\n",
      "Train Epoch: 13 [9088/14860 (61%)]\tLoss: 0.023157\n",
      "Train Epoch: 13 [9216/14860 (62%)]\tLoss: 0.026669\n",
      "Train Epoch: 13 [9344/14860 (62%)]\tLoss: 0.017527\n",
      "Train Epoch: 13 [9472/14860 (63%)]\tLoss: 0.021950\n",
      "Train Epoch: 13 [9600/14860 (64%)]\tLoss: 0.017469\n",
      "Train Epoch: 13 [9728/14860 (65%)]\tLoss: 0.025635\n",
      "Train Epoch: 13 [9856/14860 (66%)]\tLoss: 0.015343\n",
      "Train Epoch: 13 [9984/14860 (67%)]\tLoss: 0.015743\n",
      "Train Epoch: 13 [10112/14860 (68%)]\tLoss: 0.017550\n",
      "Train Epoch: 13 [10240/14860 (68%)]\tLoss: 0.023639\n",
      "Train Epoch: 13 [10368/14860 (69%)]\tLoss: 0.019327\n",
      "Train Epoch: 13 [10496/14860 (70%)]\tLoss: 0.022990\n",
      "Train Epoch: 13 [10624/14860 (71%)]\tLoss: 0.018299\n",
      "Train Epoch: 13 [10752/14860 (72%)]\tLoss: 0.020854\n",
      "Train Epoch: 13 [10880/14860 (73%)]\tLoss: 0.013181\n",
      "Train Epoch: 13 [11008/14860 (74%)]\tLoss: 0.027381\n",
      "Train Epoch: 13 [11136/14860 (74%)]\tLoss: 0.023021\n",
      "Train Epoch: 13 [11264/14860 (75%)]\tLoss: 0.017548\n",
      "Train Epoch: 13 [11392/14860 (76%)]\tLoss: 0.018959\n",
      "Train Epoch: 13 [11520/14860 (77%)]\tLoss: 0.020180\n",
      "Train Epoch: 13 [11648/14860 (78%)]\tLoss: 0.023955\n",
      "Train Epoch: 13 [11776/14860 (79%)]\tLoss: 0.024060\n",
      "Train Epoch: 13 [11904/14860 (79%)]\tLoss: 0.018214\n",
      "Train Epoch: 13 [12032/14860 (80%)]\tLoss: 0.020779\n",
      "Train Epoch: 13 [12160/14860 (81%)]\tLoss: 0.022337\n",
      "Train Epoch: 13 [12288/14860 (82%)]\tLoss: 0.029329\n",
      "Train Epoch: 13 [12416/14860 (83%)]\tLoss: 0.025474\n",
      "Train Epoch: 13 [12544/14860 (84%)]\tLoss: 0.025995\n",
      "Train Epoch: 13 [12672/14860 (85%)]\tLoss: 0.014058\n",
      "Train Epoch: 13 [12800/14860 (85%)]\tLoss: 0.029175\n",
      "Train Epoch: 13 [12928/14860 (86%)]\tLoss: 0.018972\n",
      "Train Epoch: 13 [13056/14860 (87%)]\tLoss: 0.026434\n",
      "Train Epoch: 13 [13184/14860 (88%)]\tLoss: 0.012627\n",
      "Train Epoch: 13 [13312/14860 (89%)]\tLoss: 0.016017\n",
      "Train Epoch: 13 [13440/14860 (90%)]\tLoss: 0.022664\n",
      "Train Epoch: 13 [13568/14860 (91%)]\tLoss: 0.019596\n",
      "Train Epoch: 13 [13696/14860 (91%)]\tLoss: 0.021730\n",
      "Train Epoch: 13 [13824/14860 (92%)]\tLoss: 0.023296\n",
      "Train Epoch: 13 [13952/14860 (93%)]\tLoss: 0.021514\n",
      "Train Epoch: 13 [14080/14860 (94%)]\tLoss: 0.016943\n",
      "Train Epoch: 13 [14208/14860 (95%)]\tLoss: 0.029181\n",
      "Train Epoch: 13 [14336/14860 (96%)]\tLoss: 0.016861\n",
      "Train Epoch: 13 [14464/14860 (97%)]\tLoss: 0.020777\n",
      "Train Epoch: 13 [14592/14860 (97%)]\tLoss: 0.016168\n",
      "Train Epoch: 13 [14720/14860 (98%)]\tLoss: 0.020076\n",
      "Train Epoch: 13 [1392/14860 (99%)]\tLoss: 0.011121\n",
      "epoch 13 training loss: 0.02067599722590202\n",
      "epoch 13 validation loss: 0.021041766783227066\n",
      "Train Epoch: 14 [0/14860 (0%)]\tLoss: 0.020484\n",
      "Train Epoch: 14 [128/14860 (1%)]\tLoss: 0.017907\n",
      "Train Epoch: 14 [256/14860 (2%)]\tLoss: 0.017685\n",
      "Train Epoch: 14 [384/14860 (3%)]\tLoss: 0.017737\n",
      "Train Epoch: 14 [512/14860 (3%)]\tLoss: 0.021191\n",
      "Train Epoch: 14 [640/14860 (4%)]\tLoss: 0.016459\n",
      "Train Epoch: 14 [768/14860 (5%)]\tLoss: 0.023463\n",
      "Train Epoch: 14 [896/14860 (6%)]\tLoss: 0.020347\n",
      "Train Epoch: 14 [1024/14860 (7%)]\tLoss: 0.026567\n",
      "Train Epoch: 14 [1152/14860 (8%)]\tLoss: 0.019110\n",
      "Train Epoch: 14 [1280/14860 (9%)]\tLoss: 0.018083\n",
      "Train Epoch: 14 [1408/14860 (9%)]\tLoss: 0.024781\n",
      "Train Epoch: 14 [1536/14860 (10%)]\tLoss: 0.013821\n",
      "Train Epoch: 14 [1664/14860 (11%)]\tLoss: 0.022553\n",
      "Train Epoch: 14 [1792/14860 (12%)]\tLoss: 0.013408\n",
      "Train Epoch: 14 [1920/14860 (13%)]\tLoss: 0.027111\n",
      "Train Epoch: 14 [2048/14860 (14%)]\tLoss: 0.015630\n",
      "Train Epoch: 14 [2176/14860 (15%)]\tLoss: 0.023239\n",
      "Train Epoch: 14 [2304/14860 (15%)]\tLoss: 0.020813\n",
      "Train Epoch: 14 [2432/14860 (16%)]\tLoss: 0.025028\n",
      "Train Epoch: 14 [2560/14860 (17%)]\tLoss: 0.024218\n",
      "Train Epoch: 14 [2688/14860 (18%)]\tLoss: 0.016587\n",
      "Train Epoch: 14 [2816/14860 (19%)]\tLoss: 0.018412\n",
      "Train Epoch: 14 [2944/14860 (20%)]\tLoss: 0.020762\n",
      "Train Epoch: 14 [3072/14860 (21%)]\tLoss: 0.021634\n",
      "Train Epoch: 14 [3200/14860 (21%)]\tLoss: 0.016900\n",
      "Train Epoch: 14 [3328/14860 (22%)]\tLoss: 0.017836\n",
      "Train Epoch: 14 [3456/14860 (23%)]\tLoss: 0.020384\n",
      "Train Epoch: 14 [3584/14860 (24%)]\tLoss: 0.014980\n",
      "Train Epoch: 14 [3712/14860 (25%)]\tLoss: 0.015701\n",
      "Train Epoch: 14 [3840/14860 (26%)]\tLoss: 0.022036\n",
      "Train Epoch: 14 [3968/14860 (26%)]\tLoss: 0.011752\n",
      "Train Epoch: 14 [4096/14860 (27%)]\tLoss: 0.017763\n",
      "Train Epoch: 14 [4224/14860 (28%)]\tLoss: 0.020927\n",
      "Train Epoch: 14 [4352/14860 (29%)]\tLoss: 0.027484\n",
      "Train Epoch: 14 [4480/14860 (30%)]\tLoss: 0.019352\n",
      "Train Epoch: 14 [4608/14860 (31%)]\tLoss: 0.024327\n",
      "Train Epoch: 14 [4736/14860 (32%)]\tLoss: 0.022190\n",
      "Train Epoch: 14 [4864/14860 (32%)]\tLoss: 0.019486\n",
      "Train Epoch: 14 [4992/14860 (33%)]\tLoss: 0.019733\n",
      "Train Epoch: 14 [5120/14860 (34%)]\tLoss: 0.009573\n",
      "Train Epoch: 14 [5248/14860 (35%)]\tLoss: 0.021205\n",
      "Train Epoch: 14 [5376/14860 (36%)]\tLoss: 0.017509\n",
      "Train Epoch: 14 [5504/14860 (37%)]\tLoss: 0.014775\n",
      "Train Epoch: 14 [5632/14860 (38%)]\tLoss: 0.020367\n",
      "Train Epoch: 14 [5760/14860 (38%)]\tLoss: 0.019100\n",
      "Train Epoch: 14 [5888/14860 (39%)]\tLoss: 0.020353\n",
      "Train Epoch: 14 [6016/14860 (40%)]\tLoss: 0.021912\n",
      "Train Epoch: 14 [6144/14860 (41%)]\tLoss: 0.017665\n",
      "Train Epoch: 14 [6272/14860 (42%)]\tLoss: 0.020933\n",
      "Train Epoch: 14 [6400/14860 (43%)]\tLoss: 0.020953\n",
      "Train Epoch: 14 [6528/14860 (44%)]\tLoss: 0.018892\n",
      "Train Epoch: 14 [6656/14860 (44%)]\tLoss: 0.018754\n",
      "Train Epoch: 14 [6784/14860 (45%)]\tLoss: 0.036153\n",
      "Train Epoch: 14 [6912/14860 (46%)]\tLoss: 0.024257\n",
      "Train Epoch: 14 [7040/14860 (47%)]\tLoss: 0.016579\n",
      "Train Epoch: 14 [7168/14860 (48%)]\tLoss: 0.025896\n",
      "Train Epoch: 14 [7296/14860 (49%)]\tLoss: 0.026452\n",
      "Train Epoch: 14 [7424/14860 (50%)]\tLoss: 0.020169\n",
      "Train Epoch: 14 [7552/14860 (50%)]\tLoss: 0.024938\n",
      "Train Epoch: 14 [7680/14860 (51%)]\tLoss: 0.025804\n",
      "Train Epoch: 14 [7808/14860 (52%)]\tLoss: 0.025074\n",
      "Train Epoch: 14 [7936/14860 (53%)]\tLoss: 0.020974\n",
      "Train Epoch: 14 [8064/14860 (54%)]\tLoss: 0.028435\n",
      "Train Epoch: 14 [8192/14860 (55%)]\tLoss: 0.017875\n",
      "Train Epoch: 14 [8320/14860 (56%)]\tLoss: 0.015829\n",
      "Train Epoch: 14 [8448/14860 (56%)]\tLoss: 0.028553\n",
      "Train Epoch: 14 [8576/14860 (57%)]\tLoss: 0.021986\n",
      "Train Epoch: 14 [8704/14860 (58%)]\tLoss: 0.021260\n",
      "Train Epoch: 14 [8832/14860 (59%)]\tLoss: 0.017147\n",
      "Train Epoch: 14 [8960/14860 (60%)]\tLoss: 0.019688\n",
      "Train Epoch: 14 [9088/14860 (61%)]\tLoss: 0.024237\n",
      "Train Epoch: 14 [9216/14860 (62%)]\tLoss: 0.020393\n",
      "Train Epoch: 14 [9344/14860 (62%)]\tLoss: 0.025849\n",
      "Train Epoch: 14 [9472/14860 (63%)]\tLoss: 0.022149\n",
      "Train Epoch: 14 [9600/14860 (64%)]\tLoss: 0.020974\n",
      "Train Epoch: 14 [9728/14860 (65%)]\tLoss: 0.021203\n",
      "Train Epoch: 14 [9856/14860 (66%)]\tLoss: 0.019972\n",
      "Train Epoch: 14 [9984/14860 (67%)]\tLoss: 0.014254\n",
      "Train Epoch: 14 [10112/14860 (68%)]\tLoss: 0.020238\n",
      "Train Epoch: 14 [10240/14860 (68%)]\tLoss: 0.018997\n",
      "Train Epoch: 14 [10368/14860 (69%)]\tLoss: 0.016184\n",
      "Train Epoch: 14 [10496/14860 (70%)]\tLoss: 0.018247\n",
      "Train Epoch: 14 [10624/14860 (71%)]\tLoss: 0.019073\n",
      "Train Epoch: 14 [10752/14860 (72%)]\tLoss: 0.026768\n",
      "Train Epoch: 14 [10880/14860 (73%)]\tLoss: 0.025984\n",
      "Train Epoch: 14 [11008/14860 (74%)]\tLoss: 0.015591\n",
      "Train Epoch: 14 [11136/14860 (74%)]\tLoss: 0.015316\n",
      "Train Epoch: 14 [11264/14860 (75%)]\tLoss: 0.027019\n",
      "Train Epoch: 14 [11392/14860 (76%)]\tLoss: 0.018393\n",
      "Train Epoch: 14 [11520/14860 (77%)]\tLoss: 0.020537\n",
      "Train Epoch: 14 [11648/14860 (78%)]\tLoss: 0.016152\n",
      "Train Epoch: 14 [11776/14860 (79%)]\tLoss: 0.020570\n",
      "Train Epoch: 14 [11904/14860 (79%)]\tLoss: 0.017412\n",
      "Train Epoch: 14 [12032/14860 (80%)]\tLoss: 0.016057\n",
      "Train Epoch: 14 [12160/14860 (81%)]\tLoss: 0.027111\n",
      "Train Epoch: 14 [12288/14860 (82%)]\tLoss: 0.022057\n",
      "Train Epoch: 14 [12416/14860 (83%)]\tLoss: 0.022969\n",
      "Train Epoch: 14 [12544/14860 (84%)]\tLoss: 0.021390\n",
      "Train Epoch: 14 [12672/14860 (85%)]\tLoss: 0.015545\n",
      "Train Epoch: 14 [12800/14860 (85%)]\tLoss: 0.025863\n",
      "Train Epoch: 14 [12928/14860 (86%)]\tLoss: 0.015361\n",
      "Train Epoch: 14 [13056/14860 (87%)]\tLoss: 0.020981\n",
      "Train Epoch: 14 [13184/14860 (88%)]\tLoss: 0.023374\n",
      "Train Epoch: 14 [13312/14860 (89%)]\tLoss: 0.022499\n",
      "Train Epoch: 14 [13440/14860 (90%)]\tLoss: 0.024883\n",
      "Train Epoch: 14 [13568/14860 (91%)]\tLoss: 0.015514\n",
      "Train Epoch: 14 [13696/14860 (91%)]\tLoss: 0.014750\n",
      "Train Epoch: 14 [13824/14860 (92%)]\tLoss: 0.013870\n",
      "Train Epoch: 14 [13952/14860 (93%)]\tLoss: 0.020342\n",
      "Train Epoch: 14 [14080/14860 (94%)]\tLoss: 0.019091\n",
      "Train Epoch: 14 [14208/14860 (95%)]\tLoss: 0.017129\n",
      "Train Epoch: 14 [14336/14860 (96%)]\tLoss: 0.020192\n",
      "Train Epoch: 14 [14464/14860 (97%)]\tLoss: 0.016455\n",
      "Train Epoch: 14 [14592/14860 (97%)]\tLoss: 0.013999\n",
      "Train Epoch: 14 [14720/14860 (98%)]\tLoss: 0.021941\n",
      "Train Epoch: 14 [1392/14860 (99%)]\tLoss: 0.011470\n",
      "epoch 14 training loss: 0.020216126209841326\n",
      "epoch 14 validation loss: 0.021349273495754953\n",
      "Train Epoch: 15 [0/14860 (0%)]\tLoss: 0.031213\n",
      "Train Epoch: 15 [128/14860 (1%)]\tLoss: 0.018809\n",
      "Train Epoch: 15 [256/14860 (2%)]\tLoss: 0.024672\n",
      "Train Epoch: 15 [384/14860 (3%)]\tLoss: 0.021772\n",
      "Train Epoch: 15 [512/14860 (3%)]\tLoss: 0.017414\n",
      "Train Epoch: 15 [640/14860 (4%)]\tLoss: 0.020308\n",
      "Train Epoch: 15 [768/14860 (5%)]\tLoss: 0.015784\n",
      "Train Epoch: 15 [896/14860 (6%)]\tLoss: 0.013063\n",
      "Train Epoch: 15 [1024/14860 (7%)]\tLoss: 0.015449\n",
      "Train Epoch: 15 [1152/14860 (8%)]\tLoss: 0.018631\n",
      "Train Epoch: 15 [1280/14860 (9%)]\tLoss: 0.015904\n",
      "Train Epoch: 15 [1408/14860 (9%)]\tLoss: 0.019825\n",
      "Train Epoch: 15 [1536/14860 (10%)]\tLoss: 0.023441\n",
      "Train Epoch: 15 [1664/14860 (11%)]\tLoss: 0.024053\n",
      "Train Epoch: 15 [1792/14860 (12%)]\tLoss: 0.019268\n",
      "Train Epoch: 15 [1920/14860 (13%)]\tLoss: 0.017980\n",
      "Train Epoch: 15 [2048/14860 (14%)]\tLoss: 0.028557\n",
      "Train Epoch: 15 [2176/14860 (15%)]\tLoss: 0.017411\n",
      "Train Epoch: 15 [2304/14860 (15%)]\tLoss: 0.027330\n",
      "Train Epoch: 15 [2432/14860 (16%)]\tLoss: 0.021853\n",
      "Train Epoch: 15 [2560/14860 (17%)]\tLoss: 0.024402\n",
      "Train Epoch: 15 [2688/14860 (18%)]\tLoss: 0.018935\n",
      "Train Epoch: 15 [2816/14860 (19%)]\tLoss: 0.015767\n",
      "Train Epoch: 15 [2944/14860 (20%)]\tLoss: 0.015019\n",
      "Train Epoch: 15 [3072/14860 (21%)]\tLoss: 0.023491\n",
      "Train Epoch: 15 [3200/14860 (21%)]\tLoss: 0.020794\n",
      "Train Epoch: 15 [3328/14860 (22%)]\tLoss: 0.022661\n",
      "Train Epoch: 15 [3456/14860 (23%)]\tLoss: 0.022705\n",
      "Train Epoch: 15 [3584/14860 (24%)]\tLoss: 0.019689\n",
      "Train Epoch: 15 [3712/14860 (25%)]\tLoss: 0.016940\n",
      "Train Epoch: 15 [3840/14860 (26%)]\tLoss: 0.030741\n",
      "Train Epoch: 15 [3968/14860 (26%)]\tLoss: 0.020328\n",
      "Train Epoch: 15 [4096/14860 (27%)]\tLoss: 0.018917\n",
      "Train Epoch: 15 [4224/14860 (28%)]\tLoss: 0.019489\n",
      "Train Epoch: 15 [4352/14860 (29%)]\tLoss: 0.021122\n",
      "Train Epoch: 15 [4480/14860 (30%)]\tLoss: 0.017451\n",
      "Train Epoch: 15 [4608/14860 (31%)]\tLoss: 0.016794\n",
      "Train Epoch: 15 [4736/14860 (32%)]\tLoss: 0.020805\n",
      "Train Epoch: 15 [4864/14860 (32%)]\tLoss: 0.018678\n",
      "Train Epoch: 15 [4992/14860 (33%)]\tLoss: 0.020967\n",
      "Train Epoch: 15 [5120/14860 (34%)]\tLoss: 0.023886\n",
      "Train Epoch: 15 [5248/14860 (35%)]\tLoss: 0.018992\n",
      "Train Epoch: 15 [5376/14860 (36%)]\tLoss: 0.014828\n",
      "Train Epoch: 15 [5504/14860 (37%)]\tLoss: 0.017488\n",
      "Train Epoch: 15 [5632/14860 (38%)]\tLoss: 0.018990\n",
      "Train Epoch: 15 [5760/14860 (38%)]\tLoss: 0.016705\n",
      "Train Epoch: 15 [5888/14860 (39%)]\tLoss: 0.024072\n",
      "Train Epoch: 15 [6016/14860 (40%)]\tLoss: 0.019301\n",
      "Train Epoch: 15 [6144/14860 (41%)]\tLoss: 0.021541\n",
      "Train Epoch: 15 [6272/14860 (42%)]\tLoss: 0.023150\n",
      "Train Epoch: 15 [6400/14860 (43%)]\tLoss: 0.014724\n",
      "Train Epoch: 15 [6528/14860 (44%)]\tLoss: 0.019214\n",
      "Train Epoch: 15 [6656/14860 (44%)]\tLoss: 0.016252\n",
      "Train Epoch: 15 [6784/14860 (45%)]\tLoss: 0.030171\n",
      "Train Epoch: 15 [6912/14860 (46%)]\tLoss: 0.018188\n",
      "Train Epoch: 15 [7040/14860 (47%)]\tLoss: 0.019572\n",
      "Train Epoch: 15 [7168/14860 (48%)]\tLoss: 0.020405\n",
      "Train Epoch: 15 [7296/14860 (49%)]\tLoss: 0.021437\n",
      "Train Epoch: 15 [7424/14860 (50%)]\tLoss: 0.027947\n",
      "Train Epoch: 15 [7552/14860 (50%)]\tLoss: 0.014705\n",
      "Train Epoch: 15 [7680/14860 (51%)]\tLoss: 0.019882\n",
      "Train Epoch: 15 [7808/14860 (52%)]\tLoss: 0.016932\n",
      "Train Epoch: 15 [7936/14860 (53%)]\tLoss: 0.016446\n",
      "Train Epoch: 15 [8064/14860 (54%)]\tLoss: 0.021589\n",
      "Train Epoch: 15 [8192/14860 (55%)]\tLoss: 0.019742\n",
      "Train Epoch: 15 [8320/14860 (56%)]\tLoss: 0.017890\n",
      "Train Epoch: 15 [8448/14860 (56%)]\tLoss: 0.018605\n",
      "Train Epoch: 15 [8576/14860 (57%)]\tLoss: 0.022406\n",
      "Train Epoch: 15 [8704/14860 (58%)]\tLoss: 0.026297\n",
      "Train Epoch: 15 [8832/14860 (59%)]\tLoss: 0.026358\n",
      "Train Epoch: 15 [8960/14860 (60%)]\tLoss: 0.024499\n",
      "Train Epoch: 15 [9088/14860 (61%)]\tLoss: 0.027802\n",
      "Train Epoch: 15 [9216/14860 (62%)]\tLoss: 0.017856\n",
      "Train Epoch: 15 [9344/14860 (62%)]\tLoss: 0.019323\n",
      "Train Epoch: 15 [9472/14860 (63%)]\tLoss: 0.020105\n",
      "Train Epoch: 15 [9600/14860 (64%)]\tLoss: 0.020602\n",
      "Train Epoch: 15 [9728/14860 (65%)]\tLoss: 0.020759\n",
      "Train Epoch: 15 [9856/14860 (66%)]\tLoss: 0.024138\n",
      "Train Epoch: 15 [9984/14860 (67%)]\tLoss: 0.023220\n",
      "Train Epoch: 15 [10112/14860 (68%)]\tLoss: 0.020996\n",
      "Train Epoch: 15 [10240/14860 (68%)]\tLoss: 0.025255\n",
      "Train Epoch: 15 [10368/14860 (69%)]\tLoss: 0.022808\n",
      "Train Epoch: 15 [10496/14860 (70%)]\tLoss: 0.019598\n",
      "Train Epoch: 15 [10624/14860 (71%)]\tLoss: 0.022469\n",
      "Train Epoch: 15 [10752/14860 (72%)]\tLoss: 0.016617\n",
      "Train Epoch: 15 [10880/14860 (73%)]\tLoss: 0.019700\n",
      "Train Epoch: 15 [11008/14860 (74%)]\tLoss: 0.019284\n",
      "Train Epoch: 15 [11136/14860 (74%)]\tLoss: 0.020441\n",
      "Train Epoch: 15 [11264/14860 (75%)]\tLoss: 0.015716\n",
      "Train Epoch: 15 [11392/14860 (76%)]\tLoss: 0.027888\n",
      "Train Epoch: 15 [11520/14860 (77%)]\tLoss: 0.021994\n",
      "Train Epoch: 15 [11648/14860 (78%)]\tLoss: 0.018301\n",
      "Train Epoch: 15 [11776/14860 (79%)]\tLoss: 0.013774\n",
      "Train Epoch: 15 [11904/14860 (79%)]\tLoss: 0.013613\n",
      "Train Epoch: 15 [12032/14860 (80%)]\tLoss: 0.016177\n",
      "Train Epoch: 15 [12160/14860 (81%)]\tLoss: 0.021290\n",
      "Train Epoch: 15 [12288/14860 (82%)]\tLoss: 0.023056\n",
      "Train Epoch: 15 [12416/14860 (83%)]\tLoss: 0.021890\n",
      "Train Epoch: 15 [12544/14860 (84%)]\tLoss: 0.019802\n",
      "Train Epoch: 15 [12672/14860 (85%)]\tLoss: 0.015125\n",
      "Train Epoch: 15 [12800/14860 (85%)]\tLoss: 0.026944\n",
      "Train Epoch: 15 [12928/14860 (86%)]\tLoss: 0.019997\n",
      "Train Epoch: 15 [13056/14860 (87%)]\tLoss: 0.024025\n",
      "Train Epoch: 15 [13184/14860 (88%)]\tLoss: 0.029560\n",
      "Train Epoch: 15 [13312/14860 (89%)]\tLoss: 0.016949\n",
      "Train Epoch: 15 [13440/14860 (90%)]\tLoss: 0.023539\n",
      "Train Epoch: 15 [13568/14860 (91%)]\tLoss: 0.018640\n",
      "Train Epoch: 15 [13696/14860 (91%)]\tLoss: 0.030846\n",
      "Train Epoch: 15 [13824/14860 (92%)]\tLoss: 0.028699\n",
      "Train Epoch: 15 [13952/14860 (93%)]\tLoss: 0.013250\n",
      "Train Epoch: 15 [14080/14860 (94%)]\tLoss: 0.039229\n",
      "Train Epoch: 15 [14208/14860 (95%)]\tLoss: 0.026538\n",
      "Train Epoch: 15 [14336/14860 (96%)]\tLoss: 0.023562\n",
      "Train Epoch: 15 [14464/14860 (97%)]\tLoss: 0.025974\n",
      "Train Epoch: 15 [14592/14860 (97%)]\tLoss: 0.022089\n",
      "Train Epoch: 15 [14720/14860 (98%)]\tLoss: 0.027738\n",
      "Train Epoch: 15 [1392/14860 (99%)]\tLoss: 0.028806\n",
      "epoch 15 training loss: 0.021082298073949467\n",
      "epoch 15 validation loss: 0.020972975229812882\n",
      "Train Epoch: 16 [0/14860 (0%)]\tLoss: 0.024563\n",
      "Train Epoch: 16 [128/14860 (1%)]\tLoss: 0.028320\n",
      "Train Epoch: 16 [256/14860 (2%)]\tLoss: 0.020764\n",
      "Train Epoch: 16 [384/14860 (3%)]\tLoss: 0.015281\n",
      "Train Epoch: 16 [512/14860 (3%)]\tLoss: 0.018053\n",
      "Train Epoch: 16 [640/14860 (4%)]\tLoss: 0.023384\n",
      "Train Epoch: 16 [768/14860 (5%)]\tLoss: 0.021691\n",
      "Train Epoch: 16 [896/14860 (6%)]\tLoss: 0.024898\n",
      "Train Epoch: 16 [1024/14860 (7%)]\tLoss: 0.031734\n",
      "Train Epoch: 16 [1152/14860 (8%)]\tLoss: 0.020360\n",
      "Train Epoch: 16 [1280/14860 (9%)]\tLoss: 0.026218\n",
      "Train Epoch: 16 [1408/14860 (9%)]\tLoss: 0.028807\n",
      "Train Epoch: 16 [1536/14860 (10%)]\tLoss: 0.035081\n",
      "Train Epoch: 16 [1664/14860 (11%)]\tLoss: 0.026401\n",
      "Train Epoch: 16 [1792/14860 (12%)]\tLoss: 0.031843\n",
      "Train Epoch: 16 [1920/14860 (13%)]\tLoss: 0.018643\n",
      "Train Epoch: 16 [2048/14860 (14%)]\tLoss: 0.025045\n",
      "Train Epoch: 16 [2176/14860 (15%)]\tLoss: 0.038249\n",
      "Train Epoch: 16 [2304/14860 (15%)]\tLoss: 0.014528\n",
      "Train Epoch: 16 [2432/14860 (16%)]\tLoss: 0.024410\n",
      "Train Epoch: 16 [2560/14860 (17%)]\tLoss: 0.021836\n",
      "Train Epoch: 16 [2688/14860 (18%)]\tLoss: 0.021631\n",
      "Train Epoch: 16 [2816/14860 (19%)]\tLoss: 0.023478\n",
      "Train Epoch: 16 [2944/14860 (20%)]\tLoss: 0.023439\n",
      "Train Epoch: 16 [3072/14860 (21%)]\tLoss: 0.025171\n",
      "Train Epoch: 16 [3200/14860 (21%)]\tLoss: 0.023135\n",
      "Train Epoch: 16 [3328/14860 (22%)]\tLoss: 0.022785\n",
      "Train Epoch: 16 [3456/14860 (23%)]\tLoss: 0.023389\n",
      "Train Epoch: 16 [3584/14860 (24%)]\tLoss: 0.017505\n",
      "Train Epoch: 16 [3712/14860 (25%)]\tLoss: 0.012237\n",
      "Train Epoch: 16 [3840/14860 (26%)]\tLoss: 0.018755\n",
      "Train Epoch: 16 [3968/14860 (26%)]\tLoss: 0.017342\n",
      "Train Epoch: 16 [4096/14860 (27%)]\tLoss: 0.018725\n",
      "Train Epoch: 16 [4224/14860 (28%)]\tLoss: 0.025291\n",
      "Train Epoch: 16 [4352/14860 (29%)]\tLoss: 0.019198\n",
      "Train Epoch: 16 [4480/14860 (30%)]\tLoss: 0.020055\n",
      "Train Epoch: 16 [4608/14860 (31%)]\tLoss: 0.015468\n",
      "Train Epoch: 16 [4736/14860 (32%)]\tLoss: 0.032451\n",
      "Train Epoch: 16 [4864/14860 (32%)]\tLoss: 0.012064\n",
      "Train Epoch: 16 [4992/14860 (33%)]\tLoss: 0.017984\n",
      "Train Epoch: 16 [5120/14860 (34%)]\tLoss: 0.020073\n",
      "Train Epoch: 16 [5248/14860 (35%)]\tLoss: 0.015991\n",
      "Train Epoch: 16 [5376/14860 (36%)]\tLoss: 0.021140\n",
      "Train Epoch: 16 [5504/14860 (37%)]\tLoss: 0.019213\n",
      "Train Epoch: 16 [5632/14860 (38%)]\tLoss: 0.019467\n",
      "Train Epoch: 16 [5760/14860 (38%)]\tLoss: 0.015925\n",
      "Train Epoch: 16 [5888/14860 (39%)]\tLoss: 0.016138\n",
      "Train Epoch: 16 [6016/14860 (40%)]\tLoss: 0.023318\n",
      "Train Epoch: 16 [6144/14860 (41%)]\tLoss: 0.017310\n",
      "Train Epoch: 16 [6272/14860 (42%)]\tLoss: 0.023784\n",
      "Train Epoch: 16 [6400/14860 (43%)]\tLoss: 0.017696\n",
      "Train Epoch: 16 [6528/14860 (44%)]\tLoss: 0.017680\n",
      "Train Epoch: 16 [6656/14860 (44%)]\tLoss: 0.015102\n",
      "Train Epoch: 16 [6784/14860 (45%)]\tLoss: 0.018984\n",
      "Train Epoch: 16 [6912/14860 (46%)]\tLoss: 0.022766\n",
      "Train Epoch: 16 [7040/14860 (47%)]\tLoss: 0.020801\n",
      "Train Epoch: 16 [7168/14860 (48%)]\tLoss: 0.015229\n",
      "Train Epoch: 16 [7296/14860 (49%)]\tLoss: 0.018586\n",
      "Train Epoch: 16 [7424/14860 (50%)]\tLoss: 0.021121\n",
      "Train Epoch: 16 [7552/14860 (50%)]\tLoss: 0.027190\n",
      "Train Epoch: 16 [7680/14860 (51%)]\tLoss: 0.022858\n",
      "Train Epoch: 16 [7808/14860 (52%)]\tLoss: 0.024364\n",
      "Train Epoch: 16 [7936/14860 (53%)]\tLoss: 0.025977\n",
      "Train Epoch: 16 [8064/14860 (54%)]\tLoss: 0.023878\n",
      "Train Epoch: 16 [8192/14860 (55%)]\tLoss: 0.016043\n",
      "Train Epoch: 16 [8320/14860 (56%)]\tLoss: 0.024858\n",
      "Train Epoch: 16 [8448/14860 (56%)]\tLoss: 0.022320\n",
      "Train Epoch: 16 [8576/14860 (57%)]\tLoss: 0.024218\n",
      "Train Epoch: 16 [8704/14860 (58%)]\tLoss: 0.020937\n",
      "Train Epoch: 16 [8832/14860 (59%)]\tLoss: 0.016940\n",
      "Train Epoch: 16 [8960/14860 (60%)]\tLoss: 0.020835\n",
      "Train Epoch: 16 [9088/14860 (61%)]\tLoss: 0.021779\n",
      "Train Epoch: 16 [9216/14860 (62%)]\tLoss: 0.023164\n",
      "Train Epoch: 16 [9344/14860 (62%)]\tLoss: 0.012573\n",
      "Train Epoch: 16 [9472/14860 (63%)]\tLoss: 0.018188\n",
      "Train Epoch: 16 [9600/14860 (64%)]\tLoss: 0.019272\n",
      "Train Epoch: 16 [9728/14860 (65%)]\tLoss: 0.021855\n",
      "Train Epoch: 16 [9856/14860 (66%)]\tLoss: 0.020072\n",
      "Train Epoch: 16 [9984/14860 (67%)]\tLoss: 0.014950\n",
      "Train Epoch: 16 [10112/14860 (68%)]\tLoss: 0.011585\n",
      "Train Epoch: 16 [10240/14860 (68%)]\tLoss: 0.018339\n",
      "Train Epoch: 16 [10368/14860 (69%)]\tLoss: 0.016987\n",
      "Train Epoch: 16 [10496/14860 (70%)]\tLoss: 0.017671\n",
      "Train Epoch: 16 [10624/14860 (71%)]\tLoss: 0.032687\n",
      "Train Epoch: 16 [10752/14860 (72%)]\tLoss: 0.019076\n",
      "Train Epoch: 16 [10880/14860 (73%)]\tLoss: 0.024562\n",
      "Train Epoch: 16 [11008/14860 (74%)]\tLoss: 0.023128\n",
      "Train Epoch: 16 [11136/14860 (74%)]\tLoss: 0.024877\n",
      "Train Epoch: 16 [11264/14860 (75%)]\tLoss: 0.023931\n",
      "Train Epoch: 16 [11392/14860 (76%)]\tLoss: 0.019202\n",
      "Train Epoch: 16 [11520/14860 (77%)]\tLoss: 0.019596\n",
      "Train Epoch: 16 [11648/14860 (78%)]\tLoss: 0.021502\n",
      "Train Epoch: 16 [11776/14860 (79%)]\tLoss: 0.017146\n",
      "Train Epoch: 16 [11904/14860 (79%)]\tLoss: 0.018779\n",
      "Train Epoch: 16 [12032/14860 (80%)]\tLoss: 0.020601\n",
      "Train Epoch: 16 [12160/14860 (81%)]\tLoss: 0.021270\n",
      "Train Epoch: 16 [12288/14860 (82%)]\tLoss: 0.017222\n",
      "Train Epoch: 16 [12416/14860 (83%)]\tLoss: 0.020789\n",
      "Train Epoch: 16 [12544/14860 (84%)]\tLoss: 0.019325\n",
      "Train Epoch: 16 [12672/14860 (85%)]\tLoss: 0.022137\n",
      "Train Epoch: 16 [12800/14860 (85%)]\tLoss: 0.024978\n",
      "Train Epoch: 16 [12928/14860 (86%)]\tLoss: 0.020220\n",
      "Train Epoch: 16 [13056/14860 (87%)]\tLoss: 0.019068\n",
      "Train Epoch: 16 [13184/14860 (88%)]\tLoss: 0.018959\n",
      "Train Epoch: 16 [13312/14860 (89%)]\tLoss: 0.020849\n",
      "Train Epoch: 16 [13440/14860 (90%)]\tLoss: 0.016665\n",
      "Train Epoch: 16 [13568/14860 (91%)]\tLoss: 0.019604\n",
      "Train Epoch: 16 [13696/14860 (91%)]\tLoss: 0.015081\n",
      "Train Epoch: 16 [13824/14860 (92%)]\tLoss: 0.016519\n",
      "Train Epoch: 16 [13952/14860 (93%)]\tLoss: 0.019162\n",
      "Train Epoch: 16 [14080/14860 (94%)]\tLoss: 0.020184\n",
      "Train Epoch: 16 [14208/14860 (95%)]\tLoss: 0.017169\n",
      "Train Epoch: 16 [14336/14860 (96%)]\tLoss: 0.024207\n",
      "Train Epoch: 16 [14464/14860 (97%)]\tLoss: 0.013633\n",
      "Train Epoch: 16 [14592/14860 (97%)]\tLoss: 0.024848\n",
      "Train Epoch: 16 [14720/14860 (98%)]\tLoss: 0.033662\n",
      "Train Epoch: 16 [1392/14860 (99%)]\tLoss: 0.008974\n",
      "epoch 16 training loss: 0.0210000088549832\n",
      "epoch 16 validation loss: 0.022697031209312976\n",
      "Train Epoch: 17 [0/14860 (0%)]\tLoss: 0.024293\n",
      "Train Epoch: 17 [128/14860 (1%)]\tLoss: 0.019707\n",
      "Train Epoch: 17 [256/14860 (2%)]\tLoss: 0.022805\n",
      "Train Epoch: 17 [384/14860 (3%)]\tLoss: 0.016814\n",
      "Train Epoch: 17 [512/14860 (3%)]\tLoss: 0.018244\n",
      "Train Epoch: 17 [640/14860 (4%)]\tLoss: 0.020790\n",
      "Train Epoch: 17 [768/14860 (5%)]\tLoss: 0.019593\n",
      "Train Epoch: 17 [896/14860 (6%)]\tLoss: 0.014469\n",
      "Train Epoch: 17 [1024/14860 (7%)]\tLoss: 0.021485\n",
      "Train Epoch: 17 [1152/14860 (8%)]\tLoss: 0.019130\n",
      "Train Epoch: 17 [1280/14860 (9%)]\tLoss: 0.025591\n",
      "Train Epoch: 17 [1408/14860 (9%)]\tLoss: 0.021002\n",
      "Train Epoch: 17 [1536/14860 (10%)]\tLoss: 0.022558\n",
      "Train Epoch: 17 [1664/14860 (11%)]\tLoss: 0.020257\n",
      "Train Epoch: 17 [1792/14860 (12%)]\tLoss: 0.014496\n",
      "Train Epoch: 17 [1920/14860 (13%)]\tLoss: 0.014624\n",
      "Train Epoch: 17 [2048/14860 (14%)]\tLoss: 0.021066\n",
      "Train Epoch: 17 [2176/14860 (15%)]\tLoss: 0.024545\n",
      "Train Epoch: 17 [2304/14860 (15%)]\tLoss: 0.018471\n",
      "Train Epoch: 17 [2432/14860 (16%)]\tLoss: 0.018985\n",
      "Train Epoch: 17 [2560/14860 (17%)]\tLoss: 0.019357\n",
      "Train Epoch: 17 [2688/14860 (18%)]\tLoss: 0.022972\n",
      "Train Epoch: 17 [2816/14860 (19%)]\tLoss: 0.022796\n",
      "Train Epoch: 17 [2944/14860 (20%)]\tLoss: 0.018069\n",
      "Train Epoch: 17 [3072/14860 (21%)]\tLoss: 0.020728\n",
      "Train Epoch: 17 [3200/14860 (21%)]\tLoss: 0.018668\n",
      "Train Epoch: 17 [3328/14860 (22%)]\tLoss: 0.018974\n",
      "Train Epoch: 17 [3456/14860 (23%)]\tLoss: 0.020441\n",
      "Train Epoch: 17 [3584/14860 (24%)]\tLoss: 0.020601\n",
      "Train Epoch: 17 [3712/14860 (25%)]\tLoss: 0.015965\n",
      "Train Epoch: 17 [3840/14860 (26%)]\tLoss: 0.027822\n",
      "Train Epoch: 17 [3968/14860 (26%)]\tLoss: 0.020102\n",
      "Train Epoch: 17 [4096/14860 (27%)]\tLoss: 0.021004\n",
      "Train Epoch: 17 [4224/14860 (28%)]\tLoss: 0.022518\n",
      "Train Epoch: 17 [4352/14860 (29%)]\tLoss: 0.022299\n",
      "Train Epoch: 17 [4480/14860 (30%)]\tLoss: 0.018865\n",
      "Train Epoch: 17 [4608/14860 (31%)]\tLoss: 0.020584\n",
      "Train Epoch: 17 [4736/14860 (32%)]\tLoss: 0.018325\n",
      "Train Epoch: 17 [4864/14860 (32%)]\tLoss: 0.016473\n",
      "Train Epoch: 17 [4992/14860 (33%)]\tLoss: 0.016784\n",
      "Train Epoch: 17 [5120/14860 (34%)]\tLoss: 0.025991\n",
      "Train Epoch: 17 [5248/14860 (35%)]\tLoss: 0.021802\n",
      "Train Epoch: 17 [5376/14860 (36%)]\tLoss: 0.021327\n",
      "Train Epoch: 17 [5504/14860 (37%)]\tLoss: 0.021702\n",
      "Train Epoch: 17 [5632/14860 (38%)]\tLoss: 0.023931\n",
      "Train Epoch: 17 [5760/14860 (38%)]\tLoss: 0.022803\n",
      "Train Epoch: 17 [5888/14860 (39%)]\tLoss: 0.020795\n",
      "Train Epoch: 17 [6016/14860 (40%)]\tLoss: 0.021651\n",
      "Train Epoch: 17 [6144/14860 (41%)]\tLoss: 0.016847\n",
      "Train Epoch: 17 [6272/14860 (42%)]\tLoss: 0.014500\n",
      "Train Epoch: 17 [6400/14860 (43%)]\tLoss: 0.022169\n",
      "Train Epoch: 17 [6528/14860 (44%)]\tLoss: 0.033361\n",
      "Train Epoch: 17 [6656/14860 (44%)]\tLoss: 0.020557\n",
      "Train Epoch: 17 [6784/14860 (45%)]\tLoss: 0.021161\n",
      "Train Epoch: 17 [6912/14860 (46%)]\tLoss: 0.021596\n",
      "Train Epoch: 17 [7040/14860 (47%)]\tLoss: 0.023525\n",
      "Train Epoch: 17 [7168/14860 (48%)]\tLoss: 0.020609\n",
      "Train Epoch: 17 [7296/14860 (49%)]\tLoss: 0.019487\n",
      "Train Epoch: 17 [7424/14860 (50%)]\tLoss: 0.021959\n",
      "Train Epoch: 17 [7552/14860 (50%)]\tLoss: 0.027127\n",
      "Train Epoch: 17 [7680/14860 (51%)]\tLoss: 0.015264\n",
      "Train Epoch: 17 [7808/14860 (52%)]\tLoss: 0.023616\n",
      "Train Epoch: 17 [7936/14860 (53%)]\tLoss: 0.032177\n",
      "Train Epoch: 17 [8064/14860 (54%)]\tLoss: 0.016371\n",
      "Train Epoch: 17 [8192/14860 (55%)]\tLoss: 0.023828\n",
      "Train Epoch: 17 [8320/14860 (56%)]\tLoss: 0.019456\n",
      "Train Epoch: 17 [8448/14860 (56%)]\tLoss: 0.020994\n",
      "Train Epoch: 17 [8576/14860 (57%)]\tLoss: 0.026283\n",
      "Train Epoch: 17 [8704/14860 (58%)]\tLoss: 0.017031\n",
      "Train Epoch: 17 [8832/14860 (59%)]\tLoss: 0.022693\n",
      "Train Epoch: 17 [8960/14860 (60%)]\tLoss: 0.024660\n",
      "Train Epoch: 17 [9088/14860 (61%)]\tLoss: 0.023694\n",
      "Train Epoch: 17 [9216/14860 (62%)]\tLoss: 0.019582\n",
      "Train Epoch: 17 [9344/14860 (62%)]\tLoss: 0.014960\n",
      "Train Epoch: 17 [9472/14860 (63%)]\tLoss: 0.016354\n",
      "Train Epoch: 17 [9600/14860 (64%)]\tLoss: 0.016531\n",
      "Train Epoch: 17 [9728/14860 (65%)]\tLoss: 0.018020\n",
      "Train Epoch: 17 [9856/14860 (66%)]\tLoss: 0.020598\n",
      "Train Epoch: 17 [9984/14860 (67%)]\tLoss: 0.022061\n",
      "Train Epoch: 17 [10112/14860 (68%)]\tLoss: 0.011914\n",
      "Train Epoch: 17 [10240/14860 (68%)]\tLoss: 0.025092\n",
      "Train Epoch: 17 [10368/14860 (69%)]\tLoss: 0.021033\n",
      "Train Epoch: 17 [10496/14860 (70%)]\tLoss: 0.020964\n",
      "Train Epoch: 17 [10624/14860 (71%)]\tLoss: 0.020811\n",
      "Train Epoch: 17 [10752/14860 (72%)]\tLoss: 0.021368\n",
      "Train Epoch: 17 [10880/14860 (73%)]\tLoss: 0.034533\n",
      "Train Epoch: 17 [11008/14860 (74%)]\tLoss: 0.021376\n",
      "Train Epoch: 17 [11136/14860 (74%)]\tLoss: 0.029002\n",
      "Train Epoch: 17 [11264/14860 (75%)]\tLoss: 0.026730\n",
      "Train Epoch: 17 [11392/14860 (76%)]\tLoss: 0.013892\n",
      "Train Epoch: 17 [11520/14860 (77%)]\tLoss: 0.021856\n",
      "Train Epoch: 17 [11648/14860 (78%)]\tLoss: 0.028350\n",
      "Train Epoch: 17 [11776/14860 (79%)]\tLoss: 0.022545\n",
      "Train Epoch: 17 [11904/14860 (79%)]\tLoss: 0.026352\n",
      "Train Epoch: 17 [12032/14860 (80%)]\tLoss: 0.030207\n",
      "Train Epoch: 17 [12160/14860 (81%)]\tLoss: 0.019039\n",
      "Train Epoch: 17 [12288/14860 (82%)]\tLoss: 0.032683\n",
      "Train Epoch: 17 [12416/14860 (83%)]\tLoss: 0.023478\n",
      "Train Epoch: 17 [12544/14860 (84%)]\tLoss: 0.028057\n",
      "Train Epoch: 17 [12672/14860 (85%)]\tLoss: 0.019709\n",
      "Train Epoch: 17 [12800/14860 (85%)]\tLoss: 0.019960\n",
      "Train Epoch: 17 [12928/14860 (86%)]\tLoss: 0.016791\n",
      "Train Epoch: 17 [13056/14860 (87%)]\tLoss: 0.028218\n",
      "Train Epoch: 17 [13184/14860 (88%)]\tLoss: 0.019377\n",
      "Train Epoch: 17 [13312/14860 (89%)]\tLoss: 0.021446\n",
      "Train Epoch: 17 [13440/14860 (90%)]\tLoss: 0.028755\n",
      "Train Epoch: 17 [13568/14860 (91%)]\tLoss: 0.016754\n",
      "Train Epoch: 17 [13696/14860 (91%)]\tLoss: 0.024904\n",
      "Train Epoch: 17 [13824/14860 (92%)]\tLoss: 0.014083\n",
      "Train Epoch: 17 [13952/14860 (93%)]\tLoss: 0.021122\n",
      "Train Epoch: 17 [14080/14860 (94%)]\tLoss: 0.014594\n",
      "Train Epoch: 17 [14208/14860 (95%)]\tLoss: 0.023872\n",
      "Train Epoch: 17 [14336/14860 (96%)]\tLoss: 0.017974\n",
      "Train Epoch: 17 [14464/14860 (97%)]\tLoss: 0.016266\n",
      "Train Epoch: 17 [14592/14860 (97%)]\tLoss: 0.015879\n",
      "Train Epoch: 17 [14720/14860 (98%)]\tLoss: 0.016186\n",
      "Train Epoch: 17 [1392/14860 (99%)]\tLoss: 0.017824\n",
      "epoch 17 training loss: 0.021131179852681793\n",
      "epoch 17 validation loss: 0.02116813339274963\n",
      "Train Epoch: 18 [0/14860 (0%)]\tLoss: 0.017830\n",
      "Train Epoch: 18 [128/14860 (1%)]\tLoss: 0.021756\n",
      "Train Epoch: 18 [256/14860 (2%)]\tLoss: 0.023463\n",
      "Train Epoch: 18 [384/14860 (3%)]\tLoss: 0.013757\n",
      "Train Epoch: 18 [512/14860 (3%)]\tLoss: 0.016694\n",
      "Train Epoch: 18 [640/14860 (4%)]\tLoss: 0.024664\n",
      "Train Epoch: 18 [768/14860 (5%)]\tLoss: 0.017048\n",
      "Train Epoch: 18 [896/14860 (6%)]\tLoss: 0.027104\n",
      "Train Epoch: 18 [1024/14860 (7%)]\tLoss: 0.023119\n",
      "Train Epoch: 18 [1152/14860 (8%)]\tLoss: 0.026356\n",
      "Train Epoch: 18 [1280/14860 (9%)]\tLoss: 0.020567\n",
      "Train Epoch: 18 [1408/14860 (9%)]\tLoss: 0.010086\n",
      "Train Epoch: 18 [1536/14860 (10%)]\tLoss: 0.019908\n",
      "Train Epoch: 18 [1664/14860 (11%)]\tLoss: 0.023541\n",
      "Train Epoch: 18 [1792/14860 (12%)]\tLoss: 0.017364\n",
      "Train Epoch: 18 [1920/14860 (13%)]\tLoss: 0.023606\n",
      "Train Epoch: 18 [2048/14860 (14%)]\tLoss: 0.013565\n",
      "Train Epoch: 18 [2176/14860 (15%)]\tLoss: 0.021540\n",
      "Train Epoch: 18 [2304/14860 (15%)]\tLoss: 0.018519\n",
      "Train Epoch: 18 [2432/14860 (16%)]\tLoss: 0.020155\n",
      "Train Epoch: 18 [2560/14860 (17%)]\tLoss: 0.016999\n",
      "Train Epoch: 18 [2688/14860 (18%)]\tLoss: 0.023093\n",
      "Train Epoch: 18 [2816/14860 (19%)]\tLoss: 0.021690\n",
      "Train Epoch: 18 [2944/14860 (20%)]\tLoss: 0.013637\n",
      "Train Epoch: 18 [3072/14860 (21%)]\tLoss: 0.019737\n",
      "Train Epoch: 18 [3200/14860 (21%)]\tLoss: 0.023657\n",
      "Train Epoch: 18 [3328/14860 (22%)]\tLoss: 0.023415\n",
      "Train Epoch: 18 [3456/14860 (23%)]\tLoss: 0.025082\n",
      "Train Epoch: 18 [3584/14860 (24%)]\tLoss: 0.030190\n",
      "Train Epoch: 18 [3712/14860 (25%)]\tLoss: 0.021073\n",
      "Train Epoch: 18 [3840/14860 (26%)]\tLoss: 0.023349\n",
      "Train Epoch: 18 [3968/14860 (26%)]\tLoss: 0.028098\n",
      "Train Epoch: 18 [4096/14860 (27%)]\tLoss: 0.029597\n",
      "Train Epoch: 18 [4224/14860 (28%)]\tLoss: 0.020796\n",
      "Train Epoch: 18 [4352/14860 (29%)]\tLoss: 0.026306\n",
      "Train Epoch: 18 [4480/14860 (30%)]\tLoss: 0.028845\n",
      "Train Epoch: 18 [4608/14860 (31%)]\tLoss: 0.016335\n",
      "Train Epoch: 18 [4736/14860 (32%)]\tLoss: 0.031338\n",
      "Train Epoch: 18 [4864/14860 (32%)]\tLoss: 0.024409\n",
      "Train Epoch: 18 [4992/14860 (33%)]\tLoss: 0.015175\n",
      "Train Epoch: 18 [5120/14860 (34%)]\tLoss: 0.016952\n",
      "Train Epoch: 18 [5248/14860 (35%)]\tLoss: 0.023740\n",
      "Train Epoch: 18 [5376/14860 (36%)]\tLoss: 0.021556\n",
      "Train Epoch: 18 [5504/14860 (37%)]\tLoss: 0.018411\n",
      "Train Epoch: 18 [5632/14860 (38%)]\tLoss: 0.017163\n",
      "Train Epoch: 18 [5760/14860 (38%)]\tLoss: 0.026385\n",
      "Train Epoch: 18 [5888/14860 (39%)]\tLoss: 0.017055\n",
      "Train Epoch: 18 [6016/14860 (40%)]\tLoss: 0.021631\n",
      "Train Epoch: 18 [6144/14860 (41%)]\tLoss: 0.024989\n",
      "Train Epoch: 18 [6272/14860 (42%)]\tLoss: 0.028666\n",
      "Train Epoch: 18 [6400/14860 (43%)]\tLoss: 0.028502\n",
      "Train Epoch: 18 [6528/14860 (44%)]\tLoss: 0.018774\n",
      "Train Epoch: 18 [6656/14860 (44%)]\tLoss: 0.017892\n",
      "Train Epoch: 18 [6784/14860 (45%)]\tLoss: 0.028426\n",
      "Train Epoch: 18 [6912/14860 (46%)]\tLoss: 0.012588\n",
      "Train Epoch: 18 [7040/14860 (47%)]\tLoss: 0.022305\n",
      "Train Epoch: 18 [7168/14860 (48%)]\tLoss: 0.021164\n",
      "Train Epoch: 18 [7296/14860 (49%)]\tLoss: 0.017849\n",
      "Train Epoch: 18 [7424/14860 (50%)]\tLoss: 0.029710\n",
      "Train Epoch: 18 [7552/14860 (50%)]\tLoss: 0.016642\n",
      "Train Epoch: 18 [7680/14860 (51%)]\tLoss: 0.026044\n",
      "Train Epoch: 18 [7808/14860 (52%)]\tLoss: 0.017404\n",
      "Train Epoch: 18 [7936/14860 (53%)]\tLoss: 0.020934\n",
      "Train Epoch: 18 [8064/14860 (54%)]\tLoss: 0.024941\n",
      "Train Epoch: 18 [8192/14860 (55%)]\tLoss: 0.019358\n",
      "Train Epoch: 18 [8320/14860 (56%)]\tLoss: 0.023154\n",
      "Train Epoch: 18 [8448/14860 (56%)]\tLoss: 0.017845\n",
      "Train Epoch: 18 [8576/14860 (57%)]\tLoss: 0.021104\n",
      "Train Epoch: 18 [8704/14860 (58%)]\tLoss: 0.019385\n",
      "Train Epoch: 18 [8832/14860 (59%)]\tLoss: 0.016456\n",
      "Train Epoch: 18 [8960/14860 (60%)]\tLoss: 0.012938\n",
      "Train Epoch: 18 [9088/14860 (61%)]\tLoss: 0.022681\n",
      "Train Epoch: 18 [9216/14860 (62%)]\tLoss: 0.012203\n",
      "Train Epoch: 18 [9344/14860 (62%)]\tLoss: 0.021253\n",
      "Train Epoch: 18 [9472/14860 (63%)]\tLoss: 0.022714\n",
      "Train Epoch: 18 [9600/14860 (64%)]\tLoss: 0.020527\n",
      "Train Epoch: 18 [9728/14860 (65%)]\tLoss: 0.016383\n",
      "Train Epoch: 18 [9856/14860 (66%)]\tLoss: 0.024087\n",
      "Train Epoch: 18 [9984/14860 (67%)]\tLoss: 0.028156\n",
      "Train Epoch: 18 [10112/14860 (68%)]\tLoss: 0.018669\n",
      "Train Epoch: 18 [10240/14860 (68%)]\tLoss: 0.021200\n",
      "Train Epoch: 18 [10368/14860 (69%)]\tLoss: 0.017017\n",
      "Train Epoch: 18 [10496/14860 (70%)]\tLoss: 0.021437\n",
      "Train Epoch: 18 [10624/14860 (71%)]\tLoss: 0.018119\n",
      "Train Epoch: 18 [10752/14860 (72%)]\tLoss: 0.015338\n",
      "Train Epoch: 18 [10880/14860 (73%)]\tLoss: 0.019419\n",
      "Train Epoch: 18 [11008/14860 (74%)]\tLoss: 0.021674\n",
      "Train Epoch: 18 [11136/14860 (74%)]\tLoss: 0.017266\n",
      "Train Epoch: 18 [11264/14860 (75%)]\tLoss: 0.027230\n",
      "Train Epoch: 18 [11392/14860 (76%)]\tLoss: 0.017390\n",
      "Train Epoch: 18 [11520/14860 (77%)]\tLoss: 0.024320\n",
      "Train Epoch: 18 [11648/14860 (78%)]\tLoss: 0.025158\n",
      "Train Epoch: 18 [11776/14860 (79%)]\tLoss: 0.017496\n",
      "Train Epoch: 18 [11904/14860 (79%)]\tLoss: 0.019113\n",
      "Train Epoch: 18 [12032/14860 (80%)]\tLoss: 0.021517\n",
      "Train Epoch: 18 [12160/14860 (81%)]\tLoss: 0.016694\n",
      "Train Epoch: 18 [12288/14860 (82%)]\tLoss: 0.022028\n",
      "Train Epoch: 18 [12416/14860 (83%)]\tLoss: 0.022172\n",
      "Train Epoch: 18 [12544/14860 (84%)]\tLoss: 0.036358\n",
      "Train Epoch: 18 [12672/14860 (85%)]\tLoss: 0.019542\n",
      "Train Epoch: 18 [12800/14860 (85%)]\tLoss: 0.022934\n",
      "Train Epoch: 18 [12928/14860 (86%)]\tLoss: 0.028166\n",
      "Train Epoch: 18 [13056/14860 (87%)]\tLoss: 0.016690\n",
      "Train Epoch: 18 [13184/14860 (88%)]\tLoss: 0.021667\n",
      "Train Epoch: 18 [13312/14860 (89%)]\tLoss: 0.018414\n",
      "Train Epoch: 18 [13440/14860 (90%)]\tLoss: 0.016955\n",
      "Train Epoch: 18 [13568/14860 (91%)]\tLoss: 0.015832\n",
      "Train Epoch: 18 [13696/14860 (91%)]\tLoss: 0.019074\n",
      "Train Epoch: 18 [13824/14860 (92%)]\tLoss: 0.018353\n",
      "Train Epoch: 18 [13952/14860 (93%)]\tLoss: 0.028841\n",
      "Train Epoch: 18 [14080/14860 (94%)]\tLoss: 0.010995\n",
      "Train Epoch: 18 [14208/14860 (95%)]\tLoss: 0.014400\n",
      "Train Epoch: 18 [14336/14860 (96%)]\tLoss: 0.019445\n",
      "Train Epoch: 18 [14464/14860 (97%)]\tLoss: 0.028518\n",
      "Train Epoch: 18 [14592/14860 (97%)]\tLoss: 0.015451\n",
      "Train Epoch: 18 [14720/14860 (98%)]\tLoss: 0.018358\n",
      "Train Epoch: 18 [1392/14860 (99%)]\tLoss: 0.023898\n",
      "epoch 18 training loss: 0.02101345283862872\n",
      "epoch 18 validation loss: 0.023936818644729133\n",
      "Train Epoch: 19 [0/14860 (0%)]\tLoss: 0.026265\n",
      "Train Epoch: 19 [128/14860 (1%)]\tLoss: 0.016562\n",
      "Train Epoch: 19 [256/14860 (2%)]\tLoss: 0.018621\n",
      "Train Epoch: 19 [384/14860 (3%)]\tLoss: 0.037302\n",
      "Train Epoch: 19 [512/14860 (3%)]\tLoss: 0.027355\n",
      "Train Epoch: 19 [640/14860 (4%)]\tLoss: 0.021273\n",
      "Train Epoch: 19 [768/14860 (5%)]\tLoss: 0.025834\n",
      "Train Epoch: 19 [896/14860 (6%)]\tLoss: 0.024589\n",
      "Train Epoch: 19 [1024/14860 (7%)]\tLoss: 0.022869\n",
      "Train Epoch: 19 [1152/14860 (8%)]\tLoss: 0.028540\n",
      "Train Epoch: 19 [1280/14860 (9%)]\tLoss: 0.023851\n",
      "Train Epoch: 19 [1408/14860 (9%)]\tLoss: 0.022042\n",
      "Train Epoch: 19 [1536/14860 (10%)]\tLoss: 0.025398\n",
      "Train Epoch: 19 [1664/14860 (11%)]\tLoss: 0.025118\n",
      "Train Epoch: 19 [1792/14860 (12%)]\tLoss: 0.018085\n",
      "Train Epoch: 19 [1920/14860 (13%)]\tLoss: 0.019984\n",
      "Train Epoch: 19 [2048/14860 (14%)]\tLoss: 0.018517\n",
      "Train Epoch: 19 [2176/14860 (15%)]\tLoss: 0.012074\n",
      "Train Epoch: 19 [2304/14860 (15%)]\tLoss: 0.015990\n",
      "Train Epoch: 19 [2432/14860 (16%)]\tLoss: 0.029221\n",
      "Train Epoch: 19 [2560/14860 (17%)]\tLoss: 0.013051\n",
      "Train Epoch: 19 [2688/14860 (18%)]\tLoss: 0.022125\n",
      "Train Epoch: 19 [2816/14860 (19%)]\tLoss: 0.020536\n",
      "Train Epoch: 19 [2944/14860 (20%)]\tLoss: 0.014084\n",
      "Train Epoch: 19 [3072/14860 (21%)]\tLoss: 0.018462\n",
      "Train Epoch: 19 [3200/14860 (21%)]\tLoss: 0.020397\n",
      "Train Epoch: 19 [3328/14860 (22%)]\tLoss: 0.023919\n",
      "Train Epoch: 19 [3456/14860 (23%)]\tLoss: 0.019189\n",
      "Train Epoch: 19 [3584/14860 (24%)]\tLoss: 0.021400\n",
      "Train Epoch: 19 [3712/14860 (25%)]\tLoss: 0.017841\n",
      "Train Epoch: 19 [3840/14860 (26%)]\tLoss: 0.021939\n",
      "Train Epoch: 19 [3968/14860 (26%)]\tLoss: 0.024527\n",
      "Train Epoch: 19 [4096/14860 (27%)]\tLoss: 0.018004\n",
      "Train Epoch: 19 [4224/14860 (28%)]\tLoss: 0.017295\n",
      "Train Epoch: 19 [4352/14860 (29%)]\tLoss: 0.017003\n",
      "Train Epoch: 19 [4480/14860 (30%)]\tLoss: 0.016860\n",
      "Train Epoch: 19 [4608/14860 (31%)]\tLoss: 0.025020\n",
      "Train Epoch: 19 [4736/14860 (32%)]\tLoss: 0.015596\n",
      "Train Epoch: 19 [4864/14860 (32%)]\tLoss: 0.021073\n",
      "Train Epoch: 19 [4992/14860 (33%)]\tLoss: 0.014182\n",
      "Train Epoch: 19 [5120/14860 (34%)]\tLoss: 0.019426\n",
      "Train Epoch: 19 [5248/14860 (35%)]\tLoss: 0.023785\n",
      "Train Epoch: 19 [5376/14860 (36%)]\tLoss: 0.023386\n",
      "Train Epoch: 19 [5504/14860 (37%)]\tLoss: 0.020370\n",
      "Train Epoch: 19 [5632/14860 (38%)]\tLoss: 0.021322\n",
      "Train Epoch: 19 [5760/14860 (38%)]\tLoss: 0.014098\n",
      "Train Epoch: 19 [5888/14860 (39%)]\tLoss: 0.017009\n",
      "Train Epoch: 19 [6016/14860 (40%)]\tLoss: 0.021034\n",
      "Train Epoch: 19 [6144/14860 (41%)]\tLoss: 0.015325\n",
      "Train Epoch: 19 [6272/14860 (42%)]\tLoss: 0.020271\n",
      "Train Epoch: 19 [6400/14860 (43%)]\tLoss: 0.020887\n",
      "Train Epoch: 19 [6528/14860 (44%)]\tLoss: 0.016043\n",
      "Train Epoch: 19 [6656/14860 (44%)]\tLoss: 0.023474\n",
      "Train Epoch: 19 [6784/14860 (45%)]\tLoss: 0.009553\n",
      "Train Epoch: 19 [6912/14860 (46%)]\tLoss: 0.021443\n",
      "Train Epoch: 19 [7040/14860 (47%)]\tLoss: 0.019188\n",
      "Train Epoch: 19 [7168/14860 (48%)]\tLoss: 0.017311\n",
      "Train Epoch: 19 [7296/14860 (49%)]\tLoss: 0.021819\n",
      "Train Epoch: 19 [7424/14860 (50%)]\tLoss: 0.017432\n",
      "Train Epoch: 19 [7552/14860 (50%)]\tLoss: 0.022824\n",
      "Train Epoch: 19 [7680/14860 (51%)]\tLoss: 0.020243\n",
      "Train Epoch: 19 [7808/14860 (52%)]\tLoss: 0.018911\n",
      "Train Epoch: 19 [7936/14860 (53%)]\tLoss: 0.022992\n",
      "Train Epoch: 19 [8064/14860 (54%)]\tLoss: 0.012137\n",
      "Train Epoch: 19 [8192/14860 (55%)]\tLoss: 0.021911\n",
      "Train Epoch: 19 [8320/14860 (56%)]\tLoss: 0.022158\n",
      "Train Epoch: 19 [8448/14860 (56%)]\tLoss: 0.017065\n",
      "Train Epoch: 19 [8576/14860 (57%)]\tLoss: 0.023500\n",
      "Train Epoch: 19 [8704/14860 (58%)]\tLoss: 0.019093\n",
      "Train Epoch: 19 [8832/14860 (59%)]\tLoss: 0.026861\n",
      "Train Epoch: 19 [8960/14860 (60%)]\tLoss: 0.019935\n",
      "Train Epoch: 19 [9088/14860 (61%)]\tLoss: 0.022662\n",
      "Train Epoch: 19 [9216/14860 (62%)]\tLoss: 0.019308\n",
      "Train Epoch: 19 [9344/14860 (62%)]\tLoss: 0.027770\n",
      "Train Epoch: 19 [9472/14860 (63%)]\tLoss: 0.023361\n",
      "Train Epoch: 19 [9600/14860 (64%)]\tLoss: 0.016729\n",
      "Train Epoch: 19 [9728/14860 (65%)]\tLoss: 0.023803\n",
      "Train Epoch: 19 [9856/14860 (66%)]\tLoss: 0.018321\n",
      "Train Epoch: 19 [9984/14860 (67%)]\tLoss: 0.019772\n",
      "Train Epoch: 19 [10112/14860 (68%)]\tLoss: 0.025001\n",
      "Train Epoch: 19 [10240/14860 (68%)]\tLoss: 0.019010\n",
      "Train Epoch: 19 [10368/14860 (69%)]\tLoss: 0.019008\n",
      "Train Epoch: 19 [10496/14860 (70%)]\tLoss: 0.020304\n",
      "Train Epoch: 19 [10624/14860 (71%)]\tLoss: 0.014177\n",
      "Train Epoch: 19 [10752/14860 (72%)]\tLoss: 0.031820\n",
      "Train Epoch: 19 [10880/14860 (73%)]\tLoss: 0.022077\n",
      "Train Epoch: 19 [11008/14860 (74%)]\tLoss: 0.028261\n",
      "Train Epoch: 19 [11136/14860 (74%)]\tLoss: 0.022927\n",
      "Train Epoch: 19 [11264/14860 (75%)]\tLoss: 0.019621\n",
      "Train Epoch: 19 [11392/14860 (76%)]\tLoss: 0.016793\n",
      "Train Epoch: 19 [11520/14860 (77%)]\tLoss: 0.017588\n",
      "Train Epoch: 19 [11648/14860 (78%)]\tLoss: 0.018208\n",
      "Train Epoch: 19 [11776/14860 (79%)]\tLoss: 0.019846\n",
      "Train Epoch: 19 [11904/14860 (79%)]\tLoss: 0.019870\n",
      "Train Epoch: 19 [12032/14860 (80%)]\tLoss: 0.013818\n",
      "Train Epoch: 19 [12160/14860 (81%)]\tLoss: 0.016068\n",
      "Train Epoch: 19 [12288/14860 (82%)]\tLoss: 0.023924\n",
      "Train Epoch: 19 [12416/14860 (83%)]\tLoss: 0.026033\n",
      "Train Epoch: 19 [12544/14860 (84%)]\tLoss: 0.021433\n",
      "Train Epoch: 19 [12672/14860 (85%)]\tLoss: 0.020351\n",
      "Train Epoch: 19 [12800/14860 (85%)]\tLoss: 0.016693\n",
      "Train Epoch: 19 [12928/14860 (86%)]\tLoss: 0.019222\n",
      "Train Epoch: 19 [13056/14860 (87%)]\tLoss: 0.032899\n",
      "Train Epoch: 19 [13184/14860 (88%)]\tLoss: 0.026277\n",
      "Train Epoch: 19 [13312/14860 (89%)]\tLoss: 0.028864\n",
      "Train Epoch: 19 [13440/14860 (90%)]\tLoss: 0.022409\n",
      "Train Epoch: 19 [13568/14860 (91%)]\tLoss: 0.015859\n",
      "Train Epoch: 19 [13696/14860 (91%)]\tLoss: 0.030750\n",
      "Train Epoch: 19 [13824/14860 (92%)]\tLoss: 0.025029\n",
      "Train Epoch: 19 [13952/14860 (93%)]\tLoss: 0.021013\n",
      "Train Epoch: 19 [14080/14860 (94%)]\tLoss: 0.026137\n",
      "Train Epoch: 19 [14208/14860 (95%)]\tLoss: 0.027163\n",
      "Train Epoch: 19 [14336/14860 (96%)]\tLoss: 0.019794\n",
      "Train Epoch: 19 [14464/14860 (97%)]\tLoss: 0.027663\n",
      "Train Epoch: 19 [14592/14860 (97%)]\tLoss: 0.020534\n",
      "Train Epoch: 19 [14720/14860 (98%)]\tLoss: 0.021500\n",
      "Train Epoch: 19 [1392/14860 (99%)]\tLoss: 0.016695\n",
      "epoch 19 training loss: 0.021018508328204483\n",
      "epoch 19 validation loss: 0.030029038107135395\n",
      "Train Epoch: 20 [0/14860 (0%)]\tLoss: 0.030941\n",
      "Train Epoch: 20 [128/14860 (1%)]\tLoss: 0.021137\n",
      "Train Epoch: 20 [256/14860 (2%)]\tLoss: 0.023484\n",
      "Train Epoch: 20 [384/14860 (3%)]\tLoss: 0.018886\n",
      "Train Epoch: 20 [512/14860 (3%)]\tLoss: 0.021767\n",
      "Train Epoch: 20 [640/14860 (4%)]\tLoss: 0.019764\n",
      "Train Epoch: 20 [768/14860 (5%)]\tLoss: 0.017811\n",
      "Train Epoch: 20 [896/14860 (6%)]\tLoss: 0.027038\n",
      "Train Epoch: 20 [1024/14860 (7%)]\tLoss: 0.022074\n",
      "Train Epoch: 20 [1152/14860 (8%)]\tLoss: 0.024051\n",
      "Train Epoch: 20 [1280/14860 (9%)]\tLoss: 0.020569\n",
      "Train Epoch: 20 [1408/14860 (9%)]\tLoss: 0.017494\n",
      "Train Epoch: 20 [1536/14860 (10%)]\tLoss: 0.018106\n",
      "Train Epoch: 20 [1664/14860 (11%)]\tLoss: 0.013817\n",
      "Train Epoch: 20 [1792/14860 (12%)]\tLoss: 0.023512\n",
      "Train Epoch: 20 [1920/14860 (13%)]\tLoss: 0.018445\n",
      "Train Epoch: 20 [2048/14860 (14%)]\tLoss: 0.019319\n",
      "Train Epoch: 20 [2176/14860 (15%)]\tLoss: 0.019048\n",
      "Train Epoch: 20 [2304/14860 (15%)]\tLoss: 0.022787\n",
      "Train Epoch: 20 [2432/14860 (16%)]\tLoss: 0.022633\n",
      "Train Epoch: 20 [2560/14860 (17%)]\tLoss: 0.019187\n",
      "Train Epoch: 20 [2688/14860 (18%)]\tLoss: 0.024866\n",
      "Train Epoch: 20 [2816/14860 (19%)]\tLoss: 0.013554\n",
      "Train Epoch: 20 [2944/14860 (20%)]\tLoss: 0.015141\n",
      "Train Epoch: 20 [3072/14860 (21%)]\tLoss: 0.017043\n",
      "Train Epoch: 20 [3200/14860 (21%)]\tLoss: 0.021957\n",
      "Train Epoch: 20 [3328/14860 (22%)]\tLoss: 0.019766\n",
      "Train Epoch: 20 [3456/14860 (23%)]\tLoss: 0.020529\n",
      "Train Epoch: 20 [3584/14860 (24%)]\tLoss: 0.018456\n",
      "Train Epoch: 20 [3712/14860 (25%)]\tLoss: 0.017950\n",
      "Train Epoch: 20 [3840/14860 (26%)]\tLoss: 0.028886\n",
      "Train Epoch: 20 [3968/14860 (26%)]\tLoss: 0.015479\n",
      "Train Epoch: 20 [4096/14860 (27%)]\tLoss: 0.022360\n",
      "Train Epoch: 20 [4224/14860 (28%)]\tLoss: 0.030766\n",
      "Train Epoch: 20 [4352/14860 (29%)]\tLoss: 0.017096\n",
      "Train Epoch: 20 [4480/14860 (30%)]\tLoss: 0.024940\n",
      "Train Epoch: 20 [4608/14860 (31%)]\tLoss: 0.022317\n",
      "Train Epoch: 20 [4736/14860 (32%)]\tLoss: 0.015972\n",
      "Train Epoch: 20 [4864/14860 (32%)]\tLoss: 0.013557\n",
      "Train Epoch: 20 [4992/14860 (33%)]\tLoss: 0.012655\n",
      "Train Epoch: 20 [5120/14860 (34%)]\tLoss: 0.022312\n",
      "Train Epoch: 20 [5248/14860 (35%)]\tLoss: 0.016715\n",
      "Train Epoch: 20 [5376/14860 (36%)]\tLoss: 0.019821\n",
      "Train Epoch: 20 [5504/14860 (37%)]\tLoss: 0.019332\n",
      "Train Epoch: 20 [5632/14860 (38%)]\tLoss: 0.022984\n",
      "Train Epoch: 20 [5760/14860 (38%)]\tLoss: 0.014974\n",
      "Train Epoch: 20 [5888/14860 (39%)]\tLoss: 0.015646\n",
      "Train Epoch: 20 [6016/14860 (40%)]\tLoss: 0.016677\n",
      "Train Epoch: 20 [6144/14860 (41%)]\tLoss: 0.020605\n",
      "Train Epoch: 20 [6272/14860 (42%)]\tLoss: 0.019838\n",
      "Train Epoch: 20 [6400/14860 (43%)]\tLoss: 0.020428\n",
      "Train Epoch: 20 [6528/14860 (44%)]\tLoss: 0.020554\n",
      "Train Epoch: 20 [6656/14860 (44%)]\tLoss: 0.016050\n",
      "Train Epoch: 20 [6784/14860 (45%)]\tLoss: 0.018222\n",
      "Train Epoch: 20 [6912/14860 (46%)]\tLoss: 0.017637\n",
      "Train Epoch: 20 [7040/14860 (47%)]\tLoss: 0.020936\n",
      "Train Epoch: 20 [7168/14860 (48%)]\tLoss: 0.021663\n",
      "Train Epoch: 20 [7296/14860 (49%)]\tLoss: 0.020807\n",
      "Train Epoch: 20 [7424/14860 (50%)]\tLoss: 0.027872\n",
      "Train Epoch: 20 [7552/14860 (50%)]\tLoss: 0.013422\n",
      "Train Epoch: 20 [7680/14860 (51%)]\tLoss: 0.017799\n",
      "Train Epoch: 20 [7808/14860 (52%)]\tLoss: 0.020274\n",
      "Train Epoch: 20 [7936/14860 (53%)]\tLoss: 0.020223\n",
      "Train Epoch: 20 [8064/14860 (54%)]\tLoss: 0.015780\n",
      "Train Epoch: 20 [8192/14860 (55%)]\tLoss: 0.019829\n",
      "Train Epoch: 20 [8320/14860 (56%)]\tLoss: 0.021946\n",
      "Train Epoch: 20 [8448/14860 (56%)]\tLoss: 0.025367\n",
      "Train Epoch: 20 [8576/14860 (57%)]\tLoss: 0.020277\n",
      "Train Epoch: 20 [8704/14860 (58%)]\tLoss: 0.013214\n",
      "Train Epoch: 20 [8832/14860 (59%)]\tLoss: 0.022277\n",
      "Train Epoch: 20 [8960/14860 (60%)]\tLoss: 0.015059\n",
      "Train Epoch: 20 [9088/14860 (61%)]\tLoss: 0.018674\n",
      "Train Epoch: 20 [9216/14860 (62%)]\tLoss: 0.017178\n",
      "Train Epoch: 20 [9344/14860 (62%)]\tLoss: 0.017752\n",
      "Train Epoch: 20 [9472/14860 (63%)]\tLoss: 0.030346\n",
      "Train Epoch: 20 [9600/14860 (64%)]\tLoss: 0.015063\n",
      "Train Epoch: 20 [9728/14860 (65%)]\tLoss: 0.019323\n",
      "Train Epoch: 20 [9856/14860 (66%)]\tLoss: 0.019144\n",
      "Train Epoch: 20 [9984/14860 (67%)]\tLoss: 0.027576\n",
      "Train Epoch: 20 [10112/14860 (68%)]\tLoss: 0.017629\n",
      "Train Epoch: 20 [10240/14860 (68%)]\tLoss: 0.027140\n",
      "Train Epoch: 20 [10368/14860 (69%)]\tLoss: 0.023869\n",
      "Train Epoch: 20 [10496/14860 (70%)]\tLoss: 0.016336\n",
      "Train Epoch: 20 [10624/14860 (71%)]\tLoss: 0.017913\n",
      "Train Epoch: 20 [10752/14860 (72%)]\tLoss: 0.017943\n",
      "Train Epoch: 20 [10880/14860 (73%)]\tLoss: 0.022702\n",
      "Train Epoch: 20 [11008/14860 (74%)]\tLoss: 0.022278\n",
      "Train Epoch: 20 [11136/14860 (74%)]\tLoss: 0.022729\n",
      "Train Epoch: 20 [11264/14860 (75%)]\tLoss: 0.020215\n",
      "Train Epoch: 20 [11392/14860 (76%)]\tLoss: 0.020883\n",
      "Train Epoch: 20 [11520/14860 (77%)]\tLoss: 0.016032\n",
      "Train Epoch: 20 [11648/14860 (78%)]\tLoss: 0.018841\n",
      "Train Epoch: 20 [11776/14860 (79%)]\tLoss: 0.025261\n",
      "Train Epoch: 20 [11904/14860 (79%)]\tLoss: 0.023017\n",
      "Train Epoch: 20 [12032/14860 (80%)]\tLoss: 0.032279\n",
      "Train Epoch: 20 [12160/14860 (81%)]\tLoss: 0.025638\n",
      "Train Epoch: 20 [12288/14860 (82%)]\tLoss: 0.016710\n",
      "Train Epoch: 20 [12416/14860 (83%)]\tLoss: 0.019316\n",
      "Train Epoch: 20 [12544/14860 (84%)]\tLoss: 0.026952\n",
      "Train Epoch: 20 [12672/14860 (85%)]\tLoss: 0.020644\n",
      "Train Epoch: 20 [12800/14860 (85%)]\tLoss: 0.024758\n",
      "Train Epoch: 20 [12928/14860 (86%)]\tLoss: 0.020641\n",
      "Train Epoch: 20 [13056/14860 (87%)]\tLoss: 0.018022\n",
      "Train Epoch: 20 [13184/14860 (88%)]\tLoss: 0.020771\n",
      "Train Epoch: 20 [13312/14860 (89%)]\tLoss: 0.027101\n",
      "Train Epoch: 20 [13440/14860 (90%)]\tLoss: 0.020871\n",
      "Train Epoch: 20 [13568/14860 (91%)]\tLoss: 0.021259\n",
      "Train Epoch: 20 [13696/14860 (91%)]\tLoss: 0.028433\n",
      "Train Epoch: 20 [13824/14860 (92%)]\tLoss: 0.016439\n",
      "Train Epoch: 20 [13952/14860 (93%)]\tLoss: 0.024070\n",
      "Train Epoch: 20 [14080/14860 (94%)]\tLoss: 0.019849\n",
      "Train Epoch: 20 [14208/14860 (95%)]\tLoss: 0.021204\n",
      "Train Epoch: 20 [14336/14860 (96%)]\tLoss: 0.021088\n",
      "Train Epoch: 20 [14464/14860 (97%)]\tLoss: 0.017897\n",
      "Train Epoch: 20 [14592/14860 (97%)]\tLoss: 0.025685\n",
      "Train Epoch: 20 [14720/14860 (98%)]\tLoss: 0.022495\n",
      "Train Epoch: 20 [1392/14860 (99%)]\tLoss: 0.007645\n",
      "epoch 20 training loss: 0.020438554322617687\n",
      "epoch 20 validation loss: 0.024556263451426138\n",
      "Train Epoch: 21 [0/14860 (0%)]\tLoss: 0.018243\n",
      "Train Epoch: 21 [128/14860 (1%)]\tLoss: 0.023109\n",
      "Train Epoch: 21 [256/14860 (2%)]\tLoss: 0.020379\n",
      "Train Epoch: 21 [384/14860 (3%)]\tLoss: 0.020477\n",
      "Train Epoch: 21 [512/14860 (3%)]\tLoss: 0.020232\n",
      "Train Epoch: 21 [640/14860 (4%)]\tLoss: 0.021274\n",
      "Train Epoch: 21 [768/14860 (5%)]\tLoss: 0.027750\n",
      "Train Epoch: 21 [896/14860 (6%)]\tLoss: 0.022731\n",
      "Train Epoch: 21 [1024/14860 (7%)]\tLoss: 0.020132\n",
      "Train Epoch: 21 [1152/14860 (8%)]\tLoss: 0.023395\n",
      "Train Epoch: 21 [1280/14860 (9%)]\tLoss: 0.020820\n",
      "Train Epoch: 21 [1408/14860 (9%)]\tLoss: 0.024353\n",
      "Train Epoch: 21 [1536/14860 (10%)]\tLoss: 0.024318\n",
      "Train Epoch: 21 [1664/14860 (11%)]\tLoss: 0.021365\n",
      "Train Epoch: 21 [1792/14860 (12%)]\tLoss: 0.018834\n",
      "Train Epoch: 21 [1920/14860 (13%)]\tLoss: 0.024881\n",
      "Train Epoch: 21 [2048/14860 (14%)]\tLoss: 0.018019\n",
      "Train Epoch: 21 [2176/14860 (15%)]\tLoss: 0.021269\n",
      "Train Epoch: 21 [2304/14860 (15%)]\tLoss: 0.024958\n",
      "Train Epoch: 21 [2432/14860 (16%)]\tLoss: 0.021768\n",
      "Train Epoch: 21 [2560/14860 (17%)]\tLoss: 0.022208\n",
      "Train Epoch: 21 [2688/14860 (18%)]\tLoss: 0.020931\n",
      "Train Epoch: 21 [2816/14860 (19%)]\tLoss: 0.018776\n",
      "Train Epoch: 21 [2944/14860 (20%)]\tLoss: 0.018878\n",
      "Train Epoch: 21 [3072/14860 (21%)]\tLoss: 0.018325\n",
      "Train Epoch: 21 [3200/14860 (21%)]\tLoss: 0.024081\n",
      "Train Epoch: 21 [3328/14860 (22%)]\tLoss: 0.016409\n",
      "Train Epoch: 21 [3456/14860 (23%)]\tLoss: 0.025679\n",
      "Train Epoch: 21 [3584/14860 (24%)]\tLoss: 0.015574\n",
      "Train Epoch: 21 [3712/14860 (25%)]\tLoss: 0.021537\n",
      "Train Epoch: 21 [3840/14860 (26%)]\tLoss: 0.018216\n",
      "Train Epoch: 21 [3968/14860 (26%)]\tLoss: 0.018141\n",
      "Train Epoch: 21 [4096/14860 (27%)]\tLoss: 0.017530\n",
      "Train Epoch: 21 [4224/14860 (28%)]\tLoss: 0.026741\n",
      "Train Epoch: 21 [4352/14860 (29%)]\tLoss: 0.016196\n",
      "Train Epoch: 21 [4480/14860 (30%)]\tLoss: 0.015315\n",
      "Train Epoch: 21 [4608/14860 (31%)]\tLoss: 0.020955\n",
      "Train Epoch: 21 [4736/14860 (32%)]\tLoss: 0.017103\n",
      "Train Epoch: 21 [4864/14860 (32%)]\tLoss: 0.020222\n",
      "Train Epoch: 21 [4992/14860 (33%)]\tLoss: 0.011307\n",
      "Train Epoch: 21 [5120/14860 (34%)]\tLoss: 0.020185\n",
      "Train Epoch: 21 [5248/14860 (35%)]\tLoss: 0.022885\n",
      "Train Epoch: 21 [5376/14860 (36%)]\tLoss: 0.016194\n",
      "Train Epoch: 21 [5504/14860 (37%)]\tLoss: 0.017089\n",
      "Train Epoch: 21 [5632/14860 (38%)]\tLoss: 0.017158\n",
      "Train Epoch: 21 [5760/14860 (38%)]\tLoss: 0.023107\n",
      "Train Epoch: 21 [5888/14860 (39%)]\tLoss: 0.021989\n",
      "Train Epoch: 21 [6016/14860 (40%)]\tLoss: 0.016039\n",
      "Train Epoch: 21 [6144/14860 (41%)]\tLoss: 0.011279\n",
      "Train Epoch: 21 [6272/14860 (42%)]\tLoss: 0.020133\n",
      "Train Epoch: 21 [6400/14860 (43%)]\tLoss: 0.012193\n",
      "Train Epoch: 21 [6528/14860 (44%)]\tLoss: 0.017695\n",
      "Train Epoch: 21 [6656/14860 (44%)]\tLoss: 0.013737\n",
      "Train Epoch: 21 [6784/14860 (45%)]\tLoss: 0.021260\n",
      "Train Epoch: 21 [6912/14860 (46%)]\tLoss: 0.019303\n",
      "Train Epoch: 21 [7040/14860 (47%)]\tLoss: 0.022772\n",
      "Train Epoch: 21 [7168/14860 (48%)]\tLoss: 0.018301\n",
      "Train Epoch: 21 [7296/14860 (49%)]\tLoss: 0.019565\n",
      "Train Epoch: 21 [7424/14860 (50%)]\tLoss: 0.014538\n",
      "Train Epoch: 21 [7552/14860 (50%)]\tLoss: 0.024808\n",
      "Train Epoch: 21 [7680/14860 (51%)]\tLoss: 0.023493\n",
      "Train Epoch: 21 [7808/14860 (52%)]\tLoss: 0.023098\n",
      "Train Epoch: 21 [7936/14860 (53%)]\tLoss: 0.023467\n",
      "Train Epoch: 21 [8064/14860 (54%)]\tLoss: 0.029171\n",
      "Train Epoch: 21 [8192/14860 (55%)]\tLoss: 0.028676\n",
      "Train Epoch: 21 [8320/14860 (56%)]\tLoss: 0.017800\n",
      "Train Epoch: 21 [8448/14860 (56%)]\tLoss: 0.013304\n",
      "Train Epoch: 21 [8576/14860 (57%)]\tLoss: 0.020273\n",
      "Train Epoch: 21 [8704/14860 (58%)]\tLoss: 0.018381\n",
      "Train Epoch: 21 [8832/14860 (59%)]\tLoss: 0.015586\n",
      "Train Epoch: 21 [8960/14860 (60%)]\tLoss: 0.015446\n",
      "Train Epoch: 21 [9088/14860 (61%)]\tLoss: 0.027274\n",
      "Train Epoch: 21 [9216/14860 (62%)]\tLoss: 0.021665\n",
      "Train Epoch: 21 [9344/14860 (62%)]\tLoss: 0.019693\n",
      "Train Epoch: 21 [9472/14860 (63%)]\tLoss: 0.019635\n",
      "Train Epoch: 21 [9600/14860 (64%)]\tLoss: 0.021976\n",
      "Train Epoch: 21 [9728/14860 (65%)]\tLoss: 0.023434\n",
      "Train Epoch: 21 [9856/14860 (66%)]\tLoss: 0.021107\n",
      "Train Epoch: 21 [9984/14860 (67%)]\tLoss: 0.023174\n",
      "Train Epoch: 21 [10112/14860 (68%)]\tLoss: 0.020343\n",
      "Train Epoch: 21 [10240/14860 (68%)]\tLoss: 0.016672\n",
      "Train Epoch: 21 [10368/14860 (69%)]\tLoss: 0.018664\n",
      "Train Epoch: 21 [10496/14860 (70%)]\tLoss: 0.013996\n",
      "Train Epoch: 21 [10624/14860 (71%)]\tLoss: 0.019003\n",
      "Train Epoch: 21 [10752/14860 (72%)]\tLoss: 0.020146\n",
      "Train Epoch: 21 [10880/14860 (73%)]\tLoss: 0.021504\n",
      "Train Epoch: 21 [11008/14860 (74%)]\tLoss: 0.019112\n",
      "Train Epoch: 21 [11136/14860 (74%)]\tLoss: 0.019910\n",
      "Train Epoch: 21 [11264/14860 (75%)]\tLoss: 0.018393\n",
      "Train Epoch: 21 [11392/14860 (76%)]\tLoss: 0.019661\n",
      "Train Epoch: 21 [11520/14860 (77%)]\tLoss: 0.022121\n",
      "Train Epoch: 21 [11648/14860 (78%)]\tLoss: 0.015110\n",
      "Train Epoch: 21 [11776/14860 (79%)]\tLoss: 0.021934\n",
      "Train Epoch: 21 [11904/14860 (79%)]\tLoss: 0.018486\n",
      "Train Epoch: 21 [12032/14860 (80%)]\tLoss: 0.021514\n",
      "Train Epoch: 21 [12160/14860 (81%)]\tLoss: 0.020740\n",
      "Train Epoch: 21 [12288/14860 (82%)]\tLoss: 0.013505\n",
      "Train Epoch: 21 [12416/14860 (83%)]\tLoss: 0.020780\n",
      "Train Epoch: 21 [12544/14860 (84%)]\tLoss: 0.019153\n",
      "Train Epoch: 21 [12672/14860 (85%)]\tLoss: 0.025738\n",
      "Train Epoch: 21 [12800/14860 (85%)]\tLoss: 0.017015\n",
      "Train Epoch: 21 [12928/14860 (86%)]\tLoss: 0.024753\n",
      "Train Epoch: 21 [13056/14860 (87%)]\tLoss: 0.025171\n",
      "Train Epoch: 21 [13184/14860 (88%)]\tLoss: 0.025423\n",
      "Train Epoch: 21 [13312/14860 (89%)]\tLoss: 0.020623\n",
      "Train Epoch: 21 [13440/14860 (90%)]\tLoss: 0.016306\n",
      "Train Epoch: 21 [13568/14860 (91%)]\tLoss: 0.026038\n",
      "Train Epoch: 21 [13696/14860 (91%)]\tLoss: 0.020996\n",
      "Train Epoch: 21 [13824/14860 (92%)]\tLoss: 0.020928\n",
      "Train Epoch: 21 [13952/14860 (93%)]\tLoss: 0.020204\n",
      "Train Epoch: 21 [14080/14860 (94%)]\tLoss: 0.027160\n",
      "Train Epoch: 21 [14208/14860 (95%)]\tLoss: 0.018926\n",
      "Train Epoch: 21 [14336/14860 (96%)]\tLoss: 0.027369\n",
      "Train Epoch: 21 [14464/14860 (97%)]\tLoss: 0.020217\n",
      "Train Epoch: 21 [14592/14860 (97%)]\tLoss: 0.016110\n",
      "Train Epoch: 21 [14720/14860 (98%)]\tLoss: 0.021275\n",
      "Train Epoch: 21 [1392/14860 (99%)]\tLoss: 0.007343\n",
      "epoch 21 training loss: 0.020185081988700435\n",
      "epoch 21 validation loss: 0.021762735618517416\n",
      "Train Epoch: 22 [0/14860 (0%)]\tLoss: 0.015346\n",
      "Train Epoch: 22 [128/14860 (1%)]\tLoss: 0.014379\n",
      "Train Epoch: 22 [256/14860 (2%)]\tLoss: 0.016030\n",
      "Train Epoch: 22 [384/14860 (3%)]\tLoss: 0.017676\n",
      "Train Epoch: 22 [512/14860 (3%)]\tLoss: 0.016727\n",
      "Train Epoch: 22 [640/14860 (4%)]\tLoss: 0.023768\n",
      "Train Epoch: 22 [768/14860 (5%)]\tLoss: 0.016843\n",
      "Train Epoch: 22 [896/14860 (6%)]\tLoss: 0.014705\n",
      "Train Epoch: 22 [1024/14860 (7%)]\tLoss: 0.012359\n",
      "Train Epoch: 22 [1152/14860 (8%)]\tLoss: 0.027610\n",
      "Train Epoch: 22 [1280/14860 (9%)]\tLoss: 0.016769\n",
      "Train Epoch: 22 [1408/14860 (9%)]\tLoss: 0.025939\n",
      "Train Epoch: 22 [1536/14860 (10%)]\tLoss: 0.026082\n",
      "Train Epoch: 22 [1664/14860 (11%)]\tLoss: 0.017716\n",
      "Train Epoch: 22 [1792/14860 (12%)]\tLoss: 0.021589\n",
      "Train Epoch: 22 [1920/14860 (13%)]\tLoss: 0.022925\n",
      "Train Epoch: 22 [2048/14860 (14%)]\tLoss: 0.021264\n",
      "Train Epoch: 22 [2176/14860 (15%)]\tLoss: 0.014694\n",
      "Train Epoch: 22 [2304/14860 (15%)]\tLoss: 0.014569\n",
      "Train Epoch: 22 [2432/14860 (16%)]\tLoss: 0.019024\n",
      "Train Epoch: 22 [2560/14860 (17%)]\tLoss: 0.020762\n",
      "Train Epoch: 22 [2688/14860 (18%)]\tLoss: 0.029899\n",
      "Train Epoch: 22 [2816/14860 (19%)]\tLoss: 0.020684\n",
      "Train Epoch: 22 [2944/14860 (20%)]\tLoss: 0.018673\n",
      "Train Epoch: 22 [3072/14860 (21%)]\tLoss: 0.022959\n",
      "Train Epoch: 22 [3200/14860 (21%)]\tLoss: 0.017234\n",
      "Train Epoch: 22 [3328/14860 (22%)]\tLoss: 0.020461\n",
      "Train Epoch: 22 [3456/14860 (23%)]\tLoss: 0.016806\n",
      "Train Epoch: 22 [3584/14860 (24%)]\tLoss: 0.022976\n",
      "Train Epoch: 22 [3712/14860 (25%)]\tLoss: 0.019261\n",
      "Train Epoch: 22 [3840/14860 (26%)]\tLoss: 0.021071\n",
      "Train Epoch: 22 [3968/14860 (26%)]\tLoss: 0.016210\n",
      "Train Epoch: 22 [4096/14860 (27%)]\tLoss: 0.019066\n",
      "Train Epoch: 22 [4224/14860 (28%)]\tLoss: 0.017954\n",
      "Train Epoch: 22 [4352/14860 (29%)]\tLoss: 0.022409\n",
      "Train Epoch: 22 [4480/14860 (30%)]\tLoss: 0.017316\n",
      "Train Epoch: 22 [4608/14860 (31%)]\tLoss: 0.015429\n",
      "Train Epoch: 22 [4736/14860 (32%)]\tLoss: 0.015038\n",
      "Train Epoch: 22 [4864/14860 (32%)]\tLoss: 0.013576\n",
      "Train Epoch: 22 [4992/14860 (33%)]\tLoss: 0.029368\n",
      "Train Epoch: 22 [5120/14860 (34%)]\tLoss: 0.015851\n",
      "Train Epoch: 22 [5248/14860 (35%)]\tLoss: 0.029158\n",
      "Train Epoch: 22 [5376/14860 (36%)]\tLoss: 0.019132\n",
      "Train Epoch: 22 [5504/14860 (37%)]\tLoss: 0.016800\n",
      "Train Epoch: 22 [5632/14860 (38%)]\tLoss: 0.026872\n",
      "Train Epoch: 22 [5760/14860 (38%)]\tLoss: 0.010461\n",
      "Train Epoch: 22 [5888/14860 (39%)]\tLoss: 0.020025\n",
      "Train Epoch: 22 [6016/14860 (40%)]\tLoss: 0.014962\n",
      "Train Epoch: 22 [6144/14860 (41%)]\tLoss: 0.021961\n",
      "Train Epoch: 22 [6272/14860 (42%)]\tLoss: 0.024015\n",
      "Train Epoch: 22 [6400/14860 (43%)]\tLoss: 0.018501\n",
      "Train Epoch: 22 [6528/14860 (44%)]\tLoss: 0.016222\n",
      "Train Epoch: 22 [6656/14860 (44%)]\tLoss: 0.015894\n",
      "Train Epoch: 22 [6784/14860 (45%)]\tLoss: 0.023007\n",
      "Train Epoch: 22 [6912/14860 (46%)]\tLoss: 0.024952\n",
      "Train Epoch: 22 [7040/14860 (47%)]\tLoss: 0.022181\n",
      "Train Epoch: 22 [7168/14860 (48%)]\tLoss: 0.017701\n",
      "Train Epoch: 22 [7296/14860 (49%)]\tLoss: 0.017196\n",
      "Train Epoch: 22 [7424/14860 (50%)]\tLoss: 0.018402\n",
      "Train Epoch: 22 [7552/14860 (50%)]\tLoss: 0.016035\n",
      "Train Epoch: 22 [7680/14860 (51%)]\tLoss: 0.013161\n",
      "Train Epoch: 22 [7808/14860 (52%)]\tLoss: 0.014916\n",
      "Train Epoch: 22 [7936/14860 (53%)]\tLoss: 0.015231\n",
      "Train Epoch: 22 [8064/14860 (54%)]\tLoss: 0.026770\n",
      "Train Epoch: 22 [8192/14860 (55%)]\tLoss: 0.017920\n",
      "Train Epoch: 22 [8320/14860 (56%)]\tLoss: 0.016450\n",
      "Train Epoch: 22 [8448/14860 (56%)]\tLoss: 0.020266\n",
      "Train Epoch: 22 [8576/14860 (57%)]\tLoss: 0.023883\n",
      "Train Epoch: 22 [8704/14860 (58%)]\tLoss: 0.025429\n",
      "Train Epoch: 22 [8832/14860 (59%)]\tLoss: 0.023744\n",
      "Train Epoch: 22 [8960/14860 (60%)]\tLoss: 0.027448\n",
      "Train Epoch: 22 [9088/14860 (61%)]\tLoss: 0.016786\n",
      "Train Epoch: 22 [9216/14860 (62%)]\tLoss: 0.026143\n",
      "Train Epoch: 22 [9344/14860 (62%)]\tLoss: 0.029659\n",
      "Train Epoch: 22 [9472/14860 (63%)]\tLoss: 0.028093\n",
      "Train Epoch: 22 [9600/14860 (64%)]\tLoss: 0.034697\n",
      "Train Epoch: 22 [9728/14860 (65%)]\tLoss: 0.028093\n",
      "Train Epoch: 22 [9856/14860 (66%)]\tLoss: 0.027981\n",
      "Train Epoch: 22 [9984/14860 (67%)]\tLoss: 0.018348\n",
      "Train Epoch: 22 [10112/14860 (68%)]\tLoss: 0.021202\n",
      "Train Epoch: 22 [10240/14860 (68%)]\tLoss: 0.023087\n",
      "Train Epoch: 22 [10368/14860 (69%)]\tLoss: 0.023132\n",
      "Train Epoch: 22 [10496/14860 (70%)]\tLoss: 0.016238\n",
      "Train Epoch: 22 [10624/14860 (71%)]\tLoss: 0.022167\n",
      "Train Epoch: 22 [10752/14860 (72%)]\tLoss: 0.018625\n",
      "Train Epoch: 22 [10880/14860 (73%)]\tLoss: 0.016039\n",
      "Train Epoch: 22 [11008/14860 (74%)]\tLoss: 0.018710\n",
      "Train Epoch: 22 [11136/14860 (74%)]\tLoss: 0.019295\n",
      "Train Epoch: 22 [11264/14860 (75%)]\tLoss: 0.022492\n",
      "Train Epoch: 22 [11392/14860 (76%)]\tLoss: 0.018986\n",
      "Train Epoch: 22 [11520/14860 (77%)]\tLoss: 0.020200\n",
      "Train Epoch: 22 [11648/14860 (78%)]\tLoss: 0.016595\n",
      "Train Epoch: 22 [11776/14860 (79%)]\tLoss: 0.019512\n",
      "Train Epoch: 22 [11904/14860 (79%)]\tLoss: 0.013899\n",
      "Train Epoch: 22 [12032/14860 (80%)]\tLoss: 0.016630\n",
      "Train Epoch: 22 [12160/14860 (81%)]\tLoss: 0.026013\n",
      "Train Epoch: 22 [12288/14860 (82%)]\tLoss: 0.021090\n",
      "Train Epoch: 22 [12416/14860 (83%)]\tLoss: 0.020407\n",
      "Train Epoch: 22 [12544/14860 (84%)]\tLoss: 0.021796\n",
      "Train Epoch: 22 [12672/14860 (85%)]\tLoss: 0.013646\n",
      "Train Epoch: 22 [12800/14860 (85%)]\tLoss: 0.040540\n",
      "Train Epoch: 22 [12928/14860 (86%)]\tLoss: 0.020172\n",
      "Train Epoch: 22 [13056/14860 (87%)]\tLoss: 0.032955\n",
      "Train Epoch: 22 [13184/14860 (88%)]\tLoss: 0.028480\n",
      "Train Epoch: 22 [13312/14860 (89%)]\tLoss: 0.023678\n",
      "Train Epoch: 22 [13440/14860 (90%)]\tLoss: 0.023329\n",
      "Train Epoch: 22 [13568/14860 (91%)]\tLoss: 0.027171\n",
      "Train Epoch: 22 [13696/14860 (91%)]\tLoss: 0.025663\n",
      "Train Epoch: 22 [13824/14860 (92%)]\tLoss: 0.023521\n",
      "Train Epoch: 22 [13952/14860 (93%)]\tLoss: 0.024106\n",
      "Train Epoch: 22 [14080/14860 (94%)]\tLoss: 0.020274\n",
      "Train Epoch: 22 [14208/14860 (95%)]\tLoss: 0.025538\n",
      "Train Epoch: 22 [14336/14860 (96%)]\tLoss: 0.021123\n",
      "Train Epoch: 22 [14464/14860 (97%)]\tLoss: 0.023054\n",
      "Train Epoch: 22 [14592/14860 (97%)]\tLoss: 0.022481\n",
      "Train Epoch: 22 [14720/14860 (98%)]\tLoss: 0.024014\n",
      "Train Epoch: 22 [1392/14860 (99%)]\tLoss: 0.033447\n",
      "epoch 22 training loss: 0.020912986272611678\n",
      "epoch 22 validation loss: 0.023367242432102454\n",
      "Train Epoch: 23 [0/14860 (0%)]\tLoss: 0.018369\n",
      "Train Epoch: 23 [128/14860 (1%)]\tLoss: 0.017236\n",
      "Train Epoch: 23 [256/14860 (2%)]\tLoss: 0.023233\n",
      "Train Epoch: 23 [384/14860 (3%)]\tLoss: 0.015997\n",
      "Train Epoch: 23 [512/14860 (3%)]\tLoss: 0.019634\n",
      "Train Epoch: 23 [640/14860 (4%)]\tLoss: 0.025390\n",
      "Train Epoch: 23 [768/14860 (5%)]\tLoss: 0.020613\n",
      "Train Epoch: 23 [896/14860 (6%)]\tLoss: 0.021207\n",
      "Train Epoch: 23 [1024/14860 (7%)]\tLoss: 0.019844\n",
      "Train Epoch: 23 [1152/14860 (8%)]\tLoss: 0.022682\n",
      "Train Epoch: 23 [1280/14860 (9%)]\tLoss: 0.025554\n",
      "Train Epoch: 23 [1408/14860 (9%)]\tLoss: 0.017804\n",
      "Train Epoch: 23 [1536/14860 (10%)]\tLoss: 0.017747\n",
      "Train Epoch: 23 [1664/14860 (11%)]\tLoss: 0.017186\n",
      "Train Epoch: 23 [1792/14860 (12%)]\tLoss: 0.025214\n",
      "Train Epoch: 23 [1920/14860 (13%)]\tLoss: 0.017250\n",
      "Train Epoch: 23 [2048/14860 (14%)]\tLoss: 0.015241\n",
      "Train Epoch: 23 [2176/14860 (15%)]\tLoss: 0.016964\n",
      "Train Epoch: 23 [2304/14860 (15%)]\tLoss: 0.016265\n",
      "Train Epoch: 23 [2432/14860 (16%)]\tLoss: 0.022412\n",
      "Train Epoch: 23 [2560/14860 (17%)]\tLoss: 0.021062\n",
      "Train Epoch: 23 [2688/14860 (18%)]\tLoss: 0.019383\n",
      "Train Epoch: 23 [2816/14860 (19%)]\tLoss: 0.025666\n",
      "Train Epoch: 23 [2944/14860 (20%)]\tLoss: 0.026553\n",
      "Train Epoch: 23 [3072/14860 (21%)]\tLoss: 0.015014\n",
      "Train Epoch: 23 [3200/14860 (21%)]\tLoss: 0.022009\n",
      "Train Epoch: 23 [3328/14860 (22%)]\tLoss: 0.021440\n",
      "Train Epoch: 23 [3456/14860 (23%)]\tLoss: 0.020525\n",
      "Train Epoch: 23 [3584/14860 (24%)]\tLoss: 0.023370\n",
      "Train Epoch: 23 [3712/14860 (25%)]\tLoss: 0.017632\n",
      "Train Epoch: 23 [3840/14860 (26%)]\tLoss: 0.016313\n",
      "Train Epoch: 23 [3968/14860 (26%)]\tLoss: 0.022571\n",
      "Train Epoch: 23 [4096/14860 (27%)]\tLoss: 0.017144\n",
      "Train Epoch: 23 [4224/14860 (28%)]\tLoss: 0.023903\n",
      "Train Epoch: 23 [4352/14860 (29%)]\tLoss: 0.014376\n",
      "Train Epoch: 23 [4480/14860 (30%)]\tLoss: 0.020739\n",
      "Train Epoch: 23 [4608/14860 (31%)]\tLoss: 0.021277\n",
      "Train Epoch: 23 [4736/14860 (32%)]\tLoss: 0.022144\n",
      "Train Epoch: 23 [4864/14860 (32%)]\tLoss: 0.019869\n",
      "Train Epoch: 23 [4992/14860 (33%)]\tLoss: 0.021285\n",
      "Train Epoch: 23 [5120/14860 (34%)]\tLoss: 0.024756\n",
      "Train Epoch: 23 [5248/14860 (35%)]\tLoss: 0.016063\n",
      "Train Epoch: 23 [5376/14860 (36%)]\tLoss: 0.016290\n",
      "Train Epoch: 23 [5504/14860 (37%)]\tLoss: 0.013020\n",
      "Train Epoch: 23 [5632/14860 (38%)]\tLoss: 0.021757\n",
      "Train Epoch: 23 [5760/14860 (38%)]\tLoss: 0.022639\n",
      "Train Epoch: 23 [5888/14860 (39%)]\tLoss: 0.017103\n",
      "Train Epoch: 23 [6016/14860 (40%)]\tLoss: 0.018041\n",
      "Train Epoch: 23 [6144/14860 (41%)]\tLoss: 0.026602\n",
      "Train Epoch: 23 [6272/14860 (42%)]\tLoss: 0.021476\n",
      "Train Epoch: 23 [6400/14860 (43%)]\tLoss: 0.015350\n",
      "Train Epoch: 23 [6528/14860 (44%)]\tLoss: 0.017992\n",
      "Train Epoch: 23 [6656/14860 (44%)]\tLoss: 0.013995\n",
      "Train Epoch: 23 [6784/14860 (45%)]\tLoss: 0.017483\n",
      "Train Epoch: 23 [6912/14860 (46%)]\tLoss: 0.025529\n",
      "Train Epoch: 23 [7040/14860 (47%)]\tLoss: 0.027330\n",
      "Train Epoch: 23 [7168/14860 (48%)]\tLoss: 0.015782\n",
      "Train Epoch: 23 [7296/14860 (49%)]\tLoss: 0.014584\n",
      "Train Epoch: 23 [7424/14860 (50%)]\tLoss: 0.019141\n",
      "Train Epoch: 23 [7552/14860 (50%)]\tLoss: 0.015225\n",
      "Train Epoch: 23 [7680/14860 (51%)]\tLoss: 0.016743\n",
      "Train Epoch: 23 [7808/14860 (52%)]\tLoss: 0.018011\n",
      "Train Epoch: 23 [7936/14860 (53%)]\tLoss: 0.016800\n",
      "Train Epoch: 23 [8064/14860 (54%)]\tLoss: 0.015406\n",
      "Train Epoch: 23 [8192/14860 (55%)]\tLoss: 0.023221\n",
      "Train Epoch: 23 [8320/14860 (56%)]\tLoss: 0.016590\n",
      "Train Epoch: 23 [8448/14860 (56%)]\tLoss: 0.015847\n",
      "Train Epoch: 23 [8576/14860 (57%)]\tLoss: 0.018037\n",
      "Train Epoch: 23 [8704/14860 (58%)]\tLoss: 0.016218\n",
      "Train Epoch: 23 [8832/14860 (59%)]\tLoss: 0.019668\n",
      "Train Epoch: 23 [8960/14860 (60%)]\tLoss: 0.020898\n",
      "Train Epoch: 23 [9088/14860 (61%)]\tLoss: 0.016964\n",
      "Train Epoch: 23 [9216/14860 (62%)]\tLoss: 0.018602\n",
      "Train Epoch: 23 [9344/14860 (62%)]\tLoss: 0.019845\n",
      "Train Epoch: 23 [9472/14860 (63%)]\tLoss: 0.014471\n",
      "Train Epoch: 23 [9600/14860 (64%)]\tLoss: 0.016675\n",
      "Train Epoch: 23 [9728/14860 (65%)]\tLoss: 0.010807\n",
      "Train Epoch: 23 [9856/14860 (66%)]\tLoss: 0.020751\n",
      "Train Epoch: 23 [9984/14860 (67%)]\tLoss: 0.022132\n",
      "Train Epoch: 23 [10112/14860 (68%)]\tLoss: 0.015041\n",
      "Train Epoch: 23 [10240/14860 (68%)]\tLoss: 0.027060\n",
      "Train Epoch: 23 [10368/14860 (69%)]\tLoss: 0.018216\n",
      "Train Epoch: 23 [10496/14860 (70%)]\tLoss: 0.027488\n",
      "Train Epoch: 23 [10624/14860 (71%)]\tLoss: 0.017114\n",
      "Train Epoch: 23 [10752/14860 (72%)]\tLoss: 0.020395\n",
      "Train Epoch: 23 [10880/14860 (73%)]\tLoss: 0.020472\n",
      "Train Epoch: 23 [11008/14860 (74%)]\tLoss: 0.028053\n",
      "Train Epoch: 23 [11136/14860 (74%)]\tLoss: 0.023841\n",
      "Train Epoch: 23 [11264/14860 (75%)]\tLoss: 0.029646\n",
      "Train Epoch: 23 [11392/14860 (76%)]\tLoss: 0.022274\n",
      "Train Epoch: 23 [11520/14860 (77%)]\tLoss: 0.019049\n",
      "Train Epoch: 23 [11648/14860 (78%)]\tLoss: 0.021750\n",
      "Train Epoch: 23 [11776/14860 (79%)]\tLoss: 0.019420\n",
      "Train Epoch: 23 [11904/14860 (79%)]\tLoss: 0.021571\n",
      "Train Epoch: 23 [12032/14860 (80%)]\tLoss: 0.019918\n",
      "Train Epoch: 23 [12160/14860 (81%)]\tLoss: 0.027288\n",
      "Train Epoch: 23 [12288/14860 (82%)]\tLoss: 0.012915\n",
      "Train Epoch: 23 [12416/14860 (83%)]\tLoss: 0.016738\n",
      "Train Epoch: 23 [12544/14860 (84%)]\tLoss: 0.014901\n",
      "Train Epoch: 23 [12672/14860 (85%)]\tLoss: 0.022331\n",
      "Train Epoch: 23 [12800/14860 (85%)]\tLoss: 0.020124\n",
      "Train Epoch: 23 [12928/14860 (86%)]\tLoss: 0.015210\n",
      "Train Epoch: 23 [13056/14860 (87%)]\tLoss: 0.023601\n",
      "Train Epoch: 23 [13184/14860 (88%)]\tLoss: 0.026528\n",
      "Train Epoch: 23 [13312/14860 (89%)]\tLoss: 0.019860\n",
      "Train Epoch: 23 [13440/14860 (90%)]\tLoss: 0.016235\n",
      "Train Epoch: 23 [13568/14860 (91%)]\tLoss: 0.018054\n",
      "Train Epoch: 23 [13696/14860 (91%)]\tLoss: 0.022363\n",
      "Train Epoch: 23 [13824/14860 (92%)]\tLoss: 0.012840\n",
      "Train Epoch: 23 [13952/14860 (93%)]\tLoss: 0.025021\n",
      "Train Epoch: 23 [14080/14860 (94%)]\tLoss: 0.025042\n",
      "Train Epoch: 23 [14208/14860 (95%)]\tLoss: 0.020447\n",
      "Train Epoch: 23 [14336/14860 (96%)]\tLoss: 0.026015\n",
      "Train Epoch: 23 [14464/14860 (97%)]\tLoss: 0.028617\n",
      "Train Epoch: 23 [14592/14860 (97%)]\tLoss: 0.016431\n",
      "Train Epoch: 23 [14720/14860 (98%)]\tLoss: 0.022526\n",
      "Train Epoch: 23 [1392/14860 (99%)]\tLoss: 0.017080\n",
      "epoch 23 training loss: 0.01989261782927136\n",
      "epoch 23 validation loss: 0.022448225113727856\n",
      "Train Epoch: 24 [0/14860 (0%)]\tLoss: 0.014603\n",
      "Train Epoch: 24 [128/14860 (1%)]\tLoss: 0.022967\n",
      "Train Epoch: 24 [256/14860 (2%)]\tLoss: 0.014456\n",
      "Train Epoch: 24 [384/14860 (3%)]\tLoss: 0.024593\n",
      "Train Epoch: 24 [512/14860 (3%)]\tLoss: 0.017140\n",
      "Train Epoch: 24 [640/14860 (4%)]\tLoss: 0.021091\n",
      "Train Epoch: 24 [768/14860 (5%)]\tLoss: 0.021087\n",
      "Train Epoch: 24 [896/14860 (6%)]\tLoss: 0.017279\n",
      "Train Epoch: 24 [1024/14860 (7%)]\tLoss: 0.024662\n",
      "Train Epoch: 24 [1152/14860 (8%)]\tLoss: 0.021190\n",
      "Train Epoch: 24 [1280/14860 (9%)]\tLoss: 0.022489\n",
      "Train Epoch: 24 [1408/14860 (9%)]\tLoss: 0.020783\n",
      "Train Epoch: 24 [1536/14860 (10%)]\tLoss: 0.020278\n",
      "Train Epoch: 24 [1664/14860 (11%)]\tLoss: 0.014984\n",
      "Train Epoch: 24 [1792/14860 (12%)]\tLoss: 0.025148\n",
      "Train Epoch: 24 [1920/14860 (13%)]\tLoss: 0.018909\n",
      "Train Epoch: 24 [2048/14860 (14%)]\tLoss: 0.015422\n",
      "Train Epoch: 24 [2176/14860 (15%)]\tLoss: 0.019399\n",
      "Train Epoch: 24 [2304/14860 (15%)]\tLoss: 0.014811\n",
      "Train Epoch: 24 [2432/14860 (16%)]\tLoss: 0.021086\n",
      "Train Epoch: 24 [2560/14860 (17%)]\tLoss: 0.021019\n",
      "Train Epoch: 24 [2688/14860 (18%)]\tLoss: 0.016529\n",
      "Train Epoch: 24 [2816/14860 (19%)]\tLoss: 0.016446\n",
      "Train Epoch: 24 [2944/14860 (20%)]\tLoss: 0.026078\n",
      "Train Epoch: 24 [3072/14860 (21%)]\tLoss: 0.015589\n",
      "Train Epoch: 24 [3200/14860 (21%)]\tLoss: 0.017840\n",
      "Train Epoch: 24 [3328/14860 (22%)]\tLoss: 0.027908\n",
      "Train Epoch: 24 [3456/14860 (23%)]\tLoss: 0.019265\n",
      "Train Epoch: 24 [3584/14860 (24%)]\tLoss: 0.023676\n",
      "Train Epoch: 24 [3712/14860 (25%)]\tLoss: 0.031198\n",
      "Train Epoch: 24 [3840/14860 (26%)]\tLoss: 0.018561\n",
      "Train Epoch: 24 [3968/14860 (26%)]\tLoss: 0.019416\n",
      "Train Epoch: 24 [4096/14860 (27%)]\tLoss: 0.017701\n",
      "Train Epoch: 24 [4224/14860 (28%)]\tLoss: 0.016720\n",
      "Train Epoch: 24 [4352/14860 (29%)]\tLoss: 0.018472\n",
      "Train Epoch: 24 [4480/14860 (30%)]\tLoss: 0.023538\n",
      "Train Epoch: 24 [4608/14860 (31%)]\tLoss: 0.018501\n",
      "Train Epoch: 24 [4736/14860 (32%)]\tLoss: 0.018586\n",
      "Train Epoch: 24 [4864/14860 (32%)]\tLoss: 0.024279\n",
      "Train Epoch: 24 [4992/14860 (33%)]\tLoss: 0.018763\n",
      "Train Epoch: 24 [5120/14860 (34%)]\tLoss: 0.023249\n",
      "Train Epoch: 24 [5248/14860 (35%)]\tLoss: 0.020162\n",
      "Train Epoch: 24 [5376/14860 (36%)]\tLoss: 0.017310\n",
      "Train Epoch: 24 [5504/14860 (37%)]\tLoss: 0.021812\n",
      "Train Epoch: 24 [5632/14860 (38%)]\tLoss: 0.026493\n",
      "Train Epoch: 24 [5760/14860 (38%)]\tLoss: 0.011891\n",
      "Train Epoch: 24 [5888/14860 (39%)]\tLoss: 0.023026\n",
      "Train Epoch: 24 [6016/14860 (40%)]\tLoss: 0.018229\n",
      "Train Epoch: 24 [6144/14860 (41%)]\tLoss: 0.022895\n",
      "Train Epoch: 24 [6272/14860 (42%)]\tLoss: 0.017603\n",
      "Train Epoch: 24 [6400/14860 (43%)]\tLoss: 0.015381\n",
      "Train Epoch: 24 [6528/14860 (44%)]\tLoss: 0.015695\n",
      "Train Epoch: 24 [6656/14860 (44%)]\tLoss: 0.024895\n",
      "Train Epoch: 24 [6784/14860 (45%)]\tLoss: 0.015518\n",
      "Train Epoch: 24 [6912/14860 (46%)]\tLoss: 0.019028\n",
      "Train Epoch: 24 [7040/14860 (47%)]\tLoss: 0.021704\n",
      "Train Epoch: 24 [7168/14860 (48%)]\tLoss: 0.019044\n",
      "Train Epoch: 24 [7296/14860 (49%)]\tLoss: 0.017236\n",
      "Train Epoch: 24 [7424/14860 (50%)]\tLoss: 0.017728\n",
      "Train Epoch: 24 [7552/14860 (50%)]\tLoss: 0.022120\n",
      "Train Epoch: 24 [7680/14860 (51%)]\tLoss: 0.019454\n",
      "Train Epoch: 24 [7808/14860 (52%)]\tLoss: 0.019418\n",
      "Train Epoch: 24 [7936/14860 (53%)]\tLoss: 0.025487\n",
      "Train Epoch: 24 [8064/14860 (54%)]\tLoss: 0.021215\n",
      "Train Epoch: 24 [8192/14860 (55%)]\tLoss: 0.017973\n",
      "Train Epoch: 24 [8320/14860 (56%)]\tLoss: 0.021902\n",
      "Train Epoch: 24 [8448/14860 (56%)]\tLoss: 0.015695\n",
      "Train Epoch: 24 [8576/14860 (57%)]\tLoss: 0.023546\n",
      "Train Epoch: 24 [8704/14860 (58%)]\tLoss: 0.016520\n",
      "Train Epoch: 24 [8832/14860 (59%)]\tLoss: 0.030112\n",
      "Train Epoch: 24 [8960/14860 (60%)]\tLoss: 0.021035\n",
      "Train Epoch: 24 [9088/14860 (61%)]\tLoss: 0.015648\n",
      "Train Epoch: 24 [9216/14860 (62%)]\tLoss: 0.023361\n",
      "Train Epoch: 24 [9344/14860 (62%)]\tLoss: 0.012141\n",
      "Train Epoch: 24 [9472/14860 (63%)]\tLoss: 0.033724\n",
      "Train Epoch: 24 [9600/14860 (64%)]\tLoss: 0.019616\n",
      "Train Epoch: 24 [9728/14860 (65%)]\tLoss: 0.021106\n",
      "Train Epoch: 24 [9856/14860 (66%)]\tLoss: 0.016448\n",
      "Train Epoch: 24 [9984/14860 (67%)]\tLoss: 0.021778\n",
      "Train Epoch: 24 [10112/14860 (68%)]\tLoss: 0.023060\n",
      "Train Epoch: 24 [10240/14860 (68%)]\tLoss: 0.022368\n",
      "Train Epoch: 24 [10368/14860 (69%)]\tLoss: 0.018717\n",
      "Train Epoch: 24 [10496/14860 (70%)]\tLoss: 0.022582\n",
      "Train Epoch: 24 [10624/14860 (71%)]\tLoss: 0.032952\n",
      "Train Epoch: 24 [10752/14860 (72%)]\tLoss: 0.022130\n",
      "Train Epoch: 24 [10880/14860 (73%)]\tLoss: 0.023553\n",
      "Train Epoch: 24 [11008/14860 (74%)]\tLoss: 0.023346\n",
      "Train Epoch: 24 [11136/14860 (74%)]\tLoss: 0.018209\n",
      "Train Epoch: 24 [11264/14860 (75%)]\tLoss: 0.017796\n",
      "Train Epoch: 24 [11392/14860 (76%)]\tLoss: 0.029045\n",
      "Train Epoch: 24 [11520/14860 (77%)]\tLoss: 0.025379\n",
      "Train Epoch: 24 [11648/14860 (78%)]\tLoss: 0.019804\n",
      "Train Epoch: 24 [11776/14860 (79%)]\tLoss: 0.020158\n",
      "Train Epoch: 24 [11904/14860 (79%)]\tLoss: 0.015477\n",
      "Train Epoch: 24 [12032/14860 (80%)]\tLoss: 0.017942\n",
      "Train Epoch: 24 [12160/14860 (81%)]\tLoss: 0.016333\n",
      "Train Epoch: 24 [12288/14860 (82%)]\tLoss: 0.020047\n",
      "Train Epoch: 24 [12416/14860 (83%)]\tLoss: 0.023575\n",
      "Train Epoch: 24 [12544/14860 (84%)]\tLoss: 0.022975\n",
      "Train Epoch: 24 [12672/14860 (85%)]\tLoss: 0.025965\n",
      "Train Epoch: 24 [12800/14860 (85%)]\tLoss: 0.025764\n",
      "Train Epoch: 24 [12928/14860 (86%)]\tLoss: 0.025688\n",
      "Train Epoch: 24 [13056/14860 (87%)]\tLoss: 0.017116\n",
      "Train Epoch: 24 [13184/14860 (88%)]\tLoss: 0.015683\n",
      "Train Epoch: 24 [13312/14860 (89%)]\tLoss: 0.026189\n",
      "Train Epoch: 24 [13440/14860 (90%)]\tLoss: 0.018694\n",
      "Train Epoch: 24 [13568/14860 (91%)]\tLoss: 0.016020\n",
      "Train Epoch: 24 [13696/14860 (91%)]\tLoss: 0.018568\n",
      "Train Epoch: 24 [13824/14860 (92%)]\tLoss: 0.015893\n",
      "Train Epoch: 24 [13952/14860 (93%)]\tLoss: 0.018061\n",
      "Train Epoch: 24 [14080/14860 (94%)]\tLoss: 0.019581\n",
      "Train Epoch: 24 [14208/14860 (95%)]\tLoss: 0.017911\n",
      "Train Epoch: 24 [14336/14860 (96%)]\tLoss: 0.015321\n",
      "Train Epoch: 24 [14464/14860 (97%)]\tLoss: 0.025134\n",
      "Train Epoch: 24 [14592/14860 (97%)]\tLoss: 0.025380\n",
      "Train Epoch: 24 [14720/14860 (98%)]\tLoss: 0.022562\n",
      "Train Epoch: 24 [1392/14860 (99%)]\tLoss: 0.010521\n",
      "epoch 24 training loss: 0.020385990540186565\n",
      "epoch 24 validation loss: 0.023743569562279285\n",
      "Train Epoch: 25 [0/14860 (0%)]\tLoss: 0.018816\n",
      "Train Epoch: 25 [128/14860 (1%)]\tLoss: 0.032850\n",
      "Train Epoch: 25 [256/14860 (2%)]\tLoss: 0.021628\n",
      "Train Epoch: 25 [384/14860 (3%)]\tLoss: 0.022180\n",
      "Train Epoch: 25 [512/14860 (3%)]\tLoss: 0.018319\n",
      "Train Epoch: 25 [640/14860 (4%)]\tLoss: 0.020493\n",
      "Train Epoch: 25 [768/14860 (5%)]\tLoss: 0.022414\n",
      "Train Epoch: 25 [896/14860 (6%)]\tLoss: 0.028313\n",
      "Train Epoch: 25 [1024/14860 (7%)]\tLoss: 0.022694\n",
      "Train Epoch: 25 [1152/14860 (8%)]\tLoss: 0.023323\n",
      "Train Epoch: 25 [1280/14860 (9%)]\tLoss: 0.025168\n",
      "Train Epoch: 25 [1408/14860 (9%)]\tLoss: 0.020004\n",
      "Train Epoch: 25 [1536/14860 (10%)]\tLoss: 0.020357\n",
      "Train Epoch: 25 [1664/14860 (11%)]\tLoss: 0.018201\n",
      "Train Epoch: 25 [1792/14860 (12%)]\tLoss: 0.021630\n",
      "Train Epoch: 25 [1920/14860 (13%)]\tLoss: 0.019971\n",
      "Train Epoch: 25 [2048/14860 (14%)]\tLoss: 0.027833\n",
      "Train Epoch: 25 [2176/14860 (15%)]\tLoss: 0.038153\n",
      "Train Epoch: 25 [2304/14860 (15%)]\tLoss: 0.018370\n",
      "Train Epoch: 25 [2432/14860 (16%)]\tLoss: 0.027451\n",
      "Train Epoch: 25 [2560/14860 (17%)]\tLoss: 0.023851\n",
      "Train Epoch: 25 [2688/14860 (18%)]\tLoss: 0.021225\n",
      "Train Epoch: 25 [2816/14860 (19%)]\tLoss: 0.025053\n",
      "Train Epoch: 25 [2944/14860 (20%)]\tLoss: 0.015955\n",
      "Train Epoch: 25 [3072/14860 (21%)]\tLoss: 0.019250\n",
      "Train Epoch: 25 [3200/14860 (21%)]\tLoss: 0.016197\n",
      "Train Epoch: 25 [3328/14860 (22%)]\tLoss: 0.017634\n",
      "Train Epoch: 25 [3456/14860 (23%)]\tLoss: 0.019340\n",
      "Train Epoch: 25 [3584/14860 (24%)]\tLoss: 0.018674\n",
      "Train Epoch: 25 [3712/14860 (25%)]\tLoss: 0.026224\n",
      "Train Epoch: 25 [3840/14860 (26%)]\tLoss: 0.022759\n",
      "Train Epoch: 25 [3968/14860 (26%)]\tLoss: 0.014513\n",
      "Train Epoch: 25 [4096/14860 (27%)]\tLoss: 0.022175\n",
      "Train Epoch: 25 [4224/14860 (28%)]\tLoss: 0.017003\n",
      "Train Epoch: 25 [4352/14860 (29%)]\tLoss: 0.018725\n",
      "Train Epoch: 25 [4480/14860 (30%)]\tLoss: 0.018792\n",
      "Train Epoch: 25 [4608/14860 (31%)]\tLoss: 0.022468\n",
      "Train Epoch: 25 [4736/14860 (32%)]\tLoss: 0.016407\n",
      "Train Epoch: 25 [4864/14860 (32%)]\tLoss: 0.037289\n",
      "Train Epoch: 25 [4992/14860 (33%)]\tLoss: 0.013584\n",
      "Train Epoch: 25 [5120/14860 (34%)]\tLoss: 0.024922\n",
      "Train Epoch: 25 [5248/14860 (35%)]\tLoss: 0.021681\n",
      "Train Epoch: 25 [5376/14860 (36%)]\tLoss: 0.018129\n",
      "Train Epoch: 25 [5504/14860 (37%)]\tLoss: 0.025536\n",
      "Train Epoch: 25 [5632/14860 (38%)]\tLoss: 0.021589\n",
      "Train Epoch: 25 [5760/14860 (38%)]\tLoss: 0.013856\n",
      "Train Epoch: 25 [5888/14860 (39%)]\tLoss: 0.020800\n",
      "Train Epoch: 25 [6016/14860 (40%)]\tLoss: 0.019111\n",
      "Train Epoch: 25 [6144/14860 (41%)]\tLoss: 0.014917\n",
      "Train Epoch: 25 [6272/14860 (42%)]\tLoss: 0.021750\n",
      "Train Epoch: 25 [6400/14860 (43%)]\tLoss: 0.022524\n",
      "Train Epoch: 25 [6528/14860 (44%)]\tLoss: 0.021588\n",
      "Train Epoch: 25 [6656/14860 (44%)]\tLoss: 0.015271\n",
      "Train Epoch: 25 [6784/14860 (45%)]\tLoss: 0.027313\n",
      "Train Epoch: 25 [6912/14860 (46%)]\tLoss: 0.025977\n",
      "Train Epoch: 25 [7040/14860 (47%)]\tLoss: 0.017951\n",
      "Train Epoch: 25 [7168/14860 (48%)]\tLoss: 0.024178\n",
      "Train Epoch: 25 [7296/14860 (49%)]\tLoss: 0.021198\n",
      "Train Epoch: 25 [7424/14860 (50%)]\tLoss: 0.015180\n",
      "Train Epoch: 25 [7552/14860 (50%)]\tLoss: 0.021731\n",
      "Train Epoch: 25 [7680/14860 (51%)]\tLoss: 0.017622\n",
      "Train Epoch: 25 [7808/14860 (52%)]\tLoss: 0.017644\n",
      "Train Epoch: 25 [7936/14860 (53%)]\tLoss: 0.016721\n",
      "Train Epoch: 25 [8064/14860 (54%)]\tLoss: 0.026353\n",
      "Train Epoch: 25 [8192/14860 (55%)]\tLoss: 0.022626\n",
      "Train Epoch: 25 [8320/14860 (56%)]\tLoss: 0.019975\n",
      "Train Epoch: 25 [8448/14860 (56%)]\tLoss: 0.019310\n",
      "Train Epoch: 25 [8576/14860 (57%)]\tLoss: 0.036656\n",
      "Train Epoch: 25 [8704/14860 (58%)]\tLoss: 0.017120\n",
      "Train Epoch: 25 [8832/14860 (59%)]\tLoss: 0.024209\n",
      "Train Epoch: 25 [8960/14860 (60%)]\tLoss: 0.021039\n",
      "Train Epoch: 25 [9088/14860 (61%)]\tLoss: 0.016124\n",
      "Train Epoch: 25 [9216/14860 (62%)]\tLoss: 0.011704\n",
      "Train Epoch: 25 [9344/14860 (62%)]\tLoss: 0.031902\n",
      "Train Epoch: 25 [9472/14860 (63%)]\tLoss: 0.018128\n",
      "Train Epoch: 25 [9600/14860 (64%)]\tLoss: 0.023148\n",
      "Train Epoch: 25 [9728/14860 (65%)]\tLoss: 0.030685\n",
      "Train Epoch: 25 [9856/14860 (66%)]\tLoss: 0.017824\n",
      "Train Epoch: 25 [9984/14860 (67%)]\tLoss: 0.027666\n",
      "Train Epoch: 25 [10112/14860 (68%)]\tLoss: 0.013606\n",
      "Train Epoch: 25 [10240/14860 (68%)]\tLoss: 0.018659\n",
      "Train Epoch: 25 [10368/14860 (69%)]\tLoss: 0.020236\n",
      "Train Epoch: 25 [10496/14860 (70%)]\tLoss: 0.020926\n",
      "Train Epoch: 25 [10624/14860 (71%)]\tLoss: 0.016748\n",
      "Train Epoch: 25 [10752/14860 (72%)]\tLoss: 0.024331\n",
      "Train Epoch: 25 [10880/14860 (73%)]\tLoss: 0.022448\n",
      "Train Epoch: 25 [11008/14860 (74%)]\tLoss: 0.020024\n",
      "Train Epoch: 25 [11136/14860 (74%)]\tLoss: 0.019085\n",
      "Train Epoch: 25 [11264/14860 (75%)]\tLoss: 0.023575\n",
      "Train Epoch: 25 [11392/14860 (76%)]\tLoss: 0.012197\n",
      "Train Epoch: 25 [11520/14860 (77%)]\tLoss: 0.015486\n",
      "Train Epoch: 25 [11648/14860 (78%)]\tLoss: 0.018716\n",
      "Train Epoch: 25 [11776/14860 (79%)]\tLoss: 0.017987\n",
      "Train Epoch: 25 [11904/14860 (79%)]\tLoss: 0.011308\n",
      "Train Epoch: 25 [12032/14860 (80%)]\tLoss: 0.017990\n",
      "Train Epoch: 25 [12160/14860 (81%)]\tLoss: 0.021772\n",
      "Train Epoch: 25 [12288/14860 (82%)]\tLoss: 0.023349\n",
      "Train Epoch: 25 [12416/14860 (83%)]\tLoss: 0.018136\n",
      "Train Epoch: 25 [12544/14860 (84%)]\tLoss: 0.011895\n",
      "Train Epoch: 25 [12672/14860 (85%)]\tLoss: 0.019243\n",
      "Train Epoch: 25 [12800/14860 (85%)]\tLoss: 0.017211\n",
      "Train Epoch: 25 [12928/14860 (86%)]\tLoss: 0.022614\n",
      "Train Epoch: 25 [13056/14860 (87%)]\tLoss: 0.022871\n",
      "Train Epoch: 25 [13184/14860 (88%)]\tLoss: 0.023667\n",
      "Train Epoch: 25 [13312/14860 (89%)]\tLoss: 0.014741\n",
      "Train Epoch: 25 [13440/14860 (90%)]\tLoss: 0.016583\n",
      "Train Epoch: 25 [13568/14860 (91%)]\tLoss: 0.022002\n",
      "Train Epoch: 25 [13696/14860 (91%)]\tLoss: 0.017194\n",
      "Train Epoch: 25 [13824/14860 (92%)]\tLoss: 0.020271\n",
      "Train Epoch: 25 [13952/14860 (93%)]\tLoss: 0.020650\n",
      "Train Epoch: 25 [14080/14860 (94%)]\tLoss: 0.017042\n",
      "Train Epoch: 25 [14208/14860 (95%)]\tLoss: 0.020471\n",
      "Train Epoch: 25 [14336/14860 (96%)]\tLoss: 0.016673\n",
      "Train Epoch: 25 [14464/14860 (97%)]\tLoss: 0.019020\n",
      "Train Epoch: 25 [14592/14860 (97%)]\tLoss: 0.015343\n",
      "Train Epoch: 25 [14720/14860 (98%)]\tLoss: 0.013044\n",
      "Train Epoch: 25 [1392/14860 (99%)]\tLoss: 0.011916\n",
      "epoch 25 training loss: 0.020563900351333313\n",
      "epoch 25 validation loss: 0.020686295505874672\n",
      "Train Epoch: 26 [0/14860 (0%)]\tLoss: 0.018563\n",
      "Train Epoch: 26 [128/14860 (1%)]\tLoss: 0.023742\n",
      "Train Epoch: 26 [256/14860 (2%)]\tLoss: 0.024390\n",
      "Train Epoch: 26 [384/14860 (3%)]\tLoss: 0.023685\n",
      "Train Epoch: 26 [512/14860 (3%)]\tLoss: 0.018428\n",
      "Train Epoch: 26 [640/14860 (4%)]\tLoss: 0.017519\n",
      "Train Epoch: 26 [768/14860 (5%)]\tLoss: 0.017303\n",
      "Train Epoch: 26 [896/14860 (6%)]\tLoss: 0.024213\n",
      "Train Epoch: 26 [1024/14860 (7%)]\tLoss: 0.016619\n",
      "Train Epoch: 26 [1152/14860 (8%)]\tLoss: 0.016231\n",
      "Train Epoch: 26 [1280/14860 (9%)]\tLoss: 0.016259\n",
      "Train Epoch: 26 [1408/14860 (9%)]\tLoss: 0.024643\n",
      "Train Epoch: 26 [1536/14860 (10%)]\tLoss: 0.022388\n",
      "Train Epoch: 26 [1664/14860 (11%)]\tLoss: 0.027456\n",
      "Train Epoch: 26 [1792/14860 (12%)]\tLoss: 0.024836\n",
      "Train Epoch: 26 [1920/14860 (13%)]\tLoss: 0.024569\n",
      "Train Epoch: 26 [2048/14860 (14%)]\tLoss: 0.021240\n",
      "Train Epoch: 26 [2176/14860 (15%)]\tLoss: 0.019368\n",
      "Train Epoch: 26 [2304/14860 (15%)]\tLoss: 0.023108\n",
      "Train Epoch: 26 [2432/14860 (16%)]\tLoss: 0.020297\n",
      "Train Epoch: 26 [2560/14860 (17%)]\tLoss: 0.015746\n",
      "Train Epoch: 26 [2688/14860 (18%)]\tLoss: 0.015726\n",
      "Train Epoch: 26 [2816/14860 (19%)]\tLoss: 0.025398\n",
      "Train Epoch: 26 [2944/14860 (20%)]\tLoss: 0.012169\n",
      "Train Epoch: 26 [3072/14860 (21%)]\tLoss: 0.017136\n",
      "Train Epoch: 26 [3200/14860 (21%)]\tLoss: 0.025443\n",
      "Train Epoch: 26 [3328/14860 (22%)]\tLoss: 0.018609\n",
      "Train Epoch: 26 [3456/14860 (23%)]\tLoss: 0.026035\n",
      "Train Epoch: 26 [3584/14860 (24%)]\tLoss: 0.012893\n",
      "Train Epoch: 26 [3712/14860 (25%)]\tLoss: 0.028351\n",
      "Train Epoch: 26 [3840/14860 (26%)]\tLoss: 0.013041\n",
      "Train Epoch: 26 [3968/14860 (26%)]\tLoss: 0.019561\n",
      "Train Epoch: 26 [4096/14860 (27%)]\tLoss: 0.023202\n",
      "Train Epoch: 26 [4224/14860 (28%)]\tLoss: 0.020637\n",
      "Train Epoch: 26 [4352/14860 (29%)]\tLoss: 0.027681\n",
      "Train Epoch: 26 [4480/14860 (30%)]\tLoss: 0.015956\n",
      "Train Epoch: 26 [4608/14860 (31%)]\tLoss: 0.015626\n",
      "Train Epoch: 26 [4736/14860 (32%)]\tLoss: 0.022167\n",
      "Train Epoch: 26 [4864/14860 (32%)]\tLoss: 0.020778\n",
      "Train Epoch: 26 [4992/14860 (33%)]\tLoss: 0.024167\n",
      "Train Epoch: 26 [5120/14860 (34%)]\tLoss: 0.023462\n",
      "Train Epoch: 26 [5248/14860 (35%)]\tLoss: 0.017916\n",
      "Train Epoch: 26 [5376/14860 (36%)]\tLoss: 0.013975\n",
      "Train Epoch: 26 [5504/14860 (37%)]\tLoss: 0.020118\n",
      "Train Epoch: 26 [5632/14860 (38%)]\tLoss: 0.015057\n",
      "Train Epoch: 26 [5760/14860 (38%)]\tLoss: 0.017556\n",
      "Train Epoch: 26 [5888/14860 (39%)]\tLoss: 0.017077\n",
      "Train Epoch: 26 [6016/14860 (40%)]\tLoss: 0.018676\n",
      "Train Epoch: 26 [6144/14860 (41%)]\tLoss: 0.018035\n",
      "Train Epoch: 26 [6272/14860 (42%)]\tLoss: 0.019027\n",
      "Train Epoch: 26 [6400/14860 (43%)]\tLoss: 0.024597\n",
      "Train Epoch: 26 [6528/14860 (44%)]\tLoss: 0.014659\n",
      "Train Epoch: 26 [6656/14860 (44%)]\tLoss: 0.014689\n",
      "Train Epoch: 26 [6784/14860 (45%)]\tLoss: 0.031852\n",
      "Train Epoch: 26 [6912/14860 (46%)]\tLoss: 0.016085\n",
      "Train Epoch: 26 [7040/14860 (47%)]\tLoss: 0.026623\n",
      "Train Epoch: 26 [7168/14860 (48%)]\tLoss: 0.023793\n",
      "Train Epoch: 26 [7296/14860 (49%)]\tLoss: 0.024459\n",
      "Train Epoch: 26 [7424/14860 (50%)]\tLoss: 0.021559\n",
      "Train Epoch: 26 [7552/14860 (50%)]\tLoss: 0.015548\n",
      "Train Epoch: 26 [7680/14860 (51%)]\tLoss: 0.018057\n",
      "Train Epoch: 26 [7808/14860 (52%)]\tLoss: 0.027181\n",
      "Train Epoch: 26 [7936/14860 (53%)]\tLoss: 0.021539\n",
      "Train Epoch: 26 [8064/14860 (54%)]\tLoss: 0.015904\n",
      "Train Epoch: 26 [8192/14860 (55%)]\tLoss: 0.024995\n",
      "Train Epoch: 26 [8320/14860 (56%)]\tLoss: 0.019283\n",
      "Train Epoch: 26 [8448/14860 (56%)]\tLoss: 0.024378\n",
      "Train Epoch: 26 [8576/14860 (57%)]\tLoss: 0.017180\n",
      "Train Epoch: 26 [8704/14860 (58%)]\tLoss: 0.022312\n",
      "Train Epoch: 26 [8832/14860 (59%)]\tLoss: 0.021867\n",
      "Train Epoch: 26 [8960/14860 (60%)]\tLoss: 0.026035\n",
      "Train Epoch: 26 [9088/14860 (61%)]\tLoss: 0.023900\n",
      "Train Epoch: 26 [9216/14860 (62%)]\tLoss: 0.019564\n",
      "Train Epoch: 26 [9344/14860 (62%)]\tLoss: 0.023275\n",
      "Train Epoch: 26 [9472/14860 (63%)]\tLoss: 0.031041\n",
      "Train Epoch: 26 [9600/14860 (64%)]\tLoss: 0.012881\n",
      "Train Epoch: 26 [9728/14860 (65%)]\tLoss: 0.022858\n",
      "Train Epoch: 26 [9856/14860 (66%)]\tLoss: 0.025500\n",
      "Train Epoch: 26 [9984/14860 (67%)]\tLoss: 0.018990\n",
      "Train Epoch: 26 [10112/14860 (68%)]\tLoss: 0.017088\n",
      "Train Epoch: 26 [10240/14860 (68%)]\tLoss: 0.030754\n",
      "Train Epoch: 26 [10368/14860 (69%)]\tLoss: 0.026272\n",
      "Train Epoch: 26 [10496/14860 (70%)]\tLoss: 0.022085\n",
      "Train Epoch: 26 [10624/14860 (71%)]\tLoss: 0.023150\n",
      "Train Epoch: 26 [10752/14860 (72%)]\tLoss: 0.029886\n",
      "Train Epoch: 26 [10880/14860 (73%)]\tLoss: 0.021897\n",
      "Train Epoch: 26 [11008/14860 (74%)]\tLoss: 0.022650\n",
      "Train Epoch: 26 [11136/14860 (74%)]\tLoss: 0.015941\n",
      "Train Epoch: 26 [11264/14860 (75%)]\tLoss: 0.023884\n",
      "Train Epoch: 26 [11392/14860 (76%)]\tLoss: 0.015989\n",
      "Train Epoch: 26 [11520/14860 (77%)]\tLoss: 0.020566\n",
      "Train Epoch: 26 [11648/14860 (78%)]\tLoss: 0.016524\n",
      "Train Epoch: 26 [11776/14860 (79%)]\tLoss: 0.022332\n",
      "Train Epoch: 26 [11904/14860 (79%)]\tLoss: 0.022010\n",
      "Train Epoch: 26 [12032/14860 (80%)]\tLoss: 0.020680\n",
      "Train Epoch: 26 [12160/14860 (81%)]\tLoss: 0.013443\n",
      "Train Epoch: 26 [12288/14860 (82%)]\tLoss: 0.027409\n",
      "Train Epoch: 26 [12416/14860 (83%)]\tLoss: 0.023267\n",
      "Train Epoch: 26 [12544/14860 (84%)]\tLoss: 0.017887\n",
      "Train Epoch: 26 [12672/14860 (85%)]\tLoss: 0.024587\n",
      "Train Epoch: 26 [12800/14860 (85%)]\tLoss: 0.016495\n",
      "Train Epoch: 26 [12928/14860 (86%)]\tLoss: 0.031067\n",
      "Train Epoch: 26 [13056/14860 (87%)]\tLoss: 0.021648\n",
      "Train Epoch: 26 [13184/14860 (88%)]\tLoss: 0.016661\n",
      "Train Epoch: 26 [13312/14860 (89%)]\tLoss: 0.021714\n",
      "Train Epoch: 26 [13440/14860 (90%)]\tLoss: 0.017719\n",
      "Train Epoch: 26 [13568/14860 (91%)]\tLoss: 0.030243\n",
      "Train Epoch: 26 [13696/14860 (91%)]\tLoss: 0.022545\n",
      "Train Epoch: 26 [13824/14860 (92%)]\tLoss: 0.017074\n",
      "Train Epoch: 26 [13952/14860 (93%)]\tLoss: 0.021290\n",
      "Train Epoch: 26 [14080/14860 (94%)]\tLoss: 0.018147\n",
      "Train Epoch: 26 [14208/14860 (95%)]\tLoss: 0.019128\n",
      "Train Epoch: 26 [14336/14860 (96%)]\tLoss: 0.016171\n",
      "Train Epoch: 26 [14464/14860 (97%)]\tLoss: 0.019367\n",
      "Train Epoch: 26 [14592/14860 (97%)]\tLoss: 0.021432\n",
      "Train Epoch: 26 [14720/14860 (98%)]\tLoss: 0.022894\n",
      "Train Epoch: 26 [1392/14860 (99%)]\tLoss: 0.005206\n",
      "epoch 26 training loss: 0.02080157633202198\n",
      "epoch 26 validation loss: 0.021593151889182177\n",
      "Train Epoch: 27 [0/14860 (0%)]\tLoss: 0.015344\n",
      "Train Epoch: 27 [128/14860 (1%)]\tLoss: 0.022387\n",
      "Train Epoch: 27 [256/14860 (2%)]\tLoss: 0.024452\n",
      "Train Epoch: 27 [384/14860 (3%)]\tLoss: 0.018327\n",
      "Train Epoch: 27 [512/14860 (3%)]\tLoss: 0.019207\n",
      "Train Epoch: 27 [640/14860 (4%)]\tLoss: 0.023929\n",
      "Train Epoch: 27 [768/14860 (5%)]\tLoss: 0.015709\n",
      "Train Epoch: 27 [896/14860 (6%)]\tLoss: 0.022211\n",
      "Train Epoch: 27 [1024/14860 (7%)]\tLoss: 0.016428\n",
      "Train Epoch: 27 [1152/14860 (8%)]\tLoss: 0.015077\n",
      "Train Epoch: 27 [1280/14860 (9%)]\tLoss: 0.021753\n",
      "Train Epoch: 27 [1408/14860 (9%)]\tLoss: 0.020229\n",
      "Train Epoch: 27 [1536/14860 (10%)]\tLoss: 0.021508\n",
      "Train Epoch: 27 [1664/14860 (11%)]\tLoss: 0.015061\n",
      "Train Epoch: 27 [1792/14860 (12%)]\tLoss: 0.029575\n",
      "Train Epoch: 27 [1920/14860 (13%)]\tLoss: 0.023536\n",
      "Train Epoch: 27 [2048/14860 (14%)]\tLoss: 0.022636\n",
      "Train Epoch: 27 [2176/14860 (15%)]\tLoss: 0.020217\n",
      "Train Epoch: 27 [2304/14860 (15%)]\tLoss: 0.025666\n",
      "Train Epoch: 27 [2432/14860 (16%)]\tLoss: 0.016888\n",
      "Train Epoch: 27 [2560/14860 (17%)]\tLoss: 0.037906\n",
      "Train Epoch: 27 [2688/14860 (18%)]\tLoss: 0.014033\n",
      "Train Epoch: 27 [2816/14860 (19%)]\tLoss: 0.020962\n",
      "Train Epoch: 27 [2944/14860 (20%)]\tLoss: 0.023475\n",
      "Train Epoch: 27 [3072/14860 (21%)]\tLoss: 0.021782\n",
      "Train Epoch: 27 [3200/14860 (21%)]\tLoss: 0.014876\n",
      "Train Epoch: 27 [3328/14860 (22%)]\tLoss: 0.016310\n",
      "Train Epoch: 27 [3456/14860 (23%)]\tLoss: 0.017926\n",
      "Train Epoch: 27 [3584/14860 (24%)]\tLoss: 0.012639\n",
      "Train Epoch: 27 [3712/14860 (25%)]\tLoss: 0.016128\n",
      "Train Epoch: 27 [3840/14860 (26%)]\tLoss: 0.025866\n",
      "Train Epoch: 27 [3968/14860 (26%)]\tLoss: 0.017223\n",
      "Train Epoch: 27 [4096/14860 (27%)]\tLoss: 0.025893\n",
      "Train Epoch: 27 [4224/14860 (28%)]\tLoss: 0.020534\n",
      "Train Epoch: 27 [4352/14860 (29%)]\tLoss: 0.018775\n",
      "Train Epoch: 27 [4480/14860 (30%)]\tLoss: 0.025247\n",
      "Train Epoch: 27 [4608/14860 (31%)]\tLoss: 0.021675\n",
      "Train Epoch: 27 [4736/14860 (32%)]\tLoss: 0.019686\n",
      "Train Epoch: 27 [4864/14860 (32%)]\tLoss: 0.026915\n",
      "Train Epoch: 27 [4992/14860 (33%)]\tLoss: 0.019946\n",
      "Train Epoch: 27 [5120/14860 (34%)]\tLoss: 0.021865\n",
      "Train Epoch: 27 [5248/14860 (35%)]\tLoss: 0.019969\n",
      "Train Epoch: 27 [5376/14860 (36%)]\tLoss: 0.019133\n",
      "Train Epoch: 27 [5504/14860 (37%)]\tLoss: 0.022278\n",
      "Train Epoch: 27 [5632/14860 (38%)]\tLoss: 0.023585\n",
      "Train Epoch: 27 [5760/14860 (38%)]\tLoss: 0.016955\n",
      "Train Epoch: 27 [5888/14860 (39%)]\tLoss: 0.023565\n",
      "Train Epoch: 27 [6016/14860 (40%)]\tLoss: 0.024736\n",
      "Train Epoch: 27 [6144/14860 (41%)]\tLoss: 0.018986\n",
      "Train Epoch: 27 [6272/14860 (42%)]\tLoss: 0.018709\n",
      "Train Epoch: 27 [6400/14860 (43%)]\tLoss: 0.015137\n",
      "Train Epoch: 27 [6528/14860 (44%)]\tLoss: 0.025587\n",
      "Train Epoch: 27 [6656/14860 (44%)]\tLoss: 0.021595\n",
      "Train Epoch: 27 [6784/14860 (45%)]\tLoss: 0.019025\n",
      "Train Epoch: 27 [6912/14860 (46%)]\tLoss: 0.022515\n",
      "Train Epoch: 27 [7040/14860 (47%)]\tLoss: 0.021367\n",
      "Train Epoch: 27 [7168/14860 (48%)]\tLoss: 0.017462\n",
      "Train Epoch: 27 [7296/14860 (49%)]\tLoss: 0.034022\n",
      "Train Epoch: 27 [7424/14860 (50%)]\tLoss: 0.019623\n",
      "Train Epoch: 27 [7552/14860 (50%)]\tLoss: 0.027017\n",
      "Train Epoch: 27 [7680/14860 (51%)]\tLoss: 0.015824\n",
      "Train Epoch: 27 [7808/14860 (52%)]\tLoss: 0.030300\n",
      "Train Epoch: 27 [7936/14860 (53%)]\tLoss: 0.029653\n",
      "Train Epoch: 27 [8064/14860 (54%)]\tLoss: 0.015765\n",
      "Train Epoch: 27 [8192/14860 (55%)]\tLoss: 0.021937\n",
      "Train Epoch: 27 [8320/14860 (56%)]\tLoss: 0.023937\n",
      "Train Epoch: 27 [8448/14860 (56%)]\tLoss: 0.019475\n",
      "Train Epoch: 27 [8576/14860 (57%)]\tLoss: 0.016572\n",
      "Train Epoch: 27 [8704/14860 (58%)]\tLoss: 0.021534\n",
      "Train Epoch: 27 [8832/14860 (59%)]\tLoss: 0.019392\n",
      "Train Epoch: 27 [8960/14860 (60%)]\tLoss: 0.016367\n",
      "Train Epoch: 27 [9088/14860 (61%)]\tLoss: 0.017043\n",
      "Train Epoch: 27 [9216/14860 (62%)]\tLoss: 0.022840\n",
      "Train Epoch: 27 [9344/14860 (62%)]\tLoss: 0.024670\n",
      "Train Epoch: 27 [9472/14860 (63%)]\tLoss: 0.019797\n",
      "Train Epoch: 27 [9600/14860 (64%)]\tLoss: 0.018773\n",
      "Train Epoch: 27 [9728/14860 (65%)]\tLoss: 0.020184\n",
      "Train Epoch: 27 [9856/14860 (66%)]\tLoss: 0.018446\n",
      "Train Epoch: 27 [9984/14860 (67%)]\tLoss: 0.023977\n",
      "Train Epoch: 27 [10112/14860 (68%)]\tLoss: 0.019046\n",
      "Train Epoch: 27 [10240/14860 (68%)]\tLoss: 0.016775\n",
      "Train Epoch: 27 [10368/14860 (69%)]\tLoss: 0.018243\n",
      "Train Epoch: 27 [10496/14860 (70%)]\tLoss: 0.025196\n",
      "Train Epoch: 27 [10624/14860 (71%)]\tLoss: 0.020787\n",
      "Train Epoch: 27 [10752/14860 (72%)]\tLoss: 0.026388\n",
      "Train Epoch: 27 [10880/14860 (73%)]\tLoss: 0.015238\n",
      "Train Epoch: 27 [11008/14860 (74%)]\tLoss: 0.018508\n",
      "Train Epoch: 27 [11136/14860 (74%)]\tLoss: 0.013677\n",
      "Train Epoch: 27 [11264/14860 (75%)]\tLoss: 0.016098\n",
      "Train Epoch: 27 [11392/14860 (76%)]\tLoss: 0.020209\n",
      "Train Epoch: 27 [11520/14860 (77%)]\tLoss: 0.020781\n",
      "Train Epoch: 27 [11648/14860 (78%)]\tLoss: 0.021173\n",
      "Train Epoch: 27 [11776/14860 (79%)]\tLoss: 0.018743\n",
      "Train Epoch: 27 [11904/14860 (79%)]\tLoss: 0.018821\n",
      "Train Epoch: 27 [12032/14860 (80%)]\tLoss: 0.019203\n",
      "Train Epoch: 27 [12160/14860 (81%)]\tLoss: 0.026361\n",
      "Train Epoch: 27 [12288/14860 (82%)]\tLoss: 0.018484\n",
      "Train Epoch: 27 [12416/14860 (83%)]\tLoss: 0.020392\n",
      "Train Epoch: 27 [12544/14860 (84%)]\tLoss: 0.028551\n",
      "Train Epoch: 27 [12672/14860 (85%)]\tLoss: 0.017961\n",
      "Train Epoch: 27 [12800/14860 (85%)]\tLoss: 0.020225\n",
      "Train Epoch: 27 [12928/14860 (86%)]\tLoss: 0.026790\n",
      "Train Epoch: 27 [13056/14860 (87%)]\tLoss: 0.027239\n",
      "Train Epoch: 27 [13184/14860 (88%)]\tLoss: 0.021729\n",
      "Train Epoch: 27 [13312/14860 (89%)]\tLoss: 0.022118\n",
      "Train Epoch: 27 [13440/14860 (90%)]\tLoss: 0.021940\n",
      "Train Epoch: 27 [13568/14860 (91%)]\tLoss: 0.025805\n",
      "Train Epoch: 27 [13696/14860 (91%)]\tLoss: 0.017642\n",
      "Train Epoch: 27 [13824/14860 (92%)]\tLoss: 0.015649\n",
      "Train Epoch: 27 [13952/14860 (93%)]\tLoss: 0.016569\n",
      "Train Epoch: 27 [14080/14860 (94%)]\tLoss: 0.030832\n",
      "Train Epoch: 27 [14208/14860 (95%)]\tLoss: 0.023927\n",
      "Train Epoch: 27 [14336/14860 (96%)]\tLoss: 0.018681\n",
      "Train Epoch: 27 [14464/14860 (97%)]\tLoss: 0.019433\n",
      "Train Epoch: 27 [14592/14860 (97%)]\tLoss: 0.021155\n",
      "Train Epoch: 27 [14720/14860 (98%)]\tLoss: 0.018934\n",
      "Train Epoch: 27 [1392/14860 (99%)]\tLoss: 0.031547\n",
      "epoch 27 training loss: 0.021011936358916454\n",
      "epoch 27 validation loss: 0.03335818381344147\n",
      "Train Epoch: 28 [0/14860 (0%)]\tLoss: 0.029716\n",
      "Train Epoch: 28 [128/14860 (1%)]\tLoss: 0.023770\n",
      "Train Epoch: 28 [256/14860 (2%)]\tLoss: 0.025688\n",
      "Train Epoch: 28 [384/14860 (3%)]\tLoss: 0.029173\n",
      "Train Epoch: 28 [512/14860 (3%)]\tLoss: 0.024150\n",
      "Train Epoch: 28 [640/14860 (4%)]\tLoss: 0.028909\n",
      "Train Epoch: 28 [768/14860 (5%)]\tLoss: 0.029186\n",
      "Train Epoch: 28 [896/14860 (6%)]\tLoss: 0.021345\n",
      "Train Epoch: 28 [1024/14860 (7%)]\tLoss: 0.018504\n",
      "Train Epoch: 28 [1152/14860 (8%)]\tLoss: 0.024438\n",
      "Train Epoch: 28 [1280/14860 (9%)]\tLoss: 0.021917\n",
      "Train Epoch: 28 [1408/14860 (9%)]\tLoss: 0.016157\n",
      "Train Epoch: 28 [1536/14860 (10%)]\tLoss: 0.029228\n",
      "Train Epoch: 28 [1664/14860 (11%)]\tLoss: 0.021160\n",
      "Train Epoch: 28 [1792/14860 (12%)]\tLoss: 0.018319\n",
      "Train Epoch: 28 [1920/14860 (13%)]\tLoss: 0.019463\n",
      "Train Epoch: 28 [2048/14860 (14%)]\tLoss: 0.031205\n",
      "Train Epoch: 28 [2176/14860 (15%)]\tLoss: 0.017411\n",
      "Train Epoch: 28 [2304/14860 (15%)]\tLoss: 0.024735\n",
      "Train Epoch: 28 [2432/14860 (16%)]\tLoss: 0.022607\n",
      "Train Epoch: 28 [2560/14860 (17%)]\tLoss: 0.022829\n",
      "Train Epoch: 28 [2688/14860 (18%)]\tLoss: 0.022472\n",
      "Train Epoch: 28 [2816/14860 (19%)]\tLoss: 0.020890\n",
      "Train Epoch: 28 [2944/14860 (20%)]\tLoss: 0.028596\n",
      "Train Epoch: 28 [3072/14860 (21%)]\tLoss: 0.015860\n",
      "Train Epoch: 28 [3200/14860 (21%)]\tLoss: 0.024492\n",
      "Train Epoch: 28 [3328/14860 (22%)]\tLoss: 0.018050\n",
      "Train Epoch: 28 [3456/14860 (23%)]\tLoss: 0.018872\n",
      "Train Epoch: 28 [3584/14860 (24%)]\tLoss: 0.024291\n",
      "Train Epoch: 28 [3712/14860 (25%)]\tLoss: 0.023459\n",
      "Train Epoch: 28 [3840/14860 (26%)]\tLoss: 0.017342\n",
      "Train Epoch: 28 [3968/14860 (26%)]\tLoss: 0.019316\n",
      "Train Epoch: 28 [4096/14860 (27%)]\tLoss: 0.018676\n",
      "Train Epoch: 28 [4224/14860 (28%)]\tLoss: 0.016345\n",
      "Train Epoch: 28 [4352/14860 (29%)]\tLoss: 0.019237\n",
      "Train Epoch: 28 [4480/14860 (30%)]\tLoss: 0.026010\n",
      "Train Epoch: 28 [4608/14860 (31%)]\tLoss: 0.017525\n",
      "Train Epoch: 28 [4736/14860 (32%)]\tLoss: 0.019841\n",
      "Train Epoch: 28 [4864/14860 (32%)]\tLoss: 0.028902\n",
      "Train Epoch: 28 [4992/14860 (33%)]\tLoss: 0.024456\n",
      "Train Epoch: 28 [5120/14860 (34%)]\tLoss: 0.017992\n",
      "Train Epoch: 28 [5248/14860 (35%)]\tLoss: 0.016784\n",
      "Train Epoch: 28 [5376/14860 (36%)]\tLoss: 0.022576\n",
      "Train Epoch: 28 [5504/14860 (37%)]\tLoss: 0.028010\n",
      "Train Epoch: 28 [5632/14860 (38%)]\tLoss: 0.017375\n",
      "Train Epoch: 28 [5760/14860 (38%)]\tLoss: 0.025716\n",
      "Train Epoch: 28 [5888/14860 (39%)]\tLoss: 0.017284\n",
      "Train Epoch: 28 [6016/14860 (40%)]\tLoss: 0.013360\n",
      "Train Epoch: 28 [6144/14860 (41%)]\tLoss: 0.018043\n",
      "Train Epoch: 28 [6272/14860 (42%)]\tLoss: 0.014539\n",
      "Train Epoch: 28 [6400/14860 (43%)]\tLoss: 0.019729\n",
      "Train Epoch: 28 [6528/14860 (44%)]\tLoss: 0.016023\n",
      "Train Epoch: 28 [6656/14860 (44%)]\tLoss: 0.018799\n",
      "Train Epoch: 28 [6784/14860 (45%)]\tLoss: 0.019643\n",
      "Train Epoch: 28 [6912/14860 (46%)]\tLoss: 0.020718\n",
      "Train Epoch: 28 [7040/14860 (47%)]\tLoss: 0.027039\n",
      "Train Epoch: 28 [7168/14860 (48%)]\tLoss: 0.017466\n",
      "Train Epoch: 28 [7296/14860 (49%)]\tLoss: 0.025909\n",
      "Train Epoch: 28 [7424/14860 (50%)]\tLoss: 0.017358\n",
      "Train Epoch: 28 [7552/14860 (50%)]\tLoss: 0.019444\n",
      "Train Epoch: 28 [7680/14860 (51%)]\tLoss: 0.023845\n",
      "Train Epoch: 28 [7808/14860 (52%)]\tLoss: 0.019451\n",
      "Train Epoch: 28 [7936/14860 (53%)]\tLoss: 0.015808\n",
      "Train Epoch: 28 [8064/14860 (54%)]\tLoss: 0.020406\n",
      "Train Epoch: 28 [8192/14860 (55%)]\tLoss: 0.021910\n",
      "Train Epoch: 28 [8320/14860 (56%)]\tLoss: 0.020048\n",
      "Train Epoch: 28 [8448/14860 (56%)]\tLoss: 0.016698\n",
      "Train Epoch: 28 [8576/14860 (57%)]\tLoss: 0.023263\n",
      "Train Epoch: 28 [8704/14860 (58%)]\tLoss: 0.022641\n",
      "Train Epoch: 28 [8832/14860 (59%)]\tLoss: 0.018785\n",
      "Train Epoch: 28 [8960/14860 (60%)]\tLoss: 0.020472\n",
      "Train Epoch: 28 [9088/14860 (61%)]\tLoss: 0.014812\n",
      "Train Epoch: 28 [9216/14860 (62%)]\tLoss: 0.018534\n",
      "Train Epoch: 28 [9344/14860 (62%)]\tLoss: 0.016587\n",
      "Train Epoch: 28 [9472/14860 (63%)]\tLoss: 0.020900\n",
      "Train Epoch: 28 [9600/14860 (64%)]\tLoss: 0.023944\n",
      "Train Epoch: 28 [9728/14860 (65%)]\tLoss: 0.025967\n",
      "Train Epoch: 28 [9856/14860 (66%)]\tLoss: 0.020177\n",
      "Train Epoch: 28 [9984/14860 (67%)]\tLoss: 0.019061\n",
      "Train Epoch: 28 [10112/14860 (68%)]\tLoss: 0.017299\n",
      "Train Epoch: 28 [10240/14860 (68%)]\tLoss: 0.018020\n",
      "Train Epoch: 28 [10368/14860 (69%)]\tLoss: 0.024168\n",
      "Train Epoch: 28 [10496/14860 (70%)]\tLoss: 0.019347\n",
      "Train Epoch: 28 [10624/14860 (71%)]\tLoss: 0.019679\n",
      "Train Epoch: 28 [10752/14860 (72%)]\tLoss: 0.021077\n",
      "Train Epoch: 28 [10880/14860 (73%)]\tLoss: 0.022419\n",
      "Train Epoch: 28 [11008/14860 (74%)]\tLoss: 0.014419\n",
      "Train Epoch: 28 [11136/14860 (74%)]\tLoss: 0.030067\n",
      "Train Epoch: 28 [11264/14860 (75%)]\tLoss: 0.013003\n",
      "Train Epoch: 28 [11392/14860 (76%)]\tLoss: 0.016640\n",
      "Train Epoch: 28 [11520/14860 (77%)]\tLoss: 0.021803\n",
      "Train Epoch: 28 [11648/14860 (78%)]\tLoss: 0.015179\n",
      "Train Epoch: 28 [11776/14860 (79%)]\tLoss: 0.018665\n",
      "Train Epoch: 28 [11904/14860 (79%)]\tLoss: 0.019302\n",
      "Train Epoch: 28 [12032/14860 (80%)]\tLoss: 0.021535\n",
      "Train Epoch: 28 [12160/14860 (81%)]\tLoss: 0.017784\n",
      "Train Epoch: 28 [12288/14860 (82%)]\tLoss: 0.018778\n",
      "Train Epoch: 28 [12416/14860 (83%)]\tLoss: 0.017501\n",
      "Train Epoch: 28 [12544/14860 (84%)]\tLoss: 0.025171\n",
      "Train Epoch: 28 [12672/14860 (85%)]\tLoss: 0.020761\n",
      "Train Epoch: 28 [12800/14860 (85%)]\tLoss: 0.019076\n",
      "Train Epoch: 28 [12928/14860 (86%)]\tLoss: 0.014692\n",
      "Train Epoch: 28 [13056/14860 (87%)]\tLoss: 0.023226\n",
      "Train Epoch: 28 [13184/14860 (88%)]\tLoss: 0.011146\n",
      "Train Epoch: 28 [13312/14860 (89%)]\tLoss: 0.015204\n",
      "Train Epoch: 28 [13440/14860 (90%)]\tLoss: 0.017983\n",
      "Train Epoch: 28 [13568/14860 (91%)]\tLoss: 0.019825\n",
      "Train Epoch: 28 [13696/14860 (91%)]\tLoss: 0.018794\n",
      "Train Epoch: 28 [13824/14860 (92%)]\tLoss: 0.020368\n",
      "Train Epoch: 28 [13952/14860 (93%)]\tLoss: 0.025852\n",
      "Train Epoch: 28 [14080/14860 (94%)]\tLoss: 0.023851\n",
      "Train Epoch: 28 [14208/14860 (95%)]\tLoss: 0.016242\n",
      "Train Epoch: 28 [14336/14860 (96%)]\tLoss: 0.022228\n",
      "Train Epoch: 28 [14464/14860 (97%)]\tLoss: 0.023260\n",
      "Train Epoch: 28 [14592/14860 (97%)]\tLoss: 0.017308\n",
      "Train Epoch: 28 [14720/14860 (98%)]\tLoss: 0.022790\n",
      "Train Epoch: 28 [1392/14860 (99%)]\tLoss: 0.029914\n",
      "epoch 28 training loss: 0.020820814710205946\n",
      "epoch 28 validation loss: 0.020751024851210182\n",
      "Train Epoch: 29 [0/14860 (0%)]\tLoss: 0.016288\n",
      "Train Epoch: 29 [128/14860 (1%)]\tLoss: 0.017852\n",
      "Train Epoch: 29 [256/14860 (2%)]\tLoss: 0.024034\n",
      "Train Epoch: 29 [384/14860 (3%)]\tLoss: 0.016947\n",
      "Train Epoch: 29 [512/14860 (3%)]\tLoss: 0.024599\n",
      "Train Epoch: 29 [640/14860 (4%)]\tLoss: 0.015212\n",
      "Train Epoch: 29 [768/14860 (5%)]\tLoss: 0.020287\n",
      "Train Epoch: 29 [896/14860 (6%)]\tLoss: 0.033377\n",
      "Train Epoch: 29 [1024/14860 (7%)]\tLoss: 0.018507\n",
      "Train Epoch: 29 [1152/14860 (8%)]\tLoss: 0.018380\n",
      "Train Epoch: 29 [1280/14860 (9%)]\tLoss: 0.028176\n",
      "Train Epoch: 29 [1408/14860 (9%)]\tLoss: 0.017812\n",
      "Train Epoch: 29 [1536/14860 (10%)]\tLoss: 0.017208\n",
      "Train Epoch: 29 [1664/14860 (11%)]\tLoss: 0.020232\n",
      "Train Epoch: 29 [1792/14860 (12%)]\tLoss: 0.022202\n",
      "Train Epoch: 29 [1920/14860 (13%)]\tLoss: 0.021684\n",
      "Train Epoch: 29 [2048/14860 (14%)]\tLoss: 0.013193\n",
      "Train Epoch: 29 [2176/14860 (15%)]\tLoss: 0.024926\n",
      "Train Epoch: 29 [2304/14860 (15%)]\tLoss: 0.027549\n",
      "Train Epoch: 29 [2432/14860 (16%)]\tLoss: 0.027506\n",
      "Train Epoch: 29 [2560/14860 (17%)]\tLoss: 0.018847\n",
      "Train Epoch: 29 [2688/14860 (18%)]\tLoss: 0.019804\n",
      "Train Epoch: 29 [2816/14860 (19%)]\tLoss: 0.013524\n",
      "Train Epoch: 29 [2944/14860 (20%)]\tLoss: 0.020864\n",
      "Train Epoch: 29 [3072/14860 (21%)]\tLoss: 0.019037\n",
      "Train Epoch: 29 [3200/14860 (21%)]\tLoss: 0.025273\n",
      "Train Epoch: 29 [3328/14860 (22%)]\tLoss: 0.019832\n",
      "Train Epoch: 29 [3456/14860 (23%)]\tLoss: 0.020211\n",
      "Train Epoch: 29 [3584/14860 (24%)]\tLoss: 0.021911\n",
      "Train Epoch: 29 [3712/14860 (25%)]\tLoss: 0.019193\n",
      "Train Epoch: 29 [3840/14860 (26%)]\tLoss: 0.022556\n",
      "Train Epoch: 29 [3968/14860 (26%)]\tLoss: 0.016439\n",
      "Train Epoch: 29 [4096/14860 (27%)]\tLoss: 0.017295\n",
      "Train Epoch: 29 [4224/14860 (28%)]\tLoss: 0.023935\n",
      "Train Epoch: 29 [4352/14860 (29%)]\tLoss: 0.019094\n",
      "Train Epoch: 29 [4480/14860 (30%)]\tLoss: 0.014821\n",
      "Train Epoch: 29 [4608/14860 (31%)]\tLoss: 0.019903\n",
      "Train Epoch: 29 [4736/14860 (32%)]\tLoss: 0.015301\n",
      "Train Epoch: 29 [4864/14860 (32%)]\tLoss: 0.016162\n",
      "Train Epoch: 29 [4992/14860 (33%)]\tLoss: 0.018683\n",
      "Train Epoch: 29 [5120/14860 (34%)]\tLoss: 0.015964\n",
      "Train Epoch: 29 [5248/14860 (35%)]\tLoss: 0.024548\n",
      "Train Epoch: 29 [5376/14860 (36%)]\tLoss: 0.020087\n",
      "Train Epoch: 29 [5504/14860 (37%)]\tLoss: 0.023798\n",
      "Train Epoch: 29 [5632/14860 (38%)]\tLoss: 0.023433\n",
      "Train Epoch: 29 [5760/14860 (38%)]\tLoss: 0.017025\n",
      "Train Epoch: 29 [5888/14860 (39%)]\tLoss: 0.021040\n",
      "Train Epoch: 29 [6016/14860 (40%)]\tLoss: 0.019375\n",
      "Train Epoch: 29 [6144/14860 (41%)]\tLoss: 0.015535\n",
      "Train Epoch: 29 [6272/14860 (42%)]\tLoss: 0.017898\n",
      "Train Epoch: 29 [6400/14860 (43%)]\tLoss: 0.019970\n",
      "Train Epoch: 29 [6528/14860 (44%)]\tLoss: 0.018133\n",
      "Train Epoch: 29 [6656/14860 (44%)]\tLoss: 0.019874\n",
      "Train Epoch: 29 [6784/14860 (45%)]\tLoss: 0.019973\n",
      "Train Epoch: 29 [6912/14860 (46%)]\tLoss: 0.016324\n",
      "Train Epoch: 29 [7040/14860 (47%)]\tLoss: 0.019722\n",
      "Train Epoch: 29 [7168/14860 (48%)]\tLoss: 0.017155\n",
      "Train Epoch: 29 [7296/14860 (49%)]\tLoss: 0.032925\n",
      "Train Epoch: 29 [7424/14860 (50%)]\tLoss: 0.020263\n",
      "Train Epoch: 29 [7552/14860 (50%)]\tLoss: 0.023391\n",
      "Train Epoch: 29 [7680/14860 (51%)]\tLoss: 0.020296\n",
      "Train Epoch: 29 [7808/14860 (52%)]\tLoss: 0.020113\n",
      "Train Epoch: 29 [7936/14860 (53%)]\tLoss: 0.023320\n",
      "Train Epoch: 29 [8064/14860 (54%)]\tLoss: 0.016051\n",
      "Train Epoch: 29 [8192/14860 (55%)]\tLoss: 0.016423\n",
      "Train Epoch: 29 [8320/14860 (56%)]\tLoss: 0.016536\n",
      "Train Epoch: 29 [8448/14860 (56%)]\tLoss: 0.018224\n",
      "Train Epoch: 29 [8576/14860 (57%)]\tLoss: 0.032033\n",
      "Train Epoch: 29 [8704/14860 (58%)]\tLoss: 0.017475\n",
      "Train Epoch: 29 [8832/14860 (59%)]\tLoss: 0.023951\n",
      "Train Epoch: 29 [8960/14860 (60%)]\tLoss: 0.014284\n",
      "Train Epoch: 29 [9088/14860 (61%)]\tLoss: 0.019557\n",
      "Train Epoch: 29 [9216/14860 (62%)]\tLoss: 0.022807\n",
      "Train Epoch: 29 [9344/14860 (62%)]\tLoss: 0.020978\n",
      "Train Epoch: 29 [9472/14860 (63%)]\tLoss: 0.018599\n",
      "Train Epoch: 29 [9600/14860 (64%)]\tLoss: 0.026346\n",
      "Train Epoch: 29 [9728/14860 (65%)]\tLoss: 0.009678\n",
      "Train Epoch: 29 [9856/14860 (66%)]\tLoss: 0.035811\n",
      "Train Epoch: 29 [9984/14860 (67%)]\tLoss: 0.037671\n",
      "Train Epoch: 29 [10112/14860 (68%)]\tLoss: 0.020992\n",
      "Train Epoch: 29 [10240/14860 (68%)]\tLoss: 0.035100\n",
      "Train Epoch: 29 [10368/14860 (69%)]\tLoss: 0.024872\n",
      "Train Epoch: 29 [10496/14860 (70%)]\tLoss: 0.021319\n",
      "Train Epoch: 29 [10624/14860 (71%)]\tLoss: 0.030834\n",
      "Train Epoch: 29 [10752/14860 (72%)]\tLoss: 0.019927\n",
      "Train Epoch: 29 [10880/14860 (73%)]\tLoss: 0.018225\n",
      "Train Epoch: 29 [11008/14860 (74%)]\tLoss: 0.026341\n",
      "Train Epoch: 29 [11136/14860 (74%)]\tLoss: 0.031917\n",
      "Train Epoch: 29 [11264/14860 (75%)]\tLoss: 0.023423\n",
      "Train Epoch: 29 [11392/14860 (76%)]\tLoss: 0.025885\n",
      "Train Epoch: 29 [11520/14860 (77%)]\tLoss: 0.021390\n",
      "Train Epoch: 29 [11648/14860 (78%)]\tLoss: 0.021488\n",
      "Train Epoch: 29 [11776/14860 (79%)]\tLoss: 0.022247\n",
      "Train Epoch: 29 [11904/14860 (79%)]\tLoss: 0.026238\n",
      "Train Epoch: 29 [12032/14860 (80%)]\tLoss: 0.018763\n",
      "Train Epoch: 29 [12160/14860 (81%)]\tLoss: 0.017301\n",
      "Train Epoch: 29 [12288/14860 (82%)]\tLoss: 0.020785\n",
      "Train Epoch: 29 [12416/14860 (83%)]\tLoss: 0.027663\n",
      "Train Epoch: 29 [12544/14860 (84%)]\tLoss: 0.024960\n",
      "Train Epoch: 29 [12672/14860 (85%)]\tLoss: 0.020289\n",
      "Train Epoch: 29 [12800/14860 (85%)]\tLoss: 0.020867\n",
      "Train Epoch: 29 [12928/14860 (86%)]\tLoss: 0.021284\n",
      "Train Epoch: 29 [13056/14860 (87%)]\tLoss: 0.025736\n",
      "Train Epoch: 29 [13184/14860 (88%)]\tLoss: 0.026845\n",
      "Train Epoch: 29 [13312/14860 (89%)]\tLoss: 0.016293\n",
      "Train Epoch: 29 [13440/14860 (90%)]\tLoss: 0.016174\n",
      "Train Epoch: 29 [13568/14860 (91%)]\tLoss: 0.020036\n",
      "Train Epoch: 29 [13696/14860 (91%)]\tLoss: 0.029404\n",
      "Train Epoch: 29 [13824/14860 (92%)]\tLoss: 0.013392\n",
      "Train Epoch: 29 [13952/14860 (93%)]\tLoss: 0.017721\n",
      "Train Epoch: 29 [14080/14860 (94%)]\tLoss: 0.020558\n",
      "Train Epoch: 29 [14208/14860 (95%)]\tLoss: 0.014716\n",
      "Train Epoch: 29 [14336/14860 (96%)]\tLoss: 0.027925\n",
      "Train Epoch: 29 [14464/14860 (97%)]\tLoss: 0.020436\n",
      "Train Epoch: 29 [14592/14860 (97%)]\tLoss: 0.013762\n",
      "Train Epoch: 29 [14720/14860 (98%)]\tLoss: 0.021710\n",
      "Train Epoch: 29 [1392/14860 (99%)]\tLoss: 0.013857\n",
      "epoch 29 training loss: 0.02107622417119833\n",
      "epoch 29 validation loss: 0.020871023866223942\n",
      "Train Epoch: 30 [0/14860 (0%)]\tLoss: 0.019734\n",
      "Train Epoch: 30 [128/14860 (1%)]\tLoss: 0.017819\n",
      "Train Epoch: 30 [256/14860 (2%)]\tLoss: 0.016210\n",
      "Train Epoch: 30 [384/14860 (3%)]\tLoss: 0.020152\n",
      "Train Epoch: 30 [512/14860 (3%)]\tLoss: 0.024092\n",
      "Train Epoch: 30 [640/14860 (4%)]\tLoss: 0.021452\n",
      "Train Epoch: 30 [768/14860 (5%)]\tLoss: 0.015092\n",
      "Train Epoch: 30 [896/14860 (6%)]\tLoss: 0.022904\n",
      "Train Epoch: 30 [1024/14860 (7%)]\tLoss: 0.026126\n",
      "Train Epoch: 30 [1152/14860 (8%)]\tLoss: 0.012384\n",
      "Train Epoch: 30 [1280/14860 (9%)]\tLoss: 0.012237\n",
      "Train Epoch: 30 [1408/14860 (9%)]\tLoss: 0.023453\n",
      "Train Epoch: 30 [1536/14860 (10%)]\tLoss: 0.015991\n",
      "Train Epoch: 30 [1664/14860 (11%)]\tLoss: 0.019544\n",
      "Train Epoch: 30 [1792/14860 (12%)]\tLoss: 0.018843\n",
      "Train Epoch: 30 [1920/14860 (13%)]\tLoss: 0.012340\n",
      "Train Epoch: 30 [2048/14860 (14%)]\tLoss: 0.026557\n",
      "Train Epoch: 30 [2176/14860 (15%)]\tLoss: 0.018122\n",
      "Train Epoch: 30 [2304/14860 (15%)]\tLoss: 0.027284\n",
      "Train Epoch: 30 [2432/14860 (16%)]\tLoss: 0.031954\n",
      "Train Epoch: 30 [2560/14860 (17%)]\tLoss: 0.022909\n",
      "Train Epoch: 30 [2688/14860 (18%)]\tLoss: 0.016981\n",
      "Train Epoch: 30 [2816/14860 (19%)]\tLoss: 0.026813\n",
      "Train Epoch: 30 [2944/14860 (20%)]\tLoss: 0.016062\n",
      "Train Epoch: 30 [3072/14860 (21%)]\tLoss: 0.027922\n",
      "Train Epoch: 30 [3200/14860 (21%)]\tLoss: 0.021155\n",
      "Train Epoch: 30 [3328/14860 (22%)]\tLoss: 0.019103\n",
      "Train Epoch: 30 [3456/14860 (23%)]\tLoss: 0.031786\n",
      "Train Epoch: 30 [3584/14860 (24%)]\tLoss: 0.019428\n",
      "Train Epoch: 30 [3712/14860 (25%)]\tLoss: 0.027521\n",
      "Train Epoch: 30 [3840/14860 (26%)]\tLoss: 0.026285\n",
      "Train Epoch: 30 [3968/14860 (26%)]\tLoss: 0.014477\n",
      "Train Epoch: 30 [4096/14860 (27%)]\tLoss: 0.029536\n",
      "Train Epoch: 30 [4224/14860 (28%)]\tLoss: 0.034553\n",
      "Train Epoch: 30 [4352/14860 (29%)]\tLoss: 0.016925\n",
      "Train Epoch: 30 [4480/14860 (30%)]\tLoss: 0.020764\n",
      "Train Epoch: 30 [4608/14860 (31%)]\tLoss: 0.025220\n",
      "Train Epoch: 30 [4736/14860 (32%)]\tLoss: 0.018136\n",
      "Train Epoch: 30 [4864/14860 (32%)]\tLoss: 0.017386\n",
      "Train Epoch: 30 [4992/14860 (33%)]\tLoss: 0.026796\n",
      "Train Epoch: 30 [5120/14860 (34%)]\tLoss: 0.017286\n",
      "Train Epoch: 30 [5248/14860 (35%)]\tLoss: 0.016020\n",
      "Train Epoch: 30 [5376/14860 (36%)]\tLoss: 0.023932\n",
      "Train Epoch: 30 [5504/14860 (37%)]\tLoss: 0.023536\n",
      "Train Epoch: 30 [5632/14860 (38%)]\tLoss: 0.021146\n",
      "Train Epoch: 30 [5760/14860 (38%)]\tLoss: 0.016186\n",
      "Train Epoch: 30 [5888/14860 (39%)]\tLoss: 0.022055\n",
      "Train Epoch: 30 [6016/14860 (40%)]\tLoss: 0.023747\n",
      "Train Epoch: 30 [6144/14860 (41%)]\tLoss: 0.015420\n",
      "Train Epoch: 30 [6272/14860 (42%)]\tLoss: 0.018840\n",
      "Train Epoch: 30 [6400/14860 (43%)]\tLoss: 0.018572\n",
      "Train Epoch: 30 [6528/14860 (44%)]\tLoss: 0.014630\n",
      "Train Epoch: 30 [6656/14860 (44%)]\tLoss: 0.019499\n",
      "Train Epoch: 30 [6784/14860 (45%)]\tLoss: 0.016114\n",
      "Train Epoch: 30 [6912/14860 (46%)]\tLoss: 0.018327\n",
      "Train Epoch: 30 [7040/14860 (47%)]\tLoss: 0.019066\n",
      "Train Epoch: 30 [7168/14860 (48%)]\tLoss: 0.015579\n",
      "Train Epoch: 30 [7296/14860 (49%)]\tLoss: 0.021540\n",
      "Train Epoch: 30 [7424/14860 (50%)]\tLoss: 0.018687\n",
      "Train Epoch: 30 [7552/14860 (50%)]\tLoss: 0.025151\n",
      "Train Epoch: 30 [7680/14860 (51%)]\tLoss: 0.028910\n",
      "Train Epoch: 30 [7808/14860 (52%)]\tLoss: 0.023748\n",
      "Train Epoch: 30 [7936/14860 (53%)]\tLoss: 0.019938\n",
      "Train Epoch: 30 [8064/14860 (54%)]\tLoss: 0.022723\n",
      "Train Epoch: 30 [8192/14860 (55%)]\tLoss: 0.016785\n",
      "Train Epoch: 30 [8320/14860 (56%)]\tLoss: 0.013018\n",
      "Train Epoch: 30 [8448/14860 (56%)]\tLoss: 0.014164\n",
      "Train Epoch: 30 [8576/14860 (57%)]\tLoss: 0.018084\n",
      "Train Epoch: 30 [8704/14860 (58%)]\tLoss: 0.034430\n",
      "Train Epoch: 30 [8832/14860 (59%)]\tLoss: 0.020647\n",
      "Train Epoch: 30 [8960/14860 (60%)]\tLoss: 0.019730\n",
      "Train Epoch: 30 [9088/14860 (61%)]\tLoss: 0.028026\n",
      "Train Epoch: 30 [9216/14860 (62%)]\tLoss: 0.017159\n",
      "Train Epoch: 30 [9344/14860 (62%)]\tLoss: 0.020573\n",
      "Train Epoch: 30 [9472/14860 (63%)]\tLoss: 0.024872\n",
      "Train Epoch: 30 [9600/14860 (64%)]\tLoss: 0.022460\n",
      "Train Epoch: 30 [9728/14860 (65%)]\tLoss: 0.015265\n",
      "Train Epoch: 30 [9856/14860 (66%)]\tLoss: 0.012084\n",
      "Train Epoch: 30 [9984/14860 (67%)]\tLoss: 0.018495\n",
      "Train Epoch: 30 [10112/14860 (68%)]\tLoss: 0.026397\n",
      "Train Epoch: 30 [10240/14860 (68%)]\tLoss: 0.025463\n",
      "Train Epoch: 30 [10368/14860 (69%)]\tLoss: 0.023564\n",
      "Train Epoch: 30 [10496/14860 (70%)]\tLoss: 0.020331\n",
      "Train Epoch: 30 [10624/14860 (71%)]\tLoss: 0.017894\n",
      "Train Epoch: 30 [10752/14860 (72%)]\tLoss: 0.026257\n",
      "Train Epoch: 30 [10880/14860 (73%)]\tLoss: 0.031960\n",
      "Train Epoch: 30 [11008/14860 (74%)]\tLoss: 0.015940\n",
      "Train Epoch: 30 [11136/14860 (74%)]\tLoss: 0.019801\n",
      "Train Epoch: 30 [11264/14860 (75%)]\tLoss: 0.016203\n",
      "Train Epoch: 30 [11392/14860 (76%)]\tLoss: 0.019767\n",
      "Train Epoch: 30 [11520/14860 (77%)]\tLoss: 0.021258\n",
      "Train Epoch: 30 [11648/14860 (78%)]\tLoss: 0.026193\n",
      "Train Epoch: 30 [11776/14860 (79%)]\tLoss: 0.025455\n",
      "Train Epoch: 30 [11904/14860 (79%)]\tLoss: 0.023508\n",
      "Train Epoch: 30 [12032/14860 (80%)]\tLoss: 0.017975\n",
      "Train Epoch: 30 [12160/14860 (81%)]\tLoss: 0.019504\n",
      "Train Epoch: 30 [12288/14860 (82%)]\tLoss: 0.017431\n",
      "Train Epoch: 30 [12416/14860 (83%)]\tLoss: 0.013525\n",
      "Train Epoch: 30 [12544/14860 (84%)]\tLoss: 0.020947\n",
      "Train Epoch: 30 [12672/14860 (85%)]\tLoss: 0.019783\n",
      "Train Epoch: 30 [12800/14860 (85%)]\tLoss: 0.017222\n",
      "Train Epoch: 30 [12928/14860 (86%)]\tLoss: 0.027269\n",
      "Train Epoch: 30 [13056/14860 (87%)]\tLoss: 0.013542\n",
      "Train Epoch: 30 [13184/14860 (88%)]\tLoss: 0.021909\n",
      "Train Epoch: 30 [13312/14860 (89%)]\tLoss: 0.017019\n",
      "Train Epoch: 30 [13440/14860 (90%)]\tLoss: 0.021991\n",
      "Train Epoch: 30 [13568/14860 (91%)]\tLoss: 0.013199\n",
      "Train Epoch: 30 [13696/14860 (91%)]\tLoss: 0.019790\n",
      "Train Epoch: 30 [13824/14860 (92%)]\tLoss: 0.017023\n",
      "Train Epoch: 30 [13952/14860 (93%)]\tLoss: 0.018239\n",
      "Train Epoch: 30 [14080/14860 (94%)]\tLoss: 0.018466\n",
      "Train Epoch: 30 [14208/14860 (95%)]\tLoss: 0.017531\n",
      "Train Epoch: 30 [14336/14860 (96%)]\tLoss: 0.017031\n",
      "Train Epoch: 30 [14464/14860 (97%)]\tLoss: 0.023184\n",
      "Train Epoch: 30 [14592/14860 (97%)]\tLoss: 0.026045\n",
      "Train Epoch: 30 [14720/14860 (98%)]\tLoss: 0.026602\n",
      "Train Epoch: 30 [1392/14860 (99%)]\tLoss: 0.033013\n",
      "epoch 30 training loss: 0.02082667576196866\n",
      "epoch 30 validation loss: 0.030568162552092323\n",
      "Train Epoch: 31 [0/14860 (0%)]\tLoss: 0.022809\n",
      "Train Epoch: 31 [128/14860 (1%)]\tLoss: 0.026676\n",
      "Train Epoch: 31 [256/14860 (2%)]\tLoss: 0.025918\n",
      "Train Epoch: 31 [384/14860 (3%)]\tLoss: 0.022182\n",
      "Train Epoch: 31 [512/14860 (3%)]\tLoss: 0.036141\n",
      "Train Epoch: 31 [640/14860 (4%)]\tLoss: 0.013407\n",
      "Train Epoch: 31 [768/14860 (5%)]\tLoss: 0.018037\n",
      "Train Epoch: 31 [896/14860 (6%)]\tLoss: 0.021173\n",
      "Train Epoch: 31 [1024/14860 (7%)]\tLoss: 0.026189\n",
      "Train Epoch: 31 [1152/14860 (8%)]\tLoss: 0.024704\n",
      "Train Epoch: 31 [1280/14860 (9%)]\tLoss: 0.020435\n",
      "Train Epoch: 31 [1408/14860 (9%)]\tLoss: 0.018009\n",
      "Train Epoch: 31 [1536/14860 (10%)]\tLoss: 0.021838\n",
      "Train Epoch: 31 [1664/14860 (11%)]\tLoss: 0.019331\n",
      "Train Epoch: 31 [1792/14860 (12%)]\tLoss: 0.023678\n",
      "Train Epoch: 31 [1920/14860 (13%)]\tLoss: 0.020124\n",
      "Train Epoch: 31 [2048/14860 (14%)]\tLoss: 0.013513\n",
      "Train Epoch: 31 [2176/14860 (15%)]\tLoss: 0.026666\n",
      "Train Epoch: 31 [2304/14860 (15%)]\tLoss: 0.013216\n",
      "Train Epoch: 31 [2432/14860 (16%)]\tLoss: 0.017067\n",
      "Train Epoch: 31 [2560/14860 (17%)]\tLoss: 0.015088\n",
      "Train Epoch: 31 [2688/14860 (18%)]\tLoss: 0.017330\n",
      "Train Epoch: 31 [2816/14860 (19%)]\tLoss: 0.016744\n",
      "Train Epoch: 31 [2944/14860 (20%)]\tLoss: 0.018652\n",
      "Train Epoch: 31 [3072/14860 (21%)]\tLoss: 0.021452\n",
      "Train Epoch: 31 [3200/14860 (21%)]\tLoss: 0.016240\n",
      "Train Epoch: 31 [3328/14860 (22%)]\tLoss: 0.017022\n",
      "Train Epoch: 31 [3456/14860 (23%)]\tLoss: 0.019276\n",
      "Train Epoch: 31 [3584/14860 (24%)]\tLoss: 0.011063\n",
      "Train Epoch: 31 [3712/14860 (25%)]\tLoss: 0.024692\n",
      "Train Epoch: 31 [3840/14860 (26%)]\tLoss: 0.021701\n",
      "Train Epoch: 31 [3968/14860 (26%)]\tLoss: 0.016775\n",
      "Train Epoch: 31 [4096/14860 (27%)]\tLoss: 0.015164\n",
      "Train Epoch: 31 [4224/14860 (28%)]\tLoss: 0.022932\n",
      "Train Epoch: 31 [4352/14860 (29%)]\tLoss: 0.040558\n",
      "Train Epoch: 31 [4480/14860 (30%)]\tLoss: 0.019605\n",
      "Train Epoch: 31 [4608/14860 (31%)]\tLoss: 0.018335\n",
      "Train Epoch: 31 [4736/14860 (32%)]\tLoss: 0.020104\n",
      "Train Epoch: 31 [4864/14860 (32%)]\tLoss: 0.024419\n",
      "Train Epoch: 31 [4992/14860 (33%)]\tLoss: 0.015072\n",
      "Train Epoch: 31 [5120/14860 (34%)]\tLoss: 0.020005\n",
      "Train Epoch: 31 [5248/14860 (35%)]\tLoss: 0.017198\n",
      "Train Epoch: 31 [5376/14860 (36%)]\tLoss: 0.017959\n",
      "Train Epoch: 31 [5504/14860 (37%)]\tLoss: 0.021944\n",
      "Train Epoch: 31 [5632/14860 (38%)]\tLoss: 0.014154\n",
      "Train Epoch: 31 [5760/14860 (38%)]\tLoss: 0.019622\n",
      "Train Epoch: 31 [5888/14860 (39%)]\tLoss: 0.015548\n",
      "Train Epoch: 31 [6016/14860 (40%)]\tLoss: 0.020195\n",
      "Train Epoch: 31 [6144/14860 (41%)]\tLoss: 0.015324\n",
      "Train Epoch: 31 [6272/14860 (42%)]\tLoss: 0.019583\n",
      "Train Epoch: 31 [6400/14860 (43%)]\tLoss: 0.025764\n",
      "Train Epoch: 31 [6528/14860 (44%)]\tLoss: 0.019127\n",
      "Train Epoch: 31 [6656/14860 (44%)]\tLoss: 0.019161\n",
      "Train Epoch: 31 [6784/14860 (45%)]\tLoss: 0.015441\n",
      "Train Epoch: 31 [6912/14860 (46%)]\tLoss: 0.021331\n",
      "Train Epoch: 31 [7040/14860 (47%)]\tLoss: 0.018160\n",
      "Train Epoch: 31 [7168/14860 (48%)]\tLoss: 0.014350\n",
      "Train Epoch: 31 [7296/14860 (49%)]\tLoss: 0.026354\n",
      "Train Epoch: 31 [7424/14860 (50%)]\tLoss: 0.018463\n",
      "Train Epoch: 31 [7552/14860 (50%)]\tLoss: 0.027316\n",
      "Train Epoch: 31 [7680/14860 (51%)]\tLoss: 0.021243\n",
      "Train Epoch: 31 [7808/14860 (52%)]\tLoss: 0.018354\n",
      "Train Epoch: 31 [7936/14860 (53%)]\tLoss: 0.019075\n",
      "Train Epoch: 31 [8064/14860 (54%)]\tLoss: 0.019034\n",
      "Train Epoch: 31 [8192/14860 (55%)]\tLoss: 0.021604\n",
      "Train Epoch: 31 [8320/14860 (56%)]\tLoss: 0.020395\n",
      "Train Epoch: 31 [8448/14860 (56%)]\tLoss: 0.024191\n",
      "Train Epoch: 31 [8576/14860 (57%)]\tLoss: 0.023318\n",
      "Train Epoch: 31 [8704/14860 (58%)]\tLoss: 0.019504\n",
      "Train Epoch: 31 [8832/14860 (59%)]\tLoss: 0.016974\n",
      "Train Epoch: 31 [8960/14860 (60%)]\tLoss: 0.018239\n",
      "Train Epoch: 31 [9088/14860 (61%)]\tLoss: 0.022736\n",
      "Train Epoch: 31 [9216/14860 (62%)]\tLoss: 0.021853\n",
      "Train Epoch: 31 [9344/14860 (62%)]\tLoss: 0.022383\n",
      "Train Epoch: 31 [9472/14860 (63%)]\tLoss: 0.019822\n",
      "Train Epoch: 31 [9600/14860 (64%)]\tLoss: 0.025472\n",
      "Train Epoch: 31 [9728/14860 (65%)]\tLoss: 0.023611\n",
      "Train Epoch: 31 [9856/14860 (66%)]\tLoss: 0.023137\n",
      "Train Epoch: 31 [9984/14860 (67%)]\tLoss: 0.016830\n",
      "Train Epoch: 31 [10112/14860 (68%)]\tLoss: 0.016564\n",
      "Train Epoch: 31 [10240/14860 (68%)]\tLoss: 0.014882\n",
      "Train Epoch: 31 [10368/14860 (69%)]\tLoss: 0.014517\n",
      "Train Epoch: 31 [10496/14860 (70%)]\tLoss: 0.017489\n",
      "Train Epoch: 31 [10624/14860 (71%)]\tLoss: 0.014276\n",
      "Train Epoch: 31 [10752/14860 (72%)]\tLoss: 0.021778\n",
      "Train Epoch: 31 [10880/14860 (73%)]\tLoss: 0.018048\n",
      "Train Epoch: 31 [11008/14860 (74%)]\tLoss: 0.024865\n",
      "Train Epoch: 31 [11136/14860 (74%)]\tLoss: 0.023971\n",
      "Train Epoch: 31 [11264/14860 (75%)]\tLoss: 0.021824\n",
      "Train Epoch: 31 [11392/14860 (76%)]\tLoss: 0.020047\n",
      "Train Epoch: 31 [11520/14860 (77%)]\tLoss: 0.022058\n",
      "Train Epoch: 31 [11648/14860 (78%)]\tLoss: 0.021282\n",
      "Train Epoch: 31 [11776/14860 (79%)]\tLoss: 0.017709\n",
      "Train Epoch: 31 [11904/14860 (79%)]\tLoss: 0.022176\n",
      "Train Epoch: 31 [12032/14860 (80%)]\tLoss: 0.024186\n",
      "Train Epoch: 31 [12160/14860 (81%)]\tLoss: 0.023922\n",
      "Train Epoch: 31 [12288/14860 (82%)]\tLoss: 0.021898\n",
      "Train Epoch: 31 [12416/14860 (83%)]\tLoss: 0.020619\n",
      "Train Epoch: 31 [12544/14860 (84%)]\tLoss: 0.013761\n",
      "Train Epoch: 31 [12672/14860 (85%)]\tLoss: 0.024813\n",
      "Train Epoch: 31 [12800/14860 (85%)]\tLoss: 0.022704\n",
      "Train Epoch: 31 [12928/14860 (86%)]\tLoss: 0.028697\n",
      "Train Epoch: 31 [13056/14860 (87%)]\tLoss: 0.019831\n",
      "Train Epoch: 31 [13184/14860 (88%)]\tLoss: 0.020598\n",
      "Train Epoch: 31 [13312/14860 (89%)]\tLoss: 0.017926\n",
      "Train Epoch: 31 [13440/14860 (90%)]\tLoss: 0.015319\n",
      "Train Epoch: 31 [13568/14860 (91%)]\tLoss: 0.021954\n",
      "Train Epoch: 31 [13696/14860 (91%)]\tLoss: 0.018798\n",
      "Train Epoch: 31 [13824/14860 (92%)]\tLoss: 0.014410\n",
      "Train Epoch: 31 [13952/14860 (93%)]\tLoss: 0.021540\n",
      "Train Epoch: 31 [14080/14860 (94%)]\tLoss: 0.015431\n",
      "Train Epoch: 31 [14208/14860 (95%)]\tLoss: 0.029078\n",
      "Train Epoch: 31 [14336/14860 (96%)]\tLoss: 0.016959\n",
      "Train Epoch: 31 [14464/14860 (97%)]\tLoss: 0.018306\n",
      "Train Epoch: 31 [14592/14860 (97%)]\tLoss: 0.021197\n",
      "Train Epoch: 31 [14720/14860 (98%)]\tLoss: 0.028777\n",
      "Train Epoch: 31 [1392/14860 (99%)]\tLoss: 0.013701\n",
      "epoch 31 training loss: 0.02029079217941333\n",
      "epoch 31 validation loss: 0.024828312039086663\n",
      "Train Epoch: 32 [0/14860 (0%)]\tLoss: 0.018750\n",
      "Train Epoch: 32 [128/14860 (1%)]\tLoss: 0.034213\n",
      "Train Epoch: 32 [256/14860 (2%)]\tLoss: 0.022738\n",
      "Train Epoch: 32 [384/14860 (3%)]\tLoss: 0.018266\n",
      "Train Epoch: 32 [512/14860 (3%)]\tLoss: 0.017001\n",
      "Train Epoch: 32 [640/14860 (4%)]\tLoss: 0.016374\n",
      "Train Epoch: 32 [768/14860 (5%)]\tLoss: 0.028342\n",
      "Train Epoch: 32 [896/14860 (6%)]\tLoss: 0.018271\n",
      "Train Epoch: 32 [1024/14860 (7%)]\tLoss: 0.016192\n",
      "Train Epoch: 32 [1152/14860 (8%)]\tLoss: 0.026556\n",
      "Train Epoch: 32 [1280/14860 (9%)]\tLoss: 0.020351\n",
      "Train Epoch: 32 [1408/14860 (9%)]\tLoss: 0.020847\n",
      "Train Epoch: 32 [1536/14860 (10%)]\tLoss: 0.020281\n",
      "Train Epoch: 32 [1664/14860 (11%)]\tLoss: 0.024756\n",
      "Train Epoch: 32 [1792/14860 (12%)]\tLoss: 0.029422\n",
      "Train Epoch: 32 [1920/14860 (13%)]\tLoss: 0.023880\n",
      "Train Epoch: 32 [2048/14860 (14%)]\tLoss: 0.015518\n",
      "Train Epoch: 32 [2176/14860 (15%)]\tLoss: 0.021446\n",
      "Train Epoch: 32 [2304/14860 (15%)]\tLoss: 0.021415\n",
      "Train Epoch: 32 [2432/14860 (16%)]\tLoss: 0.020747\n",
      "Train Epoch: 32 [2560/14860 (17%)]\tLoss: 0.019237\n",
      "Train Epoch: 32 [2688/14860 (18%)]\tLoss: 0.018991\n",
      "Train Epoch: 32 [2816/14860 (19%)]\tLoss: 0.020934\n",
      "Train Epoch: 32 [2944/14860 (20%)]\tLoss: 0.028807\n",
      "Train Epoch: 32 [3072/14860 (21%)]\tLoss: 0.022157\n",
      "Train Epoch: 32 [3200/14860 (21%)]\tLoss: 0.023558\n",
      "Train Epoch: 32 [3328/14860 (22%)]\tLoss: 0.019665\n",
      "Train Epoch: 32 [3456/14860 (23%)]\tLoss: 0.016858\n",
      "Train Epoch: 32 [3584/14860 (24%)]\tLoss: 0.029944\n",
      "Train Epoch: 32 [3712/14860 (25%)]\tLoss: 0.026902\n",
      "Train Epoch: 32 [3840/14860 (26%)]\tLoss: 0.019751\n",
      "Train Epoch: 32 [3968/14860 (26%)]\tLoss: 0.019592\n",
      "Train Epoch: 32 [4096/14860 (27%)]\tLoss: 0.019980\n",
      "Train Epoch: 32 [4224/14860 (28%)]\tLoss: 0.022867\n",
      "Train Epoch: 32 [4352/14860 (29%)]\tLoss: 0.023344\n",
      "Train Epoch: 32 [4480/14860 (30%)]\tLoss: 0.019561\n",
      "Train Epoch: 32 [4608/14860 (31%)]\tLoss: 0.021263\n",
      "Train Epoch: 32 [4736/14860 (32%)]\tLoss: 0.023397\n",
      "Train Epoch: 32 [4864/14860 (32%)]\tLoss: 0.020293\n",
      "Train Epoch: 32 [4992/14860 (33%)]\tLoss: 0.019204\n",
      "Train Epoch: 32 [5120/14860 (34%)]\tLoss: 0.013633\n",
      "Train Epoch: 32 [5248/14860 (35%)]\tLoss: 0.020887\n",
      "Train Epoch: 32 [5376/14860 (36%)]\tLoss: 0.021824\n",
      "Train Epoch: 32 [5504/14860 (37%)]\tLoss: 0.017105\n",
      "Train Epoch: 32 [5632/14860 (38%)]\tLoss: 0.023524\n",
      "Train Epoch: 32 [5760/14860 (38%)]\tLoss: 0.018082\n",
      "Train Epoch: 32 [5888/14860 (39%)]\tLoss: 0.022337\n",
      "Train Epoch: 32 [6016/14860 (40%)]\tLoss: 0.016141\n",
      "Train Epoch: 32 [6144/14860 (41%)]\tLoss: 0.021018\n",
      "Train Epoch: 32 [6272/14860 (42%)]\tLoss: 0.015984\n",
      "Train Epoch: 32 [6400/14860 (43%)]\tLoss: 0.022895\n",
      "Train Epoch: 32 [6528/14860 (44%)]\tLoss: 0.018348\n",
      "Train Epoch: 32 [6656/14860 (44%)]\tLoss: 0.014722\n",
      "Train Epoch: 32 [6784/14860 (45%)]\tLoss: 0.016580\n",
      "Train Epoch: 32 [6912/14860 (46%)]\tLoss: 0.018799\n",
      "Train Epoch: 32 [7040/14860 (47%)]\tLoss: 0.019369\n",
      "Train Epoch: 32 [7168/14860 (48%)]\tLoss: 0.018774\n",
      "Train Epoch: 32 [7296/14860 (49%)]\tLoss: 0.020502\n",
      "Train Epoch: 32 [7424/14860 (50%)]\tLoss: 0.016245\n",
      "Train Epoch: 32 [7552/14860 (50%)]\tLoss: 0.015159\n",
      "Train Epoch: 32 [7680/14860 (51%)]\tLoss: 0.015257\n",
      "Train Epoch: 32 [7808/14860 (52%)]\tLoss: 0.020746\n",
      "Train Epoch: 32 [7936/14860 (53%)]\tLoss: 0.015085\n",
      "Train Epoch: 32 [8064/14860 (54%)]\tLoss: 0.018038\n",
      "Train Epoch: 32 [8192/14860 (55%)]\tLoss: 0.019794\n",
      "Train Epoch: 32 [8320/14860 (56%)]\tLoss: 0.018864\n",
      "Train Epoch: 32 [8448/14860 (56%)]\tLoss: 0.016682\n",
      "Train Epoch: 32 [8576/14860 (57%)]\tLoss: 0.014574\n",
      "Train Epoch: 32 [8704/14860 (58%)]\tLoss: 0.024817\n",
      "Train Epoch: 32 [8832/14860 (59%)]\tLoss: 0.021970\n",
      "Train Epoch: 32 [8960/14860 (60%)]\tLoss: 0.020703\n",
      "Train Epoch: 32 [9088/14860 (61%)]\tLoss: 0.019364\n",
      "Train Epoch: 32 [9216/14860 (62%)]\tLoss: 0.022760\n",
      "Train Epoch: 32 [9344/14860 (62%)]\tLoss: 0.012783\n",
      "Train Epoch: 32 [9472/14860 (63%)]\tLoss: 0.022521\n",
      "Train Epoch: 32 [9600/14860 (64%)]\tLoss: 0.018489\n",
      "Train Epoch: 32 [9728/14860 (65%)]\tLoss: 0.022489\n",
      "Train Epoch: 32 [9856/14860 (66%)]\tLoss: 0.018335\n",
      "Train Epoch: 32 [9984/14860 (67%)]\tLoss: 0.019121\n",
      "Train Epoch: 32 [10112/14860 (68%)]\tLoss: 0.016403\n",
      "Train Epoch: 32 [10240/14860 (68%)]\tLoss: 0.025838\n",
      "Train Epoch: 32 [10368/14860 (69%)]\tLoss: 0.022197\n",
      "Train Epoch: 32 [10496/14860 (70%)]\tLoss: 0.016899\n",
      "Train Epoch: 32 [10624/14860 (71%)]\tLoss: 0.018434\n",
      "Train Epoch: 32 [10752/14860 (72%)]\tLoss: 0.014500\n",
      "Train Epoch: 32 [10880/14860 (73%)]\tLoss: 0.016570\n",
      "Train Epoch: 32 [11008/14860 (74%)]\tLoss: 0.015398\n",
      "Train Epoch: 32 [11136/14860 (74%)]\tLoss: 0.028435\n",
      "Train Epoch: 32 [11264/14860 (75%)]\tLoss: 0.019833\n",
      "Train Epoch: 32 [11392/14860 (76%)]\tLoss: 0.018370\n",
      "Train Epoch: 32 [11520/14860 (77%)]\tLoss: 0.017016\n",
      "Train Epoch: 32 [11648/14860 (78%)]\tLoss: 0.015215\n",
      "Train Epoch: 32 [11776/14860 (79%)]\tLoss: 0.016342\n",
      "Train Epoch: 32 [11904/14860 (79%)]\tLoss: 0.020458\n",
      "Train Epoch: 32 [12032/14860 (80%)]\tLoss: 0.020706\n",
      "Train Epoch: 32 [12160/14860 (81%)]\tLoss: 0.016551\n",
      "Train Epoch: 32 [12288/14860 (82%)]\tLoss: 0.021959\n",
      "Train Epoch: 32 [12416/14860 (83%)]\tLoss: 0.019467\n",
      "Train Epoch: 32 [12544/14860 (84%)]\tLoss: 0.017474\n",
      "Train Epoch: 32 [12672/14860 (85%)]\tLoss: 0.026642\n",
      "Train Epoch: 32 [12800/14860 (85%)]\tLoss: 0.019458\n",
      "Train Epoch: 32 [12928/14860 (86%)]\tLoss: 0.021789\n",
      "Train Epoch: 32 [13056/14860 (87%)]\tLoss: 0.014755\n",
      "Train Epoch: 32 [13184/14860 (88%)]\tLoss: 0.024968\n",
      "Train Epoch: 32 [13312/14860 (89%)]\tLoss: 0.018700\n",
      "Train Epoch: 32 [13440/14860 (90%)]\tLoss: 0.022171\n",
      "Train Epoch: 32 [13568/14860 (91%)]\tLoss: 0.019396\n",
      "Train Epoch: 32 [13696/14860 (91%)]\tLoss: 0.026765\n",
      "Train Epoch: 32 [13824/14860 (92%)]\tLoss: 0.027458\n",
      "Train Epoch: 32 [13952/14860 (93%)]\tLoss: 0.019871\n",
      "Train Epoch: 32 [14080/14860 (94%)]\tLoss: 0.028749\n",
      "Train Epoch: 32 [14208/14860 (95%)]\tLoss: 0.012323\n",
      "Train Epoch: 32 [14336/14860 (96%)]\tLoss: 0.033998\n",
      "Train Epoch: 32 [14464/14860 (97%)]\tLoss: 0.028957\n",
      "Train Epoch: 32 [14592/14860 (97%)]\tLoss: 0.021310\n",
      "Train Epoch: 32 [14720/14860 (98%)]\tLoss: 0.029648\n",
      "Train Epoch: 32 [1392/14860 (99%)]\tLoss: 0.009485\n",
      "epoch 32 training loss: 0.020431626261745252\n",
      "epoch 32 validation loss: 0.028504135244983738\n",
      "Train Epoch: 33 [0/14860 (0%)]\tLoss: 0.025755\n",
      "Train Epoch: 33 [128/14860 (1%)]\tLoss: 0.033902\n",
      "Train Epoch: 33 [256/14860 (2%)]\tLoss: 0.016245\n",
      "Train Epoch: 33 [384/14860 (3%)]\tLoss: 0.019793\n",
      "Train Epoch: 33 [512/14860 (3%)]\tLoss: 0.021829\n",
      "Train Epoch: 33 [640/14860 (4%)]\tLoss: 0.017319\n",
      "Train Epoch: 33 [768/14860 (5%)]\tLoss: 0.025066\n",
      "Train Epoch: 33 [896/14860 (6%)]\tLoss: 0.022302\n",
      "Train Epoch: 33 [1024/14860 (7%)]\tLoss: 0.016096\n",
      "Train Epoch: 33 [1152/14860 (8%)]\tLoss: 0.016021\n",
      "Train Epoch: 33 [1280/14860 (9%)]\tLoss: 0.022261\n",
      "Train Epoch: 33 [1408/14860 (9%)]\tLoss: 0.022616\n",
      "Train Epoch: 33 [1536/14860 (10%)]\tLoss: 0.015669\n",
      "Train Epoch: 33 [1664/14860 (11%)]\tLoss: 0.025397\n",
      "Train Epoch: 33 [1792/14860 (12%)]\tLoss: 0.020065\n",
      "Train Epoch: 33 [1920/14860 (13%)]\tLoss: 0.026102\n",
      "Train Epoch: 33 [2048/14860 (14%)]\tLoss: 0.023691\n",
      "Train Epoch: 33 [2176/14860 (15%)]\tLoss: 0.028413\n",
      "Train Epoch: 33 [2304/14860 (15%)]\tLoss: 0.015674\n",
      "Train Epoch: 33 [2432/14860 (16%)]\tLoss: 0.023097\n",
      "Train Epoch: 33 [2560/14860 (17%)]\tLoss: 0.021179\n",
      "Train Epoch: 33 [2688/14860 (18%)]\tLoss: 0.016814\n",
      "Train Epoch: 33 [2816/14860 (19%)]\tLoss: 0.023764\n",
      "Train Epoch: 33 [2944/14860 (20%)]\tLoss: 0.021478\n",
      "Train Epoch: 33 [3072/14860 (21%)]\tLoss: 0.022650\n",
      "Train Epoch: 33 [3200/14860 (21%)]\tLoss: 0.024699\n",
      "Train Epoch: 33 [3328/14860 (22%)]\tLoss: 0.011280\n",
      "Train Epoch: 33 [3456/14860 (23%)]\tLoss: 0.018489\n",
      "Train Epoch: 33 [3584/14860 (24%)]\tLoss: 0.018640\n",
      "Train Epoch: 33 [3712/14860 (25%)]\tLoss: 0.016994\n",
      "Train Epoch: 33 [3840/14860 (26%)]\tLoss: 0.026577\n",
      "Train Epoch: 33 [3968/14860 (26%)]\tLoss: 0.020706\n",
      "Train Epoch: 33 [4096/14860 (27%)]\tLoss: 0.017396\n",
      "Train Epoch: 33 [4224/14860 (28%)]\tLoss: 0.022431\n",
      "Train Epoch: 33 [4352/14860 (29%)]\tLoss: 0.020689\n",
      "Train Epoch: 33 [4480/14860 (30%)]\tLoss: 0.016606\n",
      "Train Epoch: 33 [4608/14860 (31%)]\tLoss: 0.026934\n",
      "Train Epoch: 33 [4736/14860 (32%)]\tLoss: 0.017958\n",
      "Train Epoch: 33 [4864/14860 (32%)]\tLoss: 0.016986\n",
      "Train Epoch: 33 [4992/14860 (33%)]\tLoss: 0.022034\n",
      "Train Epoch: 33 [5120/14860 (34%)]\tLoss: 0.025901\n",
      "Train Epoch: 33 [5248/14860 (35%)]\tLoss: 0.018069\n",
      "Train Epoch: 33 [5376/14860 (36%)]\tLoss: 0.024551\n",
      "Train Epoch: 33 [5504/14860 (37%)]\tLoss: 0.012685\n",
      "Train Epoch: 33 [5632/14860 (38%)]\tLoss: 0.019135\n",
      "Train Epoch: 33 [5760/14860 (38%)]\tLoss: 0.022590\n",
      "Train Epoch: 33 [5888/14860 (39%)]\tLoss: 0.020138\n",
      "Train Epoch: 33 [6016/14860 (40%)]\tLoss: 0.018930\n",
      "Train Epoch: 33 [6144/14860 (41%)]\tLoss: 0.019456\n",
      "Train Epoch: 33 [6272/14860 (42%)]\tLoss: 0.021025\n",
      "Train Epoch: 33 [6400/14860 (43%)]\tLoss: 0.019803\n",
      "Train Epoch: 33 [6528/14860 (44%)]\tLoss: 0.015913\n",
      "Train Epoch: 33 [6656/14860 (44%)]\tLoss: 0.029859\n",
      "Train Epoch: 33 [6784/14860 (45%)]\tLoss: 0.017024\n",
      "Train Epoch: 33 [6912/14860 (46%)]\tLoss: 0.025780\n",
      "Train Epoch: 33 [7040/14860 (47%)]\tLoss: 0.013823\n",
      "Train Epoch: 33 [7168/14860 (48%)]\tLoss: 0.020365\n",
      "Train Epoch: 33 [7296/14860 (49%)]\tLoss: 0.022769\n",
      "Train Epoch: 33 [7424/14860 (50%)]\tLoss: 0.019179\n",
      "Train Epoch: 33 [7552/14860 (50%)]\tLoss: 0.022541\n",
      "Train Epoch: 33 [7680/14860 (51%)]\tLoss: 0.022693\n",
      "Train Epoch: 33 [7808/14860 (52%)]\tLoss: 0.020177\n",
      "Train Epoch: 33 [7936/14860 (53%)]\tLoss: 0.022955\n",
      "Train Epoch: 33 [8064/14860 (54%)]\tLoss: 0.024475\n",
      "Train Epoch: 33 [8192/14860 (55%)]\tLoss: 0.016051\n",
      "Train Epoch: 33 [8320/14860 (56%)]\tLoss: 0.023590\n",
      "Train Epoch: 33 [8448/14860 (56%)]\tLoss: 0.016686\n",
      "Train Epoch: 33 [8576/14860 (57%)]\tLoss: 0.014528\n",
      "Train Epoch: 33 [8704/14860 (58%)]\tLoss: 0.019369\n",
      "Train Epoch: 33 [8832/14860 (59%)]\tLoss: 0.020236\n",
      "Train Epoch: 33 [8960/14860 (60%)]\tLoss: 0.016581\n",
      "Train Epoch: 33 [9088/14860 (61%)]\tLoss: 0.013196\n",
      "Train Epoch: 33 [9216/14860 (62%)]\tLoss: 0.030213\n",
      "Train Epoch: 33 [9344/14860 (62%)]\tLoss: 0.017565\n",
      "Train Epoch: 33 [9472/14860 (63%)]\tLoss: 0.016286\n",
      "Train Epoch: 33 [9600/14860 (64%)]\tLoss: 0.019083\n",
      "Train Epoch: 33 [9728/14860 (65%)]\tLoss: 0.017760\n",
      "Train Epoch: 33 [9856/14860 (66%)]\tLoss: 0.014221\n",
      "Train Epoch: 33 [9984/14860 (67%)]\tLoss: 0.018212\n",
      "Train Epoch: 33 [10112/14860 (68%)]\tLoss: 0.010902\n",
      "Train Epoch: 33 [10240/14860 (68%)]\tLoss: 0.024663\n",
      "Train Epoch: 33 [10368/14860 (69%)]\tLoss: 0.030730\n",
      "Train Epoch: 33 [10496/14860 (70%)]\tLoss: 0.017970\n",
      "Train Epoch: 33 [10624/14860 (71%)]\tLoss: 0.025976\n",
      "Train Epoch: 33 [10752/14860 (72%)]\tLoss: 0.016178\n",
      "Train Epoch: 33 [10880/14860 (73%)]\tLoss: 0.020499\n",
      "Train Epoch: 33 [11008/14860 (74%)]\tLoss: 0.013630\n",
      "Train Epoch: 33 [11136/14860 (74%)]\tLoss: 0.013961\n",
      "Train Epoch: 33 [11264/14860 (75%)]\tLoss: 0.020191\n",
      "Train Epoch: 33 [11392/14860 (76%)]\tLoss: 0.020150\n",
      "Train Epoch: 33 [11520/14860 (77%)]\tLoss: 0.015794\n",
      "Train Epoch: 33 [11648/14860 (78%)]\tLoss: 0.017328\n",
      "Train Epoch: 33 [11776/14860 (79%)]\tLoss: 0.027982\n",
      "Train Epoch: 33 [11904/14860 (79%)]\tLoss: 0.018410\n",
      "Train Epoch: 33 [12032/14860 (80%)]\tLoss: 0.027191\n",
      "Train Epoch: 33 [12160/14860 (81%)]\tLoss: 0.020497\n",
      "Train Epoch: 33 [12288/14860 (82%)]\tLoss: 0.015589\n",
      "Train Epoch: 33 [12416/14860 (83%)]\tLoss: 0.022347\n",
      "Train Epoch: 33 [12544/14860 (84%)]\tLoss: 0.021956\n",
      "Train Epoch: 33 [12672/14860 (85%)]\tLoss: 0.024946\n",
      "Train Epoch: 33 [12800/14860 (85%)]\tLoss: 0.032158\n",
      "Train Epoch: 33 [12928/14860 (86%)]\tLoss: 0.018522\n",
      "Train Epoch: 33 [13056/14860 (87%)]\tLoss: 0.020781\n",
      "Train Epoch: 33 [13184/14860 (88%)]\tLoss: 0.017932\n",
      "Train Epoch: 33 [13312/14860 (89%)]\tLoss: 0.014401\n",
      "Train Epoch: 33 [13440/14860 (90%)]\tLoss: 0.025472\n",
      "Train Epoch: 33 [13568/14860 (91%)]\tLoss: 0.017833\n",
      "Train Epoch: 33 [13696/14860 (91%)]\tLoss: 0.018715\n",
      "Train Epoch: 33 [13824/14860 (92%)]\tLoss: 0.020903\n",
      "Train Epoch: 33 [13952/14860 (93%)]\tLoss: 0.019154\n",
      "Train Epoch: 33 [14080/14860 (94%)]\tLoss: 0.019959\n",
      "Train Epoch: 33 [14208/14860 (95%)]\tLoss: 0.023963\n",
      "Train Epoch: 33 [14336/14860 (96%)]\tLoss: 0.015963\n",
      "Train Epoch: 33 [14464/14860 (97%)]\tLoss: 0.019538\n",
      "Train Epoch: 33 [14592/14860 (97%)]\tLoss: 0.022439\n",
      "Train Epoch: 33 [14720/14860 (98%)]\tLoss: 0.019105\n",
      "Train Epoch: 33 [1392/14860 (99%)]\tLoss: 0.034891\n",
      "epoch 33 training loss: 0.020543985896640353\n",
      "epoch 33 validation loss: 0.029735632583535034\n",
      "Train Epoch: 34 [0/14860 (0%)]\tLoss: 0.026516\n",
      "Train Epoch: 34 [128/14860 (1%)]\tLoss: 0.022566\n",
      "Train Epoch: 34 [256/14860 (2%)]\tLoss: 0.031377\n",
      "Train Epoch: 34 [384/14860 (3%)]\tLoss: 0.028704\n",
      "Train Epoch: 34 [512/14860 (3%)]\tLoss: 0.015472\n",
      "Train Epoch: 34 [640/14860 (4%)]\tLoss: 0.028722\n",
      "Train Epoch: 34 [768/14860 (5%)]\tLoss: 0.030090\n",
      "Train Epoch: 34 [896/14860 (6%)]\tLoss: 0.019159\n",
      "Train Epoch: 34 [1024/14860 (7%)]\tLoss: 0.018754\n",
      "Train Epoch: 34 [1152/14860 (8%)]\tLoss: 0.022380\n",
      "Train Epoch: 34 [1280/14860 (9%)]\tLoss: 0.024835\n",
      "Train Epoch: 34 [1408/14860 (9%)]\tLoss: 0.016119\n",
      "Train Epoch: 34 [1536/14860 (10%)]\tLoss: 0.024423\n",
      "Train Epoch: 34 [1664/14860 (11%)]\tLoss: 0.024335\n",
      "Train Epoch: 34 [1792/14860 (12%)]\tLoss: 0.027499\n",
      "Train Epoch: 34 [1920/14860 (13%)]\tLoss: 0.029378\n",
      "Train Epoch: 34 [2048/14860 (14%)]\tLoss: 0.023617\n",
      "Train Epoch: 34 [2176/14860 (15%)]\tLoss: 0.018768\n",
      "Train Epoch: 34 [2304/14860 (15%)]\tLoss: 0.023041\n",
      "Train Epoch: 34 [2432/14860 (16%)]\tLoss: 0.021411\n",
      "Train Epoch: 34 [2560/14860 (17%)]\tLoss: 0.017411\n",
      "Train Epoch: 34 [2688/14860 (18%)]\tLoss: 0.017359\n",
      "Train Epoch: 34 [2816/14860 (19%)]\tLoss: 0.019095\n",
      "Train Epoch: 34 [2944/14860 (20%)]\tLoss: 0.016366\n",
      "Train Epoch: 34 [3072/14860 (21%)]\tLoss: 0.016220\n",
      "Train Epoch: 34 [3200/14860 (21%)]\tLoss: 0.021862\n",
      "Train Epoch: 34 [3328/14860 (22%)]\tLoss: 0.026907\n",
      "Train Epoch: 34 [3456/14860 (23%)]\tLoss: 0.023936\n",
      "Train Epoch: 34 [3584/14860 (24%)]\tLoss: 0.019158\n",
      "Train Epoch: 34 [3712/14860 (25%)]\tLoss: 0.012544\n",
      "Train Epoch: 34 [3840/14860 (26%)]\tLoss: 0.020803\n",
      "Train Epoch: 34 [3968/14860 (26%)]\tLoss: 0.020670\n",
      "Train Epoch: 34 [4096/14860 (27%)]\tLoss: 0.021951\n",
      "Train Epoch: 34 [4224/14860 (28%)]\tLoss: 0.021076\n",
      "Train Epoch: 34 [4352/14860 (29%)]\tLoss: 0.017981\n",
      "Train Epoch: 34 [4480/14860 (30%)]\tLoss: 0.024533\n",
      "Train Epoch: 34 [4608/14860 (31%)]\tLoss: 0.027649\n",
      "Train Epoch: 34 [4736/14860 (32%)]\tLoss: 0.018831\n",
      "Train Epoch: 34 [4864/14860 (32%)]\tLoss: 0.015001\n",
      "Train Epoch: 34 [4992/14860 (33%)]\tLoss: 0.020200\n",
      "Train Epoch: 34 [5120/14860 (34%)]\tLoss: 0.028932\n",
      "Train Epoch: 34 [5248/14860 (35%)]\tLoss: 0.017881\n",
      "Train Epoch: 34 [5376/14860 (36%)]\tLoss: 0.020689\n",
      "Train Epoch: 34 [5504/14860 (37%)]\tLoss: 0.018431\n",
      "Train Epoch: 34 [5632/14860 (38%)]\tLoss: 0.021657\n",
      "Train Epoch: 34 [5760/14860 (38%)]\tLoss: 0.025915\n",
      "Train Epoch: 34 [5888/14860 (39%)]\tLoss: 0.014780\n",
      "Train Epoch: 34 [6016/14860 (40%)]\tLoss: 0.014088\n",
      "Train Epoch: 34 [6144/14860 (41%)]\tLoss: 0.015699\n",
      "Train Epoch: 34 [6272/14860 (42%)]\tLoss: 0.018596\n",
      "Train Epoch: 34 [6400/14860 (43%)]\tLoss: 0.022360\n",
      "Train Epoch: 34 [6528/14860 (44%)]\tLoss: 0.014908\n",
      "Train Epoch: 34 [6656/14860 (44%)]\tLoss: 0.013403\n",
      "Train Epoch: 34 [6784/14860 (45%)]\tLoss: 0.022668\n",
      "Train Epoch: 34 [6912/14860 (46%)]\tLoss: 0.018188\n",
      "Train Epoch: 34 [7040/14860 (47%)]\tLoss: 0.011985\n",
      "Train Epoch: 34 [7168/14860 (48%)]\tLoss: 0.017863\n",
      "Train Epoch: 34 [7296/14860 (49%)]\tLoss: 0.017469\n",
      "Train Epoch: 34 [7424/14860 (50%)]\tLoss: 0.016992\n",
      "Train Epoch: 34 [7552/14860 (50%)]\tLoss: 0.018381\n",
      "Train Epoch: 34 [7680/14860 (51%)]\tLoss: 0.016293\n",
      "Train Epoch: 34 [7808/14860 (52%)]\tLoss: 0.023479\n",
      "Train Epoch: 34 [7936/14860 (53%)]\tLoss: 0.023433\n",
      "Train Epoch: 34 [8064/14860 (54%)]\tLoss: 0.015886\n",
      "Train Epoch: 34 [8192/14860 (55%)]\tLoss: 0.018327\n",
      "Train Epoch: 34 [8320/14860 (56%)]\tLoss: 0.020114\n",
      "Train Epoch: 34 [8448/14860 (56%)]\tLoss: 0.015880\n",
      "Train Epoch: 34 [8576/14860 (57%)]\tLoss: 0.012447\n",
      "Train Epoch: 34 [8704/14860 (58%)]\tLoss: 0.022752\n",
      "Train Epoch: 34 [8832/14860 (59%)]\tLoss: 0.023985\n",
      "Train Epoch: 34 [8960/14860 (60%)]\tLoss: 0.020863\n",
      "Train Epoch: 34 [9088/14860 (61%)]\tLoss: 0.015009\n",
      "Train Epoch: 34 [9216/14860 (62%)]\tLoss: 0.021746\n",
      "Train Epoch: 34 [9344/14860 (62%)]\tLoss: 0.015132\n",
      "Train Epoch: 34 [9472/14860 (63%)]\tLoss: 0.015177\n",
      "Train Epoch: 34 [9600/14860 (64%)]\tLoss: 0.018888\n",
      "Train Epoch: 34 [9728/14860 (65%)]\tLoss: 0.018255\n",
      "Train Epoch: 34 [9856/14860 (66%)]\tLoss: 0.016603\n",
      "Train Epoch: 34 [9984/14860 (67%)]\tLoss: 0.022636\n",
      "Train Epoch: 34 [10112/14860 (68%)]\tLoss: 0.021763\n",
      "Train Epoch: 34 [10240/14860 (68%)]\tLoss: 0.022126\n",
      "Train Epoch: 34 [10368/14860 (69%)]\tLoss: 0.014638\n",
      "Train Epoch: 34 [10496/14860 (70%)]\tLoss: 0.019166\n",
      "Train Epoch: 34 [10624/14860 (71%)]\tLoss: 0.014116\n",
      "Train Epoch: 34 [10752/14860 (72%)]\tLoss: 0.034692\n",
      "Train Epoch: 34 [10880/14860 (73%)]\tLoss: 0.019004\n",
      "Train Epoch: 34 [11008/14860 (74%)]\tLoss: 0.014120\n",
      "Train Epoch: 34 [11136/14860 (74%)]\tLoss: 0.014232\n",
      "Train Epoch: 34 [11264/14860 (75%)]\tLoss: 0.019695\n",
      "Train Epoch: 34 [11392/14860 (76%)]\tLoss: 0.019984\n",
      "Train Epoch: 34 [11520/14860 (77%)]\tLoss: 0.019365\n",
      "Train Epoch: 34 [11648/14860 (78%)]\tLoss: 0.018668\n",
      "Train Epoch: 34 [11776/14860 (79%)]\tLoss: 0.012882\n",
      "Train Epoch: 34 [11904/14860 (79%)]\tLoss: 0.022848\n",
      "Train Epoch: 34 [12032/14860 (80%)]\tLoss: 0.021200\n",
      "Train Epoch: 34 [12160/14860 (81%)]\tLoss: 0.023521\n",
      "Train Epoch: 34 [12288/14860 (82%)]\tLoss: 0.022408\n",
      "Train Epoch: 34 [12416/14860 (83%)]\tLoss: 0.019421\n",
      "Train Epoch: 34 [12544/14860 (84%)]\tLoss: 0.035178\n",
      "Train Epoch: 34 [12672/14860 (85%)]\tLoss: 0.015827\n",
      "Train Epoch: 34 [12800/14860 (85%)]\tLoss: 0.024490\n",
      "Train Epoch: 34 [12928/14860 (86%)]\tLoss: 0.015797\n",
      "Train Epoch: 34 [13056/14860 (87%)]\tLoss: 0.022514\n",
      "Train Epoch: 34 [13184/14860 (88%)]\tLoss: 0.024500\n",
      "Train Epoch: 34 [13312/14860 (89%)]\tLoss: 0.023282\n",
      "Train Epoch: 34 [13440/14860 (90%)]\tLoss: 0.027315\n",
      "Train Epoch: 34 [13568/14860 (91%)]\tLoss: 0.028796\n",
      "Train Epoch: 34 [13696/14860 (91%)]\tLoss: 0.025035\n",
      "Train Epoch: 34 [13824/14860 (92%)]\tLoss: 0.023126\n",
      "Train Epoch: 34 [13952/14860 (93%)]\tLoss: 0.011608\n",
      "Train Epoch: 34 [14080/14860 (94%)]\tLoss: 0.015228\n",
      "Train Epoch: 34 [14208/14860 (95%)]\tLoss: 0.019365\n",
      "Train Epoch: 34 [14336/14860 (96%)]\tLoss: 0.020144\n",
      "Train Epoch: 34 [14464/14860 (97%)]\tLoss: 0.015194\n",
      "Train Epoch: 34 [14592/14860 (97%)]\tLoss: 0.023880\n",
      "Train Epoch: 34 [14720/14860 (98%)]\tLoss: 0.014624\n",
      "Train Epoch: 34 [1392/14860 (99%)]\tLoss: 0.019177\n",
      "epoch 34 training loss: 0.02037126349651406\n",
      "epoch 34 validation loss: 0.02396364030191454\n",
      "Train Epoch: 35 [0/14860 (0%)]\tLoss: 0.021031\n",
      "Train Epoch: 35 [128/14860 (1%)]\tLoss: 0.022645\n",
      "Train Epoch: 35 [256/14860 (2%)]\tLoss: 0.016613\n",
      "Train Epoch: 35 [384/14860 (3%)]\tLoss: 0.019390\n",
      "Train Epoch: 35 [512/14860 (3%)]\tLoss: 0.024891\n",
      "Train Epoch: 35 [640/14860 (4%)]\tLoss: 0.017401\n",
      "Train Epoch: 35 [768/14860 (5%)]\tLoss: 0.025630\n",
      "Train Epoch: 35 [896/14860 (6%)]\tLoss: 0.019312\n",
      "Train Epoch: 35 [1024/14860 (7%)]\tLoss: 0.018019\n",
      "Train Epoch: 35 [1152/14860 (8%)]\tLoss: 0.028010\n",
      "Train Epoch: 35 [1280/14860 (9%)]\tLoss: 0.017744\n",
      "Train Epoch: 35 [1408/14860 (9%)]\tLoss: 0.029413\n",
      "Train Epoch: 35 [1536/14860 (10%)]\tLoss: 0.016704\n",
      "Train Epoch: 35 [1664/14860 (11%)]\tLoss: 0.012973\n",
      "Train Epoch: 35 [1792/14860 (12%)]\tLoss: 0.022399\n",
      "Train Epoch: 35 [1920/14860 (13%)]\tLoss: 0.025809\n",
      "Train Epoch: 35 [2048/14860 (14%)]\tLoss: 0.022376\n",
      "Train Epoch: 35 [2176/14860 (15%)]\tLoss: 0.024795\n",
      "Train Epoch: 35 [2304/14860 (15%)]\tLoss: 0.018031\n",
      "Train Epoch: 35 [2432/14860 (16%)]\tLoss: 0.031292\n",
      "Train Epoch: 35 [2560/14860 (17%)]\tLoss: 0.025404\n",
      "Train Epoch: 35 [2688/14860 (18%)]\tLoss: 0.018055\n",
      "Train Epoch: 35 [2816/14860 (19%)]\tLoss: 0.017365\n",
      "Train Epoch: 35 [2944/14860 (20%)]\tLoss: 0.020071\n",
      "Train Epoch: 35 [3072/14860 (21%)]\tLoss: 0.016703\n",
      "Train Epoch: 35 [3200/14860 (21%)]\tLoss: 0.018707\n",
      "Train Epoch: 35 [3328/14860 (22%)]\tLoss: 0.014037\n",
      "Train Epoch: 35 [3456/14860 (23%)]\tLoss: 0.015730\n",
      "Train Epoch: 35 [3584/14860 (24%)]\tLoss: 0.019451\n",
      "Train Epoch: 35 [3712/14860 (25%)]\tLoss: 0.018829\n",
      "Train Epoch: 35 [3840/14860 (26%)]\tLoss: 0.015204\n",
      "Train Epoch: 35 [3968/14860 (26%)]\tLoss: 0.012199\n",
      "Train Epoch: 35 [4096/14860 (27%)]\tLoss: 0.016948\n",
      "Train Epoch: 35 [4224/14860 (28%)]\tLoss: 0.024044\n",
      "Train Epoch: 35 [4352/14860 (29%)]\tLoss: 0.014125\n",
      "Train Epoch: 35 [4480/14860 (30%)]\tLoss: 0.025474\n",
      "Train Epoch: 35 [4608/14860 (31%)]\tLoss: 0.026554\n",
      "Train Epoch: 35 [4736/14860 (32%)]\tLoss: 0.017165\n",
      "Train Epoch: 35 [4864/14860 (32%)]\tLoss: 0.017733\n",
      "Train Epoch: 35 [4992/14860 (33%)]\tLoss: 0.023615\n",
      "Train Epoch: 35 [5120/14860 (34%)]\tLoss: 0.014224\n",
      "Train Epoch: 35 [5248/14860 (35%)]\tLoss: 0.014064\n",
      "Train Epoch: 35 [5376/14860 (36%)]\tLoss: 0.021767\n",
      "Train Epoch: 35 [5504/14860 (37%)]\tLoss: 0.019097\n",
      "Train Epoch: 35 [5632/14860 (38%)]\tLoss: 0.024542\n",
      "Train Epoch: 35 [5760/14860 (38%)]\tLoss: 0.019431\n",
      "Train Epoch: 35 [5888/14860 (39%)]\tLoss: 0.020324\n",
      "Train Epoch: 35 [6016/14860 (40%)]\tLoss: 0.014095\n",
      "Train Epoch: 35 [6144/14860 (41%)]\tLoss: 0.041254\n",
      "Train Epoch: 35 [6272/14860 (42%)]\tLoss: 0.026887\n",
      "Train Epoch: 35 [6400/14860 (43%)]\tLoss: 0.023180\n",
      "Train Epoch: 35 [6528/14860 (44%)]\tLoss: 0.021938\n",
      "Train Epoch: 35 [6656/14860 (44%)]\tLoss: 0.014347\n",
      "Train Epoch: 35 [6784/14860 (45%)]\tLoss: 0.026459\n",
      "Train Epoch: 35 [6912/14860 (46%)]\tLoss: 0.017693\n",
      "Train Epoch: 35 [7040/14860 (47%)]\tLoss: 0.013030\n",
      "Train Epoch: 35 [7168/14860 (48%)]\tLoss: 0.017474\n",
      "Train Epoch: 35 [7296/14860 (49%)]\tLoss: 0.011982\n",
      "Train Epoch: 35 [7424/14860 (50%)]\tLoss: 0.024439\n",
      "Train Epoch: 35 [7552/14860 (50%)]\tLoss: 0.013313\n",
      "Train Epoch: 35 [7680/14860 (51%)]\tLoss: 0.022412\n",
      "Train Epoch: 35 [7808/14860 (52%)]\tLoss: 0.016960\n",
      "Train Epoch: 35 [7936/14860 (53%)]\tLoss: 0.016840\n",
      "Train Epoch: 35 [8064/14860 (54%)]\tLoss: 0.015781\n",
      "Train Epoch: 35 [8192/14860 (55%)]\tLoss: 0.022634\n",
      "Train Epoch: 35 [8320/14860 (56%)]\tLoss: 0.023188\n",
      "Train Epoch: 35 [8448/14860 (56%)]\tLoss: 0.022358\n",
      "Train Epoch: 35 [8576/14860 (57%)]\tLoss: 0.021853\n",
      "Train Epoch: 35 [8704/14860 (58%)]\tLoss: 0.017760\n",
      "Train Epoch: 35 [8832/14860 (59%)]\tLoss: 0.019971\n",
      "Train Epoch: 35 [8960/14860 (60%)]\tLoss: 0.029260\n",
      "Train Epoch: 35 [9088/14860 (61%)]\tLoss: 0.023032\n",
      "Train Epoch: 35 [9216/14860 (62%)]\tLoss: 0.019990\n",
      "Train Epoch: 35 [9344/14860 (62%)]\tLoss: 0.016630\n",
      "Train Epoch: 35 [9472/14860 (63%)]\tLoss: 0.024401\n",
      "Train Epoch: 35 [9600/14860 (64%)]\tLoss: 0.022092\n",
      "Train Epoch: 35 [9728/14860 (65%)]\tLoss: 0.022718\n",
      "Train Epoch: 35 [9856/14860 (66%)]\tLoss: 0.018343\n",
      "Train Epoch: 35 [9984/14860 (67%)]\tLoss: 0.017785\n",
      "Train Epoch: 35 [10112/14860 (68%)]\tLoss: 0.019254\n",
      "Train Epoch: 35 [10240/14860 (68%)]\tLoss: 0.023990\n",
      "Train Epoch: 35 [10368/14860 (69%)]\tLoss: 0.023582\n",
      "Train Epoch: 35 [10496/14860 (70%)]\tLoss: 0.023373\n",
      "Train Epoch: 35 [10624/14860 (71%)]\tLoss: 0.022129\n",
      "Train Epoch: 35 [10752/14860 (72%)]\tLoss: 0.012154\n",
      "Train Epoch: 35 [10880/14860 (73%)]\tLoss: 0.025912\n",
      "Train Epoch: 35 [11008/14860 (74%)]\tLoss: 0.025491\n",
      "Train Epoch: 35 [11136/14860 (74%)]\tLoss: 0.019092\n",
      "Train Epoch: 35 [11264/14860 (75%)]\tLoss: 0.018698\n",
      "Train Epoch: 35 [11392/14860 (76%)]\tLoss: 0.020024\n",
      "Train Epoch: 35 [11520/14860 (77%)]\tLoss: 0.020047\n",
      "Train Epoch: 35 [11648/14860 (78%)]\tLoss: 0.014393\n",
      "Train Epoch: 35 [11776/14860 (79%)]\tLoss: 0.025410\n",
      "Train Epoch: 35 [11904/14860 (79%)]\tLoss: 0.018700\n",
      "Train Epoch: 35 [12032/14860 (80%)]\tLoss: 0.022064\n",
      "Train Epoch: 35 [12160/14860 (81%)]\tLoss: 0.027095\n",
      "Train Epoch: 35 [12288/14860 (82%)]\tLoss: 0.026294\n",
      "Train Epoch: 35 [12416/14860 (83%)]\tLoss: 0.017472\n",
      "Train Epoch: 35 [12544/14860 (84%)]\tLoss: 0.018785\n",
      "Train Epoch: 35 [12672/14860 (85%)]\tLoss: 0.024902\n",
      "Train Epoch: 35 [12800/14860 (85%)]\tLoss: 0.017492\n",
      "Train Epoch: 35 [12928/14860 (86%)]\tLoss: 0.020569\n",
      "Train Epoch: 35 [13056/14860 (87%)]\tLoss: 0.020262\n",
      "Train Epoch: 35 [13184/14860 (88%)]\tLoss: 0.017613\n",
      "Train Epoch: 35 [13312/14860 (89%)]\tLoss: 0.021954\n",
      "Train Epoch: 35 [13440/14860 (90%)]\tLoss: 0.017283\n",
      "Train Epoch: 35 [13568/14860 (91%)]\tLoss: 0.018712\n",
      "Train Epoch: 35 [13696/14860 (91%)]\tLoss: 0.027600\n",
      "Train Epoch: 35 [13824/14860 (92%)]\tLoss: 0.020741\n",
      "Train Epoch: 35 [13952/14860 (93%)]\tLoss: 0.024829\n",
      "Train Epoch: 35 [14080/14860 (94%)]\tLoss: 0.019446\n",
      "Train Epoch: 35 [14208/14860 (95%)]\tLoss: 0.017366\n",
      "Train Epoch: 35 [14336/14860 (96%)]\tLoss: 0.021322\n",
      "Train Epoch: 35 [14464/14860 (97%)]\tLoss: 0.025858\n",
      "Train Epoch: 35 [14592/14860 (97%)]\tLoss: 0.022221\n",
      "Train Epoch: 35 [14720/14860 (98%)]\tLoss: 0.040797\n",
      "Train Epoch: 35 [1392/14860 (99%)]\tLoss: 0.021028\n",
      "epoch 35 training loss: 0.020764012327497333\n",
      "epoch 35 validation loss: 0.0356023786431652\n",
      "Train Epoch: 36 [0/14860 (0%)]\tLoss: 0.035781\n",
      "Train Epoch: 36 [128/14860 (1%)]\tLoss: 0.042406\n",
      "Train Epoch: 36 [256/14860 (2%)]\tLoss: 0.020255\n",
      "Train Epoch: 36 [384/14860 (3%)]\tLoss: 0.029226\n",
      "Train Epoch: 36 [512/14860 (3%)]\tLoss: 0.034565\n",
      "Train Epoch: 36 [640/14860 (4%)]\tLoss: 0.020368\n",
      "Train Epoch: 36 [768/14860 (5%)]\tLoss: 0.031674\n",
      "Train Epoch: 36 [896/14860 (6%)]\tLoss: 0.030929\n",
      "Train Epoch: 36 [1024/14860 (7%)]\tLoss: 0.022922\n",
      "Train Epoch: 36 [1152/14860 (8%)]\tLoss: 0.026925\n",
      "Train Epoch: 36 [1280/14860 (9%)]\tLoss: 0.024650\n",
      "Train Epoch: 36 [1408/14860 (9%)]\tLoss: 0.029112\n",
      "Train Epoch: 36 [1536/14860 (10%)]\tLoss: 0.016005\n",
      "Train Epoch: 36 [1664/14860 (11%)]\tLoss: 0.024024\n",
      "Train Epoch: 36 [1792/14860 (12%)]\tLoss: 0.023904\n",
      "Train Epoch: 36 [1920/14860 (13%)]\tLoss: 0.018460\n",
      "Train Epoch: 36 [2048/14860 (14%)]\tLoss: 0.021658\n",
      "Train Epoch: 36 [2176/14860 (15%)]\tLoss: 0.018048\n",
      "Train Epoch: 36 [2304/14860 (15%)]\tLoss: 0.017241\n",
      "Train Epoch: 36 [2432/14860 (16%)]\tLoss: 0.031662\n",
      "Train Epoch: 36 [2560/14860 (17%)]\tLoss: 0.016532\n",
      "Train Epoch: 36 [2688/14860 (18%)]\tLoss: 0.020525\n",
      "Train Epoch: 36 [2816/14860 (19%)]\tLoss: 0.018963\n",
      "Train Epoch: 36 [2944/14860 (20%)]\tLoss: 0.021202\n",
      "Train Epoch: 36 [3072/14860 (21%)]\tLoss: 0.020268\n",
      "Train Epoch: 36 [3200/14860 (21%)]\tLoss: 0.020386\n",
      "Train Epoch: 36 [3328/14860 (22%)]\tLoss: 0.018525\n",
      "Train Epoch: 36 [3456/14860 (23%)]\tLoss: 0.014375\n",
      "Train Epoch: 36 [3584/14860 (24%)]\tLoss: 0.018082\n",
      "Train Epoch: 36 [3712/14860 (25%)]\tLoss: 0.022396\n",
      "Train Epoch: 36 [3840/14860 (26%)]\tLoss: 0.012752\n",
      "Train Epoch: 36 [3968/14860 (26%)]\tLoss: 0.017021\n",
      "Train Epoch: 36 [4096/14860 (27%)]\tLoss: 0.020255\n",
      "Train Epoch: 36 [4224/14860 (28%)]\tLoss: 0.015269\n",
      "Train Epoch: 36 [4352/14860 (29%)]\tLoss: 0.020919\n",
      "Train Epoch: 36 [4480/14860 (30%)]\tLoss: 0.017910\n",
      "Train Epoch: 36 [4608/14860 (31%)]\tLoss: 0.020304\n",
      "Train Epoch: 36 [4736/14860 (32%)]\tLoss: 0.026458\n",
      "Train Epoch: 36 [4864/14860 (32%)]\tLoss: 0.022713\n",
      "Train Epoch: 36 [4992/14860 (33%)]\tLoss: 0.020133\n",
      "Train Epoch: 36 [5120/14860 (34%)]\tLoss: 0.017189\n",
      "Train Epoch: 36 [5248/14860 (35%)]\tLoss: 0.016835\n",
      "Train Epoch: 36 [5376/14860 (36%)]\tLoss: 0.025814\n",
      "Train Epoch: 36 [5504/14860 (37%)]\tLoss: 0.023771\n",
      "Train Epoch: 36 [5632/14860 (38%)]\tLoss: 0.020993\n",
      "Train Epoch: 36 [5760/14860 (38%)]\tLoss: 0.024165\n",
      "Train Epoch: 36 [5888/14860 (39%)]\tLoss: 0.018674\n",
      "Train Epoch: 36 [6016/14860 (40%)]\tLoss: 0.021692\n",
      "Train Epoch: 36 [6144/14860 (41%)]\tLoss: 0.028197\n",
      "Train Epoch: 36 [6272/14860 (42%)]\tLoss: 0.010403\n",
      "Train Epoch: 36 [6400/14860 (43%)]\tLoss: 0.021074\n",
      "Train Epoch: 36 [6528/14860 (44%)]\tLoss: 0.019450\n",
      "Train Epoch: 36 [6656/14860 (44%)]\tLoss: 0.023294\n",
      "Train Epoch: 36 [6784/14860 (45%)]\tLoss: 0.019925\n",
      "Train Epoch: 36 [6912/14860 (46%)]\tLoss: 0.025632\n",
      "Train Epoch: 36 [7040/14860 (47%)]\tLoss: 0.017605\n",
      "Train Epoch: 36 [7168/14860 (48%)]\tLoss: 0.018798\n",
      "Train Epoch: 36 [7296/14860 (49%)]\tLoss: 0.012436\n",
      "Train Epoch: 36 [7424/14860 (50%)]\tLoss: 0.022690\n",
      "Train Epoch: 36 [7552/14860 (50%)]\tLoss: 0.012665\n",
      "Train Epoch: 36 [7680/14860 (51%)]\tLoss: 0.021639\n",
      "Train Epoch: 36 [7808/14860 (52%)]\tLoss: 0.017473\n",
      "Train Epoch: 36 [7936/14860 (53%)]\tLoss: 0.013241\n",
      "Train Epoch: 36 [8064/14860 (54%)]\tLoss: 0.023169\n",
      "Train Epoch: 36 [8192/14860 (55%)]\tLoss: 0.016957\n",
      "Train Epoch: 36 [8320/14860 (56%)]\tLoss: 0.010936\n",
      "Train Epoch: 36 [8448/14860 (56%)]\tLoss: 0.020569\n",
      "Train Epoch: 36 [8576/14860 (57%)]\tLoss: 0.024108\n",
      "Train Epoch: 36 [8704/14860 (58%)]\tLoss: 0.027184\n",
      "Train Epoch: 36 [8832/14860 (59%)]\tLoss: 0.022260\n",
      "Train Epoch: 36 [8960/14860 (60%)]\tLoss: 0.026564\n",
      "Train Epoch: 36 [9088/14860 (61%)]\tLoss: 0.025308\n",
      "Train Epoch: 36 [9216/14860 (62%)]\tLoss: 0.018354\n",
      "Train Epoch: 36 [9344/14860 (62%)]\tLoss: 0.017715\n",
      "Train Epoch: 36 [9472/14860 (63%)]\tLoss: 0.020302\n",
      "Train Epoch: 36 [9600/14860 (64%)]\tLoss: 0.018578\n",
      "Train Epoch: 36 [9728/14860 (65%)]\tLoss: 0.021851\n",
      "Train Epoch: 36 [9856/14860 (66%)]\tLoss: 0.022168\n",
      "Train Epoch: 36 [9984/14860 (67%)]\tLoss: 0.032367\n",
      "Train Epoch: 36 [10112/14860 (68%)]\tLoss: 0.016074\n",
      "Train Epoch: 36 [10240/14860 (68%)]\tLoss: 0.016807\n",
      "Train Epoch: 36 [10368/14860 (69%)]\tLoss: 0.018612\n",
      "Train Epoch: 36 [10496/14860 (70%)]\tLoss: 0.017189\n",
      "Train Epoch: 36 [10624/14860 (71%)]\tLoss: 0.018080\n",
      "Train Epoch: 36 [10752/14860 (72%)]\tLoss: 0.020229\n",
      "Train Epoch: 36 [10880/14860 (73%)]\tLoss: 0.018046\n",
      "Train Epoch: 36 [11008/14860 (74%)]\tLoss: 0.014021\n",
      "Train Epoch: 36 [11136/14860 (74%)]\tLoss: 0.013809\n",
      "Train Epoch: 36 [11264/14860 (75%)]\tLoss: 0.018302\n",
      "Train Epoch: 36 [11392/14860 (76%)]\tLoss: 0.026255\n",
      "Train Epoch: 36 [11520/14860 (77%)]\tLoss: 0.013455\n",
      "Train Epoch: 36 [11648/14860 (78%)]\tLoss: 0.013218\n",
      "Train Epoch: 36 [11776/14860 (79%)]\tLoss: 0.027530\n",
      "Train Epoch: 36 [11904/14860 (79%)]\tLoss: 0.020849\n",
      "Train Epoch: 36 [12032/14860 (80%)]\tLoss: 0.013718\n",
      "Train Epoch: 36 [12160/14860 (81%)]\tLoss: 0.020708\n",
      "Train Epoch: 36 [12288/14860 (82%)]\tLoss: 0.021015\n",
      "Train Epoch: 36 [12416/14860 (83%)]\tLoss: 0.023338\n",
      "Train Epoch: 36 [12544/14860 (84%)]\tLoss: 0.032222\n",
      "Train Epoch: 36 [12672/14860 (85%)]\tLoss: 0.020868\n",
      "Train Epoch: 36 [12800/14860 (85%)]\tLoss: 0.020612\n",
      "Train Epoch: 36 [12928/14860 (86%)]\tLoss: 0.016134\n",
      "Train Epoch: 36 [13056/14860 (87%)]\tLoss: 0.019263\n",
      "Train Epoch: 36 [13184/14860 (88%)]\tLoss: 0.023962\n",
      "Train Epoch: 36 [13312/14860 (89%)]\tLoss: 0.023408\n",
      "Train Epoch: 36 [13440/14860 (90%)]\tLoss: 0.017386\n",
      "Train Epoch: 36 [13568/14860 (91%)]\tLoss: 0.013486\n",
      "Train Epoch: 36 [13696/14860 (91%)]\tLoss: 0.019448\n",
      "Train Epoch: 36 [13824/14860 (92%)]\tLoss: 0.024436\n",
      "Train Epoch: 36 [13952/14860 (93%)]\tLoss: 0.016527\n",
      "Train Epoch: 36 [14080/14860 (94%)]\tLoss: 0.017688\n",
      "Train Epoch: 36 [14208/14860 (95%)]\tLoss: 0.026389\n",
      "Train Epoch: 36 [14336/14860 (96%)]\tLoss: 0.019512\n",
      "Train Epoch: 36 [14464/14860 (97%)]\tLoss: 0.024801\n",
      "Train Epoch: 36 [14592/14860 (97%)]\tLoss: 0.018057\n",
      "Train Epoch: 36 [14720/14860 (98%)]\tLoss: 0.012122\n",
      "Train Epoch: 36 [1392/14860 (99%)]\tLoss: 0.007829\n",
      "epoch 36 training loss: 0.02078846614393923\n",
      "epoch 36 validation loss: 0.03407696748183946\n",
      "Train Epoch: 37 [0/14860 (0%)]\tLoss: 0.027136\n",
      "Train Epoch: 37 [128/14860 (1%)]\tLoss: 0.027196\n",
      "Train Epoch: 37 [256/14860 (2%)]\tLoss: 0.022026\n",
      "Train Epoch: 37 [384/14860 (3%)]\tLoss: 0.029147\n",
      "Train Epoch: 37 [512/14860 (3%)]\tLoss: 0.028081\n",
      "Train Epoch: 37 [640/14860 (4%)]\tLoss: 0.025108\n",
      "Train Epoch: 37 [768/14860 (5%)]\tLoss: 0.020653\n",
      "Train Epoch: 37 [896/14860 (6%)]\tLoss: 0.032344\n",
      "Train Epoch: 37 [1024/14860 (7%)]\tLoss: 0.018726\n",
      "Train Epoch: 37 [1152/14860 (8%)]\tLoss: 0.024357\n",
      "Train Epoch: 37 [1280/14860 (9%)]\tLoss: 0.028509\n",
      "Train Epoch: 37 [1408/14860 (9%)]\tLoss: 0.029091\n",
      "Train Epoch: 37 [1536/14860 (10%)]\tLoss: 0.026666\n",
      "Train Epoch: 37 [1664/14860 (11%)]\tLoss: 0.018186\n",
      "Train Epoch: 37 [1792/14860 (12%)]\tLoss: 0.013503\n",
      "Train Epoch: 37 [1920/14860 (13%)]\tLoss: 0.025333\n",
      "Train Epoch: 37 [2048/14860 (14%)]\tLoss: 0.021914\n",
      "Train Epoch: 37 [2176/14860 (15%)]\tLoss: 0.022139\n",
      "Train Epoch: 37 [2304/14860 (15%)]\tLoss: 0.022175\n",
      "Train Epoch: 37 [2432/14860 (16%)]\tLoss: 0.021572\n",
      "Train Epoch: 37 [2560/14860 (17%)]\tLoss: 0.020576\n",
      "Train Epoch: 37 [2688/14860 (18%)]\tLoss: 0.031789\n",
      "Train Epoch: 37 [2816/14860 (19%)]\tLoss: 0.017753\n",
      "Train Epoch: 37 [2944/14860 (20%)]\tLoss: 0.021653\n",
      "Train Epoch: 37 [3072/14860 (21%)]\tLoss: 0.024521\n",
      "Train Epoch: 37 [3200/14860 (21%)]\tLoss: 0.016337\n",
      "Train Epoch: 37 [3328/14860 (22%)]\tLoss: 0.022878\n",
      "Train Epoch: 37 [3456/14860 (23%)]\tLoss: 0.024206\n",
      "Train Epoch: 37 [3584/14860 (24%)]\tLoss: 0.029990\n",
      "Train Epoch: 37 [3712/14860 (25%)]\tLoss: 0.010668\n",
      "Train Epoch: 37 [3840/14860 (26%)]\tLoss: 0.021399\n",
      "Train Epoch: 37 [3968/14860 (26%)]\tLoss: 0.027312\n",
      "Train Epoch: 37 [4096/14860 (27%)]\tLoss: 0.027092\n",
      "Train Epoch: 37 [4224/14860 (28%)]\tLoss: 0.030915\n",
      "Train Epoch: 37 [4352/14860 (29%)]\tLoss: 0.015293\n",
      "Train Epoch: 37 [4480/14860 (30%)]\tLoss: 0.026293\n",
      "Train Epoch: 37 [4608/14860 (31%)]\tLoss: 0.016215\n",
      "Train Epoch: 37 [4736/14860 (32%)]\tLoss: 0.024818\n",
      "Train Epoch: 37 [4864/14860 (32%)]\tLoss: 0.014984\n",
      "Train Epoch: 37 [4992/14860 (33%)]\tLoss: 0.018952\n",
      "Train Epoch: 37 [5120/14860 (34%)]\tLoss: 0.016038\n",
      "Train Epoch: 37 [5248/14860 (35%)]\tLoss: 0.017913\n",
      "Train Epoch: 37 [5376/14860 (36%)]\tLoss: 0.017390\n",
      "Train Epoch: 37 [5504/14860 (37%)]\tLoss: 0.014489\n",
      "Train Epoch: 37 [5632/14860 (38%)]\tLoss: 0.023433\n",
      "Train Epoch: 37 [5760/14860 (38%)]\tLoss: 0.022964\n",
      "Train Epoch: 37 [5888/14860 (39%)]\tLoss: 0.018456\n",
      "Train Epoch: 37 [6016/14860 (40%)]\tLoss: 0.015374\n",
      "Train Epoch: 37 [6144/14860 (41%)]\tLoss: 0.018571\n",
      "Train Epoch: 37 [6272/14860 (42%)]\tLoss: 0.015884\n",
      "Train Epoch: 37 [6400/14860 (43%)]\tLoss: 0.022152\n",
      "Train Epoch: 37 [6528/14860 (44%)]\tLoss: 0.014468\n",
      "Train Epoch: 37 [6656/14860 (44%)]\tLoss: 0.016785\n",
      "Train Epoch: 37 [6784/14860 (45%)]\tLoss: 0.016414\n",
      "Train Epoch: 37 [6912/14860 (46%)]\tLoss: 0.018436\n",
      "Train Epoch: 37 [7040/14860 (47%)]\tLoss: 0.016712\n",
      "Train Epoch: 37 [7168/14860 (48%)]\tLoss: 0.030572\n",
      "Train Epoch: 37 [7296/14860 (49%)]\tLoss: 0.021025\n",
      "Train Epoch: 37 [7424/14860 (50%)]\tLoss: 0.017017\n",
      "Train Epoch: 37 [7552/14860 (50%)]\tLoss: 0.016821\n",
      "Train Epoch: 37 [7680/14860 (51%)]\tLoss: 0.018683\n",
      "Train Epoch: 37 [7808/14860 (52%)]\tLoss: 0.020380\n",
      "Train Epoch: 37 [7936/14860 (53%)]\tLoss: 0.019331\n",
      "Train Epoch: 37 [8064/14860 (54%)]\tLoss: 0.017774\n",
      "Train Epoch: 37 [8192/14860 (55%)]\tLoss: 0.017315\n",
      "Train Epoch: 37 [8320/14860 (56%)]\tLoss: 0.027481\n",
      "Train Epoch: 37 [8448/14860 (56%)]\tLoss: 0.019968\n",
      "Train Epoch: 37 [8576/14860 (57%)]\tLoss: 0.018705\n",
      "Train Epoch: 37 [8704/14860 (58%)]\tLoss: 0.015855\n",
      "Train Epoch: 37 [8832/14860 (59%)]\tLoss: 0.017792\n",
      "Train Epoch: 37 [8960/14860 (60%)]\tLoss: 0.017768\n",
      "Train Epoch: 37 [9088/14860 (61%)]\tLoss: 0.018378\n",
      "Train Epoch: 37 [9216/14860 (62%)]\tLoss: 0.017636\n",
      "Train Epoch: 37 [9344/14860 (62%)]\tLoss: 0.018623\n",
      "Train Epoch: 37 [9472/14860 (63%)]\tLoss: 0.015988\n",
      "Train Epoch: 37 [9600/14860 (64%)]\tLoss: 0.017853\n",
      "Train Epoch: 37 [9728/14860 (65%)]\tLoss: 0.016927\n",
      "Train Epoch: 37 [9856/14860 (66%)]\tLoss: 0.020051\n",
      "Train Epoch: 37 [9984/14860 (67%)]\tLoss: 0.017698\n",
      "Train Epoch: 37 [10112/14860 (68%)]\tLoss: 0.020264\n",
      "Train Epoch: 37 [10240/14860 (68%)]\tLoss: 0.017569\n",
      "Train Epoch: 37 [10368/14860 (69%)]\tLoss: 0.029665\n",
      "Train Epoch: 37 [10496/14860 (70%)]\tLoss: 0.021061\n",
      "Train Epoch: 37 [10624/14860 (71%)]\tLoss: 0.023730\n",
      "Train Epoch: 37 [10752/14860 (72%)]\tLoss: 0.020316\n",
      "Train Epoch: 37 [10880/14860 (73%)]\tLoss: 0.018542\n",
      "Train Epoch: 37 [11008/14860 (74%)]\tLoss: 0.018372\n",
      "Train Epoch: 37 [11136/14860 (74%)]\tLoss: 0.022485\n",
      "Train Epoch: 37 [11264/14860 (75%)]\tLoss: 0.020874\n",
      "Train Epoch: 37 [11392/14860 (76%)]\tLoss: 0.023870\n",
      "Train Epoch: 37 [11520/14860 (77%)]\tLoss: 0.020347\n",
      "Train Epoch: 37 [11648/14860 (78%)]\tLoss: 0.020657\n",
      "Train Epoch: 37 [11776/14860 (79%)]\tLoss: 0.013001\n",
      "Train Epoch: 37 [11904/14860 (79%)]\tLoss: 0.022513\n",
      "Train Epoch: 37 [12032/14860 (80%)]\tLoss: 0.023563\n",
      "Train Epoch: 37 [12160/14860 (81%)]\tLoss: 0.015896\n",
      "Train Epoch: 37 [12288/14860 (82%)]\tLoss: 0.015670\n",
      "Train Epoch: 37 [12416/14860 (83%)]\tLoss: 0.017866\n",
      "Train Epoch: 37 [12544/14860 (84%)]\tLoss: 0.019929\n",
      "Train Epoch: 37 [12672/14860 (85%)]\tLoss: 0.017631\n",
      "Train Epoch: 37 [12800/14860 (85%)]\tLoss: 0.021323\n",
      "Train Epoch: 37 [12928/14860 (86%)]\tLoss: 0.017165\n",
      "Train Epoch: 37 [13056/14860 (87%)]\tLoss: 0.020411\n",
      "Train Epoch: 37 [13184/14860 (88%)]\tLoss: 0.020332\n",
      "Train Epoch: 37 [13312/14860 (89%)]\tLoss: 0.015384\n",
      "Train Epoch: 37 [13440/14860 (90%)]\tLoss: 0.017338\n",
      "Train Epoch: 37 [13568/14860 (91%)]\tLoss: 0.021807\n",
      "Train Epoch: 37 [13696/14860 (91%)]\tLoss: 0.019520\n",
      "Train Epoch: 37 [13824/14860 (92%)]\tLoss: 0.019756\n",
      "Train Epoch: 37 [13952/14860 (93%)]\tLoss: 0.024964\n",
      "Train Epoch: 37 [14080/14860 (94%)]\tLoss: 0.013843\n",
      "Train Epoch: 37 [14208/14860 (95%)]\tLoss: 0.033329\n",
      "Train Epoch: 37 [14336/14860 (96%)]\tLoss: 0.024343\n",
      "Train Epoch: 37 [14464/14860 (97%)]\tLoss: 0.015970\n",
      "Train Epoch: 37 [14592/14860 (97%)]\tLoss: 0.020435\n",
      "Train Epoch: 37 [14720/14860 (98%)]\tLoss: 0.013469\n",
      "Train Epoch: 37 [1392/14860 (99%)]\tLoss: 0.029747\n",
      "epoch 37 training loss: 0.02073146363831738\n",
      "epoch 37 validation loss: 0.02038675272435888\n",
      "Train Epoch: 38 [0/14860 (0%)]\tLoss: 0.021717\n",
      "Train Epoch: 38 [128/14860 (1%)]\tLoss: 0.021635\n",
      "Train Epoch: 38 [256/14860 (2%)]\tLoss: 0.023731\n",
      "Train Epoch: 38 [384/14860 (3%)]\tLoss: 0.022606\n",
      "Train Epoch: 38 [512/14860 (3%)]\tLoss: 0.014581\n",
      "Train Epoch: 38 [640/14860 (4%)]\tLoss: 0.017557\n",
      "Train Epoch: 38 [768/14860 (5%)]\tLoss: 0.025848\n",
      "Train Epoch: 38 [896/14860 (6%)]\tLoss: 0.023407\n",
      "Train Epoch: 38 [1024/14860 (7%)]\tLoss: 0.019040\n",
      "Train Epoch: 38 [1152/14860 (8%)]\tLoss: 0.024453\n",
      "Train Epoch: 38 [1280/14860 (9%)]\tLoss: 0.017061\n",
      "Train Epoch: 38 [1408/14860 (9%)]\tLoss: 0.019722\n",
      "Train Epoch: 38 [1536/14860 (10%)]\tLoss: 0.021048\n",
      "Train Epoch: 38 [1664/14860 (11%)]\tLoss: 0.023503\n",
      "Train Epoch: 38 [1792/14860 (12%)]\tLoss: 0.013930\n",
      "Train Epoch: 38 [1920/14860 (13%)]\tLoss: 0.019241\n",
      "Train Epoch: 38 [2048/14860 (14%)]\tLoss: 0.015912\n",
      "Train Epoch: 38 [2176/14860 (15%)]\tLoss: 0.018296\n",
      "Train Epoch: 38 [2304/14860 (15%)]\tLoss: 0.017515\n",
      "Train Epoch: 38 [2432/14860 (16%)]\tLoss: 0.018546\n",
      "Train Epoch: 38 [2560/14860 (17%)]\tLoss: 0.022140\n",
      "Train Epoch: 38 [2688/14860 (18%)]\tLoss: 0.030673\n",
      "Train Epoch: 38 [2816/14860 (19%)]\tLoss: 0.020054\n",
      "Train Epoch: 38 [2944/14860 (20%)]\tLoss: 0.021059\n",
      "Train Epoch: 38 [3072/14860 (21%)]\tLoss: 0.021511\n",
      "Train Epoch: 38 [3200/14860 (21%)]\tLoss: 0.020525\n",
      "Train Epoch: 38 [3328/14860 (22%)]\tLoss: 0.013747\n",
      "Train Epoch: 38 [3456/14860 (23%)]\tLoss: 0.021031\n",
      "Train Epoch: 38 [3584/14860 (24%)]\tLoss: 0.023270\n",
      "Train Epoch: 38 [3712/14860 (25%)]\tLoss: 0.013715\n",
      "Train Epoch: 38 [3840/14860 (26%)]\tLoss: 0.012097\n",
      "Train Epoch: 38 [3968/14860 (26%)]\tLoss: 0.029266\n",
      "Train Epoch: 38 [4096/14860 (27%)]\tLoss: 0.021004\n",
      "Train Epoch: 38 [4224/14860 (28%)]\tLoss: 0.021975\n",
      "Train Epoch: 38 [4352/14860 (29%)]\tLoss: 0.032061\n",
      "Train Epoch: 38 [4480/14860 (30%)]\tLoss: 0.026392\n",
      "Train Epoch: 38 [4608/14860 (31%)]\tLoss: 0.021572\n",
      "Train Epoch: 38 [4736/14860 (32%)]\tLoss: 0.023020\n",
      "Train Epoch: 38 [4864/14860 (32%)]\tLoss: 0.017890\n",
      "Train Epoch: 38 [4992/14860 (33%)]\tLoss: 0.018467\n",
      "Train Epoch: 38 [5120/14860 (34%)]\tLoss: 0.018199\n",
      "Train Epoch: 38 [5248/14860 (35%)]\tLoss: 0.017648\n",
      "Train Epoch: 38 [5376/14860 (36%)]\tLoss: 0.019868\n",
      "Train Epoch: 38 [5504/14860 (37%)]\tLoss: 0.017599\n",
      "Train Epoch: 38 [5632/14860 (38%)]\tLoss: 0.020173\n",
      "Train Epoch: 38 [5760/14860 (38%)]\tLoss: 0.018230\n",
      "Train Epoch: 38 [5888/14860 (39%)]\tLoss: 0.019674\n",
      "Train Epoch: 38 [6016/14860 (40%)]\tLoss: 0.025513\n",
      "Train Epoch: 38 [6144/14860 (41%)]\tLoss: 0.018206\n",
      "Train Epoch: 38 [6272/14860 (42%)]\tLoss: 0.021552\n",
      "Train Epoch: 38 [6400/14860 (43%)]\tLoss: 0.015563\n",
      "Train Epoch: 38 [6528/14860 (44%)]\tLoss: 0.013787\n",
      "Train Epoch: 38 [6656/14860 (44%)]\tLoss: 0.024813\n",
      "Train Epoch: 38 [6784/14860 (45%)]\tLoss: 0.018601\n",
      "Train Epoch: 38 [6912/14860 (46%)]\tLoss: 0.021235\n",
      "Train Epoch: 38 [7040/14860 (47%)]\tLoss: 0.018062\n",
      "Train Epoch: 38 [7168/14860 (48%)]\tLoss: 0.018327\n",
      "Train Epoch: 38 [7296/14860 (49%)]\tLoss: 0.023578\n",
      "Train Epoch: 38 [7424/14860 (50%)]\tLoss: 0.017600\n",
      "Train Epoch: 38 [7552/14860 (50%)]\tLoss: 0.015073\n",
      "Train Epoch: 38 [7680/14860 (51%)]\tLoss: 0.018160\n",
      "Train Epoch: 38 [7808/14860 (52%)]\tLoss: 0.012639\n",
      "Train Epoch: 38 [7936/14860 (53%)]\tLoss: 0.018473\n",
      "Train Epoch: 38 [8064/14860 (54%)]\tLoss: 0.014922\n",
      "Train Epoch: 38 [8192/14860 (55%)]\tLoss: 0.021624\n",
      "Train Epoch: 38 [8320/14860 (56%)]\tLoss: 0.024397\n",
      "Train Epoch: 38 [8448/14860 (56%)]\tLoss: 0.013878\n",
      "Train Epoch: 38 [8576/14860 (57%)]\tLoss: 0.029234\n",
      "Train Epoch: 38 [8704/14860 (58%)]\tLoss: 0.022469\n",
      "Train Epoch: 38 [8832/14860 (59%)]\tLoss: 0.011958\n",
      "Train Epoch: 38 [8960/14860 (60%)]\tLoss: 0.020127\n",
      "Train Epoch: 38 [9088/14860 (61%)]\tLoss: 0.017948\n",
      "Train Epoch: 38 [9216/14860 (62%)]\tLoss: 0.015030\n",
      "Train Epoch: 38 [9344/14860 (62%)]\tLoss: 0.027070\n",
      "Train Epoch: 38 [9472/14860 (63%)]\tLoss: 0.022617\n",
      "Train Epoch: 38 [9600/14860 (64%)]\tLoss: 0.016018\n",
      "Train Epoch: 38 [9728/14860 (65%)]\tLoss: 0.015765\n",
      "Train Epoch: 38 [9856/14860 (66%)]\tLoss: 0.024208\n",
      "Train Epoch: 38 [9984/14860 (67%)]\tLoss: 0.011711\n",
      "Train Epoch: 38 [10112/14860 (68%)]\tLoss: 0.017722\n",
      "Train Epoch: 38 [10240/14860 (68%)]\tLoss: 0.018356\n",
      "Train Epoch: 38 [10368/14860 (69%)]\tLoss: 0.015106\n",
      "Train Epoch: 38 [10496/14860 (70%)]\tLoss: 0.023278\n",
      "Train Epoch: 38 [10624/14860 (71%)]\tLoss: 0.013399\n",
      "Train Epoch: 38 [10752/14860 (72%)]\tLoss: 0.017968\n",
      "Train Epoch: 38 [10880/14860 (73%)]\tLoss: 0.017990\n",
      "Train Epoch: 38 [11008/14860 (74%)]\tLoss: 0.015419\n",
      "Train Epoch: 38 [11136/14860 (74%)]\tLoss: 0.016606\n",
      "Train Epoch: 38 [11264/14860 (75%)]\tLoss: 0.020617\n",
      "Train Epoch: 38 [11392/14860 (76%)]\tLoss: 0.016901\n",
      "Train Epoch: 38 [11520/14860 (77%)]\tLoss: 0.017581\n",
      "Train Epoch: 38 [11648/14860 (78%)]\tLoss: 0.012438\n",
      "Train Epoch: 38 [11776/14860 (79%)]\tLoss: 0.023229\n",
      "Train Epoch: 38 [11904/14860 (79%)]\tLoss: 0.023792\n",
      "Train Epoch: 38 [12032/14860 (80%)]\tLoss: 0.018101\n",
      "Train Epoch: 38 [12160/14860 (81%)]\tLoss: 0.012217\n",
      "Train Epoch: 38 [12288/14860 (82%)]\tLoss: 0.019440\n",
      "Train Epoch: 38 [12416/14860 (83%)]\tLoss: 0.016246\n",
      "Train Epoch: 38 [12544/14860 (84%)]\tLoss: 0.016231\n",
      "Train Epoch: 38 [12672/14860 (85%)]\tLoss: 0.025215\n",
      "Train Epoch: 38 [12800/14860 (85%)]\tLoss: 0.024595\n",
      "Train Epoch: 38 [12928/14860 (86%)]\tLoss: 0.030288\n",
      "Train Epoch: 38 [13056/14860 (87%)]\tLoss: 0.027682\n",
      "Train Epoch: 38 [13184/14860 (88%)]\tLoss: 0.024932\n",
      "Train Epoch: 38 [13312/14860 (89%)]\tLoss: 0.017288\n",
      "Train Epoch: 38 [13440/14860 (90%)]\tLoss: 0.020980\n",
      "Train Epoch: 38 [13568/14860 (91%)]\tLoss: 0.021768\n",
      "Train Epoch: 38 [13696/14860 (91%)]\tLoss: 0.026218\n",
      "Train Epoch: 38 [13824/14860 (92%)]\tLoss: 0.017038\n",
      "Train Epoch: 38 [13952/14860 (93%)]\tLoss: 0.016340\n",
      "Train Epoch: 38 [14080/14860 (94%)]\tLoss: 0.024940\n",
      "Train Epoch: 38 [14208/14860 (95%)]\tLoss: 0.021503\n",
      "Train Epoch: 38 [14336/14860 (96%)]\tLoss: 0.021270\n",
      "Train Epoch: 38 [14464/14860 (97%)]\tLoss: 0.021350\n",
      "Train Epoch: 38 [14592/14860 (97%)]\tLoss: 0.011298\n",
      "Train Epoch: 38 [14720/14860 (98%)]\tLoss: 0.017448\n",
      "Train Epoch: 38 [1392/14860 (99%)]\tLoss: 0.010065\n",
      "epoch 38 training loss: 0.01970275817836961\n",
      "epoch 38 validation loss: 0.02382347918595875\n",
      "Train Epoch: 39 [0/14860 (0%)]\tLoss: 0.015492\n",
      "Train Epoch: 39 [128/14860 (1%)]\tLoss: 0.023393\n",
      "Train Epoch: 39 [256/14860 (2%)]\tLoss: 0.019807\n",
      "Train Epoch: 39 [384/14860 (3%)]\tLoss: 0.023622\n",
      "Train Epoch: 39 [512/14860 (3%)]\tLoss: 0.033377\n",
      "Train Epoch: 39 [640/14860 (4%)]\tLoss: 0.020946\n",
      "Train Epoch: 39 [768/14860 (5%)]\tLoss: 0.023791\n",
      "Train Epoch: 39 [896/14860 (6%)]\tLoss: 0.018346\n",
      "Train Epoch: 39 [1024/14860 (7%)]\tLoss: 0.015836\n",
      "Train Epoch: 39 [1152/14860 (8%)]\tLoss: 0.012036\n",
      "Train Epoch: 39 [1280/14860 (9%)]\tLoss: 0.018328\n",
      "Train Epoch: 39 [1408/14860 (9%)]\tLoss: 0.015826\n",
      "Train Epoch: 39 [1536/14860 (10%)]\tLoss: 0.020556\n",
      "Train Epoch: 39 [1664/14860 (11%)]\tLoss: 0.029516\n",
      "Train Epoch: 39 [1792/14860 (12%)]\tLoss: 0.018462\n",
      "Train Epoch: 39 [1920/14860 (13%)]\tLoss: 0.020866\n",
      "Train Epoch: 39 [2048/14860 (14%)]\tLoss: 0.023177\n",
      "Train Epoch: 39 [2176/14860 (15%)]\tLoss: 0.015516\n",
      "Train Epoch: 39 [2304/14860 (15%)]\tLoss: 0.023987\n",
      "Train Epoch: 39 [2432/14860 (16%)]\tLoss: 0.023297\n",
      "Train Epoch: 39 [2560/14860 (17%)]\tLoss: 0.021251\n",
      "Train Epoch: 39 [2688/14860 (18%)]\tLoss: 0.023762\n",
      "Train Epoch: 39 [2816/14860 (19%)]\tLoss: 0.013734\n",
      "Train Epoch: 39 [2944/14860 (20%)]\tLoss: 0.031393\n",
      "Train Epoch: 39 [3072/14860 (21%)]\tLoss: 0.020801\n",
      "Train Epoch: 39 [3200/14860 (21%)]\tLoss: 0.025472\n",
      "Train Epoch: 39 [3328/14860 (22%)]\tLoss: 0.021319\n",
      "Train Epoch: 39 [3456/14860 (23%)]\tLoss: 0.024609\n",
      "Train Epoch: 39 [3584/14860 (24%)]\tLoss: 0.018351\n",
      "Train Epoch: 39 [3712/14860 (25%)]\tLoss: 0.016497\n",
      "Train Epoch: 39 [3840/14860 (26%)]\tLoss: 0.019522\n",
      "Train Epoch: 39 [3968/14860 (26%)]\tLoss: 0.023088\n",
      "Train Epoch: 39 [4096/14860 (27%)]\tLoss: 0.023632\n",
      "Train Epoch: 39 [4224/14860 (28%)]\tLoss: 0.025504\n",
      "Train Epoch: 39 [4352/14860 (29%)]\tLoss: 0.017431\n",
      "Train Epoch: 39 [4480/14860 (30%)]\tLoss: 0.016467\n",
      "Train Epoch: 39 [4608/14860 (31%)]\tLoss: 0.026995\n",
      "Train Epoch: 39 [4736/14860 (32%)]\tLoss: 0.014432\n",
      "Train Epoch: 39 [4864/14860 (32%)]\tLoss: 0.019248\n",
      "Train Epoch: 39 [4992/14860 (33%)]\tLoss: 0.021121\n",
      "Train Epoch: 39 [5120/14860 (34%)]\tLoss: 0.024466\n",
      "Train Epoch: 39 [5248/14860 (35%)]\tLoss: 0.019935\n",
      "Train Epoch: 39 [5376/14860 (36%)]\tLoss: 0.019140\n",
      "Train Epoch: 39 [5504/14860 (37%)]\tLoss: 0.015479\n",
      "Train Epoch: 39 [5632/14860 (38%)]\tLoss: 0.018760\n",
      "Train Epoch: 39 [5760/14860 (38%)]\tLoss: 0.015917\n",
      "Train Epoch: 39 [5888/14860 (39%)]\tLoss: 0.018708\n",
      "Train Epoch: 39 [6016/14860 (40%)]\tLoss: 0.016942\n",
      "Train Epoch: 39 [6144/14860 (41%)]\tLoss: 0.018760\n",
      "Train Epoch: 39 [6272/14860 (42%)]\tLoss: 0.014326\n",
      "Train Epoch: 39 [6400/14860 (43%)]\tLoss: 0.017059\n",
      "Train Epoch: 39 [6528/14860 (44%)]\tLoss: 0.018111\n",
      "Train Epoch: 39 [6656/14860 (44%)]\tLoss: 0.021448\n",
      "Train Epoch: 39 [6784/14860 (45%)]\tLoss: 0.020996\n",
      "Train Epoch: 39 [6912/14860 (46%)]\tLoss: 0.017373\n",
      "Train Epoch: 39 [7040/14860 (47%)]\tLoss: 0.017539\n",
      "Train Epoch: 39 [7168/14860 (48%)]\tLoss: 0.021338\n",
      "Train Epoch: 39 [7296/14860 (49%)]\tLoss: 0.017951\n",
      "Train Epoch: 39 [7424/14860 (50%)]\tLoss: 0.021625\n",
      "Train Epoch: 39 [7552/14860 (50%)]\tLoss: 0.016579\n",
      "Train Epoch: 39 [7680/14860 (51%)]\tLoss: 0.011493\n",
      "Train Epoch: 39 [7808/14860 (52%)]\tLoss: 0.016346\n",
      "Train Epoch: 39 [7936/14860 (53%)]\tLoss: 0.016016\n",
      "Train Epoch: 39 [8064/14860 (54%)]\tLoss: 0.026191\n",
      "Train Epoch: 39 [8192/14860 (55%)]\tLoss: 0.020534\n",
      "Train Epoch: 39 [8320/14860 (56%)]\tLoss: 0.015062\n",
      "Train Epoch: 39 [8448/14860 (56%)]\tLoss: 0.012481\n",
      "Train Epoch: 39 [8576/14860 (57%)]\tLoss: 0.024521\n",
      "Train Epoch: 39 [8704/14860 (58%)]\tLoss: 0.028319\n",
      "Train Epoch: 39 [8832/14860 (59%)]\tLoss: 0.021774\n",
      "Train Epoch: 39 [8960/14860 (60%)]\tLoss: 0.020778\n",
      "Train Epoch: 39 [9088/14860 (61%)]\tLoss: 0.023443\n",
      "Train Epoch: 39 [9216/14860 (62%)]\tLoss: 0.026560\n",
      "Train Epoch: 39 [9344/14860 (62%)]\tLoss: 0.021048\n",
      "Train Epoch: 39 [9472/14860 (63%)]\tLoss: 0.028350\n",
      "Train Epoch: 39 [9600/14860 (64%)]\tLoss: 0.020307\n",
      "Train Epoch: 39 [9728/14860 (65%)]\tLoss: 0.018163\n",
      "Train Epoch: 39 [9856/14860 (66%)]\tLoss: 0.026040\n",
      "Train Epoch: 39 [9984/14860 (67%)]\tLoss: 0.013210\n",
      "Train Epoch: 39 [10112/14860 (68%)]\tLoss: 0.017043\n",
      "Train Epoch: 39 [10240/14860 (68%)]\tLoss: 0.026160\n",
      "Train Epoch: 39 [10368/14860 (69%)]\tLoss: 0.017236\n",
      "Train Epoch: 39 [10496/14860 (70%)]\tLoss: 0.022117\n",
      "Train Epoch: 39 [10624/14860 (71%)]\tLoss: 0.015280\n",
      "Train Epoch: 39 [10752/14860 (72%)]\tLoss: 0.022878\n",
      "Train Epoch: 39 [10880/14860 (73%)]\tLoss: 0.031802\n",
      "Train Epoch: 39 [11008/14860 (74%)]\tLoss: 0.022971\n",
      "Train Epoch: 39 [11136/14860 (74%)]\tLoss: 0.032717\n",
      "Train Epoch: 39 [11264/14860 (75%)]\tLoss: 0.023329\n",
      "Train Epoch: 39 [11392/14860 (76%)]\tLoss: 0.019447\n",
      "Train Epoch: 39 [11520/14860 (77%)]\tLoss: 0.023390\n",
      "Train Epoch: 39 [11648/14860 (78%)]\tLoss: 0.022225\n",
      "Train Epoch: 39 [11776/14860 (79%)]\tLoss: 0.017720\n",
      "Train Epoch: 39 [11904/14860 (79%)]\tLoss: 0.019842\n",
      "Train Epoch: 39 [12032/14860 (80%)]\tLoss: 0.021526\n",
      "Train Epoch: 39 [12160/14860 (81%)]\tLoss: 0.031342\n",
      "Train Epoch: 39 [12288/14860 (82%)]\tLoss: 0.026330\n",
      "Train Epoch: 39 [12416/14860 (83%)]\tLoss: 0.014786\n",
      "Train Epoch: 39 [12544/14860 (84%)]\tLoss: 0.014786\n",
      "Train Epoch: 39 [12672/14860 (85%)]\tLoss: 0.022738\n",
      "Train Epoch: 39 [12800/14860 (85%)]\tLoss: 0.024608\n",
      "Train Epoch: 39 [12928/14860 (86%)]\tLoss: 0.015694\n",
      "Train Epoch: 39 [13056/14860 (87%)]\tLoss: 0.016699\n",
      "Train Epoch: 39 [13184/14860 (88%)]\tLoss: 0.013062\n",
      "Train Epoch: 39 [13312/14860 (89%)]\tLoss: 0.018679\n",
      "Train Epoch: 39 [13440/14860 (90%)]\tLoss: 0.023388\n",
      "Train Epoch: 39 [13568/14860 (91%)]\tLoss: 0.021174\n",
      "Train Epoch: 39 [13696/14860 (91%)]\tLoss: 0.019350\n",
      "Train Epoch: 39 [13824/14860 (92%)]\tLoss: 0.019491\n",
      "Train Epoch: 39 [13952/14860 (93%)]\tLoss: 0.027636\n",
      "Train Epoch: 39 [14080/14860 (94%)]\tLoss: 0.021568\n",
      "Train Epoch: 39 [14208/14860 (95%)]\tLoss: 0.022856\n",
      "Train Epoch: 39 [14336/14860 (96%)]\tLoss: 0.017293\n",
      "Train Epoch: 39 [14464/14860 (97%)]\tLoss: 0.015620\n",
      "Train Epoch: 39 [14592/14860 (97%)]\tLoss: 0.011197\n",
      "Train Epoch: 39 [14720/14860 (98%)]\tLoss: 0.019726\n",
      "Train Epoch: 39 [1392/14860 (99%)]\tLoss: 0.007265\n",
      "epoch 39 training loss: 0.02038346643312874\n",
      "epoch 39 validation loss: 0.020348047806044756\n",
      "Train Epoch: 40 [0/14860 (0%)]\tLoss: 0.016455\n",
      "Train Epoch: 40 [128/14860 (1%)]\tLoss: 0.018328\n",
      "Train Epoch: 40 [256/14860 (2%)]\tLoss: 0.012467\n",
      "Train Epoch: 40 [384/14860 (3%)]\tLoss: 0.018029\n",
      "Train Epoch: 40 [512/14860 (3%)]\tLoss: 0.018321\n",
      "Train Epoch: 40 [640/14860 (4%)]\tLoss: 0.016959\n",
      "Train Epoch: 40 [768/14860 (5%)]\tLoss: 0.023834\n",
      "Train Epoch: 40 [896/14860 (6%)]\tLoss: 0.014942\n",
      "Train Epoch: 40 [1024/14860 (7%)]\tLoss: 0.021654\n",
      "Train Epoch: 40 [1152/14860 (8%)]\tLoss: 0.020604\n",
      "Train Epoch: 40 [1280/14860 (9%)]\tLoss: 0.018036\n",
      "Train Epoch: 40 [1408/14860 (9%)]\tLoss: 0.025055\n",
      "Train Epoch: 40 [1536/14860 (10%)]\tLoss: 0.017459\n",
      "Train Epoch: 40 [1664/14860 (11%)]\tLoss: 0.012973\n",
      "Train Epoch: 40 [1792/14860 (12%)]\tLoss: 0.019800\n",
      "Train Epoch: 40 [1920/14860 (13%)]\tLoss: 0.014864\n",
      "Train Epoch: 40 [2048/14860 (14%)]\tLoss: 0.026496\n",
      "Train Epoch: 40 [2176/14860 (15%)]\tLoss: 0.016361\n",
      "Train Epoch: 40 [2304/14860 (15%)]\tLoss: 0.020399\n",
      "Train Epoch: 40 [2432/14860 (16%)]\tLoss: 0.025792\n",
      "Train Epoch: 40 [2560/14860 (17%)]\tLoss: 0.014960\n",
      "Train Epoch: 40 [2688/14860 (18%)]\tLoss: 0.016646\n",
      "Train Epoch: 40 [2816/14860 (19%)]\tLoss: 0.019078\n",
      "Train Epoch: 40 [2944/14860 (20%)]\tLoss: 0.020232\n",
      "Train Epoch: 40 [3072/14860 (21%)]\tLoss: 0.015114\n",
      "Train Epoch: 40 [3200/14860 (21%)]\tLoss: 0.020762\n",
      "Train Epoch: 40 [3328/14860 (22%)]\tLoss: 0.017264\n",
      "Train Epoch: 40 [3456/14860 (23%)]\tLoss: 0.024669\n",
      "Train Epoch: 40 [3584/14860 (24%)]\tLoss: 0.016444\n",
      "Train Epoch: 40 [3712/14860 (25%)]\tLoss: 0.016797\n",
      "Train Epoch: 40 [3840/14860 (26%)]\tLoss: 0.017227\n",
      "Train Epoch: 40 [3968/14860 (26%)]\tLoss: 0.020325\n",
      "Train Epoch: 40 [4096/14860 (27%)]\tLoss: 0.021354\n",
      "Train Epoch: 40 [4224/14860 (28%)]\tLoss: 0.022775\n",
      "Train Epoch: 40 [4352/14860 (29%)]\tLoss: 0.027373\n",
      "Train Epoch: 40 [4480/14860 (30%)]\tLoss: 0.016539\n",
      "Train Epoch: 40 [4608/14860 (31%)]\tLoss: 0.017675\n",
      "Train Epoch: 40 [4736/14860 (32%)]\tLoss: 0.012238\n",
      "Train Epoch: 40 [4864/14860 (32%)]\tLoss: 0.016330\n",
      "Train Epoch: 40 [4992/14860 (33%)]\tLoss: 0.021066\n",
      "Train Epoch: 40 [5120/14860 (34%)]\tLoss: 0.024099\n",
      "Train Epoch: 40 [5248/14860 (35%)]\tLoss: 0.022967\n",
      "Train Epoch: 40 [5376/14860 (36%)]\tLoss: 0.018880\n",
      "Train Epoch: 40 [5504/14860 (37%)]\tLoss: 0.032919\n",
      "Train Epoch: 40 [5632/14860 (38%)]\tLoss: 0.019525\n",
      "Train Epoch: 40 [5760/14860 (38%)]\tLoss: 0.014928\n",
      "Train Epoch: 40 [5888/14860 (39%)]\tLoss: 0.017522\n",
      "Train Epoch: 40 [6016/14860 (40%)]\tLoss: 0.014878\n",
      "Train Epoch: 40 [6144/14860 (41%)]\tLoss: 0.016642\n",
      "Train Epoch: 40 [6272/14860 (42%)]\tLoss: 0.018114\n",
      "Train Epoch: 40 [6400/14860 (43%)]\tLoss: 0.023841\n",
      "Train Epoch: 40 [6528/14860 (44%)]\tLoss: 0.018166\n",
      "Train Epoch: 40 [6656/14860 (44%)]\tLoss: 0.020829\n",
      "Train Epoch: 40 [6784/14860 (45%)]\tLoss: 0.018012\n",
      "Train Epoch: 40 [6912/14860 (46%)]\tLoss: 0.024043\n",
      "Train Epoch: 40 [7040/14860 (47%)]\tLoss: 0.024341\n",
      "Train Epoch: 40 [7168/14860 (48%)]\tLoss: 0.019632\n",
      "Train Epoch: 40 [7296/14860 (49%)]\tLoss: 0.014619\n",
      "Train Epoch: 40 [7424/14860 (50%)]\tLoss: 0.018430\n",
      "Train Epoch: 40 [7552/14860 (50%)]\tLoss: 0.014887\n",
      "Train Epoch: 40 [7680/14860 (51%)]\tLoss: 0.020632\n",
      "Train Epoch: 40 [7808/14860 (52%)]\tLoss: 0.030183\n",
      "Train Epoch: 40 [7936/14860 (53%)]\tLoss: 0.014914\n",
      "Train Epoch: 40 [8064/14860 (54%)]\tLoss: 0.017351\n",
      "Train Epoch: 40 [8192/14860 (55%)]\tLoss: 0.021503\n",
      "Train Epoch: 40 [8320/14860 (56%)]\tLoss: 0.019385\n",
      "Train Epoch: 40 [8448/14860 (56%)]\tLoss: 0.018856\n",
      "Train Epoch: 40 [8576/14860 (57%)]\tLoss: 0.022823\n",
      "Train Epoch: 40 [8704/14860 (58%)]\tLoss: 0.019924\n",
      "Train Epoch: 40 [8832/14860 (59%)]\tLoss: 0.017914\n",
      "Train Epoch: 40 [8960/14860 (60%)]\tLoss: 0.016091\n",
      "Train Epoch: 40 [9088/14860 (61%)]\tLoss: 0.022809\n",
      "Train Epoch: 40 [9216/14860 (62%)]\tLoss: 0.024172\n",
      "Train Epoch: 40 [9344/14860 (62%)]\tLoss: 0.025885\n",
      "Train Epoch: 40 [9472/14860 (63%)]\tLoss: 0.033527\n",
      "Train Epoch: 40 [9600/14860 (64%)]\tLoss: 0.019907\n",
      "Train Epoch: 40 [9728/14860 (65%)]\tLoss: 0.022442\n",
      "Train Epoch: 40 [9856/14860 (66%)]\tLoss: 0.020976\n",
      "Train Epoch: 40 [9984/14860 (67%)]\tLoss: 0.022872\n",
      "Train Epoch: 40 [10112/14860 (68%)]\tLoss: 0.026567\n",
      "Train Epoch: 40 [10240/14860 (68%)]\tLoss: 0.022165\n",
      "Train Epoch: 40 [10368/14860 (69%)]\tLoss: 0.023382\n",
      "Train Epoch: 40 [10496/14860 (70%)]\tLoss: 0.025854\n",
      "Train Epoch: 40 [10624/14860 (71%)]\tLoss: 0.017541\n",
      "Train Epoch: 40 [10752/14860 (72%)]\tLoss: 0.015211\n",
      "Train Epoch: 40 [10880/14860 (73%)]\tLoss: 0.019855\n",
      "Train Epoch: 40 [11008/14860 (74%)]\tLoss: 0.023874\n",
      "Train Epoch: 40 [11136/14860 (74%)]\tLoss: 0.019867\n",
      "Train Epoch: 40 [11264/14860 (75%)]\tLoss: 0.025972\n",
      "Train Epoch: 40 [11392/14860 (76%)]\tLoss: 0.018595\n",
      "Train Epoch: 40 [11520/14860 (77%)]\tLoss: 0.022216\n",
      "Train Epoch: 40 [11648/14860 (78%)]\tLoss: 0.019578\n",
      "Train Epoch: 40 [11776/14860 (79%)]\tLoss: 0.027834\n",
      "Train Epoch: 40 [11904/14860 (79%)]\tLoss: 0.020830\n",
      "Train Epoch: 40 [12032/14860 (80%)]\tLoss: 0.029689\n",
      "Train Epoch: 40 [12160/14860 (81%)]\tLoss: 0.018879\n",
      "Train Epoch: 40 [12288/14860 (82%)]\tLoss: 0.029940\n",
      "Train Epoch: 40 [12416/14860 (83%)]\tLoss: 0.017407\n",
      "Train Epoch: 40 [12544/14860 (84%)]\tLoss: 0.023623\n",
      "Train Epoch: 40 [12672/14860 (85%)]\tLoss: 0.021611\n",
      "Train Epoch: 40 [12800/14860 (85%)]\tLoss: 0.017736\n",
      "Train Epoch: 40 [12928/14860 (86%)]\tLoss: 0.031249\n",
      "Train Epoch: 40 [13056/14860 (87%)]\tLoss: 0.024208\n",
      "Train Epoch: 40 [13184/14860 (88%)]\tLoss: 0.016879\n",
      "Train Epoch: 40 [13312/14860 (89%)]\tLoss: 0.026285\n",
      "Train Epoch: 40 [13440/14860 (90%)]\tLoss: 0.020268\n",
      "Train Epoch: 40 [13568/14860 (91%)]\tLoss: 0.022585\n",
      "Train Epoch: 40 [13696/14860 (91%)]\tLoss: 0.028404\n",
      "Train Epoch: 40 [13824/14860 (92%)]\tLoss: 0.024157\n",
      "Train Epoch: 40 [13952/14860 (93%)]\tLoss: 0.021646\n",
      "Train Epoch: 40 [14080/14860 (94%)]\tLoss: 0.025287\n",
      "Train Epoch: 40 [14208/14860 (95%)]\tLoss: 0.027409\n",
      "Train Epoch: 40 [14336/14860 (96%)]\tLoss: 0.023637\n",
      "Train Epoch: 40 [14464/14860 (97%)]\tLoss: 0.025536\n",
      "Train Epoch: 40 [14592/14860 (97%)]\tLoss: 0.028814\n",
      "Train Epoch: 40 [14720/14860 (98%)]\tLoss: 0.020688\n",
      "Train Epoch: 40 [1392/14860 (99%)]\tLoss: 0.012922\n",
      "epoch 40 training loss: 0.020780615588156585\n",
      "epoch 40 validation loss: 0.028699149375389043\n",
      "Train Epoch: 41 [0/14860 (0%)]\tLoss: 0.030039\n",
      "Train Epoch: 41 [128/14860 (1%)]\tLoss: 0.025904\n",
      "Train Epoch: 41 [256/14860 (2%)]\tLoss: 0.022438\n",
      "Train Epoch: 41 [384/14860 (3%)]\tLoss: 0.021134\n",
      "Train Epoch: 41 [512/14860 (3%)]\tLoss: 0.031204\n",
      "Train Epoch: 41 [640/14860 (4%)]\tLoss: 0.026451\n",
      "Train Epoch: 41 [768/14860 (5%)]\tLoss: 0.016057\n",
      "Train Epoch: 41 [896/14860 (6%)]\tLoss: 0.026549\n",
      "Train Epoch: 41 [1024/14860 (7%)]\tLoss: 0.032424\n",
      "Train Epoch: 41 [1152/14860 (8%)]\tLoss: 0.019847\n",
      "Train Epoch: 41 [1280/14860 (9%)]\tLoss: 0.032465\n",
      "Train Epoch: 41 [1408/14860 (9%)]\tLoss: 0.014599\n",
      "Train Epoch: 41 [1536/14860 (10%)]\tLoss: 0.025107\n",
      "Train Epoch: 41 [1664/14860 (11%)]\tLoss: 0.018228\n",
      "Train Epoch: 41 [1792/14860 (12%)]\tLoss: 0.023853\n",
      "Train Epoch: 41 [1920/14860 (13%)]\tLoss: 0.020754\n",
      "Train Epoch: 41 [2048/14860 (14%)]\tLoss: 0.018320\n",
      "Train Epoch: 41 [2176/14860 (15%)]\tLoss: 0.025431\n",
      "Train Epoch: 41 [2304/14860 (15%)]\tLoss: 0.015177\n",
      "Train Epoch: 41 [2432/14860 (16%)]\tLoss: 0.016959\n",
      "Train Epoch: 41 [2560/14860 (17%)]\tLoss: 0.016448\n",
      "Train Epoch: 41 [2688/14860 (18%)]\tLoss: 0.017735\n",
      "Train Epoch: 41 [2816/14860 (19%)]\tLoss: 0.014338\n",
      "Train Epoch: 41 [2944/14860 (20%)]\tLoss: 0.021311\n",
      "Train Epoch: 41 [3072/14860 (21%)]\tLoss: 0.017328\n",
      "Train Epoch: 41 [3200/14860 (21%)]\tLoss: 0.019598\n",
      "Train Epoch: 41 [3328/14860 (22%)]\tLoss: 0.017760\n",
      "Train Epoch: 41 [3456/14860 (23%)]\tLoss: 0.015776\n",
      "Train Epoch: 41 [3584/14860 (24%)]\tLoss: 0.015902\n",
      "Train Epoch: 41 [3712/14860 (25%)]\tLoss: 0.010936\n",
      "Train Epoch: 41 [3840/14860 (26%)]\tLoss: 0.018118\n",
      "Train Epoch: 41 [3968/14860 (26%)]\tLoss: 0.025306\n",
      "Train Epoch: 41 [4096/14860 (27%)]\tLoss: 0.021670\n",
      "Train Epoch: 41 [4224/14860 (28%)]\tLoss: 0.030083\n",
      "Train Epoch: 41 [4352/14860 (29%)]\tLoss: 0.016292\n",
      "Train Epoch: 41 [4480/14860 (30%)]\tLoss: 0.022912\n",
      "Train Epoch: 41 [4608/14860 (31%)]\tLoss: 0.017666\n",
      "Train Epoch: 41 [4736/14860 (32%)]\tLoss: 0.016661\n",
      "Train Epoch: 41 [4864/14860 (32%)]\tLoss: 0.017875\n",
      "Train Epoch: 41 [4992/14860 (33%)]\tLoss: 0.017941\n",
      "Train Epoch: 41 [5120/14860 (34%)]\tLoss: 0.010945\n",
      "Train Epoch: 41 [5248/14860 (35%)]\tLoss: 0.016873\n",
      "Train Epoch: 41 [5376/14860 (36%)]\tLoss: 0.016480\n",
      "Train Epoch: 41 [5504/14860 (37%)]\tLoss: 0.021175\n",
      "Train Epoch: 41 [5632/14860 (38%)]\tLoss: 0.018854\n",
      "Train Epoch: 41 [5760/14860 (38%)]\tLoss: 0.017290\n",
      "Train Epoch: 41 [5888/14860 (39%)]\tLoss: 0.021106\n",
      "Train Epoch: 41 [6016/14860 (40%)]\tLoss: 0.015125\n",
      "Train Epoch: 41 [6144/14860 (41%)]\tLoss: 0.016916\n",
      "Train Epoch: 41 [6272/14860 (42%)]\tLoss: 0.022987\n",
      "Train Epoch: 41 [6400/14860 (43%)]\tLoss: 0.011866\n",
      "Train Epoch: 41 [6528/14860 (44%)]\tLoss: 0.024768\n",
      "Train Epoch: 41 [6656/14860 (44%)]\tLoss: 0.016383\n",
      "Train Epoch: 41 [6784/14860 (45%)]\tLoss: 0.019032\n",
      "Train Epoch: 41 [6912/14860 (46%)]\tLoss: 0.013207\n",
      "Train Epoch: 41 [7040/14860 (47%)]\tLoss: 0.019771\n",
      "Train Epoch: 41 [7168/14860 (48%)]\tLoss: 0.014890\n",
      "Train Epoch: 41 [7296/14860 (49%)]\tLoss: 0.017179\n",
      "Train Epoch: 41 [7424/14860 (50%)]\tLoss: 0.019124\n",
      "Train Epoch: 41 [7552/14860 (50%)]\tLoss: 0.017721\n",
      "Train Epoch: 41 [7680/14860 (51%)]\tLoss: 0.013890\n",
      "Train Epoch: 41 [7808/14860 (52%)]\tLoss: 0.019983\n",
      "Train Epoch: 41 [7936/14860 (53%)]\tLoss: 0.021138\n",
      "Train Epoch: 41 [8064/14860 (54%)]\tLoss: 0.020585\n",
      "Train Epoch: 41 [8192/14860 (55%)]\tLoss: 0.026167\n",
      "Train Epoch: 41 [8320/14860 (56%)]\tLoss: 0.014814\n",
      "Train Epoch: 41 [8448/14860 (56%)]\tLoss: 0.022357\n",
      "Train Epoch: 41 [8576/14860 (57%)]\tLoss: 0.020739\n",
      "Train Epoch: 41 [8704/14860 (58%)]\tLoss: 0.021438\n",
      "Train Epoch: 41 [8832/14860 (59%)]\tLoss: 0.019453\n",
      "Train Epoch: 41 [8960/14860 (60%)]\tLoss: 0.025402\n",
      "Train Epoch: 41 [9088/14860 (61%)]\tLoss: 0.018404\n",
      "Train Epoch: 41 [9216/14860 (62%)]\tLoss: 0.022624\n",
      "Train Epoch: 41 [9344/14860 (62%)]\tLoss: 0.018985\n",
      "Train Epoch: 41 [9472/14860 (63%)]\tLoss: 0.019729\n",
      "Train Epoch: 41 [9600/14860 (64%)]\tLoss: 0.018606\n",
      "Train Epoch: 41 [9728/14860 (65%)]\tLoss: 0.012991\n",
      "Train Epoch: 41 [9856/14860 (66%)]\tLoss: 0.022915\n",
      "Train Epoch: 41 [9984/14860 (67%)]\tLoss: 0.016347\n",
      "Train Epoch: 41 [10112/14860 (68%)]\tLoss: 0.019531\n",
      "Train Epoch: 41 [10240/14860 (68%)]\tLoss: 0.032854\n",
      "Train Epoch: 41 [10368/14860 (69%)]\tLoss: 0.020799\n",
      "Train Epoch: 41 [10496/14860 (70%)]\tLoss: 0.024660\n",
      "Train Epoch: 41 [10624/14860 (71%)]\tLoss: 0.016920\n",
      "Train Epoch: 41 [10752/14860 (72%)]\tLoss: 0.022698\n",
      "Train Epoch: 41 [10880/14860 (73%)]\tLoss: 0.019577\n",
      "Train Epoch: 41 [11008/14860 (74%)]\tLoss: 0.024243\n",
      "Train Epoch: 41 [11136/14860 (74%)]\tLoss: 0.015807\n",
      "Train Epoch: 41 [11264/14860 (75%)]\tLoss: 0.023447\n",
      "Train Epoch: 41 [11392/14860 (76%)]\tLoss: 0.016604\n",
      "Train Epoch: 41 [11520/14860 (77%)]\tLoss: 0.023344\n",
      "Train Epoch: 41 [11648/14860 (78%)]\tLoss: 0.016875\n",
      "Train Epoch: 41 [11776/14860 (79%)]\tLoss: 0.019927\n",
      "Train Epoch: 41 [11904/14860 (79%)]\tLoss: 0.020159\n",
      "Train Epoch: 41 [12032/14860 (80%)]\tLoss: 0.023394\n",
      "Train Epoch: 41 [12160/14860 (81%)]\tLoss: 0.018474\n",
      "Train Epoch: 41 [12288/14860 (82%)]\tLoss: 0.021296\n",
      "Train Epoch: 41 [12416/14860 (83%)]\tLoss: 0.022007\n",
      "Train Epoch: 41 [12544/14860 (84%)]\tLoss: 0.015042\n",
      "Train Epoch: 41 [12672/14860 (85%)]\tLoss: 0.024601\n",
      "Train Epoch: 41 [12800/14860 (85%)]\tLoss: 0.017769\n",
      "Train Epoch: 41 [12928/14860 (86%)]\tLoss: 0.020107\n",
      "Train Epoch: 41 [13056/14860 (87%)]\tLoss: 0.015950\n",
      "Train Epoch: 41 [13184/14860 (88%)]\tLoss: 0.021250\n",
      "Train Epoch: 41 [13312/14860 (89%)]\tLoss: 0.019650\n",
      "Train Epoch: 41 [13440/14860 (90%)]\tLoss: 0.013370\n",
      "Train Epoch: 41 [13568/14860 (91%)]\tLoss: 0.016360\n",
      "Train Epoch: 41 [13696/14860 (91%)]\tLoss: 0.013414\n",
      "Train Epoch: 41 [13824/14860 (92%)]\tLoss: 0.018005\n",
      "Train Epoch: 41 [13952/14860 (93%)]\tLoss: 0.018350\n",
      "Train Epoch: 41 [14080/14860 (94%)]\tLoss: 0.024019\n",
      "Train Epoch: 41 [14208/14860 (95%)]\tLoss: 0.030128\n",
      "Train Epoch: 41 [14336/14860 (96%)]\tLoss: 0.022058\n",
      "Train Epoch: 41 [14464/14860 (97%)]\tLoss: 0.012626\n",
      "Train Epoch: 41 [14592/14860 (97%)]\tLoss: 0.023323\n",
      "Train Epoch: 41 [14720/14860 (98%)]\tLoss: 0.018206\n",
      "Train Epoch: 41 [1392/14860 (99%)]\tLoss: 0.008916\n",
      "epoch 41 training loss: 0.019817255604534578\n",
      "epoch 41 validation loss: 0.02835794135964234\n",
      "Train Epoch: 42 [0/14860 (0%)]\tLoss: 0.026718\n",
      "Train Epoch: 42 [128/14860 (1%)]\tLoss: 0.018594\n",
      "Train Epoch: 42 [256/14860 (2%)]\tLoss: 0.029740\n",
      "Train Epoch: 42 [384/14860 (3%)]\tLoss: 0.032806\n",
      "Train Epoch: 42 [512/14860 (3%)]\tLoss: 0.019529\n",
      "Train Epoch: 42 [640/14860 (4%)]\tLoss: 0.027797\n",
      "Train Epoch: 42 [768/14860 (5%)]\tLoss: 0.014792\n",
      "Train Epoch: 42 [896/14860 (6%)]\tLoss: 0.019894\n",
      "Train Epoch: 42 [1024/14860 (7%)]\tLoss: 0.031324\n",
      "Train Epoch: 42 [1152/14860 (8%)]\tLoss: 0.022787\n",
      "Train Epoch: 42 [1280/14860 (9%)]\tLoss: 0.014455\n",
      "Train Epoch: 42 [1408/14860 (9%)]\tLoss: 0.025694\n",
      "Train Epoch: 42 [1536/14860 (10%)]\tLoss: 0.013231\n",
      "Train Epoch: 42 [1664/14860 (11%)]\tLoss: 0.018354\n",
      "Train Epoch: 42 [1792/14860 (12%)]\tLoss: 0.020407\n",
      "Train Epoch: 42 [1920/14860 (13%)]\tLoss: 0.023756\n",
      "Train Epoch: 42 [2048/14860 (14%)]\tLoss: 0.022929\n",
      "Train Epoch: 42 [2176/14860 (15%)]\tLoss: 0.021012\n",
      "Train Epoch: 42 [2304/14860 (15%)]\tLoss: 0.022984\n",
      "Train Epoch: 42 [2432/14860 (16%)]\tLoss: 0.018738\n",
      "Train Epoch: 42 [2560/14860 (17%)]\tLoss: 0.021062\n",
      "Train Epoch: 42 [2688/14860 (18%)]\tLoss: 0.018589\n",
      "Train Epoch: 42 [2816/14860 (19%)]\tLoss: 0.016681\n",
      "Train Epoch: 42 [2944/14860 (20%)]\tLoss: 0.026956\n",
      "Train Epoch: 42 [3072/14860 (21%)]\tLoss: 0.014392\n",
      "Train Epoch: 42 [3200/14860 (21%)]\tLoss: 0.019824\n",
      "Train Epoch: 42 [3328/14860 (22%)]\tLoss: 0.025069\n",
      "Train Epoch: 42 [3456/14860 (23%)]\tLoss: 0.016465\n",
      "Train Epoch: 42 [3584/14860 (24%)]\tLoss: 0.019984\n",
      "Train Epoch: 42 [3712/14860 (25%)]\tLoss: 0.025658\n",
      "Train Epoch: 42 [3840/14860 (26%)]\tLoss: 0.023457\n",
      "Train Epoch: 42 [3968/14860 (26%)]\tLoss: 0.020296\n",
      "Train Epoch: 42 [4096/14860 (27%)]\tLoss: 0.022634\n",
      "Train Epoch: 42 [4224/14860 (28%)]\tLoss: 0.020329\n",
      "Train Epoch: 42 [4352/14860 (29%)]\tLoss: 0.024856\n",
      "Train Epoch: 42 [4480/14860 (30%)]\tLoss: 0.020824\n",
      "Train Epoch: 42 [4608/14860 (31%)]\tLoss: 0.017963\n",
      "Train Epoch: 42 [4736/14860 (32%)]\tLoss: 0.023749\n",
      "Train Epoch: 42 [4864/14860 (32%)]\tLoss: 0.015673\n",
      "Train Epoch: 42 [4992/14860 (33%)]\tLoss: 0.015268\n",
      "Train Epoch: 42 [5120/14860 (34%)]\tLoss: 0.028376\n",
      "Train Epoch: 42 [5248/14860 (35%)]\tLoss: 0.027786\n",
      "Train Epoch: 42 [5376/14860 (36%)]\tLoss: 0.023648\n",
      "Train Epoch: 42 [5504/14860 (37%)]\tLoss: 0.019287\n",
      "Train Epoch: 42 [5632/14860 (38%)]\tLoss: 0.017266\n",
      "Train Epoch: 42 [5760/14860 (38%)]\tLoss: 0.031632\n",
      "Train Epoch: 42 [5888/14860 (39%)]\tLoss: 0.017447\n",
      "Train Epoch: 42 [6016/14860 (40%)]\tLoss: 0.017178\n",
      "Train Epoch: 42 [6144/14860 (41%)]\tLoss: 0.015522\n",
      "Train Epoch: 42 [6272/14860 (42%)]\tLoss: 0.020195\n",
      "Train Epoch: 42 [6400/14860 (43%)]\tLoss: 0.013736\n",
      "Train Epoch: 42 [6528/14860 (44%)]\tLoss: 0.017650\n",
      "Train Epoch: 42 [6656/14860 (44%)]\tLoss: 0.018190\n",
      "Train Epoch: 42 [6784/14860 (45%)]\tLoss: 0.017560\n",
      "Train Epoch: 42 [6912/14860 (46%)]\tLoss: 0.021495\n",
      "Train Epoch: 42 [7040/14860 (47%)]\tLoss: 0.014213\n",
      "Train Epoch: 42 [7168/14860 (48%)]\tLoss: 0.015009\n",
      "Train Epoch: 42 [7296/14860 (49%)]\tLoss: 0.016777\n",
      "Train Epoch: 42 [7424/14860 (50%)]\tLoss: 0.030934\n",
      "Train Epoch: 42 [7552/14860 (50%)]\tLoss: 0.017747\n",
      "Train Epoch: 42 [7680/14860 (51%)]\tLoss: 0.021808\n",
      "Train Epoch: 42 [7808/14860 (52%)]\tLoss: 0.028355\n",
      "Train Epoch: 42 [7936/14860 (53%)]\tLoss: 0.024112\n",
      "Train Epoch: 42 [8064/14860 (54%)]\tLoss: 0.018344\n",
      "Train Epoch: 42 [8192/14860 (55%)]\tLoss: 0.023435\n",
      "Train Epoch: 42 [8320/14860 (56%)]\tLoss: 0.019625\n",
      "Train Epoch: 42 [8448/14860 (56%)]\tLoss: 0.020866\n",
      "Train Epoch: 42 [8576/14860 (57%)]\tLoss: 0.014462\n",
      "Train Epoch: 42 [8704/14860 (58%)]\tLoss: 0.012780\n",
      "Train Epoch: 42 [8832/14860 (59%)]\tLoss: 0.025402\n",
      "Train Epoch: 42 [8960/14860 (60%)]\tLoss: 0.017329\n",
      "Train Epoch: 42 [9088/14860 (61%)]\tLoss: 0.016108\n",
      "Train Epoch: 42 [9216/14860 (62%)]\tLoss: 0.016440\n",
      "Train Epoch: 42 [9344/14860 (62%)]\tLoss: 0.019424\n",
      "Train Epoch: 42 [9472/14860 (63%)]\tLoss: 0.015640\n",
      "Train Epoch: 42 [9600/14860 (64%)]\tLoss: 0.013298\n",
      "Train Epoch: 42 [9728/14860 (65%)]\tLoss: 0.020217\n",
      "Train Epoch: 42 [9856/14860 (66%)]\tLoss: 0.016710\n",
      "Train Epoch: 42 [9984/14860 (67%)]\tLoss: 0.019766\n",
      "Train Epoch: 42 [10112/14860 (68%)]\tLoss: 0.018178\n",
      "Train Epoch: 42 [10240/14860 (68%)]\tLoss: 0.018268\n",
      "Train Epoch: 42 [10368/14860 (69%)]\tLoss: 0.021739\n",
      "Train Epoch: 42 [10496/14860 (70%)]\tLoss: 0.020741\n",
      "Train Epoch: 42 [10624/14860 (71%)]\tLoss: 0.016145\n",
      "Train Epoch: 42 [10752/14860 (72%)]\tLoss: 0.023407\n",
      "Train Epoch: 42 [10880/14860 (73%)]\tLoss: 0.020221\n",
      "Train Epoch: 42 [11008/14860 (74%)]\tLoss: 0.018846\n",
      "Train Epoch: 42 [11136/14860 (74%)]\tLoss: 0.022784\n",
      "Train Epoch: 42 [11264/14860 (75%)]\tLoss: 0.021321\n",
      "Train Epoch: 42 [11392/14860 (76%)]\tLoss: 0.021344\n",
      "Train Epoch: 42 [11520/14860 (77%)]\tLoss: 0.021781\n",
      "Train Epoch: 42 [11648/14860 (78%)]\tLoss: 0.016637\n",
      "Train Epoch: 42 [11776/14860 (79%)]\tLoss: 0.016702\n",
      "Train Epoch: 42 [11904/14860 (79%)]\tLoss: 0.018632\n",
      "Train Epoch: 42 [12032/14860 (80%)]\tLoss: 0.022747\n",
      "Train Epoch: 42 [12160/14860 (81%)]\tLoss: 0.018349\n",
      "Train Epoch: 42 [12288/14860 (82%)]\tLoss: 0.024473\n",
      "Train Epoch: 42 [12416/14860 (83%)]\tLoss: 0.016466\n",
      "Train Epoch: 42 [12544/14860 (84%)]\tLoss: 0.023978\n",
      "Train Epoch: 42 [12672/14860 (85%)]\tLoss: 0.018988\n",
      "Train Epoch: 42 [12800/14860 (85%)]\tLoss: 0.013872\n",
      "Train Epoch: 42 [12928/14860 (86%)]\tLoss: 0.020121\n",
      "Train Epoch: 42 [13056/14860 (87%)]\tLoss: 0.019511\n",
      "Train Epoch: 42 [13184/14860 (88%)]\tLoss: 0.017638\n",
      "Train Epoch: 42 [13312/14860 (89%)]\tLoss: 0.014849\n",
      "Train Epoch: 42 [13440/14860 (90%)]\tLoss: 0.013053\n",
      "Train Epoch: 42 [13568/14860 (91%)]\tLoss: 0.018163\n",
      "Train Epoch: 42 [13696/14860 (91%)]\tLoss: 0.019812\n",
      "Train Epoch: 42 [13824/14860 (92%)]\tLoss: 0.023806\n",
      "Train Epoch: 42 [13952/14860 (93%)]\tLoss: 0.012830\n",
      "Train Epoch: 42 [14080/14860 (94%)]\tLoss: 0.014029\n",
      "Train Epoch: 42 [14208/14860 (95%)]\tLoss: 0.018916\n",
      "Train Epoch: 42 [14336/14860 (96%)]\tLoss: 0.016846\n",
      "Train Epoch: 42 [14464/14860 (97%)]\tLoss: 0.016474\n",
      "Train Epoch: 42 [14592/14860 (97%)]\tLoss: 0.018755\n",
      "Train Epoch: 42 [14720/14860 (98%)]\tLoss: 0.016073\n",
      "Train Epoch: 42 [1392/14860 (99%)]\tLoss: 0.032768\n",
      "epoch 42 training loss: 0.020088076424331237\n",
      "epoch 42 validation loss: 0.021674220123244832\n",
      "Train Epoch: 43 [0/14860 (0%)]\tLoss: 0.018784\n",
      "Train Epoch: 43 [128/14860 (1%)]\tLoss: 0.012140\n",
      "Train Epoch: 43 [256/14860 (2%)]\tLoss: 0.021354\n",
      "Train Epoch: 43 [384/14860 (3%)]\tLoss: 0.015704\n",
      "Train Epoch: 43 [512/14860 (3%)]\tLoss: 0.018669\n",
      "Train Epoch: 43 [640/14860 (4%)]\tLoss: 0.020835\n",
      "Train Epoch: 43 [768/14860 (5%)]\tLoss: 0.019230\n",
      "Train Epoch: 43 [896/14860 (6%)]\tLoss: 0.021436\n",
      "Train Epoch: 43 [1024/14860 (7%)]\tLoss: 0.014330\n",
      "Train Epoch: 43 [1152/14860 (8%)]\tLoss: 0.014962\n",
      "Train Epoch: 43 [1280/14860 (9%)]\tLoss: 0.015440\n",
      "Train Epoch: 43 [1408/14860 (9%)]\tLoss: 0.022304\n",
      "Train Epoch: 43 [1536/14860 (10%)]\tLoss: 0.018858\n",
      "Train Epoch: 43 [1664/14860 (11%)]\tLoss: 0.016932\n",
      "Train Epoch: 43 [1792/14860 (12%)]\tLoss: 0.012263\n",
      "Train Epoch: 43 [1920/14860 (13%)]\tLoss: 0.019828\n",
      "Train Epoch: 43 [2048/14860 (14%)]\tLoss: 0.019538\n",
      "Train Epoch: 43 [2176/14860 (15%)]\tLoss: 0.017593\n",
      "Train Epoch: 43 [2304/14860 (15%)]\tLoss: 0.021558\n",
      "Train Epoch: 43 [2432/14860 (16%)]\tLoss: 0.020386\n",
      "Train Epoch: 43 [2560/14860 (17%)]\tLoss: 0.014905\n",
      "Train Epoch: 43 [2688/14860 (18%)]\tLoss: 0.018071\n",
      "Train Epoch: 43 [2816/14860 (19%)]\tLoss: 0.012702\n",
      "Train Epoch: 43 [2944/14860 (20%)]\tLoss: 0.018273\n",
      "Train Epoch: 43 [3072/14860 (21%)]\tLoss: 0.018142\n",
      "Train Epoch: 43 [3200/14860 (21%)]\tLoss: 0.021560\n",
      "Train Epoch: 43 [3328/14860 (22%)]\tLoss: 0.016164\n",
      "Train Epoch: 43 [3456/14860 (23%)]\tLoss: 0.019516\n",
      "Train Epoch: 43 [3584/14860 (24%)]\tLoss: 0.024601\n",
      "Train Epoch: 43 [3712/14860 (25%)]\tLoss: 0.019057\n",
      "Train Epoch: 43 [3840/14860 (26%)]\tLoss: 0.022526\n",
      "Train Epoch: 43 [3968/14860 (26%)]\tLoss: 0.019353\n",
      "Train Epoch: 43 [4096/14860 (27%)]\tLoss: 0.017126\n",
      "Train Epoch: 43 [4224/14860 (28%)]\tLoss: 0.018027\n",
      "Train Epoch: 43 [4352/14860 (29%)]\tLoss: 0.020680\n",
      "Train Epoch: 43 [4480/14860 (30%)]\tLoss: 0.020720\n",
      "Train Epoch: 43 [4608/14860 (31%)]\tLoss: 0.011837\n",
      "Train Epoch: 43 [4736/14860 (32%)]\tLoss: 0.018616\n",
      "Train Epoch: 43 [4864/14860 (32%)]\tLoss: 0.018253\n",
      "Train Epoch: 43 [4992/14860 (33%)]\tLoss: 0.016316\n",
      "Train Epoch: 43 [5120/14860 (34%)]\tLoss: 0.016311\n",
      "Train Epoch: 43 [5248/14860 (35%)]\tLoss: 0.014241\n",
      "Train Epoch: 43 [5376/14860 (36%)]\tLoss: 0.017400\n",
      "Train Epoch: 43 [5504/14860 (37%)]\tLoss: 0.016910\n",
      "Train Epoch: 43 [5632/14860 (38%)]\tLoss: 0.030477\n",
      "Train Epoch: 43 [5760/14860 (38%)]\tLoss: 0.020937\n",
      "Train Epoch: 43 [5888/14860 (39%)]\tLoss: 0.027696\n",
      "Train Epoch: 43 [6016/14860 (40%)]\tLoss: 0.017964\n",
      "Train Epoch: 43 [6144/14860 (41%)]\tLoss: 0.016508\n",
      "Train Epoch: 43 [6272/14860 (42%)]\tLoss: 0.026963\n",
      "Train Epoch: 43 [6400/14860 (43%)]\tLoss: 0.014625\n",
      "Train Epoch: 43 [6528/14860 (44%)]\tLoss: 0.020511\n",
      "Train Epoch: 43 [6656/14860 (44%)]\tLoss: 0.021029\n",
      "Train Epoch: 43 [6784/14860 (45%)]\tLoss: 0.017510\n",
      "Train Epoch: 43 [6912/14860 (46%)]\tLoss: 0.024691\n",
      "Train Epoch: 43 [7040/14860 (47%)]\tLoss: 0.012168\n",
      "Train Epoch: 43 [7168/14860 (48%)]\tLoss: 0.020309\n",
      "Train Epoch: 43 [7296/14860 (49%)]\tLoss: 0.021739\n",
      "Train Epoch: 43 [7424/14860 (50%)]\tLoss: 0.019440\n",
      "Train Epoch: 43 [7552/14860 (50%)]\tLoss: 0.018519\n",
      "Train Epoch: 43 [7680/14860 (51%)]\tLoss: 0.018922\n",
      "Train Epoch: 43 [7808/14860 (52%)]\tLoss: 0.016283\n",
      "Train Epoch: 43 [7936/14860 (53%)]\tLoss: 0.022175\n",
      "Train Epoch: 43 [8064/14860 (54%)]\tLoss: 0.027599\n",
      "Train Epoch: 43 [8192/14860 (55%)]\tLoss: 0.027887\n",
      "Train Epoch: 43 [8320/14860 (56%)]\tLoss: 0.025484\n",
      "Train Epoch: 43 [8448/14860 (56%)]\tLoss: 0.022426\n",
      "Train Epoch: 43 [8576/14860 (57%)]\tLoss: 0.015175\n",
      "Train Epoch: 43 [8704/14860 (58%)]\tLoss: 0.021654\n",
      "Train Epoch: 43 [8832/14860 (59%)]\tLoss: 0.018655\n",
      "Train Epoch: 43 [8960/14860 (60%)]\tLoss: 0.015059\n",
      "Train Epoch: 43 [9088/14860 (61%)]\tLoss: 0.018946\n",
      "Train Epoch: 43 [9216/14860 (62%)]\tLoss: 0.025802\n",
      "Train Epoch: 43 [9344/14860 (62%)]\tLoss: 0.023331\n",
      "Train Epoch: 43 [9472/14860 (63%)]\tLoss: 0.017737\n",
      "Train Epoch: 43 [9600/14860 (64%)]\tLoss: 0.019231\n",
      "Train Epoch: 43 [9728/14860 (65%)]\tLoss: 0.020209\n",
      "Train Epoch: 43 [9856/14860 (66%)]\tLoss: 0.019264\n",
      "Train Epoch: 43 [9984/14860 (67%)]\tLoss: 0.012223\n",
      "Train Epoch: 43 [10112/14860 (68%)]\tLoss: 0.015568\n",
      "Train Epoch: 43 [10240/14860 (68%)]\tLoss: 0.025006\n",
      "Train Epoch: 43 [10368/14860 (69%)]\tLoss: 0.015874\n",
      "Train Epoch: 43 [10496/14860 (70%)]\tLoss: 0.018176\n",
      "Train Epoch: 43 [10624/14860 (71%)]\tLoss: 0.018111\n",
      "Train Epoch: 43 [10752/14860 (72%)]\tLoss: 0.016072\n",
      "Train Epoch: 43 [10880/14860 (73%)]\tLoss: 0.016682\n",
      "Train Epoch: 43 [11008/14860 (74%)]\tLoss: 0.017144\n",
      "Train Epoch: 43 [11136/14860 (74%)]\tLoss: 0.022390\n",
      "Train Epoch: 43 [11264/14860 (75%)]\tLoss: 0.018161\n",
      "Train Epoch: 43 [11392/14860 (76%)]\tLoss: 0.018458\n",
      "Train Epoch: 43 [11520/14860 (77%)]\tLoss: 0.033058\n",
      "Train Epoch: 43 [11648/14860 (78%)]\tLoss: 0.019214\n",
      "Train Epoch: 43 [11776/14860 (79%)]\tLoss: 0.022946\n",
      "Train Epoch: 43 [11904/14860 (79%)]\tLoss: 0.024510\n",
      "Train Epoch: 43 [12032/14860 (80%)]\tLoss: 0.018201\n",
      "Train Epoch: 43 [12160/14860 (81%)]\tLoss: 0.021689\n",
      "Train Epoch: 43 [12288/14860 (82%)]\tLoss: 0.016831\n",
      "Train Epoch: 43 [12416/14860 (83%)]\tLoss: 0.017326\n",
      "Train Epoch: 43 [12544/14860 (84%)]\tLoss: 0.023637\n",
      "Train Epoch: 43 [12672/14860 (85%)]\tLoss: 0.016564\n",
      "Train Epoch: 43 [12800/14860 (85%)]\tLoss: 0.026169\n",
      "Train Epoch: 43 [12928/14860 (86%)]\tLoss: 0.017633\n",
      "Train Epoch: 43 [13056/14860 (87%)]\tLoss: 0.028151\n",
      "Train Epoch: 43 [13184/14860 (88%)]\tLoss: 0.029265\n",
      "Train Epoch: 43 [13312/14860 (89%)]\tLoss: 0.021332\n",
      "Train Epoch: 43 [13440/14860 (90%)]\tLoss: 0.016159\n",
      "Train Epoch: 43 [13568/14860 (91%)]\tLoss: 0.022811\n",
      "Train Epoch: 43 [13696/14860 (91%)]\tLoss: 0.018444\n",
      "Train Epoch: 43 [13824/14860 (92%)]\tLoss: 0.019535\n",
      "Train Epoch: 43 [13952/14860 (93%)]\tLoss: 0.026837\n",
      "Train Epoch: 43 [14080/14860 (94%)]\tLoss: 0.016735\n",
      "Train Epoch: 43 [14208/14860 (95%)]\tLoss: 0.018891\n",
      "Train Epoch: 43 [14336/14860 (96%)]\tLoss: 0.025083\n",
      "Train Epoch: 43 [14464/14860 (97%)]\tLoss: 0.017833\n",
      "Train Epoch: 43 [14592/14860 (97%)]\tLoss: 0.022340\n",
      "Train Epoch: 43 [14720/14860 (98%)]\tLoss: 0.021716\n",
      "Train Epoch: 43 [1392/14860 (99%)]\tLoss: 0.007311\n",
      "epoch 43 training loss: 0.019525327258066744\n",
      "epoch 43 validation loss: 0.023731954161249118\n",
      "Train Epoch: 44 [0/14860 (0%)]\tLoss: 0.024383\n",
      "Train Epoch: 44 [128/14860 (1%)]\tLoss: 0.015212\n",
      "Train Epoch: 44 [256/14860 (2%)]\tLoss: 0.020426\n",
      "Train Epoch: 44 [384/14860 (3%)]\tLoss: 0.021892\n",
      "Train Epoch: 44 [512/14860 (3%)]\tLoss: 0.015029\n",
      "Train Epoch: 44 [640/14860 (4%)]\tLoss: 0.018468\n",
      "Train Epoch: 44 [768/14860 (5%)]\tLoss: 0.022859\n",
      "Train Epoch: 44 [896/14860 (6%)]\tLoss: 0.018121\n",
      "Train Epoch: 44 [1024/14860 (7%)]\tLoss: 0.015998\n",
      "Train Epoch: 44 [1152/14860 (8%)]\tLoss: 0.019352\n",
      "Train Epoch: 44 [1280/14860 (9%)]\tLoss: 0.026977\n",
      "Train Epoch: 44 [1408/14860 (9%)]\tLoss: 0.028698\n",
      "Train Epoch: 44 [1536/14860 (10%)]\tLoss: 0.020945\n",
      "Train Epoch: 44 [1664/14860 (11%)]\tLoss: 0.024098\n",
      "Train Epoch: 44 [1792/14860 (12%)]\tLoss: 0.021073\n",
      "Train Epoch: 44 [1920/14860 (13%)]\tLoss: 0.023754\n",
      "Train Epoch: 44 [2048/14860 (14%)]\tLoss: 0.018065\n",
      "Train Epoch: 44 [2176/14860 (15%)]\tLoss: 0.021855\n",
      "Train Epoch: 44 [2304/14860 (15%)]\tLoss: 0.013032\n",
      "Train Epoch: 44 [2432/14860 (16%)]\tLoss: 0.010598\n",
      "Train Epoch: 44 [2560/14860 (17%)]\tLoss: 0.016046\n",
      "Train Epoch: 44 [2688/14860 (18%)]\tLoss: 0.021306\n",
      "Train Epoch: 44 [2816/14860 (19%)]\tLoss: 0.019105\n",
      "Train Epoch: 44 [2944/14860 (20%)]\tLoss: 0.018255\n",
      "Train Epoch: 44 [3072/14860 (21%)]\tLoss: 0.019271\n",
      "Train Epoch: 44 [3200/14860 (21%)]\tLoss: 0.015896\n",
      "Train Epoch: 44 [3328/14860 (22%)]\tLoss: 0.016891\n",
      "Train Epoch: 44 [3456/14860 (23%)]\tLoss: 0.022630\n",
      "Train Epoch: 44 [3584/14860 (24%)]\tLoss: 0.015250\n",
      "Train Epoch: 44 [3712/14860 (25%)]\tLoss: 0.024430\n",
      "Train Epoch: 44 [3840/14860 (26%)]\tLoss: 0.023749\n",
      "Train Epoch: 44 [3968/14860 (26%)]\tLoss: 0.022061\n",
      "Train Epoch: 44 [4096/14860 (27%)]\tLoss: 0.017070\n",
      "Train Epoch: 44 [4224/14860 (28%)]\tLoss: 0.024398\n",
      "Train Epoch: 44 [4352/14860 (29%)]\tLoss: 0.016039\n",
      "Train Epoch: 44 [4480/14860 (30%)]\tLoss: 0.019714\n",
      "Train Epoch: 44 [4608/14860 (31%)]\tLoss: 0.019070\n",
      "Train Epoch: 44 [4736/14860 (32%)]\tLoss: 0.018115\n",
      "Train Epoch: 44 [4864/14860 (32%)]\tLoss: 0.015977\n",
      "Train Epoch: 44 [4992/14860 (33%)]\tLoss: 0.015850\n",
      "Train Epoch: 44 [5120/14860 (34%)]\tLoss: 0.011626\n",
      "Train Epoch: 44 [5248/14860 (35%)]\tLoss: 0.024057\n",
      "Train Epoch: 44 [5376/14860 (36%)]\tLoss: 0.016126\n",
      "Train Epoch: 44 [5504/14860 (37%)]\tLoss: 0.021377\n",
      "Train Epoch: 44 [5632/14860 (38%)]\tLoss: 0.018927\n",
      "Train Epoch: 44 [5760/14860 (38%)]\tLoss: 0.014098\n",
      "Train Epoch: 44 [5888/14860 (39%)]\tLoss: 0.020389\n",
      "Train Epoch: 44 [6016/14860 (40%)]\tLoss: 0.023744\n",
      "Train Epoch: 44 [6144/14860 (41%)]\tLoss: 0.015760\n",
      "Train Epoch: 44 [6272/14860 (42%)]\tLoss: 0.014498\n",
      "Train Epoch: 44 [6400/14860 (43%)]\tLoss: 0.020199\n",
      "Train Epoch: 44 [6528/14860 (44%)]\tLoss: 0.016715\n",
      "Train Epoch: 44 [6656/14860 (44%)]\tLoss: 0.019683\n",
      "Train Epoch: 44 [6784/14860 (45%)]\tLoss: 0.015451\n",
      "Train Epoch: 44 [6912/14860 (46%)]\tLoss: 0.019879\n",
      "Train Epoch: 44 [7040/14860 (47%)]\tLoss: 0.020086\n",
      "Train Epoch: 44 [7168/14860 (48%)]\tLoss: 0.025106\n",
      "Train Epoch: 44 [7296/14860 (49%)]\tLoss: 0.018872\n",
      "Train Epoch: 44 [7424/14860 (50%)]\tLoss: 0.016239\n",
      "Train Epoch: 44 [7552/14860 (50%)]\tLoss: 0.016274\n",
      "Train Epoch: 44 [7680/14860 (51%)]\tLoss: 0.014398\n",
      "Train Epoch: 44 [7808/14860 (52%)]\tLoss: 0.022273\n",
      "Train Epoch: 44 [7936/14860 (53%)]\tLoss: 0.013235\n",
      "Train Epoch: 44 [8064/14860 (54%)]\tLoss: 0.018835\n",
      "Train Epoch: 44 [8192/14860 (55%)]\tLoss: 0.013277\n",
      "Train Epoch: 44 [8320/14860 (56%)]\tLoss: 0.012800\n",
      "Train Epoch: 44 [8448/14860 (56%)]\tLoss: 0.026057\n",
      "Train Epoch: 44 [8576/14860 (57%)]\tLoss: 0.022146\n",
      "Train Epoch: 44 [8704/14860 (58%)]\tLoss: 0.026824\n",
      "Train Epoch: 44 [8832/14860 (59%)]\tLoss: 0.024660\n",
      "Train Epoch: 44 [8960/14860 (60%)]\tLoss: 0.012022\n",
      "Train Epoch: 44 [9088/14860 (61%)]\tLoss: 0.028443\n",
      "Train Epoch: 44 [9216/14860 (62%)]\tLoss: 0.021333\n",
      "Train Epoch: 44 [9344/14860 (62%)]\tLoss: 0.021319\n",
      "Train Epoch: 44 [9472/14860 (63%)]\tLoss: 0.025719\n",
      "Train Epoch: 44 [9600/14860 (64%)]\tLoss: 0.018680\n",
      "Train Epoch: 44 [9728/14860 (65%)]\tLoss: 0.024214\n",
      "Train Epoch: 44 [9856/14860 (66%)]\tLoss: 0.032596\n",
      "Train Epoch: 44 [9984/14860 (67%)]\tLoss: 0.024150\n",
      "Train Epoch: 44 [10112/14860 (68%)]\tLoss: 0.024318\n",
      "Train Epoch: 44 [10240/14860 (68%)]\tLoss: 0.027023\n",
      "Train Epoch: 44 [10368/14860 (69%)]\tLoss: 0.027079\n",
      "Train Epoch: 44 [10496/14860 (70%)]\tLoss: 0.030878\n",
      "Train Epoch: 44 [10624/14860 (71%)]\tLoss: 0.030799\n",
      "Train Epoch: 44 [10752/14860 (72%)]\tLoss: 0.017774\n",
      "Train Epoch: 44 [10880/14860 (73%)]\tLoss: 0.026898\n",
      "Train Epoch: 44 [11008/14860 (74%)]\tLoss: 0.016702\n",
      "Train Epoch: 44 [11136/14860 (74%)]\tLoss: 0.015780\n",
      "Train Epoch: 44 [11264/14860 (75%)]\tLoss: 0.021071\n",
      "Train Epoch: 44 [11392/14860 (76%)]\tLoss: 0.023017\n",
      "Train Epoch: 44 [11520/14860 (77%)]\tLoss: 0.018192\n",
      "Train Epoch: 44 [11648/14860 (78%)]\tLoss: 0.018426\n",
      "Train Epoch: 44 [11776/14860 (79%)]\tLoss: 0.019657\n",
      "Train Epoch: 44 [11904/14860 (79%)]\tLoss: 0.017810\n",
      "Train Epoch: 44 [12032/14860 (80%)]\tLoss: 0.010348\n",
      "Train Epoch: 44 [12160/14860 (81%)]\tLoss: 0.015431\n",
      "Train Epoch: 44 [12288/14860 (82%)]\tLoss: 0.023894\n",
      "Train Epoch: 44 [12416/14860 (83%)]\tLoss: 0.016786\n",
      "Train Epoch: 44 [12544/14860 (84%)]\tLoss: 0.026266\n",
      "Train Epoch: 44 [12672/14860 (85%)]\tLoss: 0.021660\n",
      "Train Epoch: 44 [12800/14860 (85%)]\tLoss: 0.018867\n",
      "Train Epoch: 44 [12928/14860 (86%)]\tLoss: 0.032906\n",
      "Train Epoch: 44 [13056/14860 (87%)]\tLoss: 0.020286\n",
      "Train Epoch: 44 [13184/14860 (88%)]\tLoss: 0.021448\n",
      "Train Epoch: 44 [13312/14860 (89%)]\tLoss: 0.019910\n",
      "Train Epoch: 44 [13440/14860 (90%)]\tLoss: 0.017898\n",
      "Train Epoch: 44 [13568/14860 (91%)]\tLoss: 0.018465\n",
      "Train Epoch: 44 [13696/14860 (91%)]\tLoss: 0.029480\n",
      "Train Epoch: 44 [13824/14860 (92%)]\tLoss: 0.029469\n",
      "Train Epoch: 44 [13952/14860 (93%)]\tLoss: 0.041421\n",
      "Train Epoch: 44 [14080/14860 (94%)]\tLoss: 0.023640\n",
      "Train Epoch: 44 [14208/14860 (95%)]\tLoss: 0.018582\n",
      "Train Epoch: 44 [14336/14860 (96%)]\tLoss: 0.020103\n",
      "Train Epoch: 44 [14464/14860 (97%)]\tLoss: 0.029524\n",
      "Train Epoch: 44 [14592/14860 (97%)]\tLoss: 0.016152\n",
      "Train Epoch: 44 [14720/14860 (98%)]\tLoss: 0.017153\n",
      "Train Epoch: 44 [1392/14860 (99%)]\tLoss: 0.018383\n",
      "epoch 44 training loss: 0.02049182516992347\n",
      "epoch 44 validation loss: 0.02068854388544115\n",
      "Train Epoch: 45 [0/14860 (0%)]\tLoss: 0.027638\n",
      "Train Epoch: 45 [128/14860 (1%)]\tLoss: 0.021670\n",
      "Train Epoch: 45 [256/14860 (2%)]\tLoss: 0.013868\n",
      "Train Epoch: 45 [384/14860 (3%)]\tLoss: 0.022819\n",
      "Train Epoch: 45 [512/14860 (3%)]\tLoss: 0.021344\n",
      "Train Epoch: 45 [640/14860 (4%)]\tLoss: 0.015502\n",
      "Train Epoch: 45 [768/14860 (5%)]\tLoss: 0.016765\n",
      "Train Epoch: 45 [896/14860 (6%)]\tLoss: 0.022865\n",
      "Train Epoch: 45 [1024/14860 (7%)]\tLoss: 0.021767\n",
      "Train Epoch: 45 [1152/14860 (8%)]\tLoss: 0.015149\n",
      "Train Epoch: 45 [1280/14860 (9%)]\tLoss: 0.021960\n",
      "Train Epoch: 45 [1408/14860 (9%)]\tLoss: 0.021069\n",
      "Train Epoch: 45 [1536/14860 (10%)]\tLoss: 0.015472\n",
      "Train Epoch: 45 [1664/14860 (11%)]\tLoss: 0.013053\n",
      "Train Epoch: 45 [1792/14860 (12%)]\tLoss: 0.019511\n",
      "Train Epoch: 45 [1920/14860 (13%)]\tLoss: 0.014478\n",
      "Train Epoch: 45 [2048/14860 (14%)]\tLoss: 0.015819\n",
      "Train Epoch: 45 [2176/14860 (15%)]\tLoss: 0.016627\n",
      "Train Epoch: 45 [2304/14860 (15%)]\tLoss: 0.016041\n",
      "Train Epoch: 45 [2432/14860 (16%)]\tLoss: 0.020125\n",
      "Train Epoch: 45 [2560/14860 (17%)]\tLoss: 0.021230\n",
      "Train Epoch: 45 [2688/14860 (18%)]\tLoss: 0.014814\n",
      "Train Epoch: 45 [2816/14860 (19%)]\tLoss: 0.020991\n",
      "Train Epoch: 45 [2944/14860 (20%)]\tLoss: 0.017098\n",
      "Train Epoch: 45 [3072/14860 (21%)]\tLoss: 0.024413\n",
      "Train Epoch: 45 [3200/14860 (21%)]\tLoss: 0.019583\n",
      "Train Epoch: 45 [3328/14860 (22%)]\tLoss: 0.020989\n",
      "Train Epoch: 45 [3456/14860 (23%)]\tLoss: 0.025130\n",
      "Train Epoch: 45 [3584/14860 (24%)]\tLoss: 0.028661\n",
      "Train Epoch: 45 [3712/14860 (25%)]\tLoss: 0.031579\n",
      "Train Epoch: 45 [3840/14860 (26%)]\tLoss: 0.015533\n",
      "Train Epoch: 45 [3968/14860 (26%)]\tLoss: 0.012820\n",
      "Train Epoch: 45 [4096/14860 (27%)]\tLoss: 0.021286\n",
      "Train Epoch: 45 [4224/14860 (28%)]\tLoss: 0.016731\n",
      "Train Epoch: 45 [4352/14860 (29%)]\tLoss: 0.017223\n",
      "Train Epoch: 45 [4480/14860 (30%)]\tLoss: 0.017316\n",
      "Train Epoch: 45 [4608/14860 (31%)]\tLoss: 0.023342\n",
      "Train Epoch: 45 [4736/14860 (32%)]\tLoss: 0.023166\n",
      "Train Epoch: 45 [4864/14860 (32%)]\tLoss: 0.025772\n",
      "Train Epoch: 45 [4992/14860 (33%)]\tLoss: 0.021541\n",
      "Train Epoch: 45 [5120/14860 (34%)]\tLoss: 0.016768\n",
      "Train Epoch: 45 [5248/14860 (35%)]\tLoss: 0.026006\n",
      "Train Epoch: 45 [5376/14860 (36%)]\tLoss: 0.017368\n",
      "Train Epoch: 45 [5504/14860 (37%)]\tLoss: 0.023677\n",
      "Train Epoch: 45 [5632/14860 (38%)]\tLoss: 0.017902\n",
      "Train Epoch: 45 [5760/14860 (38%)]\tLoss: 0.019006\n",
      "Train Epoch: 45 [5888/14860 (39%)]\tLoss: 0.022309\n",
      "Train Epoch: 45 [6016/14860 (40%)]\tLoss: 0.023075\n",
      "Train Epoch: 45 [6144/14860 (41%)]\tLoss: 0.023212\n",
      "Train Epoch: 45 [6272/14860 (42%)]\tLoss: 0.018583\n",
      "Train Epoch: 45 [6400/14860 (43%)]\tLoss: 0.022415\n",
      "Train Epoch: 45 [6528/14860 (44%)]\tLoss: 0.015927\n",
      "Train Epoch: 45 [6656/14860 (44%)]\tLoss: 0.013476\n",
      "Train Epoch: 45 [6784/14860 (45%)]\tLoss: 0.021138\n",
      "Train Epoch: 45 [6912/14860 (46%)]\tLoss: 0.030029\n",
      "Train Epoch: 45 [7040/14860 (47%)]\tLoss: 0.016853\n",
      "Train Epoch: 45 [7168/14860 (48%)]\tLoss: 0.023431\n",
      "Train Epoch: 45 [7296/14860 (49%)]\tLoss: 0.021822\n",
      "Train Epoch: 45 [7424/14860 (50%)]\tLoss: 0.022812\n",
      "Train Epoch: 45 [7552/14860 (50%)]\tLoss: 0.013206\n",
      "Train Epoch: 45 [7680/14860 (51%)]\tLoss: 0.038488\n",
      "Train Epoch: 45 [7808/14860 (52%)]\tLoss: 0.017744\n",
      "Train Epoch: 45 [7936/14860 (53%)]\tLoss: 0.016371\n",
      "Train Epoch: 45 [8064/14860 (54%)]\tLoss: 0.024175\n",
      "Train Epoch: 45 [8192/14860 (55%)]\tLoss: 0.019638\n",
      "Train Epoch: 45 [8320/14860 (56%)]\tLoss: 0.020594\n",
      "Train Epoch: 45 [8448/14860 (56%)]\tLoss: 0.016844\n",
      "Train Epoch: 45 [8576/14860 (57%)]\tLoss: 0.022580\n",
      "Train Epoch: 45 [8704/14860 (58%)]\tLoss: 0.016206\n",
      "Train Epoch: 45 [8832/14860 (59%)]\tLoss: 0.017033\n",
      "Train Epoch: 45 [8960/14860 (60%)]\tLoss: 0.022845\n",
      "Train Epoch: 45 [9088/14860 (61%)]\tLoss: 0.024857\n",
      "Train Epoch: 45 [9216/14860 (62%)]\tLoss: 0.017145\n",
      "Train Epoch: 45 [9344/14860 (62%)]\tLoss: 0.016132\n",
      "Train Epoch: 45 [9472/14860 (63%)]\tLoss: 0.018787\n",
      "Train Epoch: 45 [9600/14860 (64%)]\tLoss: 0.022523\n",
      "Train Epoch: 45 [9728/14860 (65%)]\tLoss: 0.012719\n",
      "Train Epoch: 45 [9856/14860 (66%)]\tLoss: 0.017946\n",
      "Train Epoch: 45 [9984/14860 (67%)]\tLoss: 0.025735\n",
      "Train Epoch: 45 [10112/14860 (68%)]\tLoss: 0.018799\n",
      "Train Epoch: 45 [10240/14860 (68%)]\tLoss: 0.019005\n",
      "Train Epoch: 45 [10368/14860 (69%)]\tLoss: 0.010440\n",
      "Train Epoch: 45 [10496/14860 (70%)]\tLoss: 0.017794\n",
      "Train Epoch: 45 [10624/14860 (71%)]\tLoss: 0.021356\n",
      "Train Epoch: 45 [10752/14860 (72%)]\tLoss: 0.020498\n",
      "Train Epoch: 45 [10880/14860 (73%)]\tLoss: 0.015767\n",
      "Train Epoch: 45 [11008/14860 (74%)]\tLoss: 0.017066\n",
      "Train Epoch: 45 [11136/14860 (74%)]\tLoss: 0.018789\n",
      "Train Epoch: 45 [11264/14860 (75%)]\tLoss: 0.014948\n",
      "Train Epoch: 45 [11392/14860 (76%)]\tLoss: 0.025367\n",
      "Train Epoch: 45 [11520/14860 (77%)]\tLoss: 0.018298\n",
      "Train Epoch: 45 [11648/14860 (78%)]\tLoss: 0.013296\n",
      "Train Epoch: 45 [11776/14860 (79%)]\tLoss: 0.013078\n",
      "Train Epoch: 45 [11904/14860 (79%)]\tLoss: 0.019790\n",
      "Train Epoch: 45 [12032/14860 (80%)]\tLoss: 0.019403\n",
      "Train Epoch: 45 [12160/14860 (81%)]\tLoss: 0.018808\n",
      "Train Epoch: 45 [12288/14860 (82%)]\tLoss: 0.017301\n",
      "Train Epoch: 45 [12416/14860 (83%)]\tLoss: 0.027419\n",
      "Train Epoch: 45 [12544/14860 (84%)]\tLoss: 0.023032\n",
      "Train Epoch: 45 [12672/14860 (85%)]\tLoss: 0.017160\n",
      "Train Epoch: 45 [12800/14860 (85%)]\tLoss: 0.023554\n",
      "Train Epoch: 45 [12928/14860 (86%)]\tLoss: 0.019056\n",
      "Train Epoch: 45 [13056/14860 (87%)]\tLoss: 0.018489\n",
      "Train Epoch: 45 [13184/14860 (88%)]\tLoss: 0.017780\n",
      "Train Epoch: 45 [13312/14860 (89%)]\tLoss: 0.025616\n",
      "Train Epoch: 45 [13440/14860 (90%)]\tLoss: 0.023474\n",
      "Train Epoch: 45 [13568/14860 (91%)]\tLoss: 0.016868\n",
      "Train Epoch: 45 [13696/14860 (91%)]\tLoss: 0.018199\n",
      "Train Epoch: 45 [13824/14860 (92%)]\tLoss: 0.020628\n",
      "Train Epoch: 45 [13952/14860 (93%)]\tLoss: 0.019779\n",
      "Train Epoch: 45 [14080/14860 (94%)]\tLoss: 0.019102\n",
      "Train Epoch: 45 [14208/14860 (95%)]\tLoss: 0.015853\n",
      "Train Epoch: 45 [14336/14860 (96%)]\tLoss: 0.018726\n",
      "Train Epoch: 45 [14464/14860 (97%)]\tLoss: 0.022960\n",
      "Train Epoch: 45 [14592/14860 (97%)]\tLoss: 0.028050\n",
      "Train Epoch: 45 [14720/14860 (98%)]\tLoss: 0.026669\n",
      "Train Epoch: 45 [1392/14860 (99%)]\tLoss: 0.006525\n",
      "epoch 45 training loss: 0.0198194821858699\n",
      "epoch 45 validation loss: 0.02091804558082008\n",
      "Train Epoch: 46 [0/14860 (0%)]\tLoss: 0.026286\n",
      "Train Epoch: 46 [128/14860 (1%)]\tLoss: 0.017872\n",
      "Train Epoch: 46 [256/14860 (2%)]\tLoss: 0.024930\n",
      "Train Epoch: 46 [384/14860 (3%)]\tLoss: 0.014141\n",
      "Train Epoch: 46 [512/14860 (3%)]\tLoss: 0.023195\n",
      "Train Epoch: 46 [640/14860 (4%)]\tLoss: 0.013930\n",
      "Train Epoch: 46 [768/14860 (5%)]\tLoss: 0.025940\n",
      "Train Epoch: 46 [896/14860 (6%)]\tLoss: 0.020932\n",
      "Train Epoch: 46 [1024/14860 (7%)]\tLoss: 0.019734\n",
      "Train Epoch: 46 [1152/14860 (8%)]\tLoss: 0.019597\n",
      "Train Epoch: 46 [1280/14860 (9%)]\tLoss: 0.011923\n",
      "Train Epoch: 46 [1408/14860 (9%)]\tLoss: 0.024590\n",
      "Train Epoch: 46 [1536/14860 (10%)]\tLoss: 0.020674\n",
      "Train Epoch: 46 [1664/14860 (11%)]\tLoss: 0.018717\n",
      "Train Epoch: 46 [1792/14860 (12%)]\tLoss: 0.017968\n",
      "Train Epoch: 46 [1920/14860 (13%)]\tLoss: 0.024146\n",
      "Train Epoch: 46 [2048/14860 (14%)]\tLoss: 0.021706\n",
      "Train Epoch: 46 [2176/14860 (15%)]\tLoss: 0.023324\n",
      "Train Epoch: 46 [2304/14860 (15%)]\tLoss: 0.020409\n",
      "Train Epoch: 46 [2432/14860 (16%)]\tLoss: 0.027551\n",
      "Train Epoch: 46 [2560/14860 (17%)]\tLoss: 0.019344\n",
      "Train Epoch: 46 [2688/14860 (18%)]\tLoss: 0.022427\n",
      "Train Epoch: 46 [2816/14860 (19%)]\tLoss: 0.023644\n",
      "Train Epoch: 46 [2944/14860 (20%)]\tLoss: 0.014384\n",
      "Train Epoch: 46 [3072/14860 (21%)]\tLoss: 0.019593\n",
      "Train Epoch: 46 [3200/14860 (21%)]\tLoss: 0.018464\n",
      "Train Epoch: 46 [3328/14860 (22%)]\tLoss: 0.016132\n",
      "Train Epoch: 46 [3456/14860 (23%)]\tLoss: 0.028296\n",
      "Train Epoch: 46 [3584/14860 (24%)]\tLoss: 0.014408\n",
      "Train Epoch: 46 [3712/14860 (25%)]\tLoss: 0.019088\n",
      "Train Epoch: 46 [3840/14860 (26%)]\tLoss: 0.017956\n",
      "Train Epoch: 46 [3968/14860 (26%)]\tLoss: 0.019842\n",
      "Train Epoch: 46 [4096/14860 (27%)]\tLoss: 0.020773\n",
      "Train Epoch: 46 [4224/14860 (28%)]\tLoss: 0.019258\n",
      "Train Epoch: 46 [4352/14860 (29%)]\tLoss: 0.017875\n",
      "Train Epoch: 46 [4480/14860 (30%)]\tLoss: 0.021428\n",
      "Train Epoch: 46 [4608/14860 (31%)]\tLoss: 0.018455\n",
      "Train Epoch: 46 [4736/14860 (32%)]\tLoss: 0.025832\n",
      "Train Epoch: 46 [4864/14860 (32%)]\tLoss: 0.016602\n",
      "Train Epoch: 46 [4992/14860 (33%)]\tLoss: 0.015870\n",
      "Train Epoch: 46 [5120/14860 (34%)]\tLoss: 0.029452\n",
      "Train Epoch: 46 [5248/14860 (35%)]\tLoss: 0.014953\n",
      "Train Epoch: 46 [5376/14860 (36%)]\tLoss: 0.011935\n",
      "Train Epoch: 46 [5504/14860 (37%)]\tLoss: 0.027074\n",
      "Train Epoch: 46 [5632/14860 (38%)]\tLoss: 0.021308\n",
      "Train Epoch: 46 [5760/14860 (38%)]\tLoss: 0.017436\n",
      "Train Epoch: 46 [5888/14860 (39%)]\tLoss: 0.020785\n",
      "Train Epoch: 46 [6016/14860 (40%)]\tLoss: 0.015175\n",
      "Train Epoch: 46 [6144/14860 (41%)]\tLoss: 0.021768\n",
      "Train Epoch: 46 [6272/14860 (42%)]\tLoss: 0.018489\n",
      "Train Epoch: 46 [6400/14860 (43%)]\tLoss: 0.018376\n",
      "Train Epoch: 46 [6528/14860 (44%)]\tLoss: 0.019318\n",
      "Train Epoch: 46 [6656/14860 (44%)]\tLoss: 0.017193\n",
      "Train Epoch: 46 [6784/14860 (45%)]\tLoss: 0.019898\n",
      "Train Epoch: 46 [6912/14860 (46%)]\tLoss: 0.015805\n",
      "Train Epoch: 46 [7040/14860 (47%)]\tLoss: 0.024044\n",
      "Train Epoch: 46 [7168/14860 (48%)]\tLoss: 0.023355\n",
      "Train Epoch: 46 [7296/14860 (49%)]\tLoss: 0.017636\n",
      "Train Epoch: 46 [7424/14860 (50%)]\tLoss: 0.024257\n",
      "Train Epoch: 46 [7552/14860 (50%)]\tLoss: 0.018904\n",
      "Train Epoch: 46 [7680/14860 (51%)]\tLoss: 0.026390\n",
      "Train Epoch: 46 [7808/14860 (52%)]\tLoss: 0.022369\n",
      "Train Epoch: 46 [7936/14860 (53%)]\tLoss: 0.015815\n",
      "Train Epoch: 46 [8064/14860 (54%)]\tLoss: 0.014205\n",
      "Train Epoch: 46 [8192/14860 (55%)]\tLoss: 0.025533\n",
      "Train Epoch: 46 [8320/14860 (56%)]\tLoss: 0.020928\n",
      "Train Epoch: 46 [8448/14860 (56%)]\tLoss: 0.016211\n",
      "Train Epoch: 46 [8576/14860 (57%)]\tLoss: 0.021190\n",
      "Train Epoch: 46 [8704/14860 (58%)]\tLoss: 0.023194\n",
      "Train Epoch: 46 [8832/14860 (59%)]\tLoss: 0.019425\n",
      "Train Epoch: 46 [8960/14860 (60%)]\tLoss: 0.017851\n",
      "Train Epoch: 46 [9088/14860 (61%)]\tLoss: 0.020878\n",
      "Train Epoch: 46 [9216/14860 (62%)]\tLoss: 0.020033\n",
      "Train Epoch: 46 [9344/14860 (62%)]\tLoss: 0.028416\n",
      "Train Epoch: 46 [9472/14860 (63%)]\tLoss: 0.021215\n",
      "Train Epoch: 46 [9600/14860 (64%)]\tLoss: 0.014377\n",
      "Train Epoch: 46 [9728/14860 (65%)]\tLoss: 0.015702\n",
      "Train Epoch: 46 [9856/14860 (66%)]\tLoss: 0.015143\n",
      "Train Epoch: 46 [9984/14860 (67%)]\tLoss: 0.017319\n",
      "Train Epoch: 46 [10112/14860 (68%)]\tLoss: 0.015282\n",
      "Train Epoch: 46 [10240/14860 (68%)]\tLoss: 0.020396\n",
      "Train Epoch: 46 [10368/14860 (69%)]\tLoss: 0.018044\n",
      "Train Epoch: 46 [10496/14860 (70%)]\tLoss: 0.019933\n",
      "Train Epoch: 46 [10624/14860 (71%)]\tLoss: 0.016197\n",
      "Train Epoch: 46 [10752/14860 (72%)]\tLoss: 0.016367\n",
      "Train Epoch: 46 [10880/14860 (73%)]\tLoss: 0.020344\n",
      "Train Epoch: 46 [11008/14860 (74%)]\tLoss: 0.023060\n",
      "Train Epoch: 46 [11136/14860 (74%)]\tLoss: 0.023723\n",
      "Train Epoch: 46 [11264/14860 (75%)]\tLoss: 0.020777\n",
      "Train Epoch: 46 [11392/14860 (76%)]\tLoss: 0.020685\n",
      "Train Epoch: 46 [11520/14860 (77%)]\tLoss: 0.018054\n",
      "Train Epoch: 46 [11648/14860 (78%)]\tLoss: 0.018272\n",
      "Train Epoch: 46 [11776/14860 (79%)]\tLoss: 0.013720\n",
      "Train Epoch: 46 [11904/14860 (79%)]\tLoss: 0.022591\n",
      "Train Epoch: 46 [12032/14860 (80%)]\tLoss: 0.019163\n",
      "Train Epoch: 46 [12160/14860 (81%)]\tLoss: 0.018391\n",
      "Train Epoch: 46 [12288/14860 (82%)]\tLoss: 0.022938\n",
      "Train Epoch: 46 [12416/14860 (83%)]\tLoss: 0.015459\n",
      "Train Epoch: 46 [12544/14860 (84%)]\tLoss: 0.014762\n",
      "Train Epoch: 46 [12672/14860 (85%)]\tLoss: 0.020384\n",
      "Train Epoch: 46 [12800/14860 (85%)]\tLoss: 0.023717\n",
      "Train Epoch: 46 [12928/14860 (86%)]\tLoss: 0.018381\n",
      "Train Epoch: 46 [13056/14860 (87%)]\tLoss: 0.014945\n",
      "Train Epoch: 46 [13184/14860 (88%)]\tLoss: 0.015126\n",
      "Train Epoch: 46 [13312/14860 (89%)]\tLoss: 0.025907\n",
      "Train Epoch: 46 [13440/14860 (90%)]\tLoss: 0.020879\n",
      "Train Epoch: 46 [13568/14860 (91%)]\tLoss: 0.016353\n",
      "Train Epoch: 46 [13696/14860 (91%)]\tLoss: 0.028835\n",
      "Train Epoch: 46 [13824/14860 (92%)]\tLoss: 0.021482\n",
      "Train Epoch: 46 [13952/14860 (93%)]\tLoss: 0.024182\n",
      "Train Epoch: 46 [14080/14860 (94%)]\tLoss: 0.014548\n",
      "Train Epoch: 46 [14208/14860 (95%)]\tLoss: 0.020663\n",
      "Train Epoch: 46 [14336/14860 (96%)]\tLoss: 0.017864\n",
      "Train Epoch: 46 [14464/14860 (97%)]\tLoss: 0.017256\n",
      "Train Epoch: 46 [14592/14860 (97%)]\tLoss: 0.020338\n",
      "Train Epoch: 46 [14720/14860 (98%)]\tLoss: 0.017628\n",
      "Train Epoch: 46 [1392/14860 (99%)]\tLoss: 0.033731\n",
      "epoch 46 training loss: 0.019922784712706875\n",
      "epoch 46 validation loss: 0.03329400072374875\n",
      "Train Epoch: 47 [0/14860 (0%)]\tLoss: 0.029148\n",
      "Train Epoch: 47 [128/14860 (1%)]\tLoss: 0.026716\n",
      "Train Epoch: 47 [256/14860 (2%)]\tLoss: 0.016540\n",
      "Train Epoch: 47 [384/14860 (3%)]\tLoss: 0.028763\n",
      "Train Epoch: 47 [512/14860 (3%)]\tLoss: 0.028878\n",
      "Train Epoch: 47 [640/14860 (4%)]\tLoss: 0.026131\n",
      "Train Epoch: 47 [768/14860 (5%)]\tLoss: 0.035280\n",
      "Train Epoch: 47 [896/14860 (6%)]\tLoss: 0.030623\n",
      "Train Epoch: 47 [1024/14860 (7%)]\tLoss: 0.019631\n",
      "Train Epoch: 47 [1152/14860 (8%)]\tLoss: 0.042650\n",
      "Train Epoch: 47 [1280/14860 (9%)]\tLoss: 0.035563\n",
      "Train Epoch: 47 [1408/14860 (9%)]\tLoss: 0.020831\n",
      "Train Epoch: 47 [1536/14860 (10%)]\tLoss: 0.021358\n",
      "Train Epoch: 47 [1664/14860 (11%)]\tLoss: 0.026274\n",
      "Train Epoch: 47 [1792/14860 (12%)]\tLoss: 0.025976\n",
      "Train Epoch: 47 [1920/14860 (13%)]\tLoss: 0.028179\n",
      "Train Epoch: 47 [2048/14860 (14%)]\tLoss: 0.026440\n",
      "Train Epoch: 47 [2176/14860 (15%)]\tLoss: 0.024569\n",
      "Train Epoch: 47 [2304/14860 (15%)]\tLoss: 0.028345\n",
      "Train Epoch: 47 [2432/14860 (16%)]\tLoss: 0.018055\n",
      "Train Epoch: 47 [2560/14860 (17%)]\tLoss: 0.022353\n",
      "Train Epoch: 47 [2688/14860 (18%)]\tLoss: 0.023943\n",
      "Train Epoch: 47 [2816/14860 (19%)]\tLoss: 0.020089\n",
      "Train Epoch: 47 [2944/14860 (20%)]\tLoss: 0.016154\n",
      "Train Epoch: 47 [3072/14860 (21%)]\tLoss: 0.019833\n",
      "Train Epoch: 47 [3200/14860 (21%)]\tLoss: 0.025278\n",
      "Train Epoch: 47 [3328/14860 (22%)]\tLoss: 0.027017\n",
      "Train Epoch: 47 [3456/14860 (23%)]\tLoss: 0.016517\n",
      "Train Epoch: 47 [3584/14860 (24%)]\tLoss: 0.026169\n",
      "Train Epoch: 47 [3712/14860 (25%)]\tLoss: 0.019616\n",
      "Train Epoch: 47 [3840/14860 (26%)]\tLoss: 0.013839\n",
      "Train Epoch: 47 [3968/14860 (26%)]\tLoss: 0.018893\n",
      "Train Epoch: 47 [4096/14860 (27%)]\tLoss: 0.024290\n",
      "Train Epoch: 47 [4224/14860 (28%)]\tLoss: 0.017195\n",
      "Train Epoch: 47 [4352/14860 (29%)]\tLoss: 0.017656\n",
      "Train Epoch: 47 [4480/14860 (30%)]\tLoss: 0.019413\n",
      "Train Epoch: 47 [4608/14860 (31%)]\tLoss: 0.017547\n",
      "Train Epoch: 47 [4736/14860 (32%)]\tLoss: 0.019260\n",
      "Train Epoch: 47 [4864/14860 (32%)]\tLoss: 0.028717\n",
      "Train Epoch: 47 [4992/14860 (33%)]\tLoss: 0.020700\n",
      "Train Epoch: 47 [5120/14860 (34%)]\tLoss: 0.022379\n",
      "Train Epoch: 47 [5248/14860 (35%)]\tLoss: 0.023325\n",
      "Train Epoch: 47 [5376/14860 (36%)]\tLoss: 0.026823\n",
      "Train Epoch: 47 [5504/14860 (37%)]\tLoss: 0.022541\n",
      "Train Epoch: 47 [5632/14860 (38%)]\tLoss: 0.014700\n",
      "Train Epoch: 47 [5760/14860 (38%)]\tLoss: 0.022516\n",
      "Train Epoch: 47 [5888/14860 (39%)]\tLoss: 0.025834\n",
      "Train Epoch: 47 [6016/14860 (40%)]\tLoss: 0.017847\n",
      "Train Epoch: 47 [6144/14860 (41%)]\tLoss: 0.015086\n",
      "Train Epoch: 47 [6272/14860 (42%)]\tLoss: 0.020329\n",
      "Train Epoch: 47 [6400/14860 (43%)]\tLoss: 0.014614\n",
      "Train Epoch: 47 [6528/14860 (44%)]\tLoss: 0.017096\n",
      "Train Epoch: 47 [6656/14860 (44%)]\tLoss: 0.020101\n",
      "Train Epoch: 47 [6784/14860 (45%)]\tLoss: 0.024225\n",
      "Train Epoch: 47 [6912/14860 (46%)]\tLoss: 0.013180\n",
      "Train Epoch: 47 [7040/14860 (47%)]\tLoss: 0.025687\n",
      "Train Epoch: 47 [7168/14860 (48%)]\tLoss: 0.020035\n",
      "Train Epoch: 47 [7296/14860 (49%)]\tLoss: 0.017919\n",
      "Train Epoch: 47 [7424/14860 (50%)]\tLoss: 0.020566\n",
      "Train Epoch: 47 [7552/14860 (50%)]\tLoss: 0.019291\n",
      "Train Epoch: 47 [7680/14860 (51%)]\tLoss: 0.015169\n",
      "Train Epoch: 47 [7808/14860 (52%)]\tLoss: 0.015736\n",
      "Train Epoch: 47 [7936/14860 (53%)]\tLoss: 0.014714\n",
      "Train Epoch: 47 [8064/14860 (54%)]\tLoss: 0.022307\n",
      "Train Epoch: 47 [8192/14860 (55%)]\tLoss: 0.018098\n",
      "Train Epoch: 47 [8320/14860 (56%)]\tLoss: 0.017614\n",
      "Train Epoch: 47 [8448/14860 (56%)]\tLoss: 0.026798\n",
      "Train Epoch: 47 [8576/14860 (57%)]\tLoss: 0.020307\n",
      "Train Epoch: 47 [8704/14860 (58%)]\tLoss: 0.016597\n",
      "Train Epoch: 47 [8832/14860 (59%)]\tLoss: 0.021186\n",
      "Train Epoch: 47 [8960/14860 (60%)]\tLoss: 0.024342\n",
      "Train Epoch: 47 [9088/14860 (61%)]\tLoss: 0.021982\n",
      "Train Epoch: 47 [9216/14860 (62%)]\tLoss: 0.017404\n",
      "Train Epoch: 47 [9344/14860 (62%)]\tLoss: 0.020381\n",
      "Train Epoch: 47 [9472/14860 (63%)]\tLoss: 0.021091\n",
      "Train Epoch: 47 [9600/14860 (64%)]\tLoss: 0.019523\n",
      "Train Epoch: 47 [9728/14860 (65%)]\tLoss: 0.022205\n",
      "Train Epoch: 47 [9856/14860 (66%)]\tLoss: 0.016729\n",
      "Train Epoch: 47 [9984/14860 (67%)]\tLoss: 0.015059\n",
      "Train Epoch: 47 [10112/14860 (68%)]\tLoss: 0.022284\n",
      "Train Epoch: 47 [10240/14860 (68%)]\tLoss: 0.017368\n",
      "Train Epoch: 47 [10368/14860 (69%)]\tLoss: 0.017627\n",
      "Train Epoch: 47 [10496/14860 (70%)]\tLoss: 0.022419\n",
      "Train Epoch: 47 [10624/14860 (71%)]\tLoss: 0.019984\n",
      "Train Epoch: 47 [10752/14860 (72%)]\tLoss: 0.023393\n",
      "Train Epoch: 47 [10880/14860 (73%)]\tLoss: 0.015321\n",
      "Train Epoch: 47 [11008/14860 (74%)]\tLoss: 0.013917\n",
      "Train Epoch: 47 [11136/14860 (74%)]\tLoss: 0.017275\n",
      "Train Epoch: 47 [11264/14860 (75%)]\tLoss: 0.014701\n",
      "Train Epoch: 47 [11392/14860 (76%)]\tLoss: 0.014499\n",
      "Train Epoch: 47 [11520/14860 (77%)]\tLoss: 0.016794\n",
      "Train Epoch: 47 [11648/14860 (78%)]\tLoss: 0.017895\n",
      "Train Epoch: 47 [11776/14860 (79%)]\tLoss: 0.013321\n",
      "Train Epoch: 47 [11904/14860 (79%)]\tLoss: 0.017647\n",
      "Train Epoch: 47 [12032/14860 (80%)]\tLoss: 0.029327\n",
      "Train Epoch: 47 [12160/14860 (81%)]\tLoss: 0.028133\n",
      "Train Epoch: 47 [12288/14860 (82%)]\tLoss: 0.017909\n",
      "Train Epoch: 47 [12416/14860 (83%)]\tLoss: 0.023479\n",
      "Train Epoch: 47 [12544/14860 (84%)]\tLoss: 0.020539\n",
      "Train Epoch: 47 [12672/14860 (85%)]\tLoss: 0.018954\n",
      "Train Epoch: 47 [12800/14860 (85%)]\tLoss: 0.023481\n",
      "Train Epoch: 47 [12928/14860 (86%)]\tLoss: 0.023402\n",
      "Train Epoch: 47 [13056/14860 (87%)]\tLoss: 0.018298\n",
      "Train Epoch: 47 [13184/14860 (88%)]\tLoss: 0.020118\n",
      "Train Epoch: 47 [13312/14860 (89%)]\tLoss: 0.021816\n",
      "Train Epoch: 47 [13440/14860 (90%)]\tLoss: 0.020111\n",
      "Train Epoch: 47 [13568/14860 (91%)]\tLoss: 0.013387\n",
      "Train Epoch: 47 [13696/14860 (91%)]\tLoss: 0.015415\n",
      "Train Epoch: 47 [13824/14860 (92%)]\tLoss: 0.020662\n",
      "Train Epoch: 47 [13952/14860 (93%)]\tLoss: 0.020358\n",
      "Train Epoch: 47 [14080/14860 (94%)]\tLoss: 0.020322\n",
      "Train Epoch: 47 [14208/14860 (95%)]\tLoss: 0.017674\n",
      "Train Epoch: 47 [14336/14860 (96%)]\tLoss: 0.014621\n",
      "Train Epoch: 47 [14464/14860 (97%)]\tLoss: 0.015972\n",
      "Train Epoch: 47 [14592/14860 (97%)]\tLoss: 0.019835\n",
      "Train Epoch: 47 [14720/14860 (98%)]\tLoss: 0.021492\n",
      "Train Epoch: 47 [1392/14860 (99%)]\tLoss: 0.013398\n",
      "epoch 47 training loss: 0.020930843141216498\n",
      "epoch 47 validation loss: 0.022182786291505753\n",
      "Train Epoch: 48 [0/14860 (0%)]\tLoss: 0.026915\n",
      "Train Epoch: 48 [128/14860 (1%)]\tLoss: 0.017890\n",
      "Train Epoch: 48 [256/14860 (2%)]\tLoss: 0.023474\n",
      "Train Epoch: 48 [384/14860 (3%)]\tLoss: 0.030020\n",
      "Train Epoch: 48 [512/14860 (3%)]\tLoss: 0.021246\n",
      "Train Epoch: 48 [640/14860 (4%)]\tLoss: 0.027273\n",
      "Train Epoch: 48 [768/14860 (5%)]\tLoss: 0.021618\n",
      "Train Epoch: 48 [896/14860 (6%)]\tLoss: 0.022590\n",
      "Train Epoch: 48 [1024/14860 (7%)]\tLoss: 0.018202\n",
      "Train Epoch: 48 [1152/14860 (8%)]\tLoss: 0.019187\n",
      "Train Epoch: 48 [1280/14860 (9%)]\tLoss: 0.017013\n",
      "Train Epoch: 48 [1408/14860 (9%)]\tLoss: 0.025148\n",
      "Train Epoch: 48 [1536/14860 (10%)]\tLoss: 0.022006\n",
      "Train Epoch: 48 [1664/14860 (11%)]\tLoss: 0.020214\n",
      "Train Epoch: 48 [1792/14860 (12%)]\tLoss: 0.016253\n",
      "Train Epoch: 48 [1920/14860 (13%)]\tLoss: 0.016239\n",
      "Train Epoch: 48 [2048/14860 (14%)]\tLoss: 0.019188\n",
      "Train Epoch: 48 [2176/14860 (15%)]\tLoss: 0.022546\n",
      "Train Epoch: 48 [2304/14860 (15%)]\tLoss: 0.020271\n",
      "Train Epoch: 48 [2432/14860 (16%)]\tLoss: 0.037053\n",
      "Train Epoch: 48 [2560/14860 (17%)]\tLoss: 0.014929\n",
      "Train Epoch: 48 [2688/14860 (18%)]\tLoss: 0.020068\n",
      "Train Epoch: 48 [2816/14860 (19%)]\tLoss: 0.017692\n",
      "Train Epoch: 48 [2944/14860 (20%)]\tLoss: 0.024120\n",
      "Train Epoch: 48 [3072/14860 (21%)]\tLoss: 0.017781\n",
      "Train Epoch: 48 [3200/14860 (21%)]\tLoss: 0.020399\n",
      "Train Epoch: 48 [3328/14860 (22%)]\tLoss: 0.018931\n",
      "Train Epoch: 48 [3456/14860 (23%)]\tLoss: 0.020215\n",
      "Train Epoch: 48 [3584/14860 (24%)]\tLoss: 0.019320\n",
      "Train Epoch: 48 [3712/14860 (25%)]\tLoss: 0.012335\n",
      "Train Epoch: 48 [3840/14860 (26%)]\tLoss: 0.015607\n",
      "Train Epoch: 48 [3968/14860 (26%)]\tLoss: 0.020799\n",
      "Train Epoch: 48 [4096/14860 (27%)]\tLoss: 0.013112\n",
      "Train Epoch: 48 [4224/14860 (28%)]\tLoss: 0.022878\n",
      "Train Epoch: 48 [4352/14860 (29%)]\tLoss: 0.024824\n",
      "Train Epoch: 48 [4480/14860 (30%)]\tLoss: 0.021881\n",
      "Train Epoch: 48 [4608/14860 (31%)]\tLoss: 0.016217\n",
      "Train Epoch: 48 [4736/14860 (32%)]\tLoss: 0.024381\n",
      "Train Epoch: 48 [4864/14860 (32%)]\tLoss: 0.015616\n",
      "Train Epoch: 48 [4992/14860 (33%)]\tLoss: 0.014168\n",
      "Train Epoch: 48 [5120/14860 (34%)]\tLoss: 0.024431\n",
      "Train Epoch: 48 [5248/14860 (35%)]\tLoss: 0.017044\n",
      "Train Epoch: 48 [5376/14860 (36%)]\tLoss: 0.012484\n",
      "Train Epoch: 48 [5504/14860 (37%)]\tLoss: 0.016068\n",
      "Train Epoch: 48 [5632/14860 (38%)]\tLoss: 0.017487\n",
      "Train Epoch: 48 [5760/14860 (38%)]\tLoss: 0.021687\n",
      "Train Epoch: 48 [5888/14860 (39%)]\tLoss: 0.022367\n",
      "Train Epoch: 48 [6016/14860 (40%)]\tLoss: 0.017323\n",
      "Train Epoch: 48 [6144/14860 (41%)]\tLoss: 0.021389\n",
      "Train Epoch: 48 [6272/14860 (42%)]\tLoss: 0.018536\n",
      "Train Epoch: 48 [6400/14860 (43%)]\tLoss: 0.020544\n",
      "Train Epoch: 48 [6528/14860 (44%)]\tLoss: 0.022545\n",
      "Train Epoch: 48 [6656/14860 (44%)]\tLoss: 0.016115\n",
      "Train Epoch: 48 [6784/14860 (45%)]\tLoss: 0.017430\n",
      "Train Epoch: 48 [6912/14860 (46%)]\tLoss: 0.016879\n",
      "Train Epoch: 48 [7040/14860 (47%)]\tLoss: 0.018259\n",
      "Train Epoch: 48 [7168/14860 (48%)]\tLoss: 0.017843\n",
      "Train Epoch: 48 [7296/14860 (49%)]\tLoss: 0.018344\n",
      "Train Epoch: 48 [7424/14860 (50%)]\tLoss: 0.016124\n",
      "Train Epoch: 48 [7552/14860 (50%)]\tLoss: 0.022267\n",
      "Train Epoch: 48 [7680/14860 (51%)]\tLoss: 0.016514\n",
      "Train Epoch: 48 [7808/14860 (52%)]\tLoss: 0.015659\n",
      "Train Epoch: 48 [7936/14860 (53%)]\tLoss: 0.019215\n",
      "Train Epoch: 48 [8064/14860 (54%)]\tLoss: 0.024354\n",
      "Train Epoch: 48 [8192/14860 (55%)]\tLoss: 0.020401\n",
      "Train Epoch: 48 [8320/14860 (56%)]\tLoss: 0.014996\n",
      "Train Epoch: 48 [8448/14860 (56%)]\tLoss: 0.015457\n",
      "Train Epoch: 48 [8576/14860 (57%)]\tLoss: 0.023481\n",
      "Train Epoch: 48 [8704/14860 (58%)]\tLoss: 0.015031\n",
      "Train Epoch: 48 [8832/14860 (59%)]\tLoss: 0.026152\n",
      "Train Epoch: 48 [8960/14860 (60%)]\tLoss: 0.018720\n",
      "Train Epoch: 48 [9088/14860 (61%)]\tLoss: 0.018249\n",
      "Train Epoch: 48 [9216/14860 (62%)]\tLoss: 0.017131\n",
      "Train Epoch: 48 [9344/14860 (62%)]\tLoss: 0.013151\n",
      "Train Epoch: 48 [9472/14860 (63%)]\tLoss: 0.018334\n",
      "Train Epoch: 48 [9600/14860 (64%)]\tLoss: 0.017026\n",
      "Train Epoch: 48 [9728/14860 (65%)]\tLoss: 0.020761\n",
      "Train Epoch: 48 [9856/14860 (66%)]\tLoss: 0.017917\n",
      "Train Epoch: 48 [9984/14860 (67%)]\tLoss: 0.019399\n",
      "Train Epoch: 48 [10112/14860 (68%)]\tLoss: 0.014742\n",
      "Train Epoch: 48 [10240/14860 (68%)]\tLoss: 0.022376\n",
      "Train Epoch: 48 [10368/14860 (69%)]\tLoss: 0.010798\n",
      "Train Epoch: 48 [10496/14860 (70%)]\tLoss: 0.019007\n",
      "Train Epoch: 48 [10624/14860 (71%)]\tLoss: 0.019409\n",
      "Train Epoch: 48 [10752/14860 (72%)]\tLoss: 0.012666\n",
      "Train Epoch: 48 [10880/14860 (73%)]\tLoss: 0.026805\n",
      "Train Epoch: 48 [11008/14860 (74%)]\tLoss: 0.016006\n",
      "Train Epoch: 48 [11136/14860 (74%)]\tLoss: 0.016033\n",
      "Train Epoch: 48 [11264/14860 (75%)]\tLoss: 0.021689\n",
      "Train Epoch: 48 [11392/14860 (76%)]\tLoss: 0.022284\n",
      "Train Epoch: 48 [11520/14860 (77%)]\tLoss: 0.018784\n",
      "Train Epoch: 48 [11648/14860 (78%)]\tLoss: 0.017331\n",
      "Train Epoch: 48 [11776/14860 (79%)]\tLoss: 0.020314\n",
      "Train Epoch: 48 [11904/14860 (79%)]\tLoss: 0.025094\n",
      "Train Epoch: 48 [12032/14860 (80%)]\tLoss: 0.016278\n",
      "Train Epoch: 48 [12160/14860 (81%)]\tLoss: 0.023550\n",
      "Train Epoch: 48 [12288/14860 (82%)]\tLoss: 0.021226\n",
      "Train Epoch: 48 [12416/14860 (83%)]\tLoss: 0.022839\n",
      "Train Epoch: 48 [12544/14860 (84%)]\tLoss: 0.020068\n",
      "Train Epoch: 48 [12672/14860 (85%)]\tLoss: 0.016815\n",
      "Train Epoch: 48 [12800/14860 (85%)]\tLoss: 0.020948\n",
      "Train Epoch: 48 [12928/14860 (86%)]\tLoss: 0.016239\n",
      "Train Epoch: 48 [13056/14860 (87%)]\tLoss: 0.023743\n",
      "Train Epoch: 48 [13184/14860 (88%)]\tLoss: 0.024785\n",
      "Train Epoch: 48 [13312/14860 (89%)]\tLoss: 0.017589\n",
      "Train Epoch: 48 [13440/14860 (90%)]\tLoss: 0.020703\n",
      "Train Epoch: 48 [13568/14860 (91%)]\tLoss: 0.023061\n",
      "Train Epoch: 48 [13696/14860 (91%)]\tLoss: 0.015048\n",
      "Train Epoch: 48 [13824/14860 (92%)]\tLoss: 0.016405\n",
      "Train Epoch: 48 [13952/14860 (93%)]\tLoss: 0.016575\n",
      "Train Epoch: 48 [14080/14860 (94%)]\tLoss: 0.016702\n",
      "Train Epoch: 48 [14208/14860 (95%)]\tLoss: 0.017969\n",
      "Train Epoch: 48 [14336/14860 (96%)]\tLoss: 0.013960\n",
      "Train Epoch: 48 [14464/14860 (97%)]\tLoss: 0.021107\n",
      "Train Epoch: 48 [14592/14860 (97%)]\tLoss: 0.015801\n",
      "Train Epoch: 48 [14720/14860 (98%)]\tLoss: 0.016400\n",
      "Train Epoch: 48 [1392/14860 (99%)]\tLoss: 0.026668\n",
      "epoch 48 training loss: 0.019440603498210255\n",
      "epoch 48 validation loss: 0.023760003847302306\n",
      "Train Epoch: 49 [0/14860 (0%)]\tLoss: 0.022760\n",
      "Train Epoch: 49 [128/14860 (1%)]\tLoss: 0.019281\n",
      "Train Epoch: 49 [256/14860 (2%)]\tLoss: 0.017501\n",
      "Train Epoch: 49 [384/14860 (3%)]\tLoss: 0.023208\n",
      "Train Epoch: 49 [512/14860 (3%)]\tLoss: 0.026329\n",
      "Train Epoch: 49 [640/14860 (4%)]\tLoss: 0.020824\n",
      "Train Epoch: 49 [768/14860 (5%)]\tLoss: 0.022863\n",
      "Train Epoch: 49 [896/14860 (6%)]\tLoss: 0.022685\n",
      "Train Epoch: 49 [1024/14860 (7%)]\tLoss: 0.018306\n",
      "Train Epoch: 49 [1152/14860 (8%)]\tLoss: 0.014421\n",
      "Train Epoch: 49 [1280/14860 (9%)]\tLoss: 0.018227\n",
      "Train Epoch: 49 [1408/14860 (9%)]\tLoss: 0.013304\n",
      "Train Epoch: 49 [1536/14860 (10%)]\tLoss: 0.022390\n",
      "Train Epoch: 49 [1664/14860 (11%)]\tLoss: 0.022652\n",
      "Train Epoch: 49 [1792/14860 (12%)]\tLoss: 0.018718\n",
      "Train Epoch: 49 [1920/14860 (13%)]\tLoss: 0.018317\n",
      "Train Epoch: 49 [2048/14860 (14%)]\tLoss: 0.017402\n",
      "Train Epoch: 49 [2176/14860 (15%)]\tLoss: 0.024035\n",
      "Train Epoch: 49 [2304/14860 (15%)]\tLoss: 0.020096\n",
      "Train Epoch: 49 [2432/14860 (16%)]\tLoss: 0.025036\n",
      "Train Epoch: 49 [2560/14860 (17%)]\tLoss: 0.021056\n",
      "Train Epoch: 49 [2688/14860 (18%)]\tLoss: 0.019033\n",
      "Train Epoch: 49 [2816/14860 (19%)]\tLoss: 0.016198\n",
      "Train Epoch: 49 [2944/14860 (20%)]\tLoss: 0.016957\n",
      "Train Epoch: 49 [3072/14860 (21%)]\tLoss: 0.013896\n",
      "Train Epoch: 49 [3200/14860 (21%)]\tLoss: 0.018190\n",
      "Train Epoch: 49 [3328/14860 (22%)]\tLoss: 0.017070\n",
      "Train Epoch: 49 [3456/14860 (23%)]\tLoss: 0.015020\n",
      "Train Epoch: 49 [3584/14860 (24%)]\tLoss: 0.017815\n",
      "Train Epoch: 49 [3712/14860 (25%)]\tLoss: 0.021986\n",
      "Train Epoch: 49 [3840/14860 (26%)]\tLoss: 0.022262\n",
      "Train Epoch: 49 [3968/14860 (26%)]\tLoss: 0.016857\n",
      "Train Epoch: 49 [4096/14860 (27%)]\tLoss: 0.019348\n",
      "Train Epoch: 49 [4224/14860 (28%)]\tLoss: 0.018167\n",
      "Train Epoch: 49 [4352/14860 (29%)]\tLoss: 0.012465\n",
      "Train Epoch: 49 [4480/14860 (30%)]\tLoss: 0.014004\n",
      "Train Epoch: 49 [4608/14860 (31%)]\tLoss: 0.017658\n",
      "Train Epoch: 49 [4736/14860 (32%)]\tLoss: 0.019701\n",
      "Train Epoch: 49 [4864/14860 (32%)]\tLoss: 0.021783\n",
      "Train Epoch: 49 [4992/14860 (33%)]\tLoss: 0.012018\n",
      "Train Epoch: 49 [5120/14860 (34%)]\tLoss: 0.018191\n",
      "Train Epoch: 49 [5248/14860 (35%)]\tLoss: 0.021715\n",
      "Train Epoch: 49 [5376/14860 (36%)]\tLoss: 0.016506\n",
      "Train Epoch: 49 [5504/14860 (37%)]\tLoss: 0.017826\n",
      "Train Epoch: 49 [5632/14860 (38%)]\tLoss: 0.016475\n",
      "Train Epoch: 49 [5760/14860 (38%)]\tLoss: 0.015298\n",
      "Train Epoch: 49 [5888/14860 (39%)]\tLoss: 0.014386\n",
      "Train Epoch: 49 [6016/14860 (40%)]\tLoss: 0.016057\n",
      "Train Epoch: 49 [6144/14860 (41%)]\tLoss: 0.024371\n",
      "Train Epoch: 49 [6272/14860 (42%)]\tLoss: 0.017909\n",
      "Train Epoch: 49 [6400/14860 (43%)]\tLoss: 0.018019\n",
      "Train Epoch: 49 [6528/14860 (44%)]\tLoss: 0.020012\n",
      "Train Epoch: 49 [6656/14860 (44%)]\tLoss: 0.017063\n",
      "Train Epoch: 49 [6784/14860 (45%)]\tLoss: 0.022440\n",
      "Train Epoch: 49 [6912/14860 (46%)]\tLoss: 0.016295\n",
      "Train Epoch: 49 [7040/14860 (47%)]\tLoss: 0.021277\n",
      "Train Epoch: 49 [7168/14860 (48%)]\tLoss: 0.019197\n",
      "Train Epoch: 49 [7296/14860 (49%)]\tLoss: 0.014824\n",
      "Train Epoch: 49 [7424/14860 (50%)]\tLoss: 0.027156\n",
      "Train Epoch: 49 [7552/14860 (50%)]\tLoss: 0.018425\n",
      "Train Epoch: 49 [7680/14860 (51%)]\tLoss: 0.029166\n",
      "Train Epoch: 49 [7808/14860 (52%)]\tLoss: 0.018781\n",
      "Train Epoch: 49 [7936/14860 (53%)]\tLoss: 0.011847\n",
      "Train Epoch: 49 [8064/14860 (54%)]\tLoss: 0.027130\n",
      "Train Epoch: 49 [8192/14860 (55%)]\tLoss: 0.027515\n",
      "Train Epoch: 49 [8320/14860 (56%)]\tLoss: 0.034172\n",
      "Train Epoch: 49 [8448/14860 (56%)]\tLoss: 0.012607\n",
      "Train Epoch: 49 [8576/14860 (57%)]\tLoss: 0.027190\n",
      "Train Epoch: 49 [8704/14860 (58%)]\tLoss: 0.030572\n",
      "Train Epoch: 49 [8832/14860 (59%)]\tLoss: 0.019049\n",
      "Train Epoch: 49 [8960/14860 (60%)]\tLoss: 0.030281\n",
      "Train Epoch: 49 [9088/14860 (61%)]\tLoss: 0.030443\n",
      "Train Epoch: 49 [9216/14860 (62%)]\tLoss: 0.013625\n",
      "Train Epoch: 49 [9344/14860 (62%)]\tLoss: 0.029939\n",
      "Train Epoch: 49 [9472/14860 (63%)]\tLoss: 0.031591\n",
      "Train Epoch: 49 [9600/14860 (64%)]\tLoss: 0.020197\n",
      "Train Epoch: 49 [9728/14860 (65%)]\tLoss: 0.024654\n",
      "Train Epoch: 49 [9856/14860 (66%)]\tLoss: 0.026271\n",
      "Train Epoch: 49 [9984/14860 (67%)]\tLoss: 0.026106\n",
      "Train Epoch: 49 [10112/14860 (68%)]\tLoss: 0.022005\n",
      "Train Epoch: 49 [10240/14860 (68%)]\tLoss: 0.015666\n",
      "Train Epoch: 49 [10368/14860 (69%)]\tLoss: 0.023498\n",
      "Train Epoch: 49 [10496/14860 (70%)]\tLoss: 0.020456\n",
      "Train Epoch: 49 [10624/14860 (71%)]\tLoss: 0.030260\n",
      "Train Epoch: 49 [10752/14860 (72%)]\tLoss: 0.015312\n",
      "Train Epoch: 49 [10880/14860 (73%)]\tLoss: 0.014812\n",
      "Train Epoch: 49 [11008/14860 (74%)]\tLoss: 0.022859\n",
      "Train Epoch: 49 [11136/14860 (74%)]\tLoss: 0.017447\n",
      "Train Epoch: 49 [11264/14860 (75%)]\tLoss: 0.018424\n",
      "Train Epoch: 49 [11392/14860 (76%)]\tLoss: 0.022458\n",
      "Train Epoch: 49 [11520/14860 (77%)]\tLoss: 0.021048\n",
      "Train Epoch: 49 [11648/14860 (78%)]\tLoss: 0.022918\n",
      "Train Epoch: 49 [11776/14860 (79%)]\tLoss: 0.020300\n",
      "Train Epoch: 49 [11904/14860 (79%)]\tLoss: 0.017736\n",
      "Train Epoch: 49 [12032/14860 (80%)]\tLoss: 0.015882\n",
      "Train Epoch: 49 [12160/14860 (81%)]\tLoss: 0.012275\n",
      "Train Epoch: 49 [12288/14860 (82%)]\tLoss: 0.027778\n",
      "Train Epoch: 49 [12416/14860 (83%)]\tLoss: 0.012241\n",
      "Train Epoch: 49 [12544/14860 (84%)]\tLoss: 0.025504\n",
      "Train Epoch: 49 [12672/14860 (85%)]\tLoss: 0.026716\n",
      "Train Epoch: 49 [12800/14860 (85%)]\tLoss: 0.021591\n",
      "Train Epoch: 49 [12928/14860 (86%)]\tLoss: 0.016677\n",
      "Train Epoch: 49 [13056/14860 (87%)]\tLoss: 0.017451\n",
      "Train Epoch: 49 [13184/14860 (88%)]\tLoss: 0.018792\n",
      "Train Epoch: 49 [13312/14860 (89%)]\tLoss: 0.017746\n",
      "Train Epoch: 49 [13440/14860 (90%)]\tLoss: 0.013300\n",
      "Train Epoch: 49 [13568/14860 (91%)]\tLoss: 0.022568\n",
      "Train Epoch: 49 [13696/14860 (91%)]\tLoss: 0.020292\n",
      "Train Epoch: 49 [13824/14860 (92%)]\tLoss: 0.016599\n",
      "Train Epoch: 49 [13952/14860 (93%)]\tLoss: 0.018085\n",
      "Train Epoch: 49 [14080/14860 (94%)]\tLoss: 0.019153\n",
      "Train Epoch: 49 [14208/14860 (95%)]\tLoss: 0.020062\n",
      "Train Epoch: 49 [14336/14860 (96%)]\tLoss: 0.015955\n",
      "Train Epoch: 49 [14464/14860 (97%)]\tLoss: 0.013684\n",
      "Train Epoch: 49 [14592/14860 (97%)]\tLoss: 0.013989\n",
      "Train Epoch: 49 [14720/14860 (98%)]\tLoss: 0.019174\n",
      "Train Epoch: 49 [1392/14860 (99%)]\tLoss: 0.036033\n",
      "epoch 49 training loss: 0.02009543006778018\n",
      "epoch 49 validation loss: 0.02016140610773396\n",
      "Train Epoch: 50 [0/14860 (0%)]\tLoss: 0.019043\n",
      "Train Epoch: 50 [128/14860 (1%)]\tLoss: 0.023522\n",
      "Train Epoch: 50 [256/14860 (2%)]\tLoss: 0.012124\n",
      "Train Epoch: 50 [384/14860 (3%)]\tLoss: 0.021295\n",
      "Train Epoch: 50 [512/14860 (3%)]\tLoss: 0.027637\n",
      "Train Epoch: 50 [640/14860 (4%)]\tLoss: 0.021023\n",
      "Train Epoch: 50 [768/14860 (5%)]\tLoss: 0.022565\n",
      "Train Epoch: 50 [896/14860 (6%)]\tLoss: 0.017897\n",
      "Train Epoch: 50 [1024/14860 (7%)]\tLoss: 0.023900\n",
      "Train Epoch: 50 [1152/14860 (8%)]\tLoss: 0.023938\n",
      "Train Epoch: 50 [1280/14860 (9%)]\tLoss: 0.021334\n",
      "Train Epoch: 50 [1408/14860 (9%)]\tLoss: 0.036299\n",
      "Train Epoch: 50 [1536/14860 (10%)]\tLoss: 0.018264\n",
      "Train Epoch: 50 [1664/14860 (11%)]\tLoss: 0.021916\n",
      "Train Epoch: 50 [1792/14860 (12%)]\tLoss: 0.022832\n",
      "Train Epoch: 50 [1920/14860 (13%)]\tLoss: 0.018623\n",
      "Train Epoch: 50 [2048/14860 (14%)]\tLoss: 0.018729\n",
      "Train Epoch: 50 [2176/14860 (15%)]\tLoss: 0.022550\n",
      "Train Epoch: 50 [2304/14860 (15%)]\tLoss: 0.020205\n",
      "Train Epoch: 50 [2432/14860 (16%)]\tLoss: 0.016414\n",
      "Train Epoch: 50 [2560/14860 (17%)]\tLoss: 0.014400\n",
      "Train Epoch: 50 [2688/14860 (18%)]\tLoss: 0.019967\n",
      "Train Epoch: 50 [2816/14860 (19%)]\tLoss: 0.020427\n",
      "Train Epoch: 50 [2944/14860 (20%)]\tLoss: 0.019088\n",
      "Train Epoch: 50 [3072/14860 (21%)]\tLoss: 0.019199\n",
      "Train Epoch: 50 [3200/14860 (21%)]\tLoss: 0.018318\n",
      "Train Epoch: 50 [3328/14860 (22%)]\tLoss: 0.021115\n",
      "Train Epoch: 50 [3456/14860 (23%)]\tLoss: 0.014950\n",
      "Train Epoch: 50 [3584/14860 (24%)]\tLoss: 0.018700\n",
      "Train Epoch: 50 [3712/14860 (25%)]\tLoss: 0.024256\n",
      "Train Epoch: 50 [3840/14860 (26%)]\tLoss: 0.020619\n",
      "Train Epoch: 50 [3968/14860 (26%)]\tLoss: 0.021471\n",
      "Train Epoch: 50 [4096/14860 (27%)]\tLoss: 0.018558\n",
      "Train Epoch: 50 [4224/14860 (28%)]\tLoss: 0.014324\n",
      "Train Epoch: 50 [4352/14860 (29%)]\tLoss: 0.027958\n",
      "Train Epoch: 50 [4480/14860 (30%)]\tLoss: 0.014534\n",
      "Train Epoch: 50 [4608/14860 (31%)]\tLoss: 0.021351\n",
      "Train Epoch: 50 [4736/14860 (32%)]\tLoss: 0.021355\n",
      "Train Epoch: 50 [4864/14860 (32%)]\tLoss: 0.020090\n",
      "Train Epoch: 50 [4992/14860 (33%)]\tLoss: 0.014565\n",
      "Train Epoch: 50 [5120/14860 (34%)]\tLoss: 0.018030\n",
      "Train Epoch: 50 [5248/14860 (35%)]\tLoss: 0.017241\n",
      "Train Epoch: 50 [5376/14860 (36%)]\tLoss: 0.023315\n",
      "Train Epoch: 50 [5504/14860 (37%)]\tLoss: 0.020232\n",
      "Train Epoch: 50 [5632/14860 (38%)]\tLoss: 0.022931\n",
      "Train Epoch: 50 [5760/14860 (38%)]\tLoss: 0.017588\n",
      "Train Epoch: 50 [5888/14860 (39%)]\tLoss: 0.015440\n",
      "Train Epoch: 50 [6016/14860 (40%)]\tLoss: 0.018221\n",
      "Train Epoch: 50 [6144/14860 (41%)]\tLoss: 0.020139\n",
      "Train Epoch: 50 [6272/14860 (42%)]\tLoss: 0.018667\n",
      "Train Epoch: 50 [6400/14860 (43%)]\tLoss: 0.018826\n",
      "Train Epoch: 50 [6528/14860 (44%)]\tLoss: 0.023409\n",
      "Train Epoch: 50 [6656/14860 (44%)]\tLoss: 0.017348\n",
      "Train Epoch: 50 [6784/14860 (45%)]\tLoss: 0.014241\n",
      "Train Epoch: 50 [6912/14860 (46%)]\tLoss: 0.020151\n",
      "Train Epoch: 50 [7040/14860 (47%)]\tLoss: 0.022463\n",
      "Train Epoch: 50 [7168/14860 (48%)]\tLoss: 0.023880\n",
      "Train Epoch: 50 [7296/14860 (49%)]\tLoss: 0.019161\n",
      "Train Epoch: 50 [7424/14860 (50%)]\tLoss: 0.014266\n",
      "Train Epoch: 50 [7552/14860 (50%)]\tLoss: 0.023270\n",
      "Train Epoch: 50 [7680/14860 (51%)]\tLoss: 0.025577\n",
      "Train Epoch: 50 [7808/14860 (52%)]\tLoss: 0.021966\n",
      "Train Epoch: 50 [7936/14860 (53%)]\tLoss: 0.014831\n",
      "Train Epoch: 50 [8064/14860 (54%)]\tLoss: 0.017680\n",
      "Train Epoch: 50 [8192/14860 (55%)]\tLoss: 0.023541\n",
      "Train Epoch: 50 [8320/14860 (56%)]\tLoss: 0.012163\n",
      "Train Epoch: 50 [8448/14860 (56%)]\tLoss: 0.013605\n",
      "Train Epoch: 50 [8576/14860 (57%)]\tLoss: 0.017552\n",
      "Train Epoch: 50 [8704/14860 (58%)]\tLoss: 0.013420\n",
      "Train Epoch: 50 [8832/14860 (59%)]\tLoss: 0.015872\n",
      "Train Epoch: 50 [8960/14860 (60%)]\tLoss: 0.022031\n",
      "Train Epoch: 50 [9088/14860 (61%)]\tLoss: 0.021051\n",
      "Train Epoch: 50 [9216/14860 (62%)]\tLoss: 0.014617\n",
      "Train Epoch: 50 [9344/14860 (62%)]\tLoss: 0.022305\n",
      "Train Epoch: 50 [9472/14860 (63%)]\tLoss: 0.018194\n",
      "Train Epoch: 50 [9600/14860 (64%)]\tLoss: 0.025839\n",
      "Train Epoch: 50 [9728/14860 (65%)]\tLoss: 0.018520\n",
      "Train Epoch: 50 [9856/14860 (66%)]\tLoss: 0.018423\n",
      "Train Epoch: 50 [9984/14860 (67%)]\tLoss: 0.016032\n",
      "Train Epoch: 50 [10112/14860 (68%)]\tLoss: 0.013197\n",
      "Train Epoch: 50 [10240/14860 (68%)]\tLoss: 0.020913\n",
      "Train Epoch: 50 [10368/14860 (69%)]\tLoss: 0.015628\n",
      "Train Epoch: 50 [10496/14860 (70%)]\tLoss: 0.017617\n",
      "Train Epoch: 50 [10624/14860 (71%)]\tLoss: 0.024043\n",
      "Train Epoch: 50 [10752/14860 (72%)]\tLoss: 0.015700\n",
      "Train Epoch: 50 [10880/14860 (73%)]\tLoss: 0.015640\n",
      "Train Epoch: 50 [11008/14860 (74%)]\tLoss: 0.018408\n",
      "Train Epoch: 50 [11136/14860 (74%)]\tLoss: 0.014698\n",
      "Train Epoch: 50 [11264/14860 (75%)]\tLoss: 0.019875\n",
      "Train Epoch: 50 [11392/14860 (76%)]\tLoss: 0.013692\n",
      "Train Epoch: 50 [11520/14860 (77%)]\tLoss: 0.021363\n",
      "Train Epoch: 50 [11648/14860 (78%)]\tLoss: 0.016402\n",
      "Train Epoch: 50 [11776/14860 (79%)]\tLoss: 0.018160\n",
      "Train Epoch: 50 [11904/14860 (79%)]\tLoss: 0.018926\n",
      "Train Epoch: 50 [12032/14860 (80%)]\tLoss: 0.017335\n",
      "Train Epoch: 50 [12160/14860 (81%)]\tLoss: 0.013920\n",
      "Train Epoch: 50 [12288/14860 (82%)]\tLoss: 0.017749\n",
      "Train Epoch: 50 [12416/14860 (83%)]\tLoss: 0.016729\n",
      "Train Epoch: 50 [12544/14860 (84%)]\tLoss: 0.014522\n",
      "Train Epoch: 50 [12672/14860 (85%)]\tLoss: 0.022531\n",
      "Train Epoch: 50 [12800/14860 (85%)]\tLoss: 0.021466\n",
      "Train Epoch: 50 [12928/14860 (86%)]\tLoss: 0.013161\n",
      "Train Epoch: 50 [13056/14860 (87%)]\tLoss: 0.015969\n",
      "Train Epoch: 50 [13184/14860 (88%)]\tLoss: 0.019368\n",
      "Train Epoch: 50 [13312/14860 (89%)]\tLoss: 0.020554\n",
      "Train Epoch: 50 [13440/14860 (90%)]\tLoss: 0.019928\n",
      "Train Epoch: 50 [13568/14860 (91%)]\tLoss: 0.014608\n",
      "Train Epoch: 50 [13696/14860 (91%)]\tLoss: 0.029417\n",
      "Train Epoch: 50 [13824/14860 (92%)]\tLoss: 0.018542\n",
      "Train Epoch: 50 [13952/14860 (93%)]\tLoss: 0.033193\n",
      "Train Epoch: 50 [14080/14860 (94%)]\tLoss: 0.019197\n",
      "Train Epoch: 50 [14208/14860 (95%)]\tLoss: 0.024913\n",
      "Train Epoch: 50 [14336/14860 (96%)]\tLoss: 0.012962\n",
      "Train Epoch: 50 [14464/14860 (97%)]\tLoss: 0.024827\n",
      "Train Epoch: 50 [14592/14860 (97%)]\tLoss: 0.018472\n",
      "Train Epoch: 50 [14720/14860 (98%)]\tLoss: 0.021892\n",
      "Train Epoch: 50 [1392/14860 (99%)]\tLoss: 0.006813\n",
      "epoch 50 training loss: 0.019313877762860466\n",
      "epoch 50 validation loss: 0.024501292526577633\n",
      "Train Epoch: 51 [0/14860 (0%)]\tLoss: 0.017280\n",
      "Train Epoch: 51 [128/14860 (1%)]\tLoss: 0.020886\n",
      "Train Epoch: 51 [256/14860 (2%)]\tLoss: 0.015267\n",
      "Train Epoch: 51 [384/14860 (3%)]\tLoss: 0.016315\n",
      "Train Epoch: 51 [512/14860 (3%)]\tLoss: 0.025119\n",
      "Train Epoch: 51 [640/14860 (4%)]\tLoss: 0.016807\n",
      "Train Epoch: 51 [768/14860 (5%)]\tLoss: 0.018579\n",
      "Train Epoch: 51 [896/14860 (6%)]\tLoss: 0.016832\n",
      "Train Epoch: 51 [1024/14860 (7%)]\tLoss: 0.019660\n",
      "Train Epoch: 51 [1152/14860 (8%)]\tLoss: 0.023143\n",
      "Train Epoch: 51 [1280/14860 (9%)]\tLoss: 0.015557\n",
      "Train Epoch: 51 [1408/14860 (9%)]\tLoss: 0.019326\n",
      "Train Epoch: 51 [1536/14860 (10%)]\tLoss: 0.013912\n",
      "Train Epoch: 51 [1664/14860 (11%)]\tLoss: 0.021576\n",
      "Train Epoch: 51 [1792/14860 (12%)]\tLoss: 0.014523\n",
      "Train Epoch: 51 [1920/14860 (13%)]\tLoss: 0.023577\n",
      "Train Epoch: 51 [2048/14860 (14%)]\tLoss: 0.021628\n",
      "Train Epoch: 51 [2176/14860 (15%)]\tLoss: 0.012967\n",
      "Train Epoch: 51 [2304/14860 (15%)]\tLoss: 0.019183\n",
      "Train Epoch: 51 [2432/14860 (16%)]\tLoss: 0.026087\n",
      "Train Epoch: 51 [2560/14860 (17%)]\tLoss: 0.021047\n",
      "Train Epoch: 51 [2688/14860 (18%)]\tLoss: 0.019647\n",
      "Train Epoch: 51 [2816/14860 (19%)]\tLoss: 0.017059\n",
      "Train Epoch: 51 [2944/14860 (20%)]\tLoss: 0.027744\n",
      "Train Epoch: 51 [3072/14860 (21%)]\tLoss: 0.020119\n",
      "Train Epoch: 51 [3200/14860 (21%)]\tLoss: 0.028601\n",
      "Train Epoch: 51 [3328/14860 (22%)]\tLoss: 0.019552\n",
      "Train Epoch: 51 [3456/14860 (23%)]\tLoss: 0.029922\n",
      "Train Epoch: 51 [3584/14860 (24%)]\tLoss: 0.020846\n",
      "Train Epoch: 51 [3712/14860 (25%)]\tLoss: 0.022610\n",
      "Train Epoch: 51 [3840/14860 (26%)]\tLoss: 0.025341\n",
      "Train Epoch: 51 [3968/14860 (26%)]\tLoss: 0.032081\n",
      "Train Epoch: 51 [4096/14860 (27%)]\tLoss: 0.024187\n",
      "Train Epoch: 51 [4224/14860 (28%)]\tLoss: 0.029639\n",
      "Train Epoch: 51 [4352/14860 (29%)]\tLoss: 0.025127\n",
      "Train Epoch: 51 [4480/14860 (30%)]\tLoss: 0.016659\n",
      "Train Epoch: 51 [4608/14860 (31%)]\tLoss: 0.034593\n",
      "Train Epoch: 51 [4736/14860 (32%)]\tLoss: 0.025708\n",
      "Train Epoch: 51 [4864/14860 (32%)]\tLoss: 0.022352\n",
      "Train Epoch: 51 [4992/14860 (33%)]\tLoss: 0.023525\n",
      "Train Epoch: 51 [5120/14860 (34%)]\tLoss: 0.024248\n",
      "Train Epoch: 51 [5248/14860 (35%)]\tLoss: 0.019846\n",
      "Train Epoch: 51 [5376/14860 (36%)]\tLoss: 0.019394\n",
      "Train Epoch: 51 [5504/14860 (37%)]\tLoss: 0.019877\n",
      "Train Epoch: 51 [5632/14860 (38%)]\tLoss: 0.012200\n",
      "Train Epoch: 51 [5760/14860 (38%)]\tLoss: 0.028362\n",
      "Train Epoch: 51 [5888/14860 (39%)]\tLoss: 0.016411\n",
      "Train Epoch: 51 [6016/14860 (40%)]\tLoss: 0.017732\n",
      "Train Epoch: 51 [6144/14860 (41%)]\tLoss: 0.027710\n",
      "Train Epoch: 51 [6272/14860 (42%)]\tLoss: 0.012854\n",
      "Train Epoch: 51 [6400/14860 (43%)]\tLoss: 0.020769\n",
      "Train Epoch: 51 [6528/14860 (44%)]\tLoss: 0.019674\n",
      "Train Epoch: 51 [6656/14860 (44%)]\tLoss: 0.023966\n",
      "Train Epoch: 51 [6784/14860 (45%)]\tLoss: 0.024984\n",
      "Train Epoch: 51 [6912/14860 (46%)]\tLoss: 0.016693\n",
      "Train Epoch: 51 [7040/14860 (47%)]\tLoss: 0.020966\n",
      "Train Epoch: 51 [7168/14860 (48%)]\tLoss: 0.020971\n",
      "Train Epoch: 51 [7296/14860 (49%)]\tLoss: 0.021081\n",
      "Train Epoch: 51 [7424/14860 (50%)]\tLoss: 0.014193\n",
      "Train Epoch: 51 [7552/14860 (50%)]\tLoss: 0.014224\n",
      "Train Epoch: 51 [7680/14860 (51%)]\tLoss: 0.020317\n",
      "Train Epoch: 51 [7808/14860 (52%)]\tLoss: 0.024810\n",
      "Train Epoch: 51 [7936/14860 (53%)]\tLoss: 0.019250\n",
      "Train Epoch: 51 [8064/14860 (54%)]\tLoss: 0.018636\n",
      "Train Epoch: 51 [8192/14860 (55%)]\tLoss: 0.015047\n",
      "Train Epoch: 51 [8320/14860 (56%)]\tLoss: 0.019689\n",
      "Train Epoch: 51 [8448/14860 (56%)]\tLoss: 0.020374\n",
      "Train Epoch: 51 [8576/14860 (57%)]\tLoss: 0.011672\n",
      "Train Epoch: 51 [8704/14860 (58%)]\tLoss: 0.017251\n",
      "Train Epoch: 51 [8832/14860 (59%)]\tLoss: 0.019183\n",
      "Train Epoch: 51 [8960/14860 (60%)]\tLoss: 0.013942\n",
      "Train Epoch: 51 [9088/14860 (61%)]\tLoss: 0.015325\n",
      "Train Epoch: 51 [9216/14860 (62%)]\tLoss: 0.021496\n",
      "Train Epoch: 51 [9344/14860 (62%)]\tLoss: 0.019114\n",
      "Train Epoch: 51 [9472/14860 (63%)]\tLoss: 0.021800\n",
      "Train Epoch: 51 [9600/14860 (64%)]\tLoss: 0.017360\n",
      "Train Epoch: 51 [9728/14860 (65%)]\tLoss: 0.020360\n",
      "Train Epoch: 51 [9856/14860 (66%)]\tLoss: 0.018885\n",
      "Train Epoch: 51 [9984/14860 (67%)]\tLoss: 0.020889\n",
      "Train Epoch: 51 [10112/14860 (68%)]\tLoss: 0.018945\n",
      "Train Epoch: 51 [10240/14860 (68%)]\tLoss: 0.014345\n",
      "Train Epoch: 51 [10368/14860 (69%)]\tLoss: 0.013707\n",
      "Train Epoch: 51 [10496/14860 (70%)]\tLoss: 0.022586\n",
      "Train Epoch: 51 [10624/14860 (71%)]\tLoss: 0.017108\n",
      "Train Epoch: 51 [10752/14860 (72%)]\tLoss: 0.018702\n",
      "Train Epoch: 51 [10880/14860 (73%)]\tLoss: 0.016473\n",
      "Train Epoch: 51 [11008/14860 (74%)]\tLoss: 0.014722\n",
      "Train Epoch: 51 [11136/14860 (74%)]\tLoss: 0.015993\n",
      "Train Epoch: 51 [11264/14860 (75%)]\tLoss: 0.019149\n",
      "Train Epoch: 51 [11392/14860 (76%)]\tLoss: 0.019573\n",
      "Train Epoch: 51 [11520/14860 (77%)]\tLoss: 0.016793\n",
      "Train Epoch: 51 [11648/14860 (78%)]\tLoss: 0.016351\n",
      "Train Epoch: 51 [11776/14860 (79%)]\tLoss: 0.018072\n",
      "Train Epoch: 51 [11904/14860 (79%)]\tLoss: 0.014174\n",
      "Train Epoch: 51 [12032/14860 (80%)]\tLoss: 0.021735\n",
      "Train Epoch: 51 [12160/14860 (81%)]\tLoss: 0.023287\n",
      "Train Epoch: 51 [12288/14860 (82%)]\tLoss: 0.020366\n",
      "Train Epoch: 51 [12416/14860 (83%)]\tLoss: 0.019205\n",
      "Train Epoch: 51 [12544/14860 (84%)]\tLoss: 0.010813\n",
      "Train Epoch: 51 [12672/14860 (85%)]\tLoss: 0.029992\n",
      "Train Epoch: 51 [12800/14860 (85%)]\tLoss: 0.021059\n",
      "Train Epoch: 51 [12928/14860 (86%)]\tLoss: 0.034077\n",
      "Train Epoch: 51 [13056/14860 (87%)]\tLoss: 0.020217\n",
      "Train Epoch: 51 [13184/14860 (88%)]\tLoss: 0.020652\n",
      "Train Epoch: 51 [13312/14860 (89%)]\tLoss: 0.027878\n",
      "Train Epoch: 51 [13440/14860 (90%)]\tLoss: 0.024953\n",
      "Train Epoch: 51 [13568/14860 (91%)]\tLoss: 0.017205\n",
      "Train Epoch: 51 [13696/14860 (91%)]\tLoss: 0.022529\n",
      "Train Epoch: 51 [13824/14860 (92%)]\tLoss: 0.021275\n",
      "Train Epoch: 51 [13952/14860 (93%)]\tLoss: 0.021347\n",
      "Train Epoch: 51 [14080/14860 (94%)]\tLoss: 0.014038\n",
      "Train Epoch: 51 [14208/14860 (95%)]\tLoss: 0.026085\n",
      "Train Epoch: 51 [14336/14860 (96%)]\tLoss: 0.017663\n",
      "Train Epoch: 51 [14464/14860 (97%)]\tLoss: 0.021181\n",
      "Train Epoch: 51 [14592/14860 (97%)]\tLoss: 0.018883\n",
      "Train Epoch: 51 [14720/14860 (98%)]\tLoss: 0.019592\n",
      "Train Epoch: 51 [1392/14860 (99%)]\tLoss: 0.050002\n",
      "epoch 51 training loss: 0.02048604063785229\n",
      "epoch 51 validation loss: 0.02022372507298541\n",
      "Train Epoch: 52 [0/14860 (0%)]\tLoss: 0.019287\n",
      "Train Epoch: 52 [128/14860 (1%)]\tLoss: 0.016979\n",
      "Train Epoch: 52 [256/14860 (2%)]\tLoss: 0.015646\n",
      "Train Epoch: 52 [384/14860 (3%)]\tLoss: 0.019459\n",
      "Train Epoch: 52 [512/14860 (3%)]\tLoss: 0.019319\n",
      "Train Epoch: 52 [640/14860 (4%)]\tLoss: 0.018360\n",
      "Train Epoch: 52 [768/14860 (5%)]\tLoss: 0.018715\n",
      "Train Epoch: 52 [896/14860 (6%)]\tLoss: 0.017827\n",
      "Train Epoch: 52 [1024/14860 (7%)]\tLoss: 0.019865\n",
      "Train Epoch: 52 [1152/14860 (8%)]\tLoss: 0.019757\n",
      "Train Epoch: 52 [1280/14860 (9%)]\tLoss: 0.022432\n",
      "Train Epoch: 52 [1408/14860 (9%)]\tLoss: 0.020892\n",
      "Train Epoch: 52 [1536/14860 (10%)]\tLoss: 0.024344\n",
      "Train Epoch: 52 [1664/14860 (11%)]\tLoss: 0.028554\n",
      "Train Epoch: 52 [1792/14860 (12%)]\tLoss: 0.015466\n",
      "Train Epoch: 52 [1920/14860 (13%)]\tLoss: 0.023811\n",
      "Train Epoch: 52 [2048/14860 (14%)]\tLoss: 0.020180\n",
      "Train Epoch: 52 [2176/14860 (15%)]\tLoss: 0.022341\n",
      "Train Epoch: 52 [2304/14860 (15%)]\tLoss: 0.017690\n",
      "Train Epoch: 52 [2432/14860 (16%)]\tLoss: 0.016619\n",
      "Train Epoch: 52 [2560/14860 (17%)]\tLoss: 0.016964\n",
      "Train Epoch: 52 [2688/14860 (18%)]\tLoss: 0.015148\n",
      "Train Epoch: 52 [2816/14860 (19%)]\tLoss: 0.022946\n",
      "Train Epoch: 52 [2944/14860 (20%)]\tLoss: 0.021192\n",
      "Train Epoch: 52 [3072/14860 (21%)]\tLoss: 0.018472\n",
      "Train Epoch: 52 [3200/14860 (21%)]\tLoss: 0.016344\n",
      "Train Epoch: 52 [3328/14860 (22%)]\tLoss: 0.016970\n",
      "Train Epoch: 52 [3456/14860 (23%)]\tLoss: 0.015042\n",
      "Train Epoch: 52 [3584/14860 (24%)]\tLoss: 0.020549\n",
      "Train Epoch: 52 [3712/14860 (25%)]\tLoss: 0.021285\n",
      "Train Epoch: 52 [3840/14860 (26%)]\tLoss: 0.017644\n",
      "Train Epoch: 52 [3968/14860 (26%)]\tLoss: 0.017221\n",
      "Train Epoch: 52 [4096/14860 (27%)]\tLoss: 0.022188\n",
      "Train Epoch: 52 [4224/14860 (28%)]\tLoss: 0.021623\n",
      "Train Epoch: 52 [4352/14860 (29%)]\tLoss: 0.020393\n",
      "Train Epoch: 52 [4480/14860 (30%)]\tLoss: 0.017223\n",
      "Train Epoch: 52 [4608/14860 (31%)]\tLoss: 0.020916\n",
      "Train Epoch: 52 [4736/14860 (32%)]\tLoss: 0.020982\n",
      "Train Epoch: 52 [4864/14860 (32%)]\tLoss: 0.025648\n",
      "Train Epoch: 52 [4992/14860 (33%)]\tLoss: 0.021515\n",
      "Train Epoch: 52 [5120/14860 (34%)]\tLoss: 0.018169\n",
      "Train Epoch: 52 [5248/14860 (35%)]\tLoss: 0.021115\n",
      "Train Epoch: 52 [5376/14860 (36%)]\tLoss: 0.015826\n",
      "Train Epoch: 52 [5504/14860 (37%)]\tLoss: 0.017684\n",
      "Train Epoch: 52 [5632/14860 (38%)]\tLoss: 0.015473\n",
      "Train Epoch: 52 [5760/14860 (38%)]\tLoss: 0.021003\n",
      "Train Epoch: 52 [5888/14860 (39%)]\tLoss: 0.024080\n",
      "Train Epoch: 52 [6016/14860 (40%)]\tLoss: 0.017412\n",
      "Train Epoch: 52 [6144/14860 (41%)]\tLoss: 0.018418\n",
      "Train Epoch: 52 [6272/14860 (42%)]\tLoss: 0.021840\n",
      "Train Epoch: 52 [6400/14860 (43%)]\tLoss: 0.018473\n",
      "Train Epoch: 52 [6528/14860 (44%)]\tLoss: 0.027317\n",
      "Train Epoch: 52 [6656/14860 (44%)]\tLoss: 0.021743\n",
      "Train Epoch: 52 [6784/14860 (45%)]\tLoss: 0.014030\n",
      "Train Epoch: 52 [6912/14860 (46%)]\tLoss: 0.016488\n",
      "Train Epoch: 52 [7040/14860 (47%)]\tLoss: 0.023346\n",
      "Train Epoch: 52 [7168/14860 (48%)]\tLoss: 0.023443\n",
      "Train Epoch: 52 [7296/14860 (49%)]\tLoss: 0.020004\n",
      "Train Epoch: 52 [7424/14860 (50%)]\tLoss: 0.020320\n",
      "Train Epoch: 52 [7552/14860 (50%)]\tLoss: 0.015939\n",
      "Train Epoch: 52 [7680/14860 (51%)]\tLoss: 0.019739\n",
      "Train Epoch: 52 [7808/14860 (52%)]\tLoss: 0.019626\n",
      "Train Epoch: 52 [7936/14860 (53%)]\tLoss: 0.016898\n",
      "Train Epoch: 52 [8064/14860 (54%)]\tLoss: 0.017065\n",
      "Train Epoch: 52 [8192/14860 (55%)]\tLoss: 0.015004\n",
      "Train Epoch: 52 [8320/14860 (56%)]\tLoss: 0.029993\n",
      "Train Epoch: 52 [8448/14860 (56%)]\tLoss: 0.019505\n",
      "Train Epoch: 52 [8576/14860 (57%)]\tLoss: 0.014104\n",
      "Train Epoch: 52 [8704/14860 (58%)]\tLoss: 0.012582\n",
      "Train Epoch: 52 [8832/14860 (59%)]\tLoss: 0.029182\n",
      "Train Epoch: 52 [8960/14860 (60%)]\tLoss: 0.018496\n",
      "Train Epoch: 52 [9088/14860 (61%)]\tLoss: 0.020020\n",
      "Train Epoch: 52 [9216/14860 (62%)]\tLoss: 0.017550\n",
      "Train Epoch: 52 [9344/14860 (62%)]\tLoss: 0.020045\n",
      "Train Epoch: 52 [9472/14860 (63%)]\tLoss: 0.025070\n",
      "Train Epoch: 52 [9600/14860 (64%)]\tLoss: 0.013815\n",
      "Train Epoch: 52 [9728/14860 (65%)]\tLoss: 0.019284\n",
      "Train Epoch: 52 [9856/14860 (66%)]\tLoss: 0.017425\n",
      "Train Epoch: 52 [9984/14860 (67%)]\tLoss: 0.017031\n",
      "Train Epoch: 52 [10112/14860 (68%)]\tLoss: 0.017962\n",
      "Train Epoch: 52 [10240/14860 (68%)]\tLoss: 0.021541\n",
      "Train Epoch: 52 [10368/14860 (69%)]\tLoss: 0.015221\n",
      "Train Epoch: 52 [10496/14860 (70%)]\tLoss: 0.025139\n",
      "Train Epoch: 52 [10624/14860 (71%)]\tLoss: 0.015234\n",
      "Train Epoch: 52 [10752/14860 (72%)]\tLoss: 0.018965\n",
      "Train Epoch: 52 [10880/14860 (73%)]\tLoss: 0.022023\n",
      "Train Epoch: 52 [11008/14860 (74%)]\tLoss: 0.020700\n",
      "Train Epoch: 52 [11136/14860 (74%)]\tLoss: 0.019270\n",
      "Train Epoch: 52 [11264/14860 (75%)]\tLoss: 0.016813\n",
      "Train Epoch: 52 [11392/14860 (76%)]\tLoss: 0.019356\n",
      "Train Epoch: 52 [11520/14860 (77%)]\tLoss: 0.019874\n",
      "Train Epoch: 52 [11648/14860 (78%)]\tLoss: 0.021240\n",
      "Train Epoch: 52 [11776/14860 (79%)]\tLoss: 0.016701\n",
      "Train Epoch: 52 [11904/14860 (79%)]\tLoss: 0.014409\n",
      "Train Epoch: 52 [12032/14860 (80%)]\tLoss: 0.019115\n",
      "Train Epoch: 52 [12160/14860 (81%)]\tLoss: 0.024067\n",
      "Train Epoch: 52 [12288/14860 (82%)]\tLoss: 0.021904\n",
      "Train Epoch: 52 [12416/14860 (83%)]\tLoss: 0.021534\n",
      "Train Epoch: 52 [12544/14860 (84%)]\tLoss: 0.020071\n",
      "Train Epoch: 52 [12672/14860 (85%)]\tLoss: 0.012671\n",
      "Train Epoch: 52 [12800/14860 (85%)]\tLoss: 0.013987\n",
      "Train Epoch: 52 [12928/14860 (86%)]\tLoss: 0.014985\n",
      "Train Epoch: 52 [13056/14860 (87%)]\tLoss: 0.015619\n",
      "Train Epoch: 52 [13184/14860 (88%)]\tLoss: 0.017839\n",
      "Train Epoch: 52 [13312/14860 (89%)]\tLoss: 0.013348\n",
      "Train Epoch: 52 [13440/14860 (90%)]\tLoss: 0.015908\n",
      "Train Epoch: 52 [13568/14860 (91%)]\tLoss: 0.025054\n",
      "Train Epoch: 52 [13696/14860 (91%)]\tLoss: 0.019419\n",
      "Train Epoch: 52 [13824/14860 (92%)]\tLoss: 0.021409\n",
      "Train Epoch: 52 [13952/14860 (93%)]\tLoss: 0.016641\n",
      "Train Epoch: 52 [14080/14860 (94%)]\tLoss: 0.026422\n",
      "Train Epoch: 52 [14208/14860 (95%)]\tLoss: 0.017272\n",
      "Train Epoch: 52 [14336/14860 (96%)]\tLoss: 0.017815\n",
      "Train Epoch: 52 [14464/14860 (97%)]\tLoss: 0.019555\n",
      "Train Epoch: 52 [14592/14860 (97%)]\tLoss: 0.017815\n",
      "Train Epoch: 52 [14720/14860 (98%)]\tLoss: 0.025022\n",
      "Train Epoch: 52 [1392/14860 (99%)]\tLoss: 0.030450\n",
      "epoch 52 training loss: 0.019442151157328717\n",
      "epoch 52 validation loss: 0.025628994221260127\n",
      "Train Epoch: 53 [0/14860 (0%)]\tLoss: 0.021676\n",
      "Train Epoch: 53 [128/14860 (1%)]\tLoss: 0.025904\n",
      "Train Epoch: 53 [256/14860 (2%)]\tLoss: 0.019520\n",
      "Train Epoch: 53 [384/14860 (3%)]\tLoss: 0.015257\n",
      "Train Epoch: 53 [512/14860 (3%)]\tLoss: 0.027100\n",
      "Train Epoch: 53 [640/14860 (4%)]\tLoss: 0.019591\n",
      "Train Epoch: 53 [768/14860 (5%)]\tLoss: 0.024985\n",
      "Train Epoch: 53 [896/14860 (6%)]\tLoss: 0.023318\n",
      "Train Epoch: 53 [1024/14860 (7%)]\tLoss: 0.018965\n",
      "Train Epoch: 53 [1152/14860 (8%)]\tLoss: 0.023958\n",
      "Train Epoch: 53 [1280/14860 (9%)]\tLoss: 0.025636\n",
      "Train Epoch: 53 [1408/14860 (9%)]\tLoss: 0.025265\n",
      "Train Epoch: 53 [1536/14860 (10%)]\tLoss: 0.022185\n",
      "Train Epoch: 53 [1664/14860 (11%)]\tLoss: 0.021486\n",
      "Train Epoch: 53 [1792/14860 (12%)]\tLoss: 0.026962\n",
      "Train Epoch: 53 [1920/14860 (13%)]\tLoss: 0.032445\n",
      "Train Epoch: 53 [2048/14860 (14%)]\tLoss: 0.017493\n",
      "Train Epoch: 53 [2176/14860 (15%)]\tLoss: 0.021693\n",
      "Train Epoch: 53 [2304/14860 (15%)]\tLoss: 0.018580\n",
      "Train Epoch: 53 [2432/14860 (16%)]\tLoss: 0.017735\n",
      "Train Epoch: 53 [2560/14860 (17%)]\tLoss: 0.021798\n",
      "Train Epoch: 53 [2688/14860 (18%)]\tLoss: 0.020658\n",
      "Train Epoch: 53 [2816/14860 (19%)]\tLoss: 0.017994\n",
      "Train Epoch: 53 [2944/14860 (20%)]\tLoss: 0.018499\n",
      "Train Epoch: 53 [3072/14860 (21%)]\tLoss: 0.020713\n",
      "Train Epoch: 53 [3200/14860 (21%)]\tLoss: 0.020388\n",
      "Train Epoch: 53 [3328/14860 (22%)]\tLoss: 0.020272\n",
      "Train Epoch: 53 [3456/14860 (23%)]\tLoss: 0.022313\n",
      "Train Epoch: 53 [3584/14860 (24%)]\tLoss: 0.022079\n",
      "Train Epoch: 53 [3712/14860 (25%)]\tLoss: 0.015577\n",
      "Train Epoch: 53 [3840/14860 (26%)]\tLoss: 0.014828\n",
      "Train Epoch: 53 [3968/14860 (26%)]\tLoss: 0.017462\n",
      "Train Epoch: 53 [4096/14860 (27%)]\tLoss: 0.017468\n",
      "Train Epoch: 53 [4224/14860 (28%)]\tLoss: 0.023987\n",
      "Train Epoch: 53 [4352/14860 (29%)]\tLoss: 0.016976\n",
      "Train Epoch: 53 [4480/14860 (30%)]\tLoss: 0.017691\n",
      "Train Epoch: 53 [4608/14860 (31%)]\tLoss: 0.018742\n",
      "Train Epoch: 53 [4736/14860 (32%)]\tLoss: 0.018813\n",
      "Train Epoch: 53 [4864/14860 (32%)]\tLoss: 0.017182\n",
      "Train Epoch: 53 [4992/14860 (33%)]\tLoss: 0.021095\n",
      "Train Epoch: 53 [5120/14860 (34%)]\tLoss: 0.018688\n",
      "Train Epoch: 53 [5248/14860 (35%)]\tLoss: 0.025446\n",
      "Train Epoch: 53 [5376/14860 (36%)]\tLoss: 0.011920\n",
      "Train Epoch: 53 [5504/14860 (37%)]\tLoss: 0.017790\n",
      "Train Epoch: 53 [5632/14860 (38%)]\tLoss: 0.019893\n",
      "Train Epoch: 53 [5760/14860 (38%)]\tLoss: 0.019068\n",
      "Train Epoch: 53 [5888/14860 (39%)]\tLoss: 0.018993\n",
      "Train Epoch: 53 [6016/14860 (40%)]\tLoss: 0.014702\n",
      "Train Epoch: 53 [6144/14860 (41%)]\tLoss: 0.014079\n",
      "Train Epoch: 53 [6272/14860 (42%)]\tLoss: 0.014121\n",
      "Train Epoch: 53 [6400/14860 (43%)]\tLoss: 0.019667\n",
      "Train Epoch: 53 [6528/14860 (44%)]\tLoss: 0.015853\n",
      "Train Epoch: 53 [6656/14860 (44%)]\tLoss: 0.027183\n",
      "Train Epoch: 53 [6784/14860 (45%)]\tLoss: 0.016176\n",
      "Train Epoch: 53 [6912/14860 (46%)]\tLoss: 0.020194\n",
      "Train Epoch: 53 [7040/14860 (47%)]\tLoss: 0.025713\n",
      "Train Epoch: 53 [7168/14860 (48%)]\tLoss: 0.016266\n",
      "Train Epoch: 53 [7296/14860 (49%)]\tLoss: 0.019045\n",
      "Train Epoch: 53 [7424/14860 (50%)]\tLoss: 0.017318\n",
      "Train Epoch: 53 [7552/14860 (50%)]\tLoss: 0.017218\n",
      "Train Epoch: 53 [7680/14860 (51%)]\tLoss: 0.019994\n",
      "Train Epoch: 53 [7808/14860 (52%)]\tLoss: 0.018551\n",
      "Train Epoch: 53 [7936/14860 (53%)]\tLoss: 0.016285\n",
      "Train Epoch: 53 [8064/14860 (54%)]\tLoss: 0.015542\n",
      "Train Epoch: 53 [8192/14860 (55%)]\tLoss: 0.022170\n",
      "Train Epoch: 53 [8320/14860 (56%)]\tLoss: 0.024536\n",
      "Train Epoch: 53 [8448/14860 (56%)]\tLoss: 0.016768\n",
      "Train Epoch: 53 [8576/14860 (57%)]\tLoss: 0.018635\n",
      "Train Epoch: 53 [8704/14860 (58%)]\tLoss: 0.014624\n",
      "Train Epoch: 53 [8832/14860 (59%)]\tLoss: 0.018793\n",
      "Train Epoch: 53 [8960/14860 (60%)]\tLoss: 0.020101\n",
      "Train Epoch: 53 [9088/14860 (61%)]\tLoss: 0.020582\n",
      "Train Epoch: 53 [9216/14860 (62%)]\tLoss: 0.018683\n",
      "Train Epoch: 53 [9344/14860 (62%)]\tLoss: 0.015244\n",
      "Train Epoch: 53 [9472/14860 (63%)]\tLoss: 0.017975\n",
      "Train Epoch: 53 [9600/14860 (64%)]\tLoss: 0.014386\n",
      "Train Epoch: 53 [9728/14860 (65%)]\tLoss: 0.027739\n",
      "Train Epoch: 53 [9856/14860 (66%)]\tLoss: 0.020178\n",
      "Train Epoch: 53 [9984/14860 (67%)]\tLoss: 0.011976\n",
      "Train Epoch: 53 [10112/14860 (68%)]\tLoss: 0.019644\n",
      "Train Epoch: 53 [10240/14860 (68%)]\tLoss: 0.018327\n",
      "Train Epoch: 53 [10368/14860 (69%)]\tLoss: 0.018074\n",
      "Train Epoch: 53 [10496/14860 (70%)]\tLoss: 0.019986\n",
      "Train Epoch: 53 [10624/14860 (71%)]\tLoss: 0.019249\n",
      "Train Epoch: 53 [10752/14860 (72%)]\tLoss: 0.015333\n",
      "Train Epoch: 53 [10880/14860 (73%)]\tLoss: 0.012860\n",
      "Train Epoch: 53 [11008/14860 (74%)]\tLoss: 0.021534\n",
      "Train Epoch: 53 [11136/14860 (74%)]\tLoss: 0.013614\n",
      "Train Epoch: 53 [11264/14860 (75%)]\tLoss: 0.016725\n",
      "Train Epoch: 53 [11392/14860 (76%)]\tLoss: 0.013207\n",
      "Train Epoch: 53 [11520/14860 (77%)]\tLoss: 0.011089\n",
      "Train Epoch: 53 [11648/14860 (78%)]\tLoss: 0.016937\n",
      "Train Epoch: 53 [11776/14860 (79%)]\tLoss: 0.021387\n",
      "Train Epoch: 53 [11904/14860 (79%)]\tLoss: 0.024016\n",
      "Train Epoch: 53 [12032/14860 (80%)]\tLoss: 0.018187\n",
      "Train Epoch: 53 [12160/14860 (81%)]\tLoss: 0.019826\n",
      "Train Epoch: 53 [12288/14860 (82%)]\tLoss: 0.015473\n",
      "Train Epoch: 53 [12416/14860 (83%)]\tLoss: 0.021510\n",
      "Train Epoch: 53 [12544/14860 (84%)]\tLoss: 0.021595\n",
      "Train Epoch: 53 [12672/14860 (85%)]\tLoss: 0.019068\n",
      "Train Epoch: 53 [12800/14860 (85%)]\tLoss: 0.014545\n",
      "Train Epoch: 53 [12928/14860 (86%)]\tLoss: 0.026265\n",
      "Train Epoch: 53 [13056/14860 (87%)]\tLoss: 0.019394\n",
      "Train Epoch: 53 [13184/14860 (88%)]\tLoss: 0.016362\n",
      "Train Epoch: 53 [13312/14860 (89%)]\tLoss: 0.024919\n",
      "Train Epoch: 53 [13440/14860 (90%)]\tLoss: 0.017026\n",
      "Train Epoch: 53 [13568/14860 (91%)]\tLoss: 0.012231\n",
      "Train Epoch: 53 [13696/14860 (91%)]\tLoss: 0.016658\n",
      "Train Epoch: 53 [13824/14860 (92%)]\tLoss: 0.020981\n",
      "Train Epoch: 53 [13952/14860 (93%)]\tLoss: 0.014710\n",
      "Train Epoch: 53 [14080/14860 (94%)]\tLoss: 0.025663\n",
      "Train Epoch: 53 [14208/14860 (95%)]\tLoss: 0.024688\n",
      "Train Epoch: 53 [14336/14860 (96%)]\tLoss: 0.029858\n",
      "Train Epoch: 53 [14464/14860 (97%)]\tLoss: 0.020832\n",
      "Train Epoch: 53 [14592/14860 (97%)]\tLoss: 0.019866\n",
      "Train Epoch: 53 [14720/14860 (98%)]\tLoss: 0.021618\n",
      "Train Epoch: 53 [1392/14860 (99%)]\tLoss: 0.012766\n",
      "epoch 53 training loss: 0.019422283388164818\n",
      "epoch 53 validation loss: 0.020521831425858467\n",
      "Train Epoch: 54 [0/14860 (0%)]\tLoss: 0.019662\n",
      "Train Epoch: 54 [128/14860 (1%)]\tLoss: 0.031372\n",
      "Train Epoch: 54 [256/14860 (2%)]\tLoss: 0.014901\n",
      "Train Epoch: 54 [384/14860 (3%)]\tLoss: 0.018991\n",
      "Train Epoch: 54 [512/14860 (3%)]\tLoss: 0.026309\n",
      "Train Epoch: 54 [640/14860 (4%)]\tLoss: 0.017618\n",
      "Train Epoch: 54 [768/14860 (5%)]\tLoss: 0.023462\n",
      "Train Epoch: 54 [896/14860 (6%)]\tLoss: 0.026504\n",
      "Train Epoch: 54 [1024/14860 (7%)]\tLoss: 0.018913\n",
      "Train Epoch: 54 [1152/14860 (8%)]\tLoss: 0.020263\n",
      "Train Epoch: 54 [1280/14860 (9%)]\tLoss: 0.013704\n",
      "Train Epoch: 54 [1408/14860 (9%)]\tLoss: 0.017835\n",
      "Train Epoch: 54 [1536/14860 (10%)]\tLoss: 0.016217\n",
      "Train Epoch: 54 [1664/14860 (11%)]\tLoss: 0.021937\n",
      "Train Epoch: 54 [1792/14860 (12%)]\tLoss: 0.033048\n",
      "Train Epoch: 54 [1920/14860 (13%)]\tLoss: 0.016867\n",
      "Train Epoch: 54 [2048/14860 (14%)]\tLoss: 0.016573\n",
      "Train Epoch: 54 [2176/14860 (15%)]\tLoss: 0.016400\n",
      "Train Epoch: 54 [2304/14860 (15%)]\tLoss: 0.014743\n",
      "Train Epoch: 54 [2432/14860 (16%)]\tLoss: 0.020214\n",
      "Train Epoch: 54 [2560/14860 (17%)]\tLoss: 0.026063\n",
      "Train Epoch: 54 [2688/14860 (18%)]\tLoss: 0.016400\n",
      "Train Epoch: 54 [2816/14860 (19%)]\tLoss: 0.027703\n",
      "Train Epoch: 54 [2944/14860 (20%)]\tLoss: 0.015077\n",
      "Train Epoch: 54 [3072/14860 (21%)]\tLoss: 0.024708\n",
      "Train Epoch: 54 [3200/14860 (21%)]\tLoss: 0.014648\n",
      "Train Epoch: 54 [3328/14860 (22%)]\tLoss: 0.014610\n",
      "Train Epoch: 54 [3456/14860 (23%)]\tLoss: 0.017770\n",
      "Train Epoch: 54 [3584/14860 (24%)]\tLoss: 0.016562\n",
      "Train Epoch: 54 [3712/14860 (25%)]\tLoss: 0.013481\n",
      "Train Epoch: 54 [3840/14860 (26%)]\tLoss: 0.014680\n",
      "Train Epoch: 54 [3968/14860 (26%)]\tLoss: 0.019123\n",
      "Train Epoch: 54 [4096/14860 (27%)]\tLoss: 0.018572\n",
      "Train Epoch: 54 [4224/14860 (28%)]\tLoss: 0.016577\n",
      "Train Epoch: 54 [4352/14860 (29%)]\tLoss: 0.021511\n",
      "Train Epoch: 54 [4480/14860 (30%)]\tLoss: 0.019646\n",
      "Train Epoch: 54 [4608/14860 (31%)]\tLoss: 0.020141\n",
      "Train Epoch: 54 [4736/14860 (32%)]\tLoss: 0.022561\n",
      "Train Epoch: 54 [4864/14860 (32%)]\tLoss: 0.020392\n",
      "Train Epoch: 54 [4992/14860 (33%)]\tLoss: 0.019311\n",
      "Train Epoch: 54 [5120/14860 (34%)]\tLoss: 0.022433\n",
      "Train Epoch: 54 [5248/14860 (35%)]\tLoss: 0.017387\n",
      "Train Epoch: 54 [5376/14860 (36%)]\tLoss: 0.020975\n",
      "Train Epoch: 54 [5504/14860 (37%)]\tLoss: 0.019778\n",
      "Train Epoch: 54 [5632/14860 (38%)]\tLoss: 0.023737\n",
      "Train Epoch: 54 [5760/14860 (38%)]\tLoss: 0.016865\n",
      "Train Epoch: 54 [5888/14860 (39%)]\tLoss: 0.017592\n",
      "Train Epoch: 54 [6016/14860 (40%)]\tLoss: 0.020580\n",
      "Train Epoch: 54 [6144/14860 (41%)]\tLoss: 0.014150\n",
      "Train Epoch: 54 [6272/14860 (42%)]\tLoss: 0.015487\n",
      "Train Epoch: 54 [6400/14860 (43%)]\tLoss: 0.027920\n",
      "Train Epoch: 54 [6528/14860 (44%)]\tLoss: 0.016648\n",
      "Train Epoch: 54 [6656/14860 (44%)]\tLoss: 0.022851\n",
      "Train Epoch: 54 [6784/14860 (45%)]\tLoss: 0.018613\n",
      "Train Epoch: 54 [6912/14860 (46%)]\tLoss: 0.012496\n",
      "Train Epoch: 54 [7040/14860 (47%)]\tLoss: 0.028260\n",
      "Train Epoch: 54 [7168/14860 (48%)]\tLoss: 0.021496\n",
      "Train Epoch: 54 [7296/14860 (49%)]\tLoss: 0.019895\n",
      "Train Epoch: 54 [7424/14860 (50%)]\tLoss: 0.030043\n",
      "Train Epoch: 54 [7552/14860 (50%)]\tLoss: 0.021741\n",
      "Train Epoch: 54 [7680/14860 (51%)]\tLoss: 0.021552\n",
      "Train Epoch: 54 [7808/14860 (52%)]\tLoss: 0.034999\n",
      "Train Epoch: 54 [7936/14860 (53%)]\tLoss: 0.016738\n",
      "Train Epoch: 54 [8064/14860 (54%)]\tLoss: 0.022028\n",
      "Train Epoch: 54 [8192/14860 (55%)]\tLoss: 0.020456\n",
      "Train Epoch: 54 [8320/14860 (56%)]\tLoss: 0.016046\n",
      "Train Epoch: 54 [8448/14860 (56%)]\tLoss: 0.022829\n",
      "Train Epoch: 54 [8576/14860 (57%)]\tLoss: 0.022508\n",
      "Train Epoch: 54 [8704/14860 (58%)]\tLoss: 0.021851\n",
      "Train Epoch: 54 [8832/14860 (59%)]\tLoss: 0.022590\n",
      "Train Epoch: 54 [8960/14860 (60%)]\tLoss: 0.018510\n",
      "Train Epoch: 54 [9088/14860 (61%)]\tLoss: 0.014768\n",
      "Train Epoch: 54 [9216/14860 (62%)]\tLoss: 0.017700\n",
      "Train Epoch: 54 [9344/14860 (62%)]\tLoss: 0.014446\n",
      "Train Epoch: 54 [9472/14860 (63%)]\tLoss: 0.015294\n",
      "Train Epoch: 54 [9600/14860 (64%)]\tLoss: 0.017498\n",
      "Train Epoch: 54 [9728/14860 (65%)]\tLoss: 0.022269\n",
      "Train Epoch: 54 [9856/14860 (66%)]\tLoss: 0.014989\n",
      "Train Epoch: 54 [9984/14860 (67%)]\tLoss: 0.015237\n",
      "Train Epoch: 54 [10112/14860 (68%)]\tLoss: 0.016685\n",
      "Train Epoch: 54 [10240/14860 (68%)]\tLoss: 0.023418\n",
      "Train Epoch: 54 [10368/14860 (69%)]\tLoss: 0.015762\n",
      "Train Epoch: 54 [10496/14860 (70%)]\tLoss: 0.018781\n",
      "Train Epoch: 54 [10624/14860 (71%)]\tLoss: 0.020632\n",
      "Train Epoch: 54 [10752/14860 (72%)]\tLoss: 0.014782\n",
      "Train Epoch: 54 [10880/14860 (73%)]\tLoss: 0.024559\n",
      "Train Epoch: 54 [11008/14860 (74%)]\tLoss: 0.020901\n",
      "Train Epoch: 54 [11136/14860 (74%)]\tLoss: 0.018158\n",
      "Train Epoch: 54 [11264/14860 (75%)]\tLoss: 0.019352\n",
      "Train Epoch: 54 [11392/14860 (76%)]\tLoss: 0.016393\n",
      "Train Epoch: 54 [11520/14860 (77%)]\tLoss: 0.022524\n",
      "Train Epoch: 54 [11648/14860 (78%)]\tLoss: 0.017401\n",
      "Train Epoch: 54 [11776/14860 (79%)]\tLoss: 0.020224\n",
      "Train Epoch: 54 [11904/14860 (79%)]\tLoss: 0.015724\n",
      "Train Epoch: 54 [12032/14860 (80%)]\tLoss: 0.025194\n",
      "Train Epoch: 54 [12160/14860 (81%)]\tLoss: 0.017718\n",
      "Train Epoch: 54 [12288/14860 (82%)]\tLoss: 0.016019\n",
      "Train Epoch: 54 [12416/14860 (83%)]\tLoss: 0.028567\n",
      "Train Epoch: 54 [12544/14860 (84%)]\tLoss: 0.017431\n",
      "Train Epoch: 54 [12672/14860 (85%)]\tLoss: 0.018279\n",
      "Train Epoch: 54 [12800/14860 (85%)]\tLoss: 0.014467\n",
      "Train Epoch: 54 [12928/14860 (86%)]\tLoss: 0.024163\n",
      "Train Epoch: 54 [13056/14860 (87%)]\tLoss: 0.022474\n",
      "Train Epoch: 54 [13184/14860 (88%)]\tLoss: 0.012720\n",
      "Train Epoch: 54 [13312/14860 (89%)]\tLoss: 0.017021\n",
      "Train Epoch: 54 [13440/14860 (90%)]\tLoss: 0.018438\n",
      "Train Epoch: 54 [13568/14860 (91%)]\tLoss: 0.016753\n",
      "Train Epoch: 54 [13696/14860 (91%)]\tLoss: 0.019009\n",
      "Train Epoch: 54 [13824/14860 (92%)]\tLoss: 0.016919\n",
      "Train Epoch: 54 [13952/14860 (93%)]\tLoss: 0.016062\n",
      "Train Epoch: 54 [14080/14860 (94%)]\tLoss: 0.029984\n",
      "Train Epoch: 54 [14208/14860 (95%)]\tLoss: 0.023576\n",
      "Train Epoch: 54 [14336/14860 (96%)]\tLoss: 0.017465\n",
      "Train Epoch: 54 [14464/14860 (97%)]\tLoss: 0.027012\n",
      "Train Epoch: 54 [14592/14860 (97%)]\tLoss: 0.023546\n",
      "Train Epoch: 54 [14720/14860 (98%)]\tLoss: 0.018026\n",
      "Train Epoch: 54 [1392/14860 (99%)]\tLoss: 0.030532\n",
      "epoch 54 training loss: 0.01985469056118248\n",
      "epoch 54 validation loss: 0.020668835097306\n",
      "Train Epoch: 55 [0/14860 (0%)]\tLoss: 0.016889\n",
      "Train Epoch: 55 [128/14860 (1%)]\tLoss: 0.015975\n",
      "Train Epoch: 55 [256/14860 (2%)]\tLoss: 0.030765\n",
      "Train Epoch: 55 [384/14860 (3%)]\tLoss: 0.011501\n",
      "Train Epoch: 55 [512/14860 (3%)]\tLoss: 0.015153\n",
      "Train Epoch: 55 [640/14860 (4%)]\tLoss: 0.020950\n",
      "Train Epoch: 55 [768/14860 (5%)]\tLoss: 0.017749\n",
      "Train Epoch: 55 [896/14860 (6%)]\tLoss: 0.016772\n",
      "Train Epoch: 55 [1024/14860 (7%)]\tLoss: 0.018413\n",
      "Train Epoch: 55 [1152/14860 (8%)]\tLoss: 0.016131\n",
      "Train Epoch: 55 [1280/14860 (9%)]\tLoss: 0.019046\n",
      "Train Epoch: 55 [1408/14860 (9%)]\tLoss: 0.021765\n",
      "Train Epoch: 55 [1536/14860 (10%)]\tLoss: 0.021131\n",
      "Train Epoch: 55 [1664/14860 (11%)]\tLoss: 0.021632\n",
      "Train Epoch: 55 [1792/14860 (12%)]\tLoss: 0.024946\n",
      "Train Epoch: 55 [1920/14860 (13%)]\tLoss: 0.021015\n",
      "Train Epoch: 55 [2048/14860 (14%)]\tLoss: 0.020030\n",
      "Train Epoch: 55 [2176/14860 (15%)]\tLoss: 0.015321\n",
      "Train Epoch: 55 [2304/14860 (15%)]\tLoss: 0.015943\n",
      "Train Epoch: 55 [2432/14860 (16%)]\tLoss: 0.027155\n",
      "Train Epoch: 55 [2560/14860 (17%)]\tLoss: 0.017495\n",
      "Train Epoch: 55 [2688/14860 (18%)]\tLoss: 0.016764\n",
      "Train Epoch: 55 [2816/14860 (19%)]\tLoss: 0.023150\n",
      "Train Epoch: 55 [2944/14860 (20%)]\tLoss: 0.016082\n",
      "Train Epoch: 55 [3072/14860 (21%)]\tLoss: 0.022825\n",
      "Train Epoch: 55 [3200/14860 (21%)]\tLoss: 0.025533\n",
      "Train Epoch: 55 [3328/14860 (22%)]\tLoss: 0.013684\n",
      "Train Epoch: 55 [3456/14860 (23%)]\tLoss: 0.020187\n",
      "Train Epoch: 55 [3584/14860 (24%)]\tLoss: 0.030523\n",
      "Train Epoch: 55 [3712/14860 (25%)]\tLoss: 0.017320\n",
      "Train Epoch: 55 [3840/14860 (26%)]\tLoss: 0.029192\n",
      "Train Epoch: 55 [3968/14860 (26%)]\tLoss: 0.016765\n",
      "Train Epoch: 55 [4096/14860 (27%)]\tLoss: 0.016015\n",
      "Train Epoch: 55 [4224/14860 (28%)]\tLoss: 0.016697\n",
      "Train Epoch: 55 [4352/14860 (29%)]\tLoss: 0.019718\n",
      "Train Epoch: 55 [4480/14860 (30%)]\tLoss: 0.012722\n",
      "Train Epoch: 55 [4608/14860 (31%)]\tLoss: 0.017845\n",
      "Train Epoch: 55 [4736/14860 (32%)]\tLoss: 0.020815\n",
      "Train Epoch: 55 [4864/14860 (32%)]\tLoss: 0.018183\n",
      "Train Epoch: 55 [4992/14860 (33%)]\tLoss: 0.011986\n",
      "Train Epoch: 55 [5120/14860 (34%)]\tLoss: 0.018008\n",
      "Train Epoch: 55 [5248/14860 (35%)]\tLoss: 0.020282\n",
      "Train Epoch: 55 [5376/14860 (36%)]\tLoss: 0.022808\n",
      "Train Epoch: 55 [5504/14860 (37%)]\tLoss: 0.018150\n",
      "Train Epoch: 55 [5632/14860 (38%)]\tLoss: 0.017891\n",
      "Train Epoch: 55 [5760/14860 (38%)]\tLoss: 0.022950\n",
      "Train Epoch: 55 [5888/14860 (39%)]\tLoss: 0.016110\n",
      "Train Epoch: 55 [6016/14860 (40%)]\tLoss: 0.019142\n",
      "Train Epoch: 55 [6144/14860 (41%)]\tLoss: 0.020235\n",
      "Train Epoch: 55 [6272/14860 (42%)]\tLoss: 0.024985\n",
      "Train Epoch: 55 [6400/14860 (43%)]\tLoss: 0.018796\n",
      "Train Epoch: 55 [6528/14860 (44%)]\tLoss: 0.018111\n",
      "Train Epoch: 55 [6656/14860 (44%)]\tLoss: 0.022180\n",
      "Train Epoch: 55 [6784/14860 (45%)]\tLoss: 0.020280\n",
      "Train Epoch: 55 [6912/14860 (46%)]\tLoss: 0.019325\n",
      "Train Epoch: 55 [7040/14860 (47%)]\tLoss: 0.021205\n",
      "Train Epoch: 55 [7168/14860 (48%)]\tLoss: 0.020649\n",
      "Train Epoch: 55 [7296/14860 (49%)]\tLoss: 0.020131\n",
      "Train Epoch: 55 [7424/14860 (50%)]\tLoss: 0.015835\n",
      "Train Epoch: 55 [7552/14860 (50%)]\tLoss: 0.021852\n",
      "Train Epoch: 55 [7680/14860 (51%)]\tLoss: 0.018063\n",
      "Train Epoch: 55 [7808/14860 (52%)]\tLoss: 0.016908\n",
      "Train Epoch: 55 [7936/14860 (53%)]\tLoss: 0.020109\n",
      "Train Epoch: 55 [8064/14860 (54%)]\tLoss: 0.017063\n",
      "Train Epoch: 55 [8192/14860 (55%)]\tLoss: 0.021821\n",
      "Train Epoch: 55 [8320/14860 (56%)]\tLoss: 0.021442\n",
      "Train Epoch: 55 [8448/14860 (56%)]\tLoss: 0.016242\n",
      "Train Epoch: 55 [8576/14860 (57%)]\tLoss: 0.024640\n",
      "Train Epoch: 55 [8704/14860 (58%)]\tLoss: 0.017893\n",
      "Train Epoch: 55 [8832/14860 (59%)]\tLoss: 0.014071\n",
      "Train Epoch: 55 [8960/14860 (60%)]\tLoss: 0.019047\n",
      "Train Epoch: 55 [9088/14860 (61%)]\tLoss: 0.025373\n",
      "Train Epoch: 55 [9216/14860 (62%)]\tLoss: 0.032354\n",
      "Train Epoch: 55 [9344/14860 (62%)]\tLoss: 0.019207\n",
      "Train Epoch: 55 [9472/14860 (63%)]\tLoss: 0.018673\n",
      "Train Epoch: 55 [9600/14860 (64%)]\tLoss: 0.017168\n",
      "Train Epoch: 55 [9728/14860 (65%)]\tLoss: 0.017026\n",
      "Train Epoch: 55 [9856/14860 (66%)]\tLoss: 0.027043\n",
      "Train Epoch: 55 [9984/14860 (67%)]\tLoss: 0.017504\n",
      "Train Epoch: 55 [10112/14860 (68%)]\tLoss: 0.023619\n",
      "Train Epoch: 55 [10240/14860 (68%)]\tLoss: 0.022756\n",
      "Train Epoch: 55 [10368/14860 (69%)]\tLoss: 0.017487\n",
      "Train Epoch: 55 [10496/14860 (70%)]\tLoss: 0.014776\n",
      "Train Epoch: 55 [10624/14860 (71%)]\tLoss: 0.024040\n",
      "Train Epoch: 55 [10752/14860 (72%)]\tLoss: 0.030039\n",
      "Train Epoch: 55 [10880/14860 (73%)]\tLoss: 0.021778\n",
      "Train Epoch: 55 [11008/14860 (74%)]\tLoss: 0.029345\n",
      "Train Epoch: 55 [11136/14860 (74%)]\tLoss: 0.021706\n",
      "Train Epoch: 55 [11264/14860 (75%)]\tLoss: 0.014164\n",
      "Train Epoch: 55 [11392/14860 (76%)]\tLoss: 0.019263\n",
      "Train Epoch: 55 [11520/14860 (77%)]\tLoss: 0.021385\n",
      "Train Epoch: 55 [11648/14860 (78%)]\tLoss: 0.016936\n",
      "Train Epoch: 55 [11776/14860 (79%)]\tLoss: 0.016917\n",
      "Train Epoch: 55 [11904/14860 (79%)]\tLoss: 0.024720\n",
      "Train Epoch: 55 [12032/14860 (80%)]\tLoss: 0.024480\n",
      "Train Epoch: 55 [12160/14860 (81%)]\tLoss: 0.026080\n",
      "Train Epoch: 55 [12288/14860 (82%)]\tLoss: 0.027615\n",
      "Train Epoch: 55 [12416/14860 (83%)]\tLoss: 0.020579\n",
      "Train Epoch: 55 [12544/14860 (84%)]\tLoss: 0.022978\n",
      "Train Epoch: 55 [12672/14860 (85%)]\tLoss: 0.017361\n",
      "Train Epoch: 55 [12800/14860 (85%)]\tLoss: 0.026888\n",
      "Train Epoch: 55 [12928/14860 (86%)]\tLoss: 0.019899\n",
      "Train Epoch: 55 [13056/14860 (87%)]\tLoss: 0.012713\n",
      "Train Epoch: 55 [13184/14860 (88%)]\tLoss: 0.013669\n",
      "Train Epoch: 55 [13312/14860 (89%)]\tLoss: 0.014279\n",
      "Train Epoch: 55 [13440/14860 (90%)]\tLoss: 0.021100\n",
      "Train Epoch: 55 [13568/14860 (91%)]\tLoss: 0.022381\n",
      "Train Epoch: 55 [13696/14860 (91%)]\tLoss: 0.025040\n",
      "Train Epoch: 55 [13824/14860 (92%)]\tLoss: 0.022451\n",
      "Train Epoch: 55 [13952/14860 (93%)]\tLoss: 0.016314\n",
      "Train Epoch: 55 [14080/14860 (94%)]\tLoss: 0.021622\n",
      "Train Epoch: 55 [14208/14860 (95%)]\tLoss: 0.019576\n",
      "Train Epoch: 55 [14336/14860 (96%)]\tLoss: 0.020749\n",
      "Train Epoch: 55 [14464/14860 (97%)]\tLoss: 0.014937\n",
      "Train Epoch: 55 [14592/14860 (97%)]\tLoss: 0.023991\n",
      "Train Epoch: 55 [14720/14860 (98%)]\tLoss: 0.014009\n",
      "Train Epoch: 55 [1392/14860 (99%)]\tLoss: 0.036356\n",
      "epoch 55 training loss: 0.020139725640034065\n",
      "epoch 55 validation loss: 0.022047742371409048\n",
      "Train Epoch: 56 [0/14860 (0%)]\tLoss: 0.018464\n",
      "Train Epoch: 56 [128/14860 (1%)]\tLoss: 0.022407\n",
      "Train Epoch: 56 [256/14860 (2%)]\tLoss: 0.020307\n",
      "Train Epoch: 56 [384/14860 (3%)]\tLoss: 0.023110\n",
      "Train Epoch: 56 [512/14860 (3%)]\tLoss: 0.019610\n",
      "Train Epoch: 56 [640/14860 (4%)]\tLoss: 0.021983\n",
      "Train Epoch: 56 [768/14860 (5%)]\tLoss: 0.018660\n",
      "Train Epoch: 56 [896/14860 (6%)]\tLoss: 0.023903\n",
      "Train Epoch: 56 [1024/14860 (7%)]\tLoss: 0.024267\n",
      "Train Epoch: 56 [1152/14860 (8%)]\tLoss: 0.015358\n",
      "Train Epoch: 56 [1280/14860 (9%)]\tLoss: 0.027000\n",
      "Train Epoch: 56 [1408/14860 (9%)]\tLoss: 0.017610\n",
      "Train Epoch: 56 [1536/14860 (10%)]\tLoss: 0.019450\n",
      "Train Epoch: 56 [1664/14860 (11%)]\tLoss: 0.024859\n",
      "Train Epoch: 56 [1792/14860 (12%)]\tLoss: 0.025474\n",
      "Train Epoch: 56 [1920/14860 (13%)]\tLoss: 0.017101\n",
      "Train Epoch: 56 [2048/14860 (14%)]\tLoss: 0.024035\n",
      "Train Epoch: 56 [2176/14860 (15%)]\tLoss: 0.016112\n",
      "Train Epoch: 56 [2304/14860 (15%)]\tLoss: 0.021772\n",
      "Train Epoch: 56 [2432/14860 (16%)]\tLoss: 0.019747\n",
      "Train Epoch: 56 [2560/14860 (17%)]\tLoss: 0.023007\n",
      "Train Epoch: 56 [2688/14860 (18%)]\tLoss: 0.018543\n",
      "Train Epoch: 56 [2816/14860 (19%)]\tLoss: 0.014423\n",
      "Train Epoch: 56 [2944/14860 (20%)]\tLoss: 0.020197\n",
      "Train Epoch: 56 [3072/14860 (21%)]\tLoss: 0.017294\n",
      "Train Epoch: 56 [3200/14860 (21%)]\tLoss: 0.022730\n",
      "Train Epoch: 56 [3328/14860 (22%)]\tLoss: 0.018762\n",
      "Train Epoch: 56 [3456/14860 (23%)]\tLoss: 0.016553\n",
      "Train Epoch: 56 [3584/14860 (24%)]\tLoss: 0.019820\n",
      "Train Epoch: 56 [3712/14860 (25%)]\tLoss: 0.020693\n",
      "Train Epoch: 56 [3840/14860 (26%)]\tLoss: 0.017870\n",
      "Train Epoch: 56 [3968/14860 (26%)]\tLoss: 0.017920\n",
      "Train Epoch: 56 [4096/14860 (27%)]\tLoss: 0.019967\n",
      "Train Epoch: 56 [4224/14860 (28%)]\tLoss: 0.024672\n",
      "Train Epoch: 56 [4352/14860 (29%)]\tLoss: 0.020192\n",
      "Train Epoch: 56 [4480/14860 (30%)]\tLoss: 0.010400\n",
      "Train Epoch: 56 [4608/14860 (31%)]\tLoss: 0.017534\n",
      "Train Epoch: 56 [4736/14860 (32%)]\tLoss: 0.019496\n",
      "Train Epoch: 56 [4864/14860 (32%)]\tLoss: 0.014006\n",
      "Train Epoch: 56 [4992/14860 (33%)]\tLoss: 0.018093\n",
      "Train Epoch: 56 [5120/14860 (34%)]\tLoss: 0.017245\n",
      "Train Epoch: 56 [5248/14860 (35%)]\tLoss: 0.024356\n",
      "Train Epoch: 56 [5376/14860 (36%)]\tLoss: 0.019252\n",
      "Train Epoch: 56 [5504/14860 (37%)]\tLoss: 0.023485\n",
      "Train Epoch: 56 [5632/14860 (38%)]\tLoss: 0.021854\n",
      "Train Epoch: 56 [5760/14860 (38%)]\tLoss: 0.028308\n",
      "Train Epoch: 56 [5888/14860 (39%)]\tLoss: 0.019808\n",
      "Train Epoch: 56 [6016/14860 (40%)]\tLoss: 0.021386\n",
      "Train Epoch: 56 [6144/14860 (41%)]\tLoss: 0.017168\n",
      "Train Epoch: 56 [6272/14860 (42%)]\tLoss: 0.016984\n",
      "Train Epoch: 56 [6400/14860 (43%)]\tLoss: 0.024400\n",
      "Train Epoch: 56 [6528/14860 (44%)]\tLoss: 0.015459\n",
      "Train Epoch: 56 [6656/14860 (44%)]\tLoss: 0.014216\n",
      "Train Epoch: 56 [6784/14860 (45%)]\tLoss: 0.019764\n",
      "Train Epoch: 56 [6912/14860 (46%)]\tLoss: 0.021739\n",
      "Train Epoch: 56 [7040/14860 (47%)]\tLoss: 0.017820\n",
      "Train Epoch: 56 [7168/14860 (48%)]\tLoss: 0.020533\n",
      "Train Epoch: 56 [7296/14860 (49%)]\tLoss: 0.011949\n",
      "Train Epoch: 56 [7424/14860 (50%)]\tLoss: 0.019099\n",
      "Train Epoch: 56 [7552/14860 (50%)]\tLoss: 0.014791\n",
      "Train Epoch: 56 [7680/14860 (51%)]\tLoss: 0.018443\n",
      "Train Epoch: 56 [7808/14860 (52%)]\tLoss: 0.022904\n",
      "Train Epoch: 56 [7936/14860 (53%)]\tLoss: 0.017403\n",
      "Train Epoch: 56 [8064/14860 (54%)]\tLoss: 0.017969\n",
      "Train Epoch: 56 [8192/14860 (55%)]\tLoss: 0.022471\n",
      "Train Epoch: 56 [8320/14860 (56%)]\tLoss: 0.015697\n",
      "Train Epoch: 56 [8448/14860 (56%)]\tLoss: 0.022771\n",
      "Train Epoch: 56 [8576/14860 (57%)]\tLoss: 0.023426\n",
      "Train Epoch: 56 [8704/14860 (58%)]\tLoss: 0.018544\n",
      "Train Epoch: 56 [8832/14860 (59%)]\tLoss: 0.017700\n",
      "Train Epoch: 56 [8960/14860 (60%)]\tLoss: 0.015352\n",
      "Train Epoch: 56 [9088/14860 (61%)]\tLoss: 0.014256\n",
      "Train Epoch: 56 [9216/14860 (62%)]\tLoss: 0.013593\n",
      "Train Epoch: 56 [9344/14860 (62%)]\tLoss: 0.020811\n",
      "Train Epoch: 56 [9472/14860 (63%)]\tLoss: 0.016955\n",
      "Train Epoch: 56 [9600/14860 (64%)]\tLoss: 0.022626\n",
      "Train Epoch: 56 [9728/14860 (65%)]\tLoss: 0.013768\n",
      "Train Epoch: 56 [9856/14860 (66%)]\tLoss: 0.032833\n",
      "Train Epoch: 56 [9984/14860 (67%)]\tLoss: 0.014496\n",
      "Train Epoch: 56 [10112/14860 (68%)]\tLoss: 0.022223\n",
      "Train Epoch: 56 [10240/14860 (68%)]\tLoss: 0.025127\n",
      "Train Epoch: 56 [10368/14860 (69%)]\tLoss: 0.021428\n",
      "Train Epoch: 56 [10496/14860 (70%)]\tLoss: 0.016219\n",
      "Train Epoch: 56 [10624/14860 (71%)]\tLoss: 0.023773\n",
      "Train Epoch: 56 [10752/14860 (72%)]\tLoss: 0.015383\n",
      "Train Epoch: 56 [10880/14860 (73%)]\tLoss: 0.017941\n",
      "Train Epoch: 56 [11008/14860 (74%)]\tLoss: 0.023402\n",
      "Train Epoch: 56 [11136/14860 (74%)]\tLoss: 0.018984\n",
      "Train Epoch: 56 [11264/14860 (75%)]\tLoss: 0.014941\n",
      "Train Epoch: 56 [11392/14860 (76%)]\tLoss: 0.023908\n",
      "Train Epoch: 56 [11520/14860 (77%)]\tLoss: 0.009008\n",
      "Train Epoch: 56 [11648/14860 (78%)]\tLoss: 0.019314\n",
      "Train Epoch: 56 [11776/14860 (79%)]\tLoss: 0.019563\n",
      "Train Epoch: 56 [11904/14860 (79%)]\tLoss: 0.016528\n",
      "Train Epoch: 56 [12032/14860 (80%)]\tLoss: 0.019510\n",
      "Train Epoch: 56 [12160/14860 (81%)]\tLoss: 0.025939\n",
      "Train Epoch: 56 [12288/14860 (82%)]\tLoss: 0.015783\n",
      "Train Epoch: 56 [12416/14860 (83%)]\tLoss: 0.014650\n",
      "Train Epoch: 56 [12544/14860 (84%)]\tLoss: 0.023242\n",
      "Train Epoch: 56 [12672/14860 (85%)]\tLoss: 0.024372\n",
      "Train Epoch: 56 [12800/14860 (85%)]\tLoss: 0.019283\n",
      "Train Epoch: 56 [12928/14860 (86%)]\tLoss: 0.023913\n",
      "Train Epoch: 56 [13056/14860 (87%)]\tLoss: 0.013686\n",
      "Train Epoch: 56 [13184/14860 (88%)]\tLoss: 0.021663\n",
      "Train Epoch: 56 [13312/14860 (89%)]\tLoss: 0.011304\n",
      "Train Epoch: 56 [13440/14860 (90%)]\tLoss: 0.017253\n",
      "Train Epoch: 56 [13568/14860 (91%)]\tLoss: 0.019217\n",
      "Train Epoch: 56 [13696/14860 (91%)]\tLoss: 0.019025\n",
      "Train Epoch: 56 [13824/14860 (92%)]\tLoss: 0.007353\n",
      "Train Epoch: 56 [13952/14860 (93%)]\tLoss: 0.018145\n",
      "Train Epoch: 56 [14080/14860 (94%)]\tLoss: 0.024678\n",
      "Train Epoch: 56 [14208/14860 (95%)]\tLoss: 0.017694\n",
      "Train Epoch: 56 [14336/14860 (96%)]\tLoss: 0.020688\n",
      "Train Epoch: 56 [14464/14860 (97%)]\tLoss: 0.020640\n",
      "Train Epoch: 56 [14592/14860 (97%)]\tLoss: 0.022897\n",
      "Train Epoch: 56 [14720/14860 (98%)]\tLoss: 0.020405\n",
      "Train Epoch: 56 [1392/14860 (99%)]\tLoss: 0.009019\n",
      "epoch 56 training loss: 0.019343098155899435\n",
      "epoch 56 validation loss: 0.02092206449254662\n",
      "Train Epoch: 57 [0/14860 (0%)]\tLoss: 0.021176\n",
      "Train Epoch: 57 [128/14860 (1%)]\tLoss: 0.017176\n",
      "Train Epoch: 57 [256/14860 (2%)]\tLoss: 0.025706\n",
      "Train Epoch: 57 [384/14860 (3%)]\tLoss: 0.020232\n",
      "Train Epoch: 57 [512/14860 (3%)]\tLoss: 0.016472\n",
      "Train Epoch: 57 [640/14860 (4%)]\tLoss: 0.024487\n",
      "Train Epoch: 57 [768/14860 (5%)]\tLoss: 0.019733\n",
      "Train Epoch: 57 [896/14860 (6%)]\tLoss: 0.017875\n",
      "Train Epoch: 57 [1024/14860 (7%)]\tLoss: 0.019391\n",
      "Train Epoch: 57 [1152/14860 (8%)]\tLoss: 0.017122\n",
      "Train Epoch: 57 [1280/14860 (9%)]\tLoss: 0.014198\n",
      "Train Epoch: 57 [1408/14860 (9%)]\tLoss: 0.024929\n",
      "Train Epoch: 57 [1536/14860 (10%)]\tLoss: 0.023050\n",
      "Train Epoch: 57 [1664/14860 (11%)]\tLoss: 0.023729\n",
      "Train Epoch: 57 [1792/14860 (12%)]\tLoss: 0.020878\n",
      "Train Epoch: 57 [1920/14860 (13%)]\tLoss: 0.015882\n",
      "Train Epoch: 57 [2048/14860 (14%)]\tLoss: 0.024000\n",
      "Train Epoch: 57 [2176/14860 (15%)]\tLoss: 0.023117\n",
      "Train Epoch: 57 [2304/14860 (15%)]\tLoss: 0.012280\n",
      "Train Epoch: 57 [2432/14860 (16%)]\tLoss: 0.012132\n",
      "Train Epoch: 57 [2560/14860 (17%)]\tLoss: 0.021154\n",
      "Train Epoch: 57 [2688/14860 (18%)]\tLoss: 0.022099\n",
      "Train Epoch: 57 [2816/14860 (19%)]\tLoss: 0.018415\n",
      "Train Epoch: 57 [2944/14860 (20%)]\tLoss: 0.013817\n",
      "Train Epoch: 57 [3072/14860 (21%)]\tLoss: 0.025717\n",
      "Train Epoch: 57 [3200/14860 (21%)]\tLoss: 0.021089\n",
      "Train Epoch: 57 [3328/14860 (22%)]\tLoss: 0.016654\n",
      "Train Epoch: 57 [3456/14860 (23%)]\tLoss: 0.022139\n",
      "Train Epoch: 57 [3584/14860 (24%)]\tLoss: 0.013124\n",
      "Train Epoch: 57 [3712/14860 (25%)]\tLoss: 0.018581\n",
      "Train Epoch: 57 [3840/14860 (26%)]\tLoss: 0.019725\n",
      "Train Epoch: 57 [3968/14860 (26%)]\tLoss: 0.022977\n",
      "Train Epoch: 57 [4096/14860 (27%)]\tLoss: 0.022885\n",
      "Train Epoch: 57 [4224/14860 (28%)]\tLoss: 0.022287\n",
      "Train Epoch: 57 [4352/14860 (29%)]\tLoss: 0.020167\n",
      "Train Epoch: 57 [4480/14860 (30%)]\tLoss: 0.023077\n",
      "Train Epoch: 57 [4608/14860 (31%)]\tLoss: 0.016077\n",
      "Train Epoch: 57 [4736/14860 (32%)]\tLoss: 0.014307\n",
      "Train Epoch: 57 [4864/14860 (32%)]\tLoss: 0.021815\n",
      "Train Epoch: 57 [4992/14860 (33%)]\tLoss: 0.018213\n",
      "Train Epoch: 57 [5120/14860 (34%)]\tLoss: 0.019709\n",
      "Train Epoch: 57 [5248/14860 (35%)]\tLoss: 0.022056\n",
      "Train Epoch: 57 [5376/14860 (36%)]\tLoss: 0.015859\n",
      "Train Epoch: 57 [5504/14860 (37%)]\tLoss: 0.020404\n",
      "Train Epoch: 57 [5632/14860 (38%)]\tLoss: 0.023455\n",
      "Train Epoch: 57 [5760/14860 (38%)]\tLoss: 0.022293\n",
      "Train Epoch: 57 [5888/14860 (39%)]\tLoss: 0.021868\n",
      "Train Epoch: 57 [6016/14860 (40%)]\tLoss: 0.020305\n",
      "Train Epoch: 57 [6144/14860 (41%)]\tLoss: 0.013731\n",
      "Train Epoch: 57 [6272/14860 (42%)]\tLoss: 0.022827\n",
      "Train Epoch: 57 [6400/14860 (43%)]\tLoss: 0.021861\n",
      "Train Epoch: 57 [6528/14860 (44%)]\tLoss: 0.024322\n",
      "Train Epoch: 57 [6656/14860 (44%)]\tLoss: 0.019802\n",
      "Train Epoch: 57 [6784/14860 (45%)]\tLoss: 0.018044\n",
      "Train Epoch: 57 [6912/14860 (46%)]\tLoss: 0.018252\n",
      "Train Epoch: 57 [7040/14860 (47%)]\tLoss: 0.015969\n",
      "Train Epoch: 57 [7168/14860 (48%)]\tLoss: 0.038285\n",
      "Train Epoch: 57 [7296/14860 (49%)]\tLoss: 0.020446\n",
      "Train Epoch: 57 [7424/14860 (50%)]\tLoss: 0.021661\n",
      "Train Epoch: 57 [7552/14860 (50%)]\tLoss: 0.022845\n",
      "Train Epoch: 57 [7680/14860 (51%)]\tLoss: 0.031255\n",
      "Train Epoch: 57 [7808/14860 (52%)]\tLoss: 0.023782\n",
      "Train Epoch: 57 [7936/14860 (53%)]\tLoss: 0.026551\n",
      "Train Epoch: 57 [8064/14860 (54%)]\tLoss: 0.019451\n",
      "Train Epoch: 57 [8192/14860 (55%)]\tLoss: 0.013209\n",
      "Train Epoch: 57 [8320/14860 (56%)]\tLoss: 0.019657\n",
      "Train Epoch: 57 [8448/14860 (56%)]\tLoss: 0.018788\n",
      "Train Epoch: 57 [8576/14860 (57%)]\tLoss: 0.014915\n",
      "Train Epoch: 57 [8704/14860 (58%)]\tLoss: 0.018316\n",
      "Train Epoch: 57 [8832/14860 (59%)]\tLoss: 0.012611\n",
      "Train Epoch: 57 [8960/14860 (60%)]\tLoss: 0.014974\n",
      "Train Epoch: 57 [9088/14860 (61%)]\tLoss: 0.015032\n",
      "Train Epoch: 57 [9216/14860 (62%)]\tLoss: 0.019518\n",
      "Train Epoch: 57 [9344/14860 (62%)]\tLoss: 0.022074\n",
      "Train Epoch: 57 [9472/14860 (63%)]\tLoss: 0.025135\n",
      "Train Epoch: 57 [9600/14860 (64%)]\tLoss: 0.019014\n",
      "Train Epoch: 57 [9728/14860 (65%)]\tLoss: 0.018198\n",
      "Train Epoch: 57 [9856/14860 (66%)]\tLoss: 0.016682\n",
      "Train Epoch: 57 [9984/14860 (67%)]\tLoss: 0.017888\n",
      "Train Epoch: 57 [10112/14860 (68%)]\tLoss: 0.029435\n",
      "Train Epoch: 57 [10240/14860 (68%)]\tLoss: 0.013928\n",
      "Train Epoch: 57 [10368/14860 (69%)]\tLoss: 0.015765\n",
      "Train Epoch: 57 [10496/14860 (70%)]\tLoss: 0.017696\n",
      "Train Epoch: 57 [10624/14860 (71%)]\tLoss: 0.021380\n",
      "Train Epoch: 57 [10752/14860 (72%)]\tLoss: 0.022167\n",
      "Train Epoch: 57 [10880/14860 (73%)]\tLoss: 0.018110\n",
      "Train Epoch: 57 [11008/14860 (74%)]\tLoss: 0.017954\n",
      "Train Epoch: 57 [11136/14860 (74%)]\tLoss: 0.020275\n",
      "Train Epoch: 57 [11264/14860 (75%)]\tLoss: 0.023048\n",
      "Train Epoch: 57 [11392/14860 (76%)]\tLoss: 0.024829\n",
      "Train Epoch: 57 [11520/14860 (77%)]\tLoss: 0.018473\n",
      "Train Epoch: 57 [11648/14860 (78%)]\tLoss: 0.015323\n",
      "Train Epoch: 57 [11776/14860 (79%)]\tLoss: 0.013567\n",
      "Train Epoch: 57 [11904/14860 (79%)]\tLoss: 0.019256\n",
      "Train Epoch: 57 [12032/14860 (80%)]\tLoss: 0.022938\n",
      "Train Epoch: 57 [12160/14860 (81%)]\tLoss: 0.012628\n",
      "Train Epoch: 57 [12288/14860 (82%)]\tLoss: 0.016509\n",
      "Train Epoch: 57 [12416/14860 (83%)]\tLoss: 0.018545\n",
      "Train Epoch: 57 [12544/14860 (84%)]\tLoss: 0.014865\n",
      "Train Epoch: 57 [12672/14860 (85%)]\tLoss: 0.019132\n",
      "Train Epoch: 57 [12800/14860 (85%)]\tLoss: 0.025577\n",
      "Train Epoch: 57 [12928/14860 (86%)]\tLoss: 0.019058\n",
      "Train Epoch: 57 [13056/14860 (87%)]\tLoss: 0.013340\n",
      "Train Epoch: 57 [13184/14860 (88%)]\tLoss: 0.013636\n",
      "Train Epoch: 57 [13312/14860 (89%)]\tLoss: 0.017847\n",
      "Train Epoch: 57 [13440/14860 (90%)]\tLoss: 0.015490\n",
      "Train Epoch: 57 [13568/14860 (91%)]\tLoss: 0.019735\n",
      "Train Epoch: 57 [13696/14860 (91%)]\tLoss: 0.021074\n",
      "Train Epoch: 57 [13824/14860 (92%)]\tLoss: 0.021944\n",
      "Train Epoch: 57 [13952/14860 (93%)]\tLoss: 0.022371\n",
      "Train Epoch: 57 [14080/14860 (94%)]\tLoss: 0.028264\n",
      "Train Epoch: 57 [14208/14860 (95%)]\tLoss: 0.012019\n",
      "Train Epoch: 57 [14336/14860 (96%)]\tLoss: 0.017570\n",
      "Train Epoch: 57 [14464/14860 (97%)]\tLoss: 0.015515\n",
      "Train Epoch: 57 [14592/14860 (97%)]\tLoss: 0.021499\n",
      "Train Epoch: 57 [14720/14860 (98%)]\tLoss: 0.022008\n",
      "Train Epoch: 57 [1392/14860 (99%)]\tLoss: 0.009287\n",
      "epoch 57 training loss: 0.019581093293670405\n",
      "epoch 57 validation loss: 0.020260566299821793\n",
      "Train Epoch: 58 [0/14860 (0%)]\tLoss: 0.018824\n",
      "Train Epoch: 58 [128/14860 (1%)]\tLoss: 0.015406\n",
      "Train Epoch: 58 [256/14860 (2%)]\tLoss: 0.014702\n",
      "Train Epoch: 58 [384/14860 (3%)]\tLoss: 0.021004\n",
      "Train Epoch: 58 [512/14860 (3%)]\tLoss: 0.019897\n",
      "Train Epoch: 58 [640/14860 (4%)]\tLoss: 0.025056\n",
      "Train Epoch: 58 [768/14860 (5%)]\tLoss: 0.015843\n",
      "Train Epoch: 58 [896/14860 (6%)]\tLoss: 0.024622\n",
      "Train Epoch: 58 [1024/14860 (7%)]\tLoss: 0.016996\n",
      "Train Epoch: 58 [1152/14860 (8%)]\tLoss: 0.020125\n",
      "Train Epoch: 58 [1280/14860 (9%)]\tLoss: 0.016872\n",
      "Train Epoch: 58 [1408/14860 (9%)]\tLoss: 0.016115\n",
      "Train Epoch: 58 [1536/14860 (10%)]\tLoss: 0.028318\n",
      "Train Epoch: 58 [1664/14860 (11%)]\tLoss: 0.028566\n",
      "Train Epoch: 58 [1792/14860 (12%)]\tLoss: 0.018436\n",
      "Train Epoch: 58 [1920/14860 (13%)]\tLoss: 0.020039\n",
      "Train Epoch: 58 [2048/14860 (14%)]\tLoss: 0.024861\n",
      "Train Epoch: 58 [2176/14860 (15%)]\tLoss: 0.017881\n",
      "Train Epoch: 58 [2304/14860 (15%)]\tLoss: 0.020858\n",
      "Train Epoch: 58 [2432/14860 (16%)]\tLoss: 0.022839\n",
      "Train Epoch: 58 [2560/14860 (17%)]\tLoss: 0.020724\n",
      "Train Epoch: 58 [2688/14860 (18%)]\tLoss: 0.019111\n",
      "Train Epoch: 58 [2816/14860 (19%)]\tLoss: 0.013352\n",
      "Train Epoch: 58 [2944/14860 (20%)]\tLoss: 0.029930\n",
      "Train Epoch: 58 [3072/14860 (21%)]\tLoss: 0.015139\n",
      "Train Epoch: 58 [3200/14860 (21%)]\tLoss: 0.017928\n",
      "Train Epoch: 58 [3328/14860 (22%)]\tLoss: 0.015912\n",
      "Train Epoch: 58 [3456/14860 (23%)]\tLoss: 0.018489\n",
      "Train Epoch: 58 [3584/14860 (24%)]\tLoss: 0.018325\n",
      "Train Epoch: 58 [3712/14860 (25%)]\tLoss: 0.017296\n",
      "Train Epoch: 58 [3840/14860 (26%)]\tLoss: 0.019627\n",
      "Train Epoch: 58 [3968/14860 (26%)]\tLoss: 0.012302\n",
      "Train Epoch: 58 [4096/14860 (27%)]\tLoss: 0.020555\n",
      "Train Epoch: 58 [4224/14860 (28%)]\tLoss: 0.026335\n",
      "Train Epoch: 58 [4352/14860 (29%)]\tLoss: 0.024636\n",
      "Train Epoch: 58 [4480/14860 (30%)]\tLoss: 0.025800\n",
      "Train Epoch: 58 [4608/14860 (31%)]\tLoss: 0.019501\n",
      "Train Epoch: 58 [4736/14860 (32%)]\tLoss: 0.024378\n",
      "Train Epoch: 58 [4864/14860 (32%)]\tLoss: 0.022101\n",
      "Train Epoch: 58 [4992/14860 (33%)]\tLoss: 0.014688\n",
      "Train Epoch: 58 [5120/14860 (34%)]\tLoss: 0.019640\n",
      "Train Epoch: 58 [5248/14860 (35%)]\tLoss: 0.017325\n",
      "Train Epoch: 58 [5376/14860 (36%)]\tLoss: 0.018228\n",
      "Train Epoch: 58 [5504/14860 (37%)]\tLoss: 0.020715\n",
      "Train Epoch: 58 [5632/14860 (38%)]\tLoss: 0.020337\n",
      "Train Epoch: 58 [5760/14860 (38%)]\tLoss: 0.024686\n",
      "Train Epoch: 58 [5888/14860 (39%)]\tLoss: 0.010099\n",
      "Train Epoch: 58 [6016/14860 (40%)]\tLoss: 0.018976\n",
      "Train Epoch: 58 [6144/14860 (41%)]\tLoss: 0.014945\n",
      "Train Epoch: 58 [6272/14860 (42%)]\tLoss: 0.016504\n",
      "Train Epoch: 58 [6400/14860 (43%)]\tLoss: 0.017279\n",
      "Train Epoch: 58 [6528/14860 (44%)]\tLoss: 0.013581\n",
      "Train Epoch: 58 [6656/14860 (44%)]\tLoss: 0.017438\n",
      "Train Epoch: 58 [6784/14860 (45%)]\tLoss: 0.014501\n",
      "Train Epoch: 58 [6912/14860 (46%)]\tLoss: 0.012155\n",
      "Train Epoch: 58 [7040/14860 (47%)]\tLoss: 0.020481\n",
      "Train Epoch: 58 [7168/14860 (48%)]\tLoss: 0.012330\n",
      "Train Epoch: 58 [7296/14860 (49%)]\tLoss: 0.017192\n",
      "Train Epoch: 58 [7424/14860 (50%)]\tLoss: 0.024142\n",
      "Train Epoch: 58 [7552/14860 (50%)]\tLoss: 0.018735\n",
      "Train Epoch: 58 [7680/14860 (51%)]\tLoss: 0.019112\n",
      "Train Epoch: 58 [7808/14860 (52%)]\tLoss: 0.021079\n",
      "Train Epoch: 58 [7936/14860 (53%)]\tLoss: 0.027574\n",
      "Train Epoch: 58 [8064/14860 (54%)]\tLoss: 0.023985\n",
      "Train Epoch: 58 [8192/14860 (55%)]\tLoss: 0.030033\n",
      "Train Epoch: 58 [8320/14860 (56%)]\tLoss: 0.018740\n",
      "Train Epoch: 58 [8448/14860 (56%)]\tLoss: 0.018912\n",
      "Train Epoch: 58 [8576/14860 (57%)]\tLoss: 0.019846\n",
      "Train Epoch: 58 [8704/14860 (58%)]\tLoss: 0.012326\n",
      "Train Epoch: 58 [8832/14860 (59%)]\tLoss: 0.016338\n",
      "Train Epoch: 58 [8960/14860 (60%)]\tLoss: 0.017587\n",
      "Train Epoch: 58 [9088/14860 (61%)]\tLoss: 0.020438\n",
      "Train Epoch: 58 [9216/14860 (62%)]\tLoss: 0.018629\n",
      "Train Epoch: 58 [9344/14860 (62%)]\tLoss: 0.012668\n",
      "Train Epoch: 58 [9472/14860 (63%)]\tLoss: 0.025407\n",
      "Train Epoch: 58 [9600/14860 (64%)]\tLoss: 0.016197\n",
      "Train Epoch: 58 [9728/14860 (65%)]\tLoss: 0.020537\n",
      "Train Epoch: 58 [9856/14860 (66%)]\tLoss: 0.018831\n",
      "Train Epoch: 58 [9984/14860 (67%)]\tLoss: 0.015489\n",
      "Train Epoch: 58 [10112/14860 (68%)]\tLoss: 0.028441\n",
      "Train Epoch: 58 [10240/14860 (68%)]\tLoss: 0.016404\n",
      "Train Epoch: 58 [10368/14860 (69%)]\tLoss: 0.017743\n",
      "Train Epoch: 58 [10496/14860 (70%)]\tLoss: 0.021573\n",
      "Train Epoch: 58 [10624/14860 (71%)]\tLoss: 0.025164\n",
      "Train Epoch: 58 [10752/14860 (72%)]\tLoss: 0.023499\n",
      "Train Epoch: 58 [10880/14860 (73%)]\tLoss: 0.013067\n",
      "Train Epoch: 58 [11008/14860 (74%)]\tLoss: 0.020168\n",
      "Train Epoch: 58 [11136/14860 (74%)]\tLoss: 0.017611\n",
      "Train Epoch: 58 [11264/14860 (75%)]\tLoss: 0.023655\n",
      "Train Epoch: 58 [11392/14860 (76%)]\tLoss: 0.015031\n",
      "Train Epoch: 58 [11520/14860 (77%)]\tLoss: 0.020912\n",
      "Train Epoch: 58 [11648/14860 (78%)]\tLoss: 0.018239\n",
      "Train Epoch: 58 [11776/14860 (79%)]\tLoss: 0.017742\n",
      "Train Epoch: 58 [11904/14860 (79%)]\tLoss: 0.019013\n",
      "Train Epoch: 58 [12032/14860 (80%)]\tLoss: 0.018279\n",
      "Train Epoch: 58 [12160/14860 (81%)]\tLoss: 0.013903\n",
      "Train Epoch: 58 [12288/14860 (82%)]\tLoss: 0.014566\n",
      "Train Epoch: 58 [12416/14860 (83%)]\tLoss: 0.024696\n",
      "Train Epoch: 58 [12544/14860 (84%)]\tLoss: 0.021845\n",
      "Train Epoch: 58 [12672/14860 (85%)]\tLoss: 0.014761\n",
      "Train Epoch: 58 [12800/14860 (85%)]\tLoss: 0.023134\n",
      "Train Epoch: 58 [12928/14860 (86%)]\tLoss: 0.023081\n",
      "Train Epoch: 58 [13056/14860 (87%)]\tLoss: 0.010590\n",
      "Train Epoch: 58 [13184/14860 (88%)]\tLoss: 0.018622\n",
      "Train Epoch: 58 [13312/14860 (89%)]\tLoss: 0.013774\n",
      "Train Epoch: 58 [13440/14860 (90%)]\tLoss: 0.011798\n",
      "Train Epoch: 58 [13568/14860 (91%)]\tLoss: 0.012493\n",
      "Train Epoch: 58 [13696/14860 (91%)]\tLoss: 0.019300\n",
      "Train Epoch: 58 [13824/14860 (92%)]\tLoss: 0.021215\n",
      "Train Epoch: 58 [13952/14860 (93%)]\tLoss: 0.023153\n",
      "Train Epoch: 58 [14080/14860 (94%)]\tLoss: 0.026546\n",
      "Train Epoch: 58 [14208/14860 (95%)]\tLoss: 0.021942\n",
      "Train Epoch: 58 [14336/14860 (96%)]\tLoss: 0.018868\n",
      "Train Epoch: 58 [14464/14860 (97%)]\tLoss: 0.017753\n",
      "Train Epoch: 58 [14592/14860 (97%)]\tLoss: 0.018460\n",
      "Train Epoch: 58 [14720/14860 (98%)]\tLoss: 0.021682\n",
      "Train Epoch: 58 [1392/14860 (99%)]\tLoss: 0.013871\n",
      "epoch 58 training loss: 0.01922222723563512\n",
      "epoch 58 validation loss: 0.020299333492722407\n",
      "Train Epoch: 59 [0/14860 (0%)]\tLoss: 0.017811\n",
      "Train Epoch: 59 [128/14860 (1%)]\tLoss: 0.014270\n",
      "Train Epoch: 59 [256/14860 (2%)]\tLoss: 0.015322\n",
      "Train Epoch: 59 [384/14860 (3%)]\tLoss: 0.023634\n",
      "Train Epoch: 59 [512/14860 (3%)]\tLoss: 0.017707\n",
      "Train Epoch: 59 [640/14860 (4%)]\tLoss: 0.020222\n",
      "Train Epoch: 59 [768/14860 (5%)]\tLoss: 0.017644\n",
      "Train Epoch: 59 [896/14860 (6%)]\tLoss: 0.013054\n",
      "Train Epoch: 59 [1024/14860 (7%)]\tLoss: 0.032967\n",
      "Train Epoch: 59 [1152/14860 (8%)]\tLoss: 0.023043\n",
      "Train Epoch: 59 [1280/14860 (9%)]\tLoss: 0.022851\n",
      "Train Epoch: 59 [1408/14860 (9%)]\tLoss: 0.019481\n",
      "Train Epoch: 59 [1536/14860 (10%)]\tLoss: 0.018587\n",
      "Train Epoch: 59 [1664/14860 (11%)]\tLoss: 0.015578\n",
      "Train Epoch: 59 [1792/14860 (12%)]\tLoss: 0.013545\n",
      "Train Epoch: 59 [1920/14860 (13%)]\tLoss: 0.031125\n",
      "Train Epoch: 59 [2048/14860 (14%)]\tLoss: 0.017462\n",
      "Train Epoch: 59 [2176/14860 (15%)]\tLoss: 0.033345\n",
      "Train Epoch: 59 [2304/14860 (15%)]\tLoss: 0.021352\n",
      "Train Epoch: 59 [2432/14860 (16%)]\tLoss: 0.014159\n",
      "Train Epoch: 59 [2560/14860 (17%)]\tLoss: 0.019912\n",
      "Train Epoch: 59 [2688/14860 (18%)]\tLoss: 0.015662\n",
      "Train Epoch: 59 [2816/14860 (19%)]\tLoss: 0.020114\n",
      "Train Epoch: 59 [2944/14860 (20%)]\tLoss: 0.019087\n",
      "Train Epoch: 59 [3072/14860 (21%)]\tLoss: 0.025580\n",
      "Train Epoch: 59 [3200/14860 (21%)]\tLoss: 0.017220\n",
      "Train Epoch: 59 [3328/14860 (22%)]\tLoss: 0.021857\n",
      "Train Epoch: 59 [3456/14860 (23%)]\tLoss: 0.027048\n",
      "Train Epoch: 59 [3584/14860 (24%)]\tLoss: 0.017791\n",
      "Train Epoch: 59 [3712/14860 (25%)]\tLoss: 0.021729\n",
      "Train Epoch: 59 [3840/14860 (26%)]\tLoss: 0.016541\n",
      "Train Epoch: 59 [3968/14860 (26%)]\tLoss: 0.017324\n",
      "Train Epoch: 59 [4096/14860 (27%)]\tLoss: 0.020688\n",
      "Train Epoch: 59 [4224/14860 (28%)]\tLoss: 0.014729\n",
      "Train Epoch: 59 [4352/14860 (29%)]\tLoss: 0.012512\n",
      "Train Epoch: 59 [4480/14860 (30%)]\tLoss: 0.026948\n",
      "Train Epoch: 59 [4608/14860 (31%)]\tLoss: 0.016100\n",
      "Train Epoch: 59 [4736/14860 (32%)]\tLoss: 0.020621\n",
      "Train Epoch: 59 [4864/14860 (32%)]\tLoss: 0.018124\n",
      "Train Epoch: 59 [4992/14860 (33%)]\tLoss: 0.015352\n",
      "Train Epoch: 59 [5120/14860 (34%)]\tLoss: 0.017288\n",
      "Train Epoch: 59 [5248/14860 (35%)]\tLoss: 0.023148\n",
      "Train Epoch: 59 [5376/14860 (36%)]\tLoss: 0.018523\n",
      "Train Epoch: 59 [5504/14860 (37%)]\tLoss: 0.019137\n",
      "Train Epoch: 59 [5632/14860 (38%)]\tLoss: 0.013107\n",
      "Train Epoch: 59 [5760/14860 (38%)]\tLoss: 0.021749\n",
      "Train Epoch: 59 [5888/14860 (39%)]\tLoss: 0.021684\n",
      "Train Epoch: 59 [6016/14860 (40%)]\tLoss: 0.017097\n",
      "Train Epoch: 59 [6144/14860 (41%)]\tLoss: 0.019625\n",
      "Train Epoch: 59 [6272/14860 (42%)]\tLoss: 0.024405\n",
      "Train Epoch: 59 [6400/14860 (43%)]\tLoss: 0.019555\n",
      "Train Epoch: 59 [6528/14860 (44%)]\tLoss: 0.021768\n",
      "Train Epoch: 59 [6656/14860 (44%)]\tLoss: 0.018361\n",
      "Train Epoch: 59 [6784/14860 (45%)]\tLoss: 0.025322\n",
      "Train Epoch: 59 [6912/14860 (46%)]\tLoss: 0.017440\n",
      "Train Epoch: 59 [7040/14860 (47%)]\tLoss: 0.017497\n",
      "Train Epoch: 59 [7168/14860 (48%)]\tLoss: 0.020741\n",
      "Train Epoch: 59 [7296/14860 (49%)]\tLoss: 0.021277\n",
      "Train Epoch: 59 [7424/14860 (50%)]\tLoss: 0.022104\n",
      "Train Epoch: 59 [7552/14860 (50%)]\tLoss: 0.020032\n",
      "Train Epoch: 59 [7680/14860 (51%)]\tLoss: 0.013819\n",
      "Train Epoch: 59 [7808/14860 (52%)]\tLoss: 0.018064\n",
      "Train Epoch: 59 [7936/14860 (53%)]\tLoss: 0.017622\n",
      "Train Epoch: 59 [8064/14860 (54%)]\tLoss: 0.018818\n",
      "Train Epoch: 59 [8192/14860 (55%)]\tLoss: 0.022008\n",
      "Train Epoch: 59 [8320/14860 (56%)]\tLoss: 0.025850\n",
      "Train Epoch: 59 [8448/14860 (56%)]\tLoss: 0.018728\n",
      "Train Epoch: 59 [8576/14860 (57%)]\tLoss: 0.017548\n",
      "Train Epoch: 59 [8704/14860 (58%)]\tLoss: 0.020365\n",
      "Train Epoch: 59 [8832/14860 (59%)]\tLoss: 0.021453\n",
      "Train Epoch: 59 [8960/14860 (60%)]\tLoss: 0.017980\n",
      "Train Epoch: 59 [9088/14860 (61%)]\tLoss: 0.019515\n",
      "Train Epoch: 59 [9216/14860 (62%)]\tLoss: 0.020124\n",
      "Train Epoch: 59 [9344/14860 (62%)]\tLoss: 0.020423\n",
      "Train Epoch: 59 [9472/14860 (63%)]\tLoss: 0.026796\n",
      "Train Epoch: 59 [9600/14860 (64%)]\tLoss: 0.019563\n",
      "Train Epoch: 59 [9728/14860 (65%)]\tLoss: 0.017655\n",
      "Train Epoch: 59 [9856/14860 (66%)]\tLoss: 0.021013\n",
      "Train Epoch: 59 [9984/14860 (67%)]\tLoss: 0.013342\n",
      "Train Epoch: 59 [10112/14860 (68%)]\tLoss: 0.015233\n",
      "Train Epoch: 59 [10240/14860 (68%)]\tLoss: 0.018502\n",
      "Train Epoch: 59 [10368/14860 (69%)]\tLoss: 0.014617\n",
      "Train Epoch: 59 [10496/14860 (70%)]\tLoss: 0.019652\n",
      "Train Epoch: 59 [10624/14860 (71%)]\tLoss: 0.028697\n",
      "Train Epoch: 59 [10752/14860 (72%)]\tLoss: 0.013805\n",
      "Train Epoch: 59 [10880/14860 (73%)]\tLoss: 0.016341\n",
      "Train Epoch: 59 [11008/14860 (74%)]\tLoss: 0.019587\n",
      "Train Epoch: 59 [11136/14860 (74%)]\tLoss: 0.028454\n",
      "Train Epoch: 59 [11264/14860 (75%)]\tLoss: 0.021113\n",
      "Train Epoch: 59 [11392/14860 (76%)]\tLoss: 0.015276\n",
      "Train Epoch: 59 [11520/14860 (77%)]\tLoss: 0.017347\n",
      "Train Epoch: 59 [11648/14860 (78%)]\tLoss: 0.028145\n",
      "Train Epoch: 59 [11776/14860 (79%)]\tLoss: 0.016757\n",
      "Train Epoch: 59 [11904/14860 (79%)]\tLoss: 0.016205\n",
      "Train Epoch: 59 [12032/14860 (80%)]\tLoss: 0.015350\n",
      "Train Epoch: 59 [12160/14860 (81%)]\tLoss: 0.018538\n",
      "Train Epoch: 59 [12288/14860 (82%)]\tLoss: 0.024227\n",
      "Train Epoch: 59 [12416/14860 (83%)]\tLoss: 0.020502\n",
      "Train Epoch: 59 [12544/14860 (84%)]\tLoss: 0.015491\n",
      "Train Epoch: 59 [12672/14860 (85%)]\tLoss: 0.019578\n",
      "Train Epoch: 59 [12800/14860 (85%)]\tLoss: 0.021431\n",
      "Train Epoch: 59 [12928/14860 (86%)]\tLoss: 0.022027\n",
      "Train Epoch: 59 [13056/14860 (87%)]\tLoss: 0.021354\n",
      "Train Epoch: 59 [13184/14860 (88%)]\tLoss: 0.018683\n",
      "Train Epoch: 59 [13312/14860 (89%)]\tLoss: 0.017795\n",
      "Train Epoch: 59 [13440/14860 (90%)]\tLoss: 0.018274\n",
      "Train Epoch: 59 [13568/14860 (91%)]\tLoss: 0.013031\n",
      "Train Epoch: 59 [13696/14860 (91%)]\tLoss: 0.013772\n",
      "Train Epoch: 59 [13824/14860 (92%)]\tLoss: 0.014780\n",
      "Train Epoch: 59 [13952/14860 (93%)]\tLoss: 0.017823\n",
      "Train Epoch: 59 [14080/14860 (94%)]\tLoss: 0.016272\n",
      "Train Epoch: 59 [14208/14860 (95%)]\tLoss: 0.014123\n",
      "Train Epoch: 59 [14336/14860 (96%)]\tLoss: 0.020328\n",
      "Train Epoch: 59 [14464/14860 (97%)]\tLoss: 0.024674\n",
      "Train Epoch: 59 [14592/14860 (97%)]\tLoss: 0.015947\n",
      "Train Epoch: 59 [14720/14860 (98%)]\tLoss: 0.035358\n",
      "Train Epoch: 59 [1392/14860 (99%)]\tLoss: 0.009484\n",
      "epoch 59 training loss: 0.019463363891610734\n",
      "epoch 59 validation loss: 0.019983039424725364\n",
      "Train Epoch: 60 [0/14860 (0%)]\tLoss: 0.014664\n",
      "Train Epoch: 60 [128/14860 (1%)]\tLoss: 0.020936\n",
      "Train Epoch: 60 [256/14860 (2%)]\tLoss: 0.013055\n",
      "Train Epoch: 60 [384/14860 (3%)]\tLoss: 0.021587\n",
      "Train Epoch: 60 [512/14860 (3%)]\tLoss: 0.023112\n",
      "Train Epoch: 60 [640/14860 (4%)]\tLoss: 0.028073\n",
      "Train Epoch: 60 [768/14860 (5%)]\tLoss: 0.018842\n",
      "Train Epoch: 60 [896/14860 (6%)]\tLoss: 0.016646\n",
      "Train Epoch: 60 [1024/14860 (7%)]\tLoss: 0.011890\n",
      "Train Epoch: 60 [1152/14860 (8%)]\tLoss: 0.024842\n",
      "Train Epoch: 60 [1280/14860 (9%)]\tLoss: 0.021118\n",
      "Train Epoch: 60 [1408/14860 (9%)]\tLoss: 0.018510\n",
      "Train Epoch: 60 [1536/14860 (10%)]\tLoss: 0.017480\n",
      "Train Epoch: 60 [1664/14860 (11%)]\tLoss: 0.024882\n",
      "Train Epoch: 60 [1792/14860 (12%)]\tLoss: 0.018519\n",
      "Train Epoch: 60 [1920/14860 (13%)]\tLoss: 0.015821\n",
      "Train Epoch: 60 [2048/14860 (14%)]\tLoss: 0.017614\n",
      "Train Epoch: 60 [2176/14860 (15%)]\tLoss: 0.012961\n",
      "Train Epoch: 60 [2304/14860 (15%)]\tLoss: 0.019315\n",
      "Train Epoch: 60 [2432/14860 (16%)]\tLoss: 0.024197\n",
      "Train Epoch: 60 [2560/14860 (17%)]\tLoss: 0.020165\n",
      "Train Epoch: 60 [2688/14860 (18%)]\tLoss: 0.016540\n",
      "Train Epoch: 60 [2816/14860 (19%)]\tLoss: 0.012371\n",
      "Train Epoch: 60 [2944/14860 (20%)]\tLoss: 0.018815\n",
      "Train Epoch: 60 [3072/14860 (21%)]\tLoss: 0.016230\n",
      "Train Epoch: 60 [3200/14860 (21%)]\tLoss: 0.019268\n",
      "Train Epoch: 60 [3328/14860 (22%)]\tLoss: 0.019133\n",
      "Train Epoch: 60 [3456/14860 (23%)]\tLoss: 0.013580\n",
      "Train Epoch: 60 [3584/14860 (24%)]\tLoss: 0.030375\n",
      "Train Epoch: 60 [3712/14860 (25%)]\tLoss: 0.018912\n",
      "Train Epoch: 60 [3840/14860 (26%)]\tLoss: 0.021422\n",
      "Train Epoch: 60 [3968/14860 (26%)]\tLoss: 0.023373\n",
      "Train Epoch: 60 [4096/14860 (27%)]\tLoss: 0.021509\n",
      "Train Epoch: 60 [4224/14860 (28%)]\tLoss: 0.018829\n",
      "Train Epoch: 60 [4352/14860 (29%)]\tLoss: 0.020529\n",
      "Train Epoch: 60 [4480/14860 (30%)]\tLoss: 0.021393\n",
      "Train Epoch: 60 [4608/14860 (31%)]\tLoss: 0.028751\n",
      "Train Epoch: 60 [4736/14860 (32%)]\tLoss: 0.019038\n",
      "Train Epoch: 60 [4864/14860 (32%)]\tLoss: 0.030212\n",
      "Train Epoch: 60 [4992/14860 (33%)]\tLoss: 0.022674\n",
      "Train Epoch: 60 [5120/14860 (34%)]\tLoss: 0.018948\n",
      "Train Epoch: 60 [5248/14860 (35%)]\tLoss: 0.022017\n",
      "Train Epoch: 60 [5376/14860 (36%)]\tLoss: 0.024346\n",
      "Train Epoch: 60 [5504/14860 (37%)]\tLoss: 0.017484\n",
      "Train Epoch: 60 [5632/14860 (38%)]\tLoss: 0.016079\n",
      "Train Epoch: 60 [5760/14860 (38%)]\tLoss: 0.014630\n",
      "Train Epoch: 60 [5888/14860 (39%)]\tLoss: 0.014194\n",
      "Train Epoch: 60 [6016/14860 (40%)]\tLoss: 0.026769\n",
      "Train Epoch: 60 [6144/14860 (41%)]\tLoss: 0.018579\n",
      "Train Epoch: 60 [6272/14860 (42%)]\tLoss: 0.016177\n",
      "Train Epoch: 60 [6400/14860 (43%)]\tLoss: 0.023894\n",
      "Train Epoch: 60 [6528/14860 (44%)]\tLoss: 0.028713\n",
      "Train Epoch: 60 [6656/14860 (44%)]\tLoss: 0.015954\n",
      "Train Epoch: 60 [6784/14860 (45%)]\tLoss: 0.020903\n",
      "Train Epoch: 60 [6912/14860 (46%)]\tLoss: 0.013814\n",
      "Train Epoch: 60 [7040/14860 (47%)]\tLoss: 0.016493\n",
      "Train Epoch: 60 [7168/14860 (48%)]\tLoss: 0.017320\n",
      "Train Epoch: 60 [7296/14860 (49%)]\tLoss: 0.023924\n",
      "Train Epoch: 60 [7424/14860 (50%)]\tLoss: 0.017989\n",
      "Train Epoch: 60 [7552/14860 (50%)]\tLoss: 0.023919\n",
      "Train Epoch: 60 [7680/14860 (51%)]\tLoss: 0.021624\n",
      "Train Epoch: 60 [7808/14860 (52%)]\tLoss: 0.017600\n",
      "Train Epoch: 60 [7936/14860 (53%)]\tLoss: 0.017770\n",
      "Train Epoch: 60 [8064/14860 (54%)]\tLoss: 0.018165\n",
      "Train Epoch: 60 [8192/14860 (55%)]\tLoss: 0.025409\n",
      "Train Epoch: 60 [8320/14860 (56%)]\tLoss: 0.015935\n",
      "Train Epoch: 60 [8448/14860 (56%)]\tLoss: 0.022802\n",
      "Train Epoch: 60 [8576/14860 (57%)]\tLoss: 0.027241\n",
      "Train Epoch: 60 [8704/14860 (58%)]\tLoss: 0.018060\n",
      "Train Epoch: 60 [8832/14860 (59%)]\tLoss: 0.026875\n",
      "Train Epoch: 60 [8960/14860 (60%)]\tLoss: 0.020423\n",
      "Train Epoch: 60 [9088/14860 (61%)]\tLoss: 0.016432\n",
      "Train Epoch: 60 [9216/14860 (62%)]\tLoss: 0.018603\n",
      "Train Epoch: 60 [9344/14860 (62%)]\tLoss: 0.021728\n",
      "Train Epoch: 60 [9472/14860 (63%)]\tLoss: 0.018783\n",
      "Train Epoch: 60 [9600/14860 (64%)]\tLoss: 0.018408\n",
      "Train Epoch: 60 [9728/14860 (65%)]\tLoss: 0.014302\n",
      "Train Epoch: 60 [9856/14860 (66%)]\tLoss: 0.025560\n",
      "Train Epoch: 60 [9984/14860 (67%)]\tLoss: 0.022144\n",
      "Train Epoch: 60 [10112/14860 (68%)]\tLoss: 0.018081\n",
      "Train Epoch: 60 [10240/14860 (68%)]\tLoss: 0.019212\n",
      "Train Epoch: 60 [10368/14860 (69%)]\tLoss: 0.017653\n",
      "Train Epoch: 60 [10496/14860 (70%)]\tLoss: 0.013491\n",
      "Train Epoch: 60 [10624/14860 (71%)]\tLoss: 0.011677\n",
      "Train Epoch: 60 [10752/14860 (72%)]\tLoss: 0.025829\n",
      "Train Epoch: 60 [10880/14860 (73%)]\tLoss: 0.019522\n",
      "Train Epoch: 60 [11008/14860 (74%)]\tLoss: 0.015466\n",
      "Train Epoch: 60 [11136/14860 (74%)]\tLoss: 0.016233\n",
      "Train Epoch: 60 [11264/14860 (75%)]\tLoss: 0.021034\n",
      "Train Epoch: 60 [11392/14860 (76%)]\tLoss: 0.019139\n",
      "Train Epoch: 60 [11520/14860 (77%)]\tLoss: 0.032648\n",
      "Train Epoch: 60 [11648/14860 (78%)]\tLoss: 0.020020\n",
      "Train Epoch: 60 [11776/14860 (79%)]\tLoss: 0.027539\n",
      "Train Epoch: 60 [11904/14860 (79%)]\tLoss: 0.024562\n",
      "Train Epoch: 60 [12032/14860 (80%)]\tLoss: 0.016857\n",
      "Train Epoch: 60 [12160/14860 (81%)]\tLoss: 0.021351\n",
      "Train Epoch: 60 [12288/14860 (82%)]\tLoss: 0.013511\n",
      "Train Epoch: 60 [12416/14860 (83%)]\tLoss: 0.024308\n",
      "Train Epoch: 60 [12544/14860 (84%)]\tLoss: 0.020366\n",
      "Train Epoch: 60 [12672/14860 (85%)]\tLoss: 0.018598\n",
      "Train Epoch: 60 [12800/14860 (85%)]\tLoss: 0.023439\n",
      "Train Epoch: 60 [12928/14860 (86%)]\tLoss: 0.022781\n",
      "Train Epoch: 60 [13056/14860 (87%)]\tLoss: 0.019924\n",
      "Train Epoch: 60 [13184/14860 (88%)]\tLoss: 0.012640\n",
      "Train Epoch: 60 [13312/14860 (89%)]\tLoss: 0.020349\n",
      "Train Epoch: 60 [13440/14860 (90%)]\tLoss: 0.017022\n",
      "Train Epoch: 60 [13568/14860 (91%)]\tLoss: 0.017842\n",
      "Train Epoch: 60 [13696/14860 (91%)]\tLoss: 0.017701\n",
      "Train Epoch: 60 [13824/14860 (92%)]\tLoss: 0.018373\n",
      "Train Epoch: 60 [13952/14860 (93%)]\tLoss: 0.019956\n",
      "Train Epoch: 60 [14080/14860 (94%)]\tLoss: 0.022055\n",
      "Train Epoch: 60 [14208/14860 (95%)]\tLoss: 0.016596\n",
      "Train Epoch: 60 [14336/14860 (96%)]\tLoss: 0.021360\n",
      "Train Epoch: 60 [14464/14860 (97%)]\tLoss: 0.013789\n",
      "Train Epoch: 60 [14592/14860 (97%)]\tLoss: 0.019684\n",
      "Train Epoch: 60 [14720/14860 (98%)]\tLoss: 0.018350\n",
      "Train Epoch: 60 [1392/14860 (99%)]\tLoss: 0.010976\n",
      "epoch 60 training loss: 0.019719057612948947\n",
      "epoch 60 validation loss: 0.02078951350424538\n",
      "Train Epoch: 61 [0/14860 (0%)]\tLoss: 0.016781\n",
      "Train Epoch: 61 [128/14860 (1%)]\tLoss: 0.016914\n",
      "Train Epoch: 61 [256/14860 (2%)]\tLoss: 0.016202\n",
      "Train Epoch: 61 [384/14860 (3%)]\tLoss: 0.019888\n",
      "Train Epoch: 61 [512/14860 (3%)]\tLoss: 0.021376\n",
      "Train Epoch: 61 [640/14860 (4%)]\tLoss: 0.029907\n",
      "Train Epoch: 61 [768/14860 (5%)]\tLoss: 0.015160\n",
      "Train Epoch: 61 [896/14860 (6%)]\tLoss: 0.014507\n",
      "Train Epoch: 61 [1024/14860 (7%)]\tLoss: 0.016372\n",
      "Train Epoch: 61 [1152/14860 (8%)]\tLoss: 0.025516\n",
      "Train Epoch: 61 [1280/14860 (9%)]\tLoss: 0.028376\n",
      "Train Epoch: 61 [1408/14860 (9%)]\tLoss: 0.015566\n",
      "Train Epoch: 61 [1536/14860 (10%)]\tLoss: 0.020411\n",
      "Train Epoch: 61 [1664/14860 (11%)]\tLoss: 0.014960\n",
      "Train Epoch: 61 [1792/14860 (12%)]\tLoss: 0.019949\n",
      "Train Epoch: 61 [1920/14860 (13%)]\tLoss: 0.023091\n",
      "Train Epoch: 61 [2048/14860 (14%)]\tLoss: 0.021860\n",
      "Train Epoch: 61 [2176/14860 (15%)]\tLoss: 0.016337\n",
      "Train Epoch: 61 [2304/14860 (15%)]\tLoss: 0.015739\n",
      "Train Epoch: 61 [2432/14860 (16%)]\tLoss: 0.023867\n",
      "Train Epoch: 61 [2560/14860 (17%)]\tLoss: 0.027843\n",
      "Train Epoch: 61 [2688/14860 (18%)]\tLoss: 0.017170\n",
      "Train Epoch: 61 [2816/14860 (19%)]\tLoss: 0.023766\n",
      "Train Epoch: 61 [2944/14860 (20%)]\tLoss: 0.015217\n",
      "Train Epoch: 61 [3072/14860 (21%)]\tLoss: 0.031623\n",
      "Train Epoch: 61 [3200/14860 (21%)]\tLoss: 0.026457\n",
      "Train Epoch: 61 [3328/14860 (22%)]\tLoss: 0.025807\n",
      "Train Epoch: 61 [3456/14860 (23%)]\tLoss: 0.019355\n",
      "Train Epoch: 61 [3584/14860 (24%)]\tLoss: 0.025006\n",
      "Train Epoch: 61 [3712/14860 (25%)]\tLoss: 0.016432\n",
      "Train Epoch: 61 [3840/14860 (26%)]\tLoss: 0.011129\n",
      "Train Epoch: 61 [3968/14860 (26%)]\tLoss: 0.023362\n",
      "Train Epoch: 61 [4096/14860 (27%)]\tLoss: 0.013679\n",
      "Train Epoch: 61 [4224/14860 (28%)]\tLoss: 0.014435\n",
      "Train Epoch: 61 [4352/14860 (29%)]\tLoss: 0.018023\n",
      "Train Epoch: 61 [4480/14860 (30%)]\tLoss: 0.018294\n",
      "Train Epoch: 61 [4608/14860 (31%)]\tLoss: 0.016310\n",
      "Train Epoch: 61 [4736/14860 (32%)]\tLoss: 0.012558\n",
      "Train Epoch: 61 [4864/14860 (32%)]\tLoss: 0.019042\n",
      "Train Epoch: 61 [4992/14860 (33%)]\tLoss: 0.020799\n",
      "Train Epoch: 61 [5120/14860 (34%)]\tLoss: 0.017262\n",
      "Train Epoch: 61 [5248/14860 (35%)]\tLoss: 0.017072\n",
      "Train Epoch: 61 [5376/14860 (36%)]\tLoss: 0.020736\n",
      "Train Epoch: 61 [5504/14860 (37%)]\tLoss: 0.013276\n",
      "Train Epoch: 61 [5632/14860 (38%)]\tLoss: 0.030514\n",
      "Train Epoch: 61 [5760/14860 (38%)]\tLoss: 0.018922\n",
      "Train Epoch: 61 [5888/14860 (39%)]\tLoss: 0.016320\n",
      "Train Epoch: 61 [6016/14860 (40%)]\tLoss: 0.028308\n",
      "Train Epoch: 61 [6144/14860 (41%)]\tLoss: 0.021684\n",
      "Train Epoch: 61 [6272/14860 (42%)]\tLoss: 0.012408\n",
      "Train Epoch: 61 [6400/14860 (43%)]\tLoss: 0.026462\n",
      "Train Epoch: 61 [6528/14860 (44%)]\tLoss: 0.017499\n",
      "Train Epoch: 61 [6656/14860 (44%)]\tLoss: 0.012686\n",
      "Train Epoch: 61 [6784/14860 (45%)]\tLoss: 0.029154\n",
      "Train Epoch: 61 [6912/14860 (46%)]\tLoss: 0.016754\n",
      "Train Epoch: 61 [7040/14860 (47%)]\tLoss: 0.023258\n",
      "Train Epoch: 61 [7168/14860 (48%)]\tLoss: 0.015682\n",
      "Train Epoch: 61 [7296/14860 (49%)]\tLoss: 0.023748\n",
      "Train Epoch: 61 [7424/14860 (50%)]\tLoss: 0.024301\n",
      "Train Epoch: 61 [7552/14860 (50%)]\tLoss: 0.023986\n",
      "Train Epoch: 61 [7680/14860 (51%)]\tLoss: 0.018908\n",
      "Train Epoch: 61 [7808/14860 (52%)]\tLoss: 0.022025\n",
      "Train Epoch: 61 [7936/14860 (53%)]\tLoss: 0.019916\n",
      "Train Epoch: 61 [8064/14860 (54%)]\tLoss: 0.020099\n",
      "Train Epoch: 61 [8192/14860 (55%)]\tLoss: 0.015328\n",
      "Train Epoch: 61 [8320/14860 (56%)]\tLoss: 0.018145\n",
      "Train Epoch: 61 [8448/14860 (56%)]\tLoss: 0.017948\n",
      "Train Epoch: 61 [8576/14860 (57%)]\tLoss: 0.023191\n",
      "Train Epoch: 61 [8704/14860 (58%)]\tLoss: 0.018410\n",
      "Train Epoch: 61 [8832/14860 (59%)]\tLoss: 0.016191\n",
      "Train Epoch: 61 [8960/14860 (60%)]\tLoss: 0.014003\n",
      "Train Epoch: 61 [9088/14860 (61%)]\tLoss: 0.017112\n",
      "Train Epoch: 61 [9216/14860 (62%)]\tLoss: 0.019392\n",
      "Train Epoch: 61 [9344/14860 (62%)]\tLoss: 0.018459\n",
      "Train Epoch: 61 [9472/14860 (63%)]\tLoss: 0.019147\n",
      "Train Epoch: 61 [9600/14860 (64%)]\tLoss: 0.022297\n",
      "Train Epoch: 61 [9728/14860 (65%)]\tLoss: 0.014528\n",
      "Train Epoch: 61 [9856/14860 (66%)]\tLoss: 0.020107\n",
      "Train Epoch: 61 [9984/14860 (67%)]\tLoss: 0.016251\n",
      "Train Epoch: 61 [10112/14860 (68%)]\tLoss: 0.022440\n",
      "Train Epoch: 61 [10240/14860 (68%)]\tLoss: 0.017032\n",
      "Train Epoch: 61 [10368/14860 (69%)]\tLoss: 0.022170\n",
      "Train Epoch: 61 [10496/14860 (70%)]\tLoss: 0.016885\n",
      "Train Epoch: 61 [10624/14860 (71%)]\tLoss: 0.022625\n",
      "Train Epoch: 61 [10752/14860 (72%)]\tLoss: 0.021587\n",
      "Train Epoch: 61 [10880/14860 (73%)]\tLoss: 0.013004\n",
      "Train Epoch: 61 [11008/14860 (74%)]\tLoss: 0.015284\n",
      "Train Epoch: 61 [11136/14860 (74%)]\tLoss: 0.020411\n",
      "Train Epoch: 61 [11264/14860 (75%)]\tLoss: 0.017330\n",
      "Train Epoch: 61 [11392/14860 (76%)]\tLoss: 0.019649\n",
      "Train Epoch: 61 [11520/14860 (77%)]\tLoss: 0.021581\n",
      "Train Epoch: 61 [11648/14860 (78%)]\tLoss: 0.015652\n",
      "Train Epoch: 61 [11776/14860 (79%)]\tLoss: 0.019840\n",
      "Train Epoch: 61 [11904/14860 (79%)]\tLoss: 0.013414\n",
      "Train Epoch: 61 [12032/14860 (80%)]\tLoss: 0.019342\n",
      "Train Epoch: 61 [12160/14860 (81%)]\tLoss: 0.037248\n",
      "Train Epoch: 61 [12288/14860 (82%)]\tLoss: 0.023853\n",
      "Train Epoch: 61 [12416/14860 (83%)]\tLoss: 0.024083\n",
      "Train Epoch: 61 [12544/14860 (84%)]\tLoss: 0.021767\n",
      "Train Epoch: 61 [12672/14860 (85%)]\tLoss: 0.021878\n",
      "Train Epoch: 61 [12800/14860 (85%)]\tLoss: 0.022416\n",
      "Train Epoch: 61 [12928/14860 (86%)]\tLoss: 0.026920\n",
      "Train Epoch: 61 [13056/14860 (87%)]\tLoss: 0.014431\n",
      "Train Epoch: 61 [13184/14860 (88%)]\tLoss: 0.023098\n",
      "Train Epoch: 61 [13312/14860 (89%)]\tLoss: 0.012225\n",
      "Train Epoch: 61 [13440/14860 (90%)]\tLoss: 0.011168\n",
      "Train Epoch: 61 [13568/14860 (91%)]\tLoss: 0.020339\n",
      "Train Epoch: 61 [13696/14860 (91%)]\tLoss: 0.021534\n",
      "Train Epoch: 61 [13824/14860 (92%)]\tLoss: 0.023031\n",
      "Train Epoch: 61 [13952/14860 (93%)]\tLoss: 0.021323\n",
      "Train Epoch: 61 [14080/14860 (94%)]\tLoss: 0.014720\n",
      "Train Epoch: 61 [14208/14860 (95%)]\tLoss: 0.024340\n",
      "Train Epoch: 61 [14336/14860 (96%)]\tLoss: 0.021398\n",
      "Train Epoch: 61 [14464/14860 (97%)]\tLoss: 0.025620\n",
      "Train Epoch: 61 [14592/14860 (97%)]\tLoss: 0.025680\n",
      "Train Epoch: 61 [14720/14860 (98%)]\tLoss: 0.021815\n",
      "Train Epoch: 61 [1392/14860 (99%)]\tLoss: 0.046106\n",
      "epoch 61 training loss: 0.020118085564010672\n",
      "epoch 61 validation loss: 0.0279117314636563\n",
      "Train Epoch: 62 [0/14860 (0%)]\tLoss: 0.030856\n",
      "Train Epoch: 62 [128/14860 (1%)]\tLoss: 0.019841\n",
      "Train Epoch: 62 [256/14860 (2%)]\tLoss: 0.015640\n",
      "Train Epoch: 62 [384/14860 (3%)]\tLoss: 0.019983\n",
      "Train Epoch: 62 [512/14860 (3%)]\tLoss: 0.030474\n",
      "Train Epoch: 62 [640/14860 (4%)]\tLoss: 0.030294\n",
      "Train Epoch: 62 [768/14860 (5%)]\tLoss: 0.018599\n",
      "Train Epoch: 62 [896/14860 (6%)]\tLoss: 0.024375\n",
      "Train Epoch: 62 [1024/14860 (7%)]\tLoss: 0.025343\n",
      "Train Epoch: 62 [1152/14860 (8%)]\tLoss: 0.015073\n",
      "Train Epoch: 62 [1280/14860 (9%)]\tLoss: 0.018830\n",
      "Train Epoch: 62 [1408/14860 (9%)]\tLoss: 0.018292\n",
      "Train Epoch: 62 [1536/14860 (10%)]\tLoss: 0.021917\n",
      "Train Epoch: 62 [1664/14860 (11%)]\tLoss: 0.014396\n",
      "Train Epoch: 62 [1792/14860 (12%)]\tLoss: 0.018019\n",
      "Train Epoch: 62 [1920/14860 (13%)]\tLoss: 0.023820\n",
      "Train Epoch: 62 [2048/14860 (14%)]\tLoss: 0.028357\n",
      "Train Epoch: 62 [2176/14860 (15%)]\tLoss: 0.018526\n",
      "Train Epoch: 62 [2304/14860 (15%)]\tLoss: 0.017973\n",
      "Train Epoch: 62 [2432/14860 (16%)]\tLoss: 0.025904\n",
      "Train Epoch: 62 [2560/14860 (17%)]\tLoss: 0.028887\n",
      "Train Epoch: 62 [2688/14860 (18%)]\tLoss: 0.025059\n",
      "Train Epoch: 62 [2816/14860 (19%)]\tLoss: 0.016787\n",
      "Train Epoch: 62 [2944/14860 (20%)]\tLoss: 0.027817\n",
      "Train Epoch: 62 [3072/14860 (21%)]\tLoss: 0.020089\n",
      "Train Epoch: 62 [3200/14860 (21%)]\tLoss: 0.015006\n",
      "Train Epoch: 62 [3328/14860 (22%)]\tLoss: 0.021927\n",
      "Train Epoch: 62 [3456/14860 (23%)]\tLoss: 0.030933\n",
      "Train Epoch: 62 [3584/14860 (24%)]\tLoss: 0.025529\n",
      "Train Epoch: 62 [3712/14860 (25%)]\tLoss: 0.021650\n",
      "Train Epoch: 62 [3840/14860 (26%)]\tLoss: 0.023870\n",
      "Train Epoch: 62 [3968/14860 (26%)]\tLoss: 0.020923\n",
      "Train Epoch: 62 [4096/14860 (27%)]\tLoss: 0.020960\n",
      "Train Epoch: 62 [4224/14860 (28%)]\tLoss: 0.013150\n",
      "Train Epoch: 62 [4352/14860 (29%)]\tLoss: 0.019994\n",
      "Train Epoch: 62 [4480/14860 (30%)]\tLoss: 0.027478\n",
      "Train Epoch: 62 [4608/14860 (31%)]\tLoss: 0.015877\n",
      "Train Epoch: 62 [4736/14860 (32%)]\tLoss: 0.023987\n",
      "Train Epoch: 62 [4864/14860 (32%)]\tLoss: 0.019770\n",
      "Train Epoch: 62 [4992/14860 (33%)]\tLoss: 0.025620\n",
      "Train Epoch: 62 [5120/14860 (34%)]\tLoss: 0.020550\n",
      "Train Epoch: 62 [5248/14860 (35%)]\tLoss: 0.019560\n",
      "Train Epoch: 62 [5376/14860 (36%)]\tLoss: 0.019133\n",
      "Train Epoch: 62 [5504/14860 (37%)]\tLoss: 0.022538\n",
      "Train Epoch: 62 [5632/14860 (38%)]\tLoss: 0.032226\n",
      "Train Epoch: 62 [5760/14860 (38%)]\tLoss: 0.013661\n",
      "Train Epoch: 62 [5888/14860 (39%)]\tLoss: 0.018321\n",
      "Train Epoch: 62 [6016/14860 (40%)]\tLoss: 0.021965\n",
      "Train Epoch: 62 [6144/14860 (41%)]\tLoss: 0.016768\n",
      "Train Epoch: 62 [6272/14860 (42%)]\tLoss: 0.023484\n",
      "Train Epoch: 62 [6400/14860 (43%)]\tLoss: 0.021332\n",
      "Train Epoch: 62 [6528/14860 (44%)]\tLoss: 0.021096\n",
      "Train Epoch: 62 [6656/14860 (44%)]\tLoss: 0.017573\n",
      "Train Epoch: 62 [6784/14860 (45%)]\tLoss: 0.019586\n",
      "Train Epoch: 62 [6912/14860 (46%)]\tLoss: 0.015496\n",
      "Train Epoch: 62 [7040/14860 (47%)]\tLoss: 0.017683\n",
      "Train Epoch: 62 [7168/14860 (48%)]\tLoss: 0.014181\n",
      "Train Epoch: 62 [7296/14860 (49%)]\tLoss: 0.016547\n",
      "Train Epoch: 62 [7424/14860 (50%)]\tLoss: 0.019691\n",
      "Train Epoch: 62 [7552/14860 (50%)]\tLoss: 0.014257\n",
      "Train Epoch: 62 [7680/14860 (51%)]\tLoss: 0.016023\n",
      "Train Epoch: 62 [7808/14860 (52%)]\tLoss: 0.020421\n",
      "Train Epoch: 62 [7936/14860 (53%)]\tLoss: 0.013400\n",
      "Train Epoch: 62 [8064/14860 (54%)]\tLoss: 0.017993\n",
      "Train Epoch: 62 [8192/14860 (55%)]\tLoss: 0.020969\n",
      "Train Epoch: 62 [8320/14860 (56%)]\tLoss: 0.016508\n",
      "Train Epoch: 62 [8448/14860 (56%)]\tLoss: 0.017282\n",
      "Train Epoch: 62 [8576/14860 (57%)]\tLoss: 0.021410\n",
      "Train Epoch: 62 [8704/14860 (58%)]\tLoss: 0.018762\n",
      "Train Epoch: 62 [8832/14860 (59%)]\tLoss: 0.024642\n",
      "Train Epoch: 62 [8960/14860 (60%)]\tLoss: 0.020349\n",
      "Train Epoch: 62 [9088/14860 (61%)]\tLoss: 0.023785\n",
      "Train Epoch: 62 [9216/14860 (62%)]\tLoss: 0.016061\n",
      "Train Epoch: 62 [9344/14860 (62%)]\tLoss: 0.020919\n",
      "Train Epoch: 62 [9472/14860 (63%)]\tLoss: 0.021149\n",
      "Train Epoch: 62 [9600/14860 (64%)]\tLoss: 0.018518\n",
      "Train Epoch: 62 [9728/14860 (65%)]\tLoss: 0.015919\n",
      "Train Epoch: 62 [9856/14860 (66%)]\tLoss: 0.019167\n",
      "Train Epoch: 62 [9984/14860 (67%)]\tLoss: 0.016180\n",
      "Train Epoch: 62 [10112/14860 (68%)]\tLoss: 0.014034\n",
      "Train Epoch: 62 [10240/14860 (68%)]\tLoss: 0.017583\n",
      "Train Epoch: 62 [10368/14860 (69%)]\tLoss: 0.023210\n",
      "Train Epoch: 62 [10496/14860 (70%)]\tLoss: 0.018528\n",
      "Train Epoch: 62 [10624/14860 (71%)]\tLoss: 0.021626\n",
      "Train Epoch: 62 [10752/14860 (72%)]\tLoss: 0.021086\n",
      "Train Epoch: 62 [10880/14860 (73%)]\tLoss: 0.017899\n",
      "Train Epoch: 62 [11008/14860 (74%)]\tLoss: 0.023800\n",
      "Train Epoch: 62 [11136/14860 (74%)]\tLoss: 0.015734\n",
      "Train Epoch: 62 [11264/14860 (75%)]\tLoss: 0.020280\n",
      "Train Epoch: 62 [11392/14860 (76%)]\tLoss: 0.020796\n",
      "Train Epoch: 62 [11520/14860 (77%)]\tLoss: 0.025651\n",
      "Train Epoch: 62 [11648/14860 (78%)]\tLoss: 0.020966\n",
      "Train Epoch: 62 [11776/14860 (79%)]\tLoss: 0.019574\n",
      "Train Epoch: 62 [11904/14860 (79%)]\tLoss: 0.017613\n",
      "Train Epoch: 62 [12032/14860 (80%)]\tLoss: 0.011613\n",
      "Train Epoch: 62 [12160/14860 (81%)]\tLoss: 0.018550\n",
      "Train Epoch: 62 [12288/14860 (82%)]\tLoss: 0.020137\n",
      "Train Epoch: 62 [12416/14860 (83%)]\tLoss: 0.018367\n",
      "Train Epoch: 62 [12544/14860 (84%)]\tLoss: 0.017728\n",
      "Train Epoch: 62 [12672/14860 (85%)]\tLoss: 0.019481\n",
      "Train Epoch: 62 [12800/14860 (85%)]\tLoss: 0.019569\n",
      "Train Epoch: 62 [12928/14860 (86%)]\tLoss: 0.017163\n",
      "Train Epoch: 62 [13056/14860 (87%)]\tLoss: 0.017034\n",
      "Train Epoch: 62 [13184/14860 (88%)]\tLoss: 0.014966\n",
      "Train Epoch: 62 [13312/14860 (89%)]\tLoss: 0.022519\n",
      "Train Epoch: 62 [13440/14860 (90%)]\tLoss: 0.021273\n",
      "Train Epoch: 62 [13568/14860 (91%)]\tLoss: 0.013175\n",
      "Train Epoch: 62 [13696/14860 (91%)]\tLoss: 0.014300\n",
      "Train Epoch: 62 [13824/14860 (92%)]\tLoss: 0.024608\n",
      "Train Epoch: 62 [13952/14860 (93%)]\tLoss: 0.017696\n",
      "Train Epoch: 62 [14080/14860 (94%)]\tLoss: 0.016856\n",
      "Train Epoch: 62 [14208/14860 (95%)]\tLoss: 0.019259\n",
      "Train Epoch: 62 [14336/14860 (96%)]\tLoss: 0.017265\n",
      "Train Epoch: 62 [14464/14860 (97%)]\tLoss: 0.017868\n",
      "Train Epoch: 62 [14592/14860 (97%)]\tLoss: 0.023911\n",
      "Train Epoch: 62 [14720/14860 (98%)]\tLoss: 0.021689\n",
      "Train Epoch: 62 [1392/14860 (99%)]\tLoss: 0.041160\n",
      "epoch 62 training loss: 0.02026918017042753\n",
      "epoch 62 validation loss: 0.021663676018287715\n",
      "Train Epoch: 63 [0/14860 (0%)]\tLoss: 0.018924\n",
      "Train Epoch: 63 [128/14860 (1%)]\tLoss: 0.009933\n",
      "Train Epoch: 63 [256/14860 (2%)]\tLoss: 0.030324\n",
      "Train Epoch: 63 [384/14860 (3%)]\tLoss: 0.016797\n",
      "Train Epoch: 63 [512/14860 (3%)]\tLoss: 0.013586\n",
      "Train Epoch: 63 [640/14860 (4%)]\tLoss: 0.017648\n",
      "Train Epoch: 63 [768/14860 (5%)]\tLoss: 0.017113\n",
      "Train Epoch: 63 [896/14860 (6%)]\tLoss: 0.017959\n",
      "Train Epoch: 63 [1024/14860 (7%)]\tLoss: 0.018267\n",
      "Train Epoch: 63 [1152/14860 (8%)]\tLoss: 0.019076\n",
      "Train Epoch: 63 [1280/14860 (9%)]\tLoss: 0.017312\n",
      "Train Epoch: 63 [1408/14860 (9%)]\tLoss: 0.011426\n",
      "Train Epoch: 63 [1536/14860 (10%)]\tLoss: 0.018619\n",
      "Train Epoch: 63 [1664/14860 (11%)]\tLoss: 0.015605\n",
      "Train Epoch: 63 [1792/14860 (12%)]\tLoss: 0.026879\n",
      "Train Epoch: 63 [1920/14860 (13%)]\tLoss: 0.022827\n",
      "Train Epoch: 63 [2048/14860 (14%)]\tLoss: 0.020048\n",
      "Train Epoch: 63 [2176/14860 (15%)]\tLoss: 0.015856\n",
      "Train Epoch: 63 [2304/14860 (15%)]\tLoss: 0.017218\n",
      "Train Epoch: 63 [2432/14860 (16%)]\tLoss: 0.021728\n",
      "Train Epoch: 63 [2560/14860 (17%)]\tLoss: 0.017565\n",
      "Train Epoch: 63 [2688/14860 (18%)]\tLoss: 0.014824\n",
      "Train Epoch: 63 [2816/14860 (19%)]\tLoss: 0.023035\n",
      "Train Epoch: 63 [2944/14860 (20%)]\tLoss: 0.013987\n",
      "Train Epoch: 63 [3072/14860 (21%)]\tLoss: 0.013417\n",
      "Train Epoch: 63 [3200/14860 (21%)]\tLoss: 0.024568\n",
      "Train Epoch: 63 [3328/14860 (22%)]\tLoss: 0.022210\n",
      "Train Epoch: 63 [3456/14860 (23%)]\tLoss: 0.016881\n",
      "Train Epoch: 63 [3584/14860 (24%)]\tLoss: 0.014513\n",
      "Train Epoch: 63 [3712/14860 (25%)]\tLoss: 0.024525\n",
      "Train Epoch: 63 [3840/14860 (26%)]\tLoss: 0.024377\n",
      "Train Epoch: 63 [3968/14860 (26%)]\tLoss: 0.019216\n",
      "Train Epoch: 63 [4096/14860 (27%)]\tLoss: 0.020808\n",
      "Train Epoch: 63 [4224/14860 (28%)]\tLoss: 0.024325\n",
      "Train Epoch: 63 [4352/14860 (29%)]\tLoss: 0.025687\n",
      "Train Epoch: 63 [4480/14860 (30%)]\tLoss: 0.015675\n",
      "Train Epoch: 63 [4608/14860 (31%)]\tLoss: 0.016699\n",
      "Train Epoch: 63 [4736/14860 (32%)]\tLoss: 0.022592\n",
      "Train Epoch: 63 [4864/14860 (32%)]\tLoss: 0.017274\n",
      "Train Epoch: 63 [4992/14860 (33%)]\tLoss: 0.017768\n",
      "Train Epoch: 63 [5120/14860 (34%)]\tLoss: 0.021065\n",
      "Train Epoch: 63 [5248/14860 (35%)]\tLoss: 0.013903\n",
      "Train Epoch: 63 [5376/14860 (36%)]\tLoss: 0.020941\n",
      "Train Epoch: 63 [5504/14860 (37%)]\tLoss: 0.021047\n",
      "Train Epoch: 63 [5632/14860 (38%)]\tLoss: 0.024262\n",
      "Train Epoch: 63 [5760/14860 (38%)]\tLoss: 0.016450\n",
      "Train Epoch: 63 [5888/14860 (39%)]\tLoss: 0.032314\n",
      "Train Epoch: 63 [6016/14860 (40%)]\tLoss: 0.016841\n",
      "Train Epoch: 63 [6144/14860 (41%)]\tLoss: 0.019498\n",
      "Train Epoch: 63 [6272/14860 (42%)]\tLoss: 0.024743\n",
      "Train Epoch: 63 [6400/14860 (43%)]\tLoss: 0.025895\n",
      "Train Epoch: 63 [6528/14860 (44%)]\tLoss: 0.021662\n",
      "Train Epoch: 63 [6656/14860 (44%)]\tLoss: 0.022475\n",
      "Train Epoch: 63 [6784/14860 (45%)]\tLoss: 0.018045\n",
      "Train Epoch: 63 [6912/14860 (46%)]\tLoss: 0.019639\n",
      "Train Epoch: 63 [7040/14860 (47%)]\tLoss: 0.025356\n",
      "Train Epoch: 63 [7168/14860 (48%)]\tLoss: 0.023212\n",
      "Train Epoch: 63 [7296/14860 (49%)]\tLoss: 0.019048\n",
      "Train Epoch: 63 [7424/14860 (50%)]\tLoss: 0.015399\n",
      "Train Epoch: 63 [7552/14860 (50%)]\tLoss: 0.021614\n",
      "Train Epoch: 63 [7680/14860 (51%)]\tLoss: 0.020351\n",
      "Train Epoch: 63 [7808/14860 (52%)]\tLoss: 0.016716\n",
      "Train Epoch: 63 [7936/14860 (53%)]\tLoss: 0.016353\n",
      "Train Epoch: 63 [8064/14860 (54%)]\tLoss: 0.018810\n",
      "Train Epoch: 63 [8192/14860 (55%)]\tLoss: 0.018052\n",
      "Train Epoch: 63 [8320/14860 (56%)]\tLoss: 0.016671\n",
      "Train Epoch: 63 [8448/14860 (56%)]\tLoss: 0.018479\n",
      "Train Epoch: 63 [8576/14860 (57%)]\tLoss: 0.016123\n",
      "Train Epoch: 63 [8704/14860 (58%)]\tLoss: 0.020989\n",
      "Train Epoch: 63 [8832/14860 (59%)]\tLoss: 0.022250\n",
      "Train Epoch: 63 [8960/14860 (60%)]\tLoss: 0.013369\n",
      "Train Epoch: 63 [9088/14860 (61%)]\tLoss: 0.019321\n",
      "Train Epoch: 63 [9216/14860 (62%)]\tLoss: 0.015206\n",
      "Train Epoch: 63 [9344/14860 (62%)]\tLoss: 0.018311\n",
      "Train Epoch: 63 [9472/14860 (63%)]\tLoss: 0.014378\n",
      "Train Epoch: 63 [9600/14860 (64%)]\tLoss: 0.010816\n",
      "Train Epoch: 63 [9728/14860 (65%)]\tLoss: 0.018593\n",
      "Train Epoch: 63 [9856/14860 (66%)]\tLoss: 0.016523\n",
      "Train Epoch: 63 [9984/14860 (67%)]\tLoss: 0.021721\n",
      "Train Epoch: 63 [10112/14860 (68%)]\tLoss: 0.029851\n",
      "Train Epoch: 63 [10240/14860 (68%)]\tLoss: 0.027688\n",
      "Train Epoch: 63 [10368/14860 (69%)]\tLoss: 0.017567\n",
      "Train Epoch: 63 [10496/14860 (70%)]\tLoss: 0.012780\n",
      "Train Epoch: 63 [10624/14860 (71%)]\tLoss: 0.021000\n",
      "Train Epoch: 63 [10752/14860 (72%)]\tLoss: 0.022826\n",
      "Train Epoch: 63 [10880/14860 (73%)]\tLoss: 0.018329\n",
      "Train Epoch: 63 [11008/14860 (74%)]\tLoss: 0.012924\n",
      "Train Epoch: 63 [11136/14860 (74%)]\tLoss: 0.018503\n",
      "Train Epoch: 63 [11264/14860 (75%)]\tLoss: 0.021731\n",
      "Train Epoch: 63 [11392/14860 (76%)]\tLoss: 0.020587\n",
      "Train Epoch: 63 [11520/14860 (77%)]\tLoss: 0.017864\n",
      "Train Epoch: 63 [11648/14860 (78%)]\tLoss: 0.017123\n",
      "Train Epoch: 63 [11776/14860 (79%)]\tLoss: 0.016100\n",
      "Train Epoch: 63 [11904/14860 (79%)]\tLoss: 0.015571\n",
      "Train Epoch: 63 [12032/14860 (80%)]\tLoss: 0.023518\n",
      "Train Epoch: 63 [12160/14860 (81%)]\tLoss: 0.020069\n",
      "Train Epoch: 63 [12288/14860 (82%)]\tLoss: 0.023743\n",
      "Train Epoch: 63 [12416/14860 (83%)]\tLoss: 0.018740\n",
      "Train Epoch: 63 [12544/14860 (84%)]\tLoss: 0.020035\n",
      "Train Epoch: 63 [12672/14860 (85%)]\tLoss: 0.020039\n",
      "Train Epoch: 63 [12800/14860 (85%)]\tLoss: 0.022482\n",
      "Train Epoch: 63 [12928/14860 (86%)]\tLoss: 0.020006\n",
      "Train Epoch: 63 [13056/14860 (87%)]\tLoss: 0.013678\n",
      "Train Epoch: 63 [13184/14860 (88%)]\tLoss: 0.015849\n",
      "Train Epoch: 63 [13312/14860 (89%)]\tLoss: 0.013967\n",
      "Train Epoch: 63 [13440/14860 (90%)]\tLoss: 0.014974\n",
      "Train Epoch: 63 [13568/14860 (91%)]\tLoss: 0.019331\n",
      "Train Epoch: 63 [13696/14860 (91%)]\tLoss: 0.020500\n",
      "Train Epoch: 63 [13824/14860 (92%)]\tLoss: 0.017998\n",
      "Train Epoch: 63 [13952/14860 (93%)]\tLoss: 0.017891\n",
      "Train Epoch: 63 [14080/14860 (94%)]\tLoss: 0.015187\n",
      "Train Epoch: 63 [14208/14860 (95%)]\tLoss: 0.011908\n",
      "Train Epoch: 63 [14336/14860 (96%)]\tLoss: 0.016438\n",
      "Train Epoch: 63 [14464/14860 (97%)]\tLoss: 0.021094\n",
      "Train Epoch: 63 [14592/14860 (97%)]\tLoss: 0.013086\n",
      "Train Epoch: 63 [14720/14860 (98%)]\tLoss: 0.014469\n",
      "Train Epoch: 63 [1392/14860 (99%)]\tLoss: 0.012525\n",
      "epoch 63 training loss: 0.018901723452931285\n",
      "epoch 63 validation loss: 0.019905584776372654\n",
      "Train Epoch: 64 [0/14860 (0%)]\tLoss: 0.025194\n",
      "Train Epoch: 64 [128/14860 (1%)]\tLoss: 0.017708\n",
      "Train Epoch: 64 [256/14860 (2%)]\tLoss: 0.017704\n",
      "Train Epoch: 64 [384/14860 (3%)]\tLoss: 0.018620\n",
      "Train Epoch: 64 [512/14860 (3%)]\tLoss: 0.015416\n",
      "Train Epoch: 64 [640/14860 (4%)]\tLoss: 0.019926\n",
      "Train Epoch: 64 [768/14860 (5%)]\tLoss: 0.017294\n",
      "Train Epoch: 64 [896/14860 (6%)]\tLoss: 0.013313\n",
      "Train Epoch: 64 [1024/14860 (7%)]\tLoss: 0.014966\n",
      "Train Epoch: 64 [1152/14860 (8%)]\tLoss: 0.019671\n",
      "Train Epoch: 64 [1280/14860 (9%)]\tLoss: 0.020244\n",
      "Train Epoch: 64 [1408/14860 (9%)]\tLoss: 0.032480\n",
      "Train Epoch: 64 [1536/14860 (10%)]\tLoss: 0.028595\n",
      "Train Epoch: 64 [1664/14860 (11%)]\tLoss: 0.019815\n",
      "Train Epoch: 64 [1792/14860 (12%)]\tLoss: 0.025191\n",
      "Train Epoch: 64 [1920/14860 (13%)]\tLoss: 0.018966\n",
      "Train Epoch: 64 [2048/14860 (14%)]\tLoss: 0.027083\n",
      "Train Epoch: 64 [2176/14860 (15%)]\tLoss: 0.019453\n",
      "Train Epoch: 64 [2304/14860 (15%)]\tLoss: 0.013627\n",
      "Train Epoch: 64 [2432/14860 (16%)]\tLoss: 0.032357\n",
      "Train Epoch: 64 [2560/14860 (17%)]\tLoss: 0.017368\n",
      "Train Epoch: 64 [2688/14860 (18%)]\tLoss: 0.013913\n",
      "Train Epoch: 64 [2816/14860 (19%)]\tLoss: 0.013921\n",
      "Train Epoch: 64 [2944/14860 (20%)]\tLoss: 0.018371\n",
      "Train Epoch: 64 [3072/14860 (21%)]\tLoss: 0.013201\n",
      "Train Epoch: 64 [3200/14860 (21%)]\tLoss: 0.020657\n",
      "Train Epoch: 64 [3328/14860 (22%)]\tLoss: 0.020626\n",
      "Train Epoch: 64 [3456/14860 (23%)]\tLoss: 0.021463\n",
      "Train Epoch: 64 [3584/14860 (24%)]\tLoss: 0.014227\n",
      "Train Epoch: 64 [3712/14860 (25%)]\tLoss: 0.017199\n",
      "Train Epoch: 64 [3840/14860 (26%)]\tLoss: 0.013182\n",
      "Train Epoch: 64 [3968/14860 (26%)]\tLoss: 0.024106\n",
      "Train Epoch: 64 [4096/14860 (27%)]\tLoss: 0.021664\n",
      "Train Epoch: 64 [4224/14860 (28%)]\tLoss: 0.023183\n",
      "Train Epoch: 64 [4352/14860 (29%)]\tLoss: 0.022108\n",
      "Train Epoch: 64 [4480/14860 (30%)]\tLoss: 0.014676\n",
      "Train Epoch: 64 [4608/14860 (31%)]\tLoss: 0.021916\n",
      "Train Epoch: 64 [4736/14860 (32%)]\tLoss: 0.031223\n",
      "Train Epoch: 64 [4864/14860 (32%)]\tLoss: 0.027009\n",
      "Train Epoch: 64 [4992/14860 (33%)]\tLoss: 0.024567\n",
      "Train Epoch: 64 [5120/14860 (34%)]\tLoss: 0.025728\n",
      "Train Epoch: 64 [5248/14860 (35%)]\tLoss: 0.015220\n",
      "Train Epoch: 64 [5376/14860 (36%)]\tLoss: 0.021612\n",
      "Train Epoch: 64 [5504/14860 (37%)]\tLoss: 0.022936\n",
      "Train Epoch: 64 [5632/14860 (38%)]\tLoss: 0.025038\n",
      "Train Epoch: 64 [5760/14860 (38%)]\tLoss: 0.023667\n",
      "Train Epoch: 64 [5888/14860 (39%)]\tLoss: 0.026183\n",
      "Train Epoch: 64 [6016/14860 (40%)]\tLoss: 0.021762\n",
      "Train Epoch: 64 [6144/14860 (41%)]\tLoss: 0.018844\n",
      "Train Epoch: 64 [6272/14860 (42%)]\tLoss: 0.025548\n",
      "Train Epoch: 64 [6400/14860 (43%)]\tLoss: 0.026858\n",
      "Train Epoch: 64 [6528/14860 (44%)]\tLoss: 0.024856\n",
      "Train Epoch: 64 [6656/14860 (44%)]\tLoss: 0.028070\n",
      "Train Epoch: 64 [6784/14860 (45%)]\tLoss: 0.019186\n",
      "Train Epoch: 64 [6912/14860 (46%)]\tLoss: 0.024429\n",
      "Train Epoch: 64 [7040/14860 (47%)]\tLoss: 0.014938\n",
      "Train Epoch: 64 [7168/14860 (48%)]\tLoss: 0.017254\n",
      "Train Epoch: 64 [7296/14860 (49%)]\tLoss: 0.022145\n",
      "Train Epoch: 64 [7424/14860 (50%)]\tLoss: 0.015489\n",
      "Train Epoch: 64 [7552/14860 (50%)]\tLoss: 0.016456\n",
      "Train Epoch: 64 [7680/14860 (51%)]\tLoss: 0.021480\n",
      "Train Epoch: 64 [7808/14860 (52%)]\tLoss: 0.022587\n",
      "Train Epoch: 64 [7936/14860 (53%)]\tLoss: 0.017254\n",
      "Train Epoch: 64 [8064/14860 (54%)]\tLoss: 0.013946\n",
      "Train Epoch: 64 [8192/14860 (55%)]\tLoss: 0.026352\n",
      "Train Epoch: 64 [8320/14860 (56%)]\tLoss: 0.020065\n",
      "Train Epoch: 64 [8448/14860 (56%)]\tLoss: 0.017386\n",
      "Train Epoch: 64 [8576/14860 (57%)]\tLoss: 0.026361\n",
      "Train Epoch: 64 [8704/14860 (58%)]\tLoss: 0.017221\n",
      "Train Epoch: 64 [8832/14860 (59%)]\tLoss: 0.019503\n",
      "Train Epoch: 64 [8960/14860 (60%)]\tLoss: 0.022107\n",
      "Train Epoch: 64 [9088/14860 (61%)]\tLoss: 0.014813\n",
      "Train Epoch: 64 [9216/14860 (62%)]\tLoss: 0.013992\n",
      "Train Epoch: 64 [9344/14860 (62%)]\tLoss: 0.018107\n",
      "Train Epoch: 64 [9472/14860 (63%)]\tLoss: 0.024271\n",
      "Train Epoch: 64 [9600/14860 (64%)]\tLoss: 0.023299\n",
      "Train Epoch: 64 [9728/14860 (65%)]\tLoss: 0.014130\n",
      "Train Epoch: 64 [9856/14860 (66%)]\tLoss: 0.023945\n",
      "Train Epoch: 64 [9984/14860 (67%)]\tLoss: 0.021472\n",
      "Train Epoch: 64 [10112/14860 (68%)]\tLoss: 0.018425\n",
      "Train Epoch: 64 [10240/14860 (68%)]\tLoss: 0.015907\n",
      "Train Epoch: 64 [10368/14860 (69%)]\tLoss: 0.014050\n",
      "Train Epoch: 64 [10496/14860 (70%)]\tLoss: 0.017587\n",
      "Train Epoch: 64 [10624/14860 (71%)]\tLoss: 0.022902\n",
      "Train Epoch: 64 [10752/14860 (72%)]\tLoss: 0.013193\n",
      "Train Epoch: 64 [10880/14860 (73%)]\tLoss: 0.021930\n",
      "Train Epoch: 64 [11008/14860 (74%)]\tLoss: 0.011124\n",
      "Train Epoch: 64 [11136/14860 (74%)]\tLoss: 0.012497\n",
      "Train Epoch: 64 [11264/14860 (75%)]\tLoss: 0.017488\n",
      "Train Epoch: 64 [11392/14860 (76%)]\tLoss: 0.019831\n",
      "Train Epoch: 64 [11520/14860 (77%)]\tLoss: 0.015020\n",
      "Train Epoch: 64 [11648/14860 (78%)]\tLoss: 0.019252\n",
      "Train Epoch: 64 [11776/14860 (79%)]\tLoss: 0.020280\n",
      "Train Epoch: 64 [11904/14860 (79%)]\tLoss: 0.012297\n",
      "Train Epoch: 64 [12032/14860 (80%)]\tLoss: 0.021729\n",
      "Train Epoch: 64 [12160/14860 (81%)]\tLoss: 0.018570\n",
      "Train Epoch: 64 [12288/14860 (82%)]\tLoss: 0.018602\n",
      "Train Epoch: 64 [12416/14860 (83%)]\tLoss: 0.016560\n",
      "Train Epoch: 64 [12544/14860 (84%)]\tLoss: 0.020353\n",
      "Train Epoch: 64 [12672/14860 (85%)]\tLoss: 0.021031\n",
      "Train Epoch: 64 [12800/14860 (85%)]\tLoss: 0.018173\n",
      "Train Epoch: 64 [12928/14860 (86%)]\tLoss: 0.017241\n",
      "Train Epoch: 64 [13056/14860 (87%)]\tLoss: 0.020126\n",
      "Train Epoch: 64 [13184/14860 (88%)]\tLoss: 0.013112\n",
      "Train Epoch: 64 [13312/14860 (89%)]\tLoss: 0.019409\n",
      "Train Epoch: 64 [13440/14860 (90%)]\tLoss: 0.018820\n",
      "Train Epoch: 64 [13568/14860 (91%)]\tLoss: 0.014031\n",
      "Train Epoch: 64 [13696/14860 (91%)]\tLoss: 0.012084\n",
      "Train Epoch: 64 [13824/14860 (92%)]\tLoss: 0.013528\n",
      "Train Epoch: 64 [13952/14860 (93%)]\tLoss: 0.023278\n",
      "Train Epoch: 64 [14080/14860 (94%)]\tLoss: 0.015220\n",
      "Train Epoch: 64 [14208/14860 (95%)]\tLoss: 0.019397\n",
      "Train Epoch: 64 [14336/14860 (96%)]\tLoss: 0.016560\n",
      "Train Epoch: 64 [14464/14860 (97%)]\tLoss: 0.025210\n",
      "Train Epoch: 64 [14592/14860 (97%)]\tLoss: 0.017926\n",
      "Train Epoch: 64 [14720/14860 (98%)]\tLoss: 0.018599\n",
      "Train Epoch: 64 [1392/14860 (99%)]\tLoss: 0.007319\n",
      "epoch 64 training loss: 0.01953311935544778\n",
      "epoch 64 validation loss: 0.021497784457541552\n",
      "Train Epoch: 65 [0/14860 (0%)]\tLoss: 0.018688\n",
      "Train Epoch: 65 [128/14860 (1%)]\tLoss: 0.017941\n",
      "Train Epoch: 65 [256/14860 (2%)]\tLoss: 0.014848\n",
      "Train Epoch: 65 [384/14860 (3%)]\tLoss: 0.017713\n",
      "Train Epoch: 65 [512/14860 (3%)]\tLoss: 0.018677\n",
      "Train Epoch: 65 [640/14860 (4%)]\tLoss: 0.021815\n",
      "Train Epoch: 65 [768/14860 (5%)]\tLoss: 0.017019\n",
      "Train Epoch: 65 [896/14860 (6%)]\tLoss: 0.015049\n",
      "Train Epoch: 65 [1024/14860 (7%)]\tLoss: 0.019890\n",
      "Train Epoch: 65 [1152/14860 (8%)]\tLoss: 0.017123\n",
      "Train Epoch: 65 [1280/14860 (9%)]\tLoss: 0.013732\n",
      "Train Epoch: 65 [1408/14860 (9%)]\tLoss: 0.016613\n",
      "Train Epoch: 65 [1536/14860 (10%)]\tLoss: 0.017125\n",
      "Train Epoch: 65 [1664/14860 (11%)]\tLoss: 0.015465\n",
      "Train Epoch: 65 [1792/14860 (12%)]\tLoss: 0.015808\n",
      "Train Epoch: 65 [1920/14860 (13%)]\tLoss: 0.018872\n",
      "Train Epoch: 65 [2048/14860 (14%)]\tLoss: 0.016435\n",
      "Train Epoch: 65 [2176/14860 (15%)]\tLoss: 0.016972\n",
      "Train Epoch: 65 [2304/14860 (15%)]\tLoss: 0.022667\n",
      "Train Epoch: 65 [2432/14860 (16%)]\tLoss: 0.015083\n",
      "Train Epoch: 65 [2560/14860 (17%)]\tLoss: 0.018660\n",
      "Train Epoch: 65 [2688/14860 (18%)]\tLoss: 0.018730\n",
      "Train Epoch: 65 [2816/14860 (19%)]\tLoss: 0.022112\n",
      "Train Epoch: 65 [2944/14860 (20%)]\tLoss: 0.020134\n",
      "Train Epoch: 65 [3072/14860 (21%)]\tLoss: 0.020543\n",
      "Train Epoch: 65 [3200/14860 (21%)]\tLoss: 0.029497\n",
      "Train Epoch: 65 [3328/14860 (22%)]\tLoss: 0.023155\n",
      "Train Epoch: 65 [3456/14860 (23%)]\tLoss: 0.022553\n",
      "Train Epoch: 65 [3584/14860 (24%)]\tLoss: 0.023745\n",
      "Train Epoch: 65 [3712/14860 (25%)]\tLoss: 0.016989\n",
      "Train Epoch: 65 [3840/14860 (26%)]\tLoss: 0.022003\n",
      "Train Epoch: 65 [3968/14860 (26%)]\tLoss: 0.019672\n",
      "Train Epoch: 65 [4096/14860 (27%)]\tLoss: 0.022412\n",
      "Train Epoch: 65 [4224/14860 (28%)]\tLoss: 0.017575\n",
      "Train Epoch: 65 [4352/14860 (29%)]\tLoss: 0.016100\n",
      "Train Epoch: 65 [4480/14860 (30%)]\tLoss: 0.019323\n",
      "Train Epoch: 65 [4608/14860 (31%)]\tLoss: 0.025977\n",
      "Train Epoch: 65 [4736/14860 (32%)]\tLoss: 0.017460\n",
      "Train Epoch: 65 [4864/14860 (32%)]\tLoss: 0.014669\n",
      "Train Epoch: 65 [4992/14860 (33%)]\tLoss: 0.017359\n",
      "Train Epoch: 65 [5120/14860 (34%)]\tLoss: 0.010800\n",
      "Train Epoch: 65 [5248/14860 (35%)]\tLoss: 0.022343\n",
      "Train Epoch: 65 [5376/14860 (36%)]\tLoss: 0.013880\n",
      "Train Epoch: 65 [5504/14860 (37%)]\tLoss: 0.013755\n",
      "Train Epoch: 65 [5632/14860 (38%)]\tLoss: 0.014724\n",
      "Train Epoch: 65 [5760/14860 (38%)]\tLoss: 0.022875\n",
      "Train Epoch: 65 [5888/14860 (39%)]\tLoss: 0.017635\n",
      "Train Epoch: 65 [6016/14860 (40%)]\tLoss: 0.021745\n",
      "Train Epoch: 65 [6144/14860 (41%)]\tLoss: 0.021538\n",
      "Train Epoch: 65 [6272/14860 (42%)]\tLoss: 0.018948\n",
      "Train Epoch: 65 [6400/14860 (43%)]\tLoss: 0.020081\n",
      "Train Epoch: 65 [6528/14860 (44%)]\tLoss: 0.014106\n",
      "Train Epoch: 65 [6656/14860 (44%)]\tLoss: 0.024452\n",
      "Train Epoch: 65 [6784/14860 (45%)]\tLoss: 0.016593\n",
      "Train Epoch: 65 [6912/14860 (46%)]\tLoss: 0.020319\n",
      "Train Epoch: 65 [7040/14860 (47%)]\tLoss: 0.014928\n",
      "Train Epoch: 65 [7168/14860 (48%)]\tLoss: 0.021706\n",
      "Train Epoch: 65 [7296/14860 (49%)]\tLoss: 0.024808\n",
      "Train Epoch: 65 [7424/14860 (50%)]\tLoss: 0.011703\n",
      "Train Epoch: 65 [7552/14860 (50%)]\tLoss: 0.021369\n",
      "Train Epoch: 65 [7680/14860 (51%)]\tLoss: 0.024750\n",
      "Train Epoch: 65 [7808/14860 (52%)]\tLoss: 0.015128\n",
      "Train Epoch: 65 [7936/14860 (53%)]\tLoss: 0.012962\n",
      "Train Epoch: 65 [8064/14860 (54%)]\tLoss: 0.018611\n",
      "Train Epoch: 65 [8192/14860 (55%)]\tLoss: 0.022009\n",
      "Train Epoch: 65 [8320/14860 (56%)]\tLoss: 0.018502\n",
      "Train Epoch: 65 [8448/14860 (56%)]\tLoss: 0.023146\n",
      "Train Epoch: 65 [8576/14860 (57%)]\tLoss: 0.022447\n",
      "Train Epoch: 65 [8704/14860 (58%)]\tLoss: 0.023119\n",
      "Train Epoch: 65 [8832/14860 (59%)]\tLoss: 0.022365\n",
      "Train Epoch: 65 [8960/14860 (60%)]\tLoss: 0.013625\n",
      "Train Epoch: 65 [9088/14860 (61%)]\tLoss: 0.017830\n",
      "Train Epoch: 65 [9216/14860 (62%)]\tLoss: 0.022133\n",
      "Train Epoch: 65 [9344/14860 (62%)]\tLoss: 0.021713\n",
      "Train Epoch: 65 [9472/14860 (63%)]\tLoss: 0.016925\n",
      "Train Epoch: 65 [9600/14860 (64%)]\tLoss: 0.016485\n",
      "Train Epoch: 65 [9728/14860 (65%)]\tLoss: 0.017568\n",
      "Train Epoch: 65 [9856/14860 (66%)]\tLoss: 0.021128\n",
      "Train Epoch: 65 [9984/14860 (67%)]\tLoss: 0.025444\n",
      "Train Epoch: 65 [10112/14860 (68%)]\tLoss: 0.020264\n",
      "Train Epoch: 65 [10240/14860 (68%)]\tLoss: 0.016599\n",
      "Train Epoch: 65 [10368/14860 (69%)]\tLoss: 0.025379\n",
      "Train Epoch: 65 [10496/14860 (70%)]\tLoss: 0.015337\n",
      "Train Epoch: 65 [10624/14860 (71%)]\tLoss: 0.030211\n",
      "Train Epoch: 65 [10752/14860 (72%)]\tLoss: 0.019460\n",
      "Train Epoch: 65 [10880/14860 (73%)]\tLoss: 0.015441\n",
      "Train Epoch: 65 [11008/14860 (74%)]\tLoss: 0.015333\n",
      "Train Epoch: 65 [11136/14860 (74%)]\tLoss: 0.022995\n",
      "Train Epoch: 65 [11264/14860 (75%)]\tLoss: 0.017611\n",
      "Train Epoch: 65 [11392/14860 (76%)]\tLoss: 0.025786\n",
      "Train Epoch: 65 [11520/14860 (77%)]\tLoss: 0.023064\n",
      "Train Epoch: 65 [11648/14860 (78%)]\tLoss: 0.014170\n",
      "Train Epoch: 65 [11776/14860 (79%)]\tLoss: 0.015989\n",
      "Train Epoch: 65 [11904/14860 (79%)]\tLoss: 0.021496\n",
      "Train Epoch: 65 [12032/14860 (80%)]\tLoss: 0.027165\n",
      "Train Epoch: 65 [12160/14860 (81%)]\tLoss: 0.017690\n",
      "Train Epoch: 65 [12288/14860 (82%)]\tLoss: 0.022736\n",
      "Train Epoch: 65 [12416/14860 (83%)]\tLoss: 0.019864\n",
      "Train Epoch: 65 [12544/14860 (84%)]\tLoss: 0.017659\n",
      "Train Epoch: 65 [12672/14860 (85%)]\tLoss: 0.019641\n",
      "Train Epoch: 65 [12800/14860 (85%)]\tLoss: 0.025399\n",
      "Train Epoch: 65 [12928/14860 (86%)]\tLoss: 0.015522\n",
      "Train Epoch: 65 [13056/14860 (87%)]\tLoss: 0.022901\n",
      "Train Epoch: 65 [13184/14860 (88%)]\tLoss: 0.020186\n",
      "Train Epoch: 65 [13312/14860 (89%)]\tLoss: 0.026682\n",
      "Train Epoch: 65 [13440/14860 (90%)]\tLoss: 0.021713\n",
      "Train Epoch: 65 [13568/14860 (91%)]\tLoss: 0.020852\n",
      "Train Epoch: 65 [13696/14860 (91%)]\tLoss: 0.026042\n",
      "Train Epoch: 65 [13824/14860 (92%)]\tLoss: 0.021721\n",
      "Train Epoch: 65 [13952/14860 (93%)]\tLoss: 0.013254\n",
      "Train Epoch: 65 [14080/14860 (94%)]\tLoss: 0.016163\n",
      "Train Epoch: 65 [14208/14860 (95%)]\tLoss: 0.018665\n",
      "Train Epoch: 65 [14336/14860 (96%)]\tLoss: 0.017411\n",
      "Train Epoch: 65 [14464/14860 (97%)]\tLoss: 0.021848\n",
      "Train Epoch: 65 [14592/14860 (97%)]\tLoss: 0.018832\n",
      "Train Epoch: 65 [14720/14860 (98%)]\tLoss: 0.017939\n",
      "Train Epoch: 65 [1392/14860 (99%)]\tLoss: 0.009874\n",
      "epoch 65 training loss: 0.019310205235567868\n",
      "epoch 65 validation loss: 0.019824916672764332\n",
      "Train Epoch: 66 [0/14860 (0%)]\tLoss: 0.019250\n",
      "Train Epoch: 66 [128/14860 (1%)]\tLoss: 0.016281\n",
      "Train Epoch: 66 [256/14860 (2%)]\tLoss: 0.019679\n",
      "Train Epoch: 66 [384/14860 (3%)]\tLoss: 0.025867\n",
      "Train Epoch: 66 [512/14860 (3%)]\tLoss: 0.020469\n",
      "Train Epoch: 66 [640/14860 (4%)]\tLoss: 0.024067\n",
      "Train Epoch: 66 [768/14860 (5%)]\tLoss: 0.015320\n",
      "Train Epoch: 66 [896/14860 (6%)]\tLoss: 0.026687\n",
      "Train Epoch: 66 [1024/14860 (7%)]\tLoss: 0.014784\n",
      "Train Epoch: 66 [1152/14860 (8%)]\tLoss: 0.016311\n",
      "Train Epoch: 66 [1280/14860 (9%)]\tLoss: 0.017023\n",
      "Train Epoch: 66 [1408/14860 (9%)]\tLoss: 0.012389\n",
      "Train Epoch: 66 [1536/14860 (10%)]\tLoss: 0.022217\n",
      "Train Epoch: 66 [1664/14860 (11%)]\tLoss: 0.021666\n",
      "Train Epoch: 66 [1792/14860 (12%)]\tLoss: 0.015105\n",
      "Train Epoch: 66 [1920/14860 (13%)]\tLoss: 0.016742\n",
      "Train Epoch: 66 [2048/14860 (14%)]\tLoss: 0.017408\n",
      "Train Epoch: 66 [2176/14860 (15%)]\tLoss: 0.014740\n",
      "Train Epoch: 66 [2304/14860 (15%)]\tLoss: 0.017100\n",
      "Train Epoch: 66 [2432/14860 (16%)]\tLoss: 0.016353\n",
      "Train Epoch: 66 [2560/14860 (17%)]\tLoss: 0.017058\n",
      "Train Epoch: 66 [2688/14860 (18%)]\tLoss: 0.031548\n",
      "Train Epoch: 66 [2816/14860 (19%)]\tLoss: 0.014323\n",
      "Train Epoch: 66 [2944/14860 (20%)]\tLoss: 0.016842\n",
      "Train Epoch: 66 [3072/14860 (21%)]\tLoss: 0.014206\n",
      "Train Epoch: 66 [3200/14860 (21%)]\tLoss: 0.015990\n",
      "Train Epoch: 66 [3328/14860 (22%)]\tLoss: 0.030370\n",
      "Train Epoch: 66 [3456/14860 (23%)]\tLoss: 0.014937\n",
      "Train Epoch: 66 [3584/14860 (24%)]\tLoss: 0.014868\n",
      "Train Epoch: 66 [3712/14860 (25%)]\tLoss: 0.017796\n",
      "Train Epoch: 66 [3840/14860 (26%)]\tLoss: 0.021339\n",
      "Train Epoch: 66 [3968/14860 (26%)]\tLoss: 0.010745\n",
      "Train Epoch: 66 [4096/14860 (27%)]\tLoss: 0.014614\n",
      "Train Epoch: 66 [4224/14860 (28%)]\tLoss: 0.017292\n",
      "Train Epoch: 66 [4352/14860 (29%)]\tLoss: 0.012880\n",
      "Train Epoch: 66 [4480/14860 (30%)]\tLoss: 0.031670\n",
      "Train Epoch: 66 [4608/14860 (31%)]\tLoss: 0.014273\n",
      "Train Epoch: 66 [4736/14860 (32%)]\tLoss: 0.025000\n",
      "Train Epoch: 66 [4864/14860 (32%)]\tLoss: 0.020981\n",
      "Train Epoch: 66 [4992/14860 (33%)]\tLoss: 0.016593\n",
      "Train Epoch: 66 [5120/14860 (34%)]\tLoss: 0.016090\n",
      "Train Epoch: 66 [5248/14860 (35%)]\tLoss: 0.030155\n",
      "Train Epoch: 66 [5376/14860 (36%)]\tLoss: 0.023700\n",
      "Train Epoch: 66 [5504/14860 (37%)]\tLoss: 0.026735\n",
      "Train Epoch: 66 [5632/14860 (38%)]\tLoss: 0.023888\n",
      "Train Epoch: 66 [5760/14860 (38%)]\tLoss: 0.025835\n",
      "Train Epoch: 66 [5888/14860 (39%)]\tLoss: 0.017960\n",
      "Train Epoch: 66 [6016/14860 (40%)]\tLoss: 0.015138\n",
      "Train Epoch: 66 [6144/14860 (41%)]\tLoss: 0.012505\n",
      "Train Epoch: 66 [6272/14860 (42%)]\tLoss: 0.019307\n",
      "Train Epoch: 66 [6400/14860 (43%)]\tLoss: 0.013269\n",
      "Train Epoch: 66 [6528/14860 (44%)]\tLoss: 0.011022\n",
      "Train Epoch: 66 [6656/14860 (44%)]\tLoss: 0.012930\n",
      "Train Epoch: 66 [6784/14860 (45%)]\tLoss: 0.019291\n",
      "Train Epoch: 66 [6912/14860 (46%)]\tLoss: 0.016858\n",
      "Train Epoch: 66 [7040/14860 (47%)]\tLoss: 0.025172\n",
      "Train Epoch: 66 [7168/14860 (48%)]\tLoss: 0.022670\n",
      "Train Epoch: 66 [7296/14860 (49%)]\tLoss: 0.025249\n",
      "Train Epoch: 66 [7424/14860 (50%)]\tLoss: 0.016480\n",
      "Train Epoch: 66 [7552/14860 (50%)]\tLoss: 0.016261\n",
      "Train Epoch: 66 [7680/14860 (51%)]\tLoss: 0.018465\n",
      "Train Epoch: 66 [7808/14860 (52%)]\tLoss: 0.022357\n",
      "Train Epoch: 66 [7936/14860 (53%)]\tLoss: 0.019929\n",
      "Train Epoch: 66 [8064/14860 (54%)]\tLoss: 0.022290\n",
      "Train Epoch: 66 [8192/14860 (55%)]\tLoss: 0.021934\n",
      "Train Epoch: 66 [8320/14860 (56%)]\tLoss: 0.021033\n",
      "Train Epoch: 66 [8448/14860 (56%)]\tLoss: 0.020180\n",
      "Train Epoch: 66 [8576/14860 (57%)]\tLoss: 0.017181\n",
      "Train Epoch: 66 [8704/14860 (58%)]\tLoss: 0.018363\n",
      "Train Epoch: 66 [8832/14860 (59%)]\tLoss: 0.020312\n",
      "Train Epoch: 66 [8960/14860 (60%)]\tLoss: 0.016113\n",
      "Train Epoch: 66 [9088/14860 (61%)]\tLoss: 0.025683\n",
      "Train Epoch: 66 [9216/14860 (62%)]\tLoss: 0.022934\n",
      "Train Epoch: 66 [9344/14860 (62%)]\tLoss: 0.014741\n",
      "Train Epoch: 66 [9472/14860 (63%)]\tLoss: 0.020722\n",
      "Train Epoch: 66 [9600/14860 (64%)]\tLoss: 0.013521\n",
      "Train Epoch: 66 [9728/14860 (65%)]\tLoss: 0.020232\n",
      "Train Epoch: 66 [9856/14860 (66%)]\tLoss: 0.027082\n",
      "Train Epoch: 66 [9984/14860 (67%)]\tLoss: 0.012574\n",
      "Train Epoch: 66 [10112/14860 (68%)]\tLoss: 0.019620\n",
      "Train Epoch: 66 [10240/14860 (68%)]\tLoss: 0.018743\n",
      "Train Epoch: 66 [10368/14860 (69%)]\tLoss: 0.022492\n",
      "Train Epoch: 66 [10496/14860 (70%)]\tLoss: 0.017767\n",
      "Train Epoch: 66 [10624/14860 (71%)]\tLoss: 0.021499\n",
      "Train Epoch: 66 [10752/14860 (72%)]\tLoss: 0.017068\n",
      "Train Epoch: 66 [10880/14860 (73%)]\tLoss: 0.021292\n",
      "Train Epoch: 66 [11008/14860 (74%)]\tLoss: 0.017793\n",
      "Train Epoch: 66 [11136/14860 (74%)]\tLoss: 0.019143\n",
      "Train Epoch: 66 [11264/14860 (75%)]\tLoss: 0.013233\n",
      "Train Epoch: 66 [11392/14860 (76%)]\tLoss: 0.024287\n",
      "Train Epoch: 66 [11520/14860 (77%)]\tLoss: 0.013903\n",
      "Train Epoch: 66 [11648/14860 (78%)]\tLoss: 0.019120\n",
      "Train Epoch: 66 [11776/14860 (79%)]\tLoss: 0.024698\n",
      "Train Epoch: 66 [11904/14860 (79%)]\tLoss: 0.022032\n",
      "Train Epoch: 66 [12032/14860 (80%)]\tLoss: 0.021660\n",
      "Train Epoch: 66 [12160/14860 (81%)]\tLoss: 0.013454\n",
      "Train Epoch: 66 [12288/14860 (82%)]\tLoss: 0.018350\n",
      "Train Epoch: 66 [12416/14860 (83%)]\tLoss: 0.020943\n",
      "Train Epoch: 66 [12544/14860 (84%)]\tLoss: 0.026320\n",
      "Train Epoch: 66 [12672/14860 (85%)]\tLoss: 0.020336\n",
      "Train Epoch: 66 [12800/14860 (85%)]\tLoss: 0.019941\n",
      "Train Epoch: 66 [12928/14860 (86%)]\tLoss: 0.019860\n",
      "Train Epoch: 66 [13056/14860 (87%)]\tLoss: 0.022375\n",
      "Train Epoch: 66 [13184/14860 (88%)]\tLoss: 0.019026\n",
      "Train Epoch: 66 [13312/14860 (89%)]\tLoss: 0.025287\n",
      "Train Epoch: 66 [13440/14860 (90%)]\tLoss: 0.018188\n",
      "Train Epoch: 66 [13568/14860 (91%)]\tLoss: 0.015127\n",
      "Train Epoch: 66 [13696/14860 (91%)]\tLoss: 0.016863\n",
      "Train Epoch: 66 [13824/14860 (92%)]\tLoss: 0.018775\n",
      "Train Epoch: 66 [13952/14860 (93%)]\tLoss: 0.017741\n",
      "Train Epoch: 66 [14080/14860 (94%)]\tLoss: 0.020702\n",
      "Train Epoch: 66 [14208/14860 (95%)]\tLoss: 0.025217\n",
      "Train Epoch: 66 [14336/14860 (96%)]\tLoss: 0.033235\n",
      "Train Epoch: 66 [14464/14860 (97%)]\tLoss: 0.012287\n",
      "Train Epoch: 66 [14592/14860 (97%)]\tLoss: 0.014043\n",
      "Train Epoch: 66 [14720/14860 (98%)]\tLoss: 0.019979\n",
      "Train Epoch: 66 [1392/14860 (99%)]\tLoss: 0.032605\n",
      "epoch 66 training loss: 0.019435407920207225\n",
      "epoch 66 validation loss: 0.021051335998655232\n",
      "Train Epoch: 67 [0/14860 (0%)]\tLoss: 0.014134\n",
      "Train Epoch: 67 [128/14860 (1%)]\tLoss: 0.022411\n",
      "Train Epoch: 67 [256/14860 (2%)]\tLoss: 0.018378\n",
      "Train Epoch: 67 [384/14860 (3%)]\tLoss: 0.018496\n",
      "Train Epoch: 67 [512/14860 (3%)]\tLoss: 0.023893\n",
      "Train Epoch: 67 [640/14860 (4%)]\tLoss: 0.016321\n",
      "Train Epoch: 67 [768/14860 (5%)]\tLoss: 0.019155\n",
      "Train Epoch: 67 [896/14860 (6%)]\tLoss: 0.023264\n",
      "Train Epoch: 67 [1024/14860 (7%)]\tLoss: 0.017767\n",
      "Train Epoch: 67 [1152/14860 (8%)]\tLoss: 0.013607\n",
      "Train Epoch: 67 [1280/14860 (9%)]\tLoss: 0.013238\n",
      "Train Epoch: 67 [1408/14860 (9%)]\tLoss: 0.019347\n",
      "Train Epoch: 67 [1536/14860 (10%)]\tLoss: 0.018276\n",
      "Train Epoch: 67 [1664/14860 (11%)]\tLoss: 0.022178\n",
      "Train Epoch: 67 [1792/14860 (12%)]\tLoss: 0.018776\n",
      "Train Epoch: 67 [1920/14860 (13%)]\tLoss: 0.016706\n",
      "Train Epoch: 67 [2048/14860 (14%)]\tLoss: 0.024030\n",
      "Train Epoch: 67 [2176/14860 (15%)]\tLoss: 0.022558\n",
      "Train Epoch: 67 [2304/14860 (15%)]\tLoss: 0.019910\n",
      "Train Epoch: 67 [2432/14860 (16%)]\tLoss: 0.017529\n",
      "Train Epoch: 67 [2560/14860 (17%)]\tLoss: 0.017347\n",
      "Train Epoch: 67 [2688/14860 (18%)]\tLoss: 0.021499\n",
      "Train Epoch: 67 [2816/14860 (19%)]\tLoss: 0.026231\n",
      "Train Epoch: 67 [2944/14860 (20%)]\tLoss: 0.019304\n",
      "Train Epoch: 67 [3072/14860 (21%)]\tLoss: 0.015077\n",
      "Train Epoch: 67 [3200/14860 (21%)]\tLoss: 0.021027\n",
      "Train Epoch: 67 [3328/14860 (22%)]\tLoss: 0.018748\n",
      "Train Epoch: 67 [3456/14860 (23%)]\tLoss: 0.024883\n",
      "Train Epoch: 67 [3584/14860 (24%)]\tLoss: 0.013293\n",
      "Train Epoch: 67 [3712/14860 (25%)]\tLoss: 0.016926\n",
      "Train Epoch: 67 [3840/14860 (26%)]\tLoss: 0.014099\n",
      "Train Epoch: 67 [3968/14860 (26%)]\tLoss: 0.018971\n",
      "Train Epoch: 67 [4096/14860 (27%)]\tLoss: 0.018665\n",
      "Train Epoch: 67 [4224/14860 (28%)]\tLoss: 0.016847\n",
      "Train Epoch: 67 [4352/14860 (29%)]\tLoss: 0.026767\n",
      "Train Epoch: 67 [4480/14860 (30%)]\tLoss: 0.017943\n",
      "Train Epoch: 67 [4608/14860 (31%)]\tLoss: 0.017367\n",
      "Train Epoch: 67 [4736/14860 (32%)]\tLoss: 0.017365\n",
      "Train Epoch: 67 [4864/14860 (32%)]\tLoss: 0.014172\n",
      "Train Epoch: 67 [4992/14860 (33%)]\tLoss: 0.019331\n",
      "Train Epoch: 67 [5120/14860 (34%)]\tLoss: 0.019126\n",
      "Train Epoch: 67 [5248/14860 (35%)]\tLoss: 0.023360\n",
      "Train Epoch: 67 [5376/14860 (36%)]\tLoss: 0.012869\n",
      "Train Epoch: 67 [5504/14860 (37%)]\tLoss: 0.014796\n",
      "Train Epoch: 67 [5632/14860 (38%)]\tLoss: 0.018389\n",
      "Train Epoch: 67 [5760/14860 (38%)]\tLoss: 0.014202\n",
      "Train Epoch: 67 [5888/14860 (39%)]\tLoss: 0.015318\n",
      "Train Epoch: 67 [6016/14860 (40%)]\tLoss: 0.016924\n",
      "Train Epoch: 67 [6144/14860 (41%)]\tLoss: 0.019606\n",
      "Train Epoch: 67 [6272/14860 (42%)]\tLoss: 0.016204\n",
      "Train Epoch: 67 [6400/14860 (43%)]\tLoss: 0.018292\n",
      "Train Epoch: 67 [6528/14860 (44%)]\tLoss: 0.018707\n",
      "Train Epoch: 67 [6656/14860 (44%)]\tLoss: 0.021549\n",
      "Train Epoch: 67 [6784/14860 (45%)]\tLoss: 0.015593\n",
      "Train Epoch: 67 [6912/14860 (46%)]\tLoss: 0.019871\n",
      "Train Epoch: 67 [7040/14860 (47%)]\tLoss: 0.011826\n",
      "Train Epoch: 67 [7168/14860 (48%)]\tLoss: 0.019033\n",
      "Train Epoch: 67 [7296/14860 (49%)]\tLoss: 0.024901\n",
      "Train Epoch: 67 [7424/14860 (50%)]\tLoss: 0.019809\n",
      "Train Epoch: 67 [7552/14860 (50%)]\tLoss: 0.017051\n",
      "Train Epoch: 67 [7680/14860 (51%)]\tLoss: 0.017875\n",
      "Train Epoch: 67 [7808/14860 (52%)]\tLoss: 0.017577\n",
      "Train Epoch: 67 [7936/14860 (53%)]\tLoss: 0.020430\n",
      "Train Epoch: 67 [8064/14860 (54%)]\tLoss: 0.023237\n",
      "Train Epoch: 67 [8192/14860 (55%)]\tLoss: 0.018392\n",
      "Train Epoch: 67 [8320/14860 (56%)]\tLoss: 0.029580\n",
      "Train Epoch: 67 [8448/14860 (56%)]\tLoss: 0.016954\n",
      "Train Epoch: 67 [8576/14860 (57%)]\tLoss: 0.022458\n",
      "Train Epoch: 67 [8704/14860 (58%)]\tLoss: 0.021402\n",
      "Train Epoch: 67 [8832/14860 (59%)]\tLoss: 0.021830\n",
      "Train Epoch: 67 [8960/14860 (60%)]\tLoss: 0.025607\n",
      "Train Epoch: 67 [9088/14860 (61%)]\tLoss: 0.019480\n",
      "Train Epoch: 67 [9216/14860 (62%)]\tLoss: 0.016700\n",
      "Train Epoch: 67 [9344/14860 (62%)]\tLoss: 0.018702\n",
      "Train Epoch: 67 [9472/14860 (63%)]\tLoss: 0.016680\n",
      "Train Epoch: 67 [9600/14860 (64%)]\tLoss: 0.018842\n",
      "Train Epoch: 67 [9728/14860 (65%)]\tLoss: 0.019591\n",
      "Train Epoch: 67 [9856/14860 (66%)]\tLoss: 0.015692\n",
      "Train Epoch: 67 [9984/14860 (67%)]\tLoss: 0.023142\n",
      "Train Epoch: 67 [10112/14860 (68%)]\tLoss: 0.016459\n",
      "Train Epoch: 67 [10240/14860 (68%)]\tLoss: 0.023454\n",
      "Train Epoch: 67 [10368/14860 (69%)]\tLoss: 0.019132\n",
      "Train Epoch: 67 [10496/14860 (70%)]\tLoss: 0.010318\n",
      "Train Epoch: 67 [10624/14860 (71%)]\tLoss: 0.022445\n",
      "Train Epoch: 67 [10752/14860 (72%)]\tLoss: 0.023725\n",
      "Train Epoch: 67 [10880/14860 (73%)]\tLoss: 0.010916\n",
      "Train Epoch: 67 [11008/14860 (74%)]\tLoss: 0.015976\n",
      "Train Epoch: 67 [11136/14860 (74%)]\tLoss: 0.013736\n",
      "Train Epoch: 67 [11264/14860 (75%)]\tLoss: 0.026461\n",
      "Train Epoch: 67 [11392/14860 (76%)]\tLoss: 0.020721\n",
      "Train Epoch: 67 [11520/14860 (77%)]\tLoss: 0.018487\n",
      "Train Epoch: 67 [11648/14860 (78%)]\tLoss: 0.016345\n",
      "Train Epoch: 67 [11776/14860 (79%)]\tLoss: 0.012409\n",
      "Train Epoch: 67 [11904/14860 (79%)]\tLoss: 0.020367\n",
      "Train Epoch: 67 [12032/14860 (80%)]\tLoss: 0.010725\n",
      "Train Epoch: 67 [12160/14860 (81%)]\tLoss: 0.023295\n",
      "Train Epoch: 67 [12288/14860 (82%)]\tLoss: 0.020347\n",
      "Train Epoch: 67 [12416/14860 (83%)]\tLoss: 0.019181\n",
      "Train Epoch: 67 [12544/14860 (84%)]\tLoss: 0.024212\n",
      "Train Epoch: 67 [12672/14860 (85%)]\tLoss: 0.017876\n",
      "Train Epoch: 67 [12800/14860 (85%)]\tLoss: 0.033728\n",
      "Train Epoch: 67 [12928/14860 (86%)]\tLoss: 0.019338\n",
      "Train Epoch: 67 [13056/14860 (87%)]\tLoss: 0.018034\n",
      "Train Epoch: 67 [13184/14860 (88%)]\tLoss: 0.024462\n",
      "Train Epoch: 67 [13312/14860 (89%)]\tLoss: 0.028522\n",
      "Train Epoch: 67 [13440/14860 (90%)]\tLoss: 0.021906\n",
      "Train Epoch: 67 [13568/14860 (91%)]\tLoss: 0.025538\n",
      "Train Epoch: 67 [13696/14860 (91%)]\tLoss: 0.020353\n",
      "Train Epoch: 67 [13824/14860 (92%)]\tLoss: 0.018474\n",
      "Train Epoch: 67 [13952/14860 (93%)]\tLoss: 0.022929\n",
      "Train Epoch: 67 [14080/14860 (94%)]\tLoss: 0.024198\n",
      "Train Epoch: 67 [14208/14860 (95%)]\tLoss: 0.023733\n",
      "Train Epoch: 67 [14336/14860 (96%)]\tLoss: 0.017093\n",
      "Train Epoch: 67 [14464/14860 (97%)]\tLoss: 0.015710\n",
      "Train Epoch: 67 [14592/14860 (97%)]\tLoss: 0.023326\n",
      "Train Epoch: 67 [14720/14860 (98%)]\tLoss: 0.017091\n",
      "Train Epoch: 67 [1392/14860 (99%)]\tLoss: 0.016895\n",
      "epoch 67 training loss: 0.0192765223626525\n",
      "epoch 67 validation loss: 0.019907475383749308\n",
      "Train Epoch: 68 [0/14860 (0%)]\tLoss: 0.015718\n",
      "Train Epoch: 68 [128/14860 (1%)]\tLoss: 0.018166\n",
      "Train Epoch: 68 [256/14860 (2%)]\tLoss: 0.024024\n",
      "Train Epoch: 68 [384/14860 (3%)]\tLoss: 0.013174\n",
      "Train Epoch: 68 [512/14860 (3%)]\tLoss: 0.018867\n",
      "Train Epoch: 68 [640/14860 (4%)]\tLoss: 0.016640\n",
      "Train Epoch: 68 [768/14860 (5%)]\tLoss: 0.016759\n",
      "Train Epoch: 68 [896/14860 (6%)]\tLoss: 0.014152\n",
      "Train Epoch: 68 [1024/14860 (7%)]\tLoss: 0.016489\n",
      "Train Epoch: 68 [1152/14860 (8%)]\tLoss: 0.015345\n",
      "Train Epoch: 68 [1280/14860 (9%)]\tLoss: 0.016443\n",
      "Train Epoch: 68 [1408/14860 (9%)]\tLoss: 0.017564\n",
      "Train Epoch: 68 [1536/14860 (10%)]\tLoss: 0.016876\n",
      "Train Epoch: 68 [1664/14860 (11%)]\tLoss: 0.019482\n",
      "Train Epoch: 68 [1792/14860 (12%)]\tLoss: 0.015746\n",
      "Train Epoch: 68 [1920/14860 (13%)]\tLoss: 0.021494\n",
      "Train Epoch: 68 [2048/14860 (14%)]\tLoss: 0.016999\n",
      "Train Epoch: 68 [2176/14860 (15%)]\tLoss: 0.018333\n",
      "Train Epoch: 68 [2304/14860 (15%)]\tLoss: 0.022688\n",
      "Train Epoch: 68 [2432/14860 (16%)]\tLoss: 0.021226\n",
      "Train Epoch: 68 [2560/14860 (17%)]\tLoss: 0.020759\n",
      "Train Epoch: 68 [2688/14860 (18%)]\tLoss: 0.023512\n",
      "Train Epoch: 68 [2816/14860 (19%)]\tLoss: 0.014923\n",
      "Train Epoch: 68 [2944/14860 (20%)]\tLoss: 0.018454\n",
      "Train Epoch: 68 [3072/14860 (21%)]\tLoss: 0.016145\n",
      "Train Epoch: 68 [3200/14860 (21%)]\tLoss: 0.013370\n",
      "Train Epoch: 68 [3328/14860 (22%)]\tLoss: 0.021453\n",
      "Train Epoch: 68 [3456/14860 (23%)]\tLoss: 0.013649\n",
      "Train Epoch: 68 [3584/14860 (24%)]\tLoss: 0.020447\n",
      "Train Epoch: 68 [3712/14860 (25%)]\tLoss: 0.017848\n",
      "Train Epoch: 68 [3840/14860 (26%)]\tLoss: 0.022132\n",
      "Train Epoch: 68 [3968/14860 (26%)]\tLoss: 0.013999\n",
      "Train Epoch: 68 [4096/14860 (27%)]\tLoss: 0.019067\n",
      "Train Epoch: 68 [4224/14860 (28%)]\tLoss: 0.026260\n",
      "Train Epoch: 68 [4352/14860 (29%)]\tLoss: 0.017172\n",
      "Train Epoch: 68 [4480/14860 (30%)]\tLoss: 0.018373\n",
      "Train Epoch: 68 [4608/14860 (31%)]\tLoss: 0.025284\n",
      "Train Epoch: 68 [4736/14860 (32%)]\tLoss: 0.010322\n",
      "Train Epoch: 68 [4864/14860 (32%)]\tLoss: 0.016470\n",
      "Train Epoch: 68 [4992/14860 (33%)]\tLoss: 0.017009\n",
      "Train Epoch: 68 [5120/14860 (34%)]\tLoss: 0.020775\n",
      "Train Epoch: 68 [5248/14860 (35%)]\tLoss: 0.013111\n",
      "Train Epoch: 68 [5376/14860 (36%)]\tLoss: 0.020570\n",
      "Train Epoch: 68 [5504/14860 (37%)]\tLoss: 0.020203\n",
      "Train Epoch: 68 [5632/14860 (38%)]\tLoss: 0.020905\n",
      "Train Epoch: 68 [5760/14860 (38%)]\tLoss: 0.013581\n",
      "Train Epoch: 68 [5888/14860 (39%)]\tLoss: 0.021348\n",
      "Train Epoch: 68 [6016/14860 (40%)]\tLoss: 0.015569\n",
      "Train Epoch: 68 [6144/14860 (41%)]\tLoss: 0.015978\n",
      "Train Epoch: 68 [6272/14860 (42%)]\tLoss: 0.016161\n",
      "Train Epoch: 68 [6400/14860 (43%)]\tLoss: 0.021645\n",
      "Train Epoch: 68 [6528/14860 (44%)]\tLoss: 0.022295\n",
      "Train Epoch: 68 [6656/14860 (44%)]\tLoss: 0.022028\n",
      "Train Epoch: 68 [6784/14860 (45%)]\tLoss: 0.018458\n",
      "Train Epoch: 68 [6912/14860 (46%)]\tLoss: 0.016389\n",
      "Train Epoch: 68 [7040/14860 (47%)]\tLoss: 0.013664\n",
      "Train Epoch: 68 [7168/14860 (48%)]\tLoss: 0.015515\n",
      "Train Epoch: 68 [7296/14860 (49%)]\tLoss: 0.013855\n",
      "Train Epoch: 68 [7424/14860 (50%)]\tLoss: 0.023127\n",
      "Train Epoch: 68 [7552/14860 (50%)]\tLoss: 0.019809\n",
      "Train Epoch: 68 [7680/14860 (51%)]\tLoss: 0.014920\n",
      "Train Epoch: 68 [7808/14860 (52%)]\tLoss: 0.017404\n",
      "Train Epoch: 68 [7936/14860 (53%)]\tLoss: 0.016775\n",
      "Train Epoch: 68 [8064/14860 (54%)]\tLoss: 0.015896\n",
      "Train Epoch: 68 [8192/14860 (55%)]\tLoss: 0.025136\n",
      "Train Epoch: 68 [8320/14860 (56%)]\tLoss: 0.022687\n",
      "Train Epoch: 68 [8448/14860 (56%)]\tLoss: 0.013233\n",
      "Train Epoch: 68 [8576/14860 (57%)]\tLoss: 0.016300\n",
      "Train Epoch: 68 [8704/14860 (58%)]\tLoss: 0.020436\n",
      "Train Epoch: 68 [8832/14860 (59%)]\tLoss: 0.015972\n",
      "Train Epoch: 68 [8960/14860 (60%)]\tLoss: 0.018351\n",
      "Train Epoch: 68 [9088/14860 (61%)]\tLoss: 0.018822\n",
      "Train Epoch: 68 [9216/14860 (62%)]\tLoss: 0.014442\n",
      "Train Epoch: 68 [9344/14860 (62%)]\tLoss: 0.022936\n",
      "Train Epoch: 68 [9472/14860 (63%)]\tLoss: 0.024787\n",
      "Train Epoch: 68 [9600/14860 (64%)]\tLoss: 0.015734\n",
      "Train Epoch: 68 [9728/14860 (65%)]\tLoss: 0.017710\n",
      "Train Epoch: 68 [9856/14860 (66%)]\tLoss: 0.023553\n",
      "Train Epoch: 68 [9984/14860 (67%)]\tLoss: 0.018924\n",
      "Train Epoch: 68 [10112/14860 (68%)]\tLoss: 0.018150\n",
      "Train Epoch: 68 [10240/14860 (68%)]\tLoss: 0.022692\n",
      "Train Epoch: 68 [10368/14860 (69%)]\tLoss: 0.024197\n",
      "Train Epoch: 68 [10496/14860 (70%)]\tLoss: 0.021328\n",
      "Train Epoch: 68 [10624/14860 (71%)]\tLoss: 0.013397\n",
      "Train Epoch: 68 [10752/14860 (72%)]\tLoss: 0.025728\n",
      "Train Epoch: 68 [10880/14860 (73%)]\tLoss: 0.016820\n",
      "Train Epoch: 68 [11008/14860 (74%)]\tLoss: 0.020741\n",
      "Train Epoch: 68 [11136/14860 (74%)]\tLoss: 0.015163\n",
      "Train Epoch: 68 [11264/14860 (75%)]\tLoss: 0.021848\n",
      "Train Epoch: 68 [11392/14860 (76%)]\tLoss: 0.015685\n",
      "Train Epoch: 68 [11520/14860 (77%)]\tLoss: 0.020413\n",
      "Train Epoch: 68 [11648/14860 (78%)]\tLoss: 0.017172\n",
      "Train Epoch: 68 [11776/14860 (79%)]\tLoss: 0.018608\n",
      "Train Epoch: 68 [11904/14860 (79%)]\tLoss: 0.019523\n",
      "Train Epoch: 68 [12032/14860 (80%)]\tLoss: 0.020296\n",
      "Train Epoch: 68 [12160/14860 (81%)]\tLoss: 0.025454\n",
      "Train Epoch: 68 [12288/14860 (82%)]\tLoss: 0.018312\n",
      "Train Epoch: 68 [12416/14860 (83%)]\tLoss: 0.019180\n",
      "Train Epoch: 68 [12544/14860 (84%)]\tLoss: 0.023659\n",
      "Train Epoch: 68 [12672/14860 (85%)]\tLoss: 0.018695\n",
      "Train Epoch: 68 [12800/14860 (85%)]\tLoss: 0.023145\n",
      "Train Epoch: 68 [12928/14860 (86%)]\tLoss: 0.020017\n",
      "Train Epoch: 68 [13056/14860 (87%)]\tLoss: 0.022602\n",
      "Train Epoch: 68 [13184/14860 (88%)]\tLoss: 0.031506\n",
      "Train Epoch: 68 [13312/14860 (89%)]\tLoss: 0.016515\n",
      "Train Epoch: 68 [13440/14860 (90%)]\tLoss: 0.024668\n",
      "Train Epoch: 68 [13568/14860 (91%)]\tLoss: 0.022530\n",
      "Train Epoch: 68 [13696/14860 (91%)]\tLoss: 0.020323\n",
      "Train Epoch: 68 [13824/14860 (92%)]\tLoss: 0.019156\n",
      "Train Epoch: 68 [13952/14860 (93%)]\tLoss: 0.019577\n",
      "Train Epoch: 68 [14080/14860 (94%)]\tLoss: 0.022398\n",
      "Train Epoch: 68 [14208/14860 (95%)]\tLoss: 0.028337\n",
      "Train Epoch: 68 [14336/14860 (96%)]\tLoss: 0.017619\n",
      "Train Epoch: 68 [14464/14860 (97%)]\tLoss: 0.021505\n",
      "Train Epoch: 68 [14592/14860 (97%)]\tLoss: 0.010596\n",
      "Train Epoch: 68 [14720/14860 (98%)]\tLoss: 0.018520\n",
      "Train Epoch: 68 [1392/14860 (99%)]\tLoss: 0.020383\n",
      "epoch 68 training loss: 0.018959752084989834\n",
      "epoch 68 validation loss: 0.02259618303677649\n",
      "Train Epoch: 69 [0/14860 (0%)]\tLoss: 0.020192\n",
      "Train Epoch: 69 [128/14860 (1%)]\tLoss: 0.027101\n",
      "Train Epoch: 69 [256/14860 (2%)]\tLoss: 0.017001\n",
      "Train Epoch: 69 [384/14860 (3%)]\tLoss: 0.017078\n",
      "Train Epoch: 69 [512/14860 (3%)]\tLoss: 0.019693\n",
      "Train Epoch: 69 [640/14860 (4%)]\tLoss: 0.017562\n",
      "Train Epoch: 69 [768/14860 (5%)]\tLoss: 0.025530\n",
      "Train Epoch: 69 [896/14860 (6%)]\tLoss: 0.024525\n",
      "Train Epoch: 69 [1024/14860 (7%)]\tLoss: 0.021296\n",
      "Train Epoch: 69 [1152/14860 (8%)]\tLoss: 0.019970\n",
      "Train Epoch: 69 [1280/14860 (9%)]\tLoss: 0.023360\n",
      "Train Epoch: 69 [1408/14860 (9%)]\tLoss: 0.024313\n",
      "Train Epoch: 69 [1536/14860 (10%)]\tLoss: 0.017618\n",
      "Train Epoch: 69 [1664/14860 (11%)]\tLoss: 0.021304\n",
      "Train Epoch: 69 [1792/14860 (12%)]\tLoss: 0.015035\n",
      "Train Epoch: 69 [1920/14860 (13%)]\tLoss: 0.012616\n",
      "Train Epoch: 69 [2048/14860 (14%)]\tLoss: 0.022212\n",
      "Train Epoch: 69 [2176/14860 (15%)]\tLoss: 0.020321\n",
      "Train Epoch: 69 [2304/14860 (15%)]\tLoss: 0.012099\n",
      "Train Epoch: 69 [2432/14860 (16%)]\tLoss: 0.023801\n",
      "Train Epoch: 69 [2560/14860 (17%)]\tLoss: 0.015219\n",
      "Train Epoch: 69 [2688/14860 (18%)]\tLoss: 0.016793\n",
      "Train Epoch: 69 [2816/14860 (19%)]\tLoss: 0.016026\n",
      "Train Epoch: 69 [2944/14860 (20%)]\tLoss: 0.028615\n",
      "Train Epoch: 69 [3072/14860 (21%)]\tLoss: 0.018102\n",
      "Train Epoch: 69 [3200/14860 (21%)]\tLoss: 0.013130\n",
      "Train Epoch: 69 [3328/14860 (22%)]\tLoss: 0.021700\n",
      "Train Epoch: 69 [3456/14860 (23%)]\tLoss: 0.023617\n",
      "Train Epoch: 69 [3584/14860 (24%)]\tLoss: 0.020091\n",
      "Train Epoch: 69 [3712/14860 (25%)]\tLoss: 0.019727\n",
      "Train Epoch: 69 [3840/14860 (26%)]\tLoss: 0.014568\n",
      "Train Epoch: 69 [3968/14860 (26%)]\tLoss: 0.015785\n",
      "Train Epoch: 69 [4096/14860 (27%)]\tLoss: 0.022550\n",
      "Train Epoch: 69 [4224/14860 (28%)]\tLoss: 0.019083\n",
      "Train Epoch: 69 [4352/14860 (29%)]\tLoss: 0.018344\n",
      "Train Epoch: 69 [4480/14860 (30%)]\tLoss: 0.027269\n",
      "Train Epoch: 69 [4608/14860 (31%)]\tLoss: 0.018937\n",
      "Train Epoch: 69 [4736/14860 (32%)]\tLoss: 0.022663\n",
      "Train Epoch: 69 [4864/14860 (32%)]\tLoss: 0.017428\n",
      "Train Epoch: 69 [4992/14860 (33%)]\tLoss: 0.017882\n",
      "Train Epoch: 69 [5120/14860 (34%)]\tLoss: 0.021297\n",
      "Train Epoch: 69 [5248/14860 (35%)]\tLoss: 0.020550\n",
      "Train Epoch: 69 [5376/14860 (36%)]\tLoss: 0.019249\n",
      "Train Epoch: 69 [5504/14860 (37%)]\tLoss: 0.018642\n",
      "Train Epoch: 69 [5632/14860 (38%)]\tLoss: 0.015932\n",
      "Train Epoch: 69 [5760/14860 (38%)]\tLoss: 0.014335\n",
      "Train Epoch: 69 [5888/14860 (39%)]\tLoss: 0.009630\n",
      "Train Epoch: 69 [6016/14860 (40%)]\tLoss: 0.013716\n",
      "Train Epoch: 69 [6144/14860 (41%)]\tLoss: 0.024699\n",
      "Train Epoch: 69 [6272/14860 (42%)]\tLoss: 0.025875\n",
      "Train Epoch: 69 [6400/14860 (43%)]\tLoss: 0.022348\n",
      "Train Epoch: 69 [6528/14860 (44%)]\tLoss: 0.027226\n",
      "Train Epoch: 69 [6656/14860 (44%)]\tLoss: 0.023518\n",
      "Train Epoch: 69 [6784/14860 (45%)]\tLoss: 0.025633\n",
      "Train Epoch: 69 [6912/14860 (46%)]\tLoss: 0.015847\n",
      "Train Epoch: 69 [7040/14860 (47%)]\tLoss: 0.016742\n",
      "Train Epoch: 69 [7168/14860 (48%)]\tLoss: 0.018042\n",
      "Train Epoch: 69 [7296/14860 (49%)]\tLoss: 0.013216\n",
      "Train Epoch: 69 [7424/14860 (50%)]\tLoss: 0.025757\n",
      "Train Epoch: 69 [7552/14860 (50%)]\tLoss: 0.017371\n",
      "Train Epoch: 69 [7680/14860 (51%)]\tLoss: 0.026612\n",
      "Train Epoch: 69 [7808/14860 (52%)]\tLoss: 0.022259\n",
      "Train Epoch: 69 [7936/14860 (53%)]\tLoss: 0.027509\n",
      "Train Epoch: 69 [8064/14860 (54%)]\tLoss: 0.019862\n",
      "Train Epoch: 69 [8192/14860 (55%)]\tLoss: 0.026691\n",
      "Train Epoch: 69 [8320/14860 (56%)]\tLoss: 0.013378\n",
      "Train Epoch: 69 [8448/14860 (56%)]\tLoss: 0.014208\n",
      "Train Epoch: 69 [8576/14860 (57%)]\tLoss: 0.016755\n",
      "Train Epoch: 69 [8704/14860 (58%)]\tLoss: 0.018240\n",
      "Train Epoch: 69 [8832/14860 (59%)]\tLoss: 0.018295\n",
      "Train Epoch: 69 [8960/14860 (60%)]\tLoss: 0.015273\n",
      "Train Epoch: 69 [9088/14860 (61%)]\tLoss: 0.017794\n",
      "Train Epoch: 69 [9216/14860 (62%)]\tLoss: 0.023549\n",
      "Train Epoch: 69 [9344/14860 (62%)]\tLoss: 0.020449\n",
      "Train Epoch: 69 [9472/14860 (63%)]\tLoss: 0.013812\n",
      "Train Epoch: 69 [9600/14860 (64%)]\tLoss: 0.016902\n",
      "Train Epoch: 69 [9728/14860 (65%)]\tLoss: 0.017649\n",
      "Train Epoch: 69 [9856/14860 (66%)]\tLoss: 0.016736\n",
      "Train Epoch: 69 [9984/14860 (67%)]\tLoss: 0.018690\n",
      "Train Epoch: 69 [10112/14860 (68%)]\tLoss: 0.028032\n",
      "Train Epoch: 69 [10240/14860 (68%)]\tLoss: 0.013632\n",
      "Train Epoch: 69 [10368/14860 (69%)]\tLoss: 0.024115\n",
      "Train Epoch: 69 [10496/14860 (70%)]\tLoss: 0.018674\n",
      "Train Epoch: 69 [10624/14860 (71%)]\tLoss: 0.018603\n",
      "Train Epoch: 69 [10752/14860 (72%)]\tLoss: 0.024841\n",
      "Train Epoch: 69 [10880/14860 (73%)]\tLoss: 0.015475\n",
      "Train Epoch: 69 [11008/14860 (74%)]\tLoss: 0.016177\n",
      "Train Epoch: 69 [11136/14860 (74%)]\tLoss: 0.015786\n",
      "Train Epoch: 69 [11264/14860 (75%)]\tLoss: 0.009791\n",
      "Train Epoch: 69 [11392/14860 (76%)]\tLoss: 0.013979\n",
      "Train Epoch: 69 [11520/14860 (77%)]\tLoss: 0.024660\n",
      "Train Epoch: 69 [11648/14860 (78%)]\tLoss: 0.027355\n",
      "Train Epoch: 69 [11776/14860 (79%)]\tLoss: 0.020475\n",
      "Train Epoch: 69 [11904/14860 (79%)]\tLoss: 0.023256\n",
      "Train Epoch: 69 [12032/14860 (80%)]\tLoss: 0.018580\n",
      "Train Epoch: 69 [12160/14860 (81%)]\tLoss: 0.020096\n",
      "Train Epoch: 69 [12288/14860 (82%)]\tLoss: 0.023470\n",
      "Train Epoch: 69 [12416/14860 (83%)]\tLoss: 0.019736\n",
      "Train Epoch: 69 [12544/14860 (84%)]\tLoss: 0.022020\n",
      "Train Epoch: 69 [12672/14860 (85%)]\tLoss: 0.015974\n",
      "Train Epoch: 69 [12800/14860 (85%)]\tLoss: 0.020158\n",
      "Train Epoch: 69 [12928/14860 (86%)]\tLoss: 0.022659\n",
      "Train Epoch: 69 [13056/14860 (87%)]\tLoss: 0.016343\n",
      "Train Epoch: 69 [13184/14860 (88%)]\tLoss: 0.013016\n",
      "Train Epoch: 69 [13312/14860 (89%)]\tLoss: 0.024990\n",
      "Train Epoch: 69 [13440/14860 (90%)]\tLoss: 0.025327\n",
      "Train Epoch: 69 [13568/14860 (91%)]\tLoss: 0.014650\n",
      "Train Epoch: 69 [13696/14860 (91%)]\tLoss: 0.021435\n",
      "Train Epoch: 69 [13824/14860 (92%)]\tLoss: 0.014616\n",
      "Train Epoch: 69 [13952/14860 (93%)]\tLoss: 0.015538\n",
      "Train Epoch: 69 [14080/14860 (94%)]\tLoss: 0.023949\n",
      "Train Epoch: 69 [14208/14860 (95%)]\tLoss: 0.022932\n",
      "Train Epoch: 69 [14336/14860 (96%)]\tLoss: 0.025831\n",
      "Train Epoch: 69 [14464/14860 (97%)]\tLoss: 0.016284\n",
      "Train Epoch: 69 [14592/14860 (97%)]\tLoss: 0.019636\n",
      "Train Epoch: 69 [14720/14860 (98%)]\tLoss: 0.024502\n",
      "Train Epoch: 69 [1392/14860 (99%)]\tLoss: 0.028228\n",
      "epoch 69 training loss: 0.019737364795918647\n",
      "epoch 69 validation loss: 0.02106246503732972\n",
      "Train Epoch: 70 [0/14860 (0%)]\tLoss: 0.023011\n",
      "Train Epoch: 70 [128/14860 (1%)]\tLoss: 0.029572\n",
      "Train Epoch: 70 [256/14860 (2%)]\tLoss: 0.019415\n",
      "Train Epoch: 70 [384/14860 (3%)]\tLoss: 0.019590\n",
      "Train Epoch: 70 [512/14860 (3%)]\tLoss: 0.042017\n",
      "Train Epoch: 70 [640/14860 (4%)]\tLoss: 0.022745\n",
      "Train Epoch: 70 [768/14860 (5%)]\tLoss: 0.015863\n",
      "Train Epoch: 70 [896/14860 (6%)]\tLoss: 0.019320\n",
      "Train Epoch: 70 [1024/14860 (7%)]\tLoss: 0.030649\n",
      "Train Epoch: 70 [1152/14860 (8%)]\tLoss: 0.022811\n",
      "Train Epoch: 70 [1280/14860 (9%)]\tLoss: 0.019354\n",
      "Train Epoch: 70 [1408/14860 (9%)]\tLoss: 0.025943\n",
      "Train Epoch: 70 [1536/14860 (10%)]\tLoss: 0.021550\n",
      "Train Epoch: 70 [1664/14860 (11%)]\tLoss: 0.014216\n",
      "Train Epoch: 70 [1792/14860 (12%)]\tLoss: 0.014194\n",
      "Train Epoch: 70 [1920/14860 (13%)]\tLoss: 0.020749\n",
      "Train Epoch: 70 [2048/14860 (14%)]\tLoss: 0.020711\n",
      "Train Epoch: 70 [2176/14860 (15%)]\tLoss: 0.019655\n",
      "Train Epoch: 70 [2304/14860 (15%)]\tLoss: 0.014414\n",
      "Train Epoch: 70 [2432/14860 (16%)]\tLoss: 0.020050\n",
      "Train Epoch: 70 [2560/14860 (17%)]\tLoss: 0.014707\n",
      "Train Epoch: 70 [2688/14860 (18%)]\tLoss: 0.015973\n",
      "Train Epoch: 70 [2816/14860 (19%)]\tLoss: 0.013731\n",
      "Train Epoch: 70 [2944/14860 (20%)]\tLoss: 0.013120\n",
      "Train Epoch: 70 [3072/14860 (21%)]\tLoss: 0.017167\n",
      "Train Epoch: 70 [3200/14860 (21%)]\tLoss: 0.013691\n",
      "Train Epoch: 70 [3328/14860 (22%)]\tLoss: 0.021610\n",
      "Train Epoch: 70 [3456/14860 (23%)]\tLoss: 0.023971\n",
      "Train Epoch: 70 [3584/14860 (24%)]\tLoss: 0.026023\n",
      "Train Epoch: 70 [3712/14860 (25%)]\tLoss: 0.017504\n",
      "Train Epoch: 70 [3840/14860 (26%)]\tLoss: 0.020591\n",
      "Train Epoch: 70 [3968/14860 (26%)]\tLoss: 0.018603\n",
      "Train Epoch: 70 [4096/14860 (27%)]\tLoss: 0.022862\n",
      "Train Epoch: 70 [4224/14860 (28%)]\tLoss: 0.017954\n",
      "Train Epoch: 70 [4352/14860 (29%)]\tLoss: 0.022717\n",
      "Train Epoch: 70 [4480/14860 (30%)]\tLoss: 0.013942\n",
      "Train Epoch: 70 [4608/14860 (31%)]\tLoss: 0.021378\n",
      "Train Epoch: 70 [4736/14860 (32%)]\tLoss: 0.022999\n",
      "Train Epoch: 70 [4864/14860 (32%)]\tLoss: 0.023168\n",
      "Train Epoch: 70 [4992/14860 (33%)]\tLoss: 0.019740\n",
      "Train Epoch: 70 [5120/14860 (34%)]\tLoss: 0.017548\n",
      "Train Epoch: 70 [5248/14860 (35%)]\tLoss: 0.012575\n",
      "Train Epoch: 70 [5376/14860 (36%)]\tLoss: 0.013937\n",
      "Train Epoch: 70 [5504/14860 (37%)]\tLoss: 0.020011\n",
      "Train Epoch: 70 [5632/14860 (38%)]\tLoss: 0.025779\n",
      "Train Epoch: 70 [5760/14860 (38%)]\tLoss: 0.019582\n",
      "Train Epoch: 70 [5888/14860 (39%)]\tLoss: 0.027640\n",
      "Train Epoch: 70 [6016/14860 (40%)]\tLoss: 0.018629\n",
      "Train Epoch: 70 [6144/14860 (41%)]\tLoss: 0.018055\n",
      "Train Epoch: 70 [6272/14860 (42%)]\tLoss: 0.018657\n",
      "Train Epoch: 70 [6400/14860 (43%)]\tLoss: 0.018079\n",
      "Train Epoch: 70 [6528/14860 (44%)]\tLoss: 0.021877\n",
      "Train Epoch: 70 [6656/14860 (44%)]\tLoss: 0.015535\n",
      "Train Epoch: 70 [6784/14860 (45%)]\tLoss: 0.021121\n",
      "Train Epoch: 70 [6912/14860 (46%)]\tLoss: 0.021007\n",
      "Train Epoch: 70 [7040/14860 (47%)]\tLoss: 0.025047\n",
      "Train Epoch: 70 [7168/14860 (48%)]\tLoss: 0.013656\n",
      "Train Epoch: 70 [7296/14860 (49%)]\tLoss: 0.015962\n",
      "Train Epoch: 70 [7424/14860 (50%)]\tLoss: 0.015089\n",
      "Train Epoch: 70 [7552/14860 (50%)]\tLoss: 0.014694\n",
      "Train Epoch: 70 [7680/14860 (51%)]\tLoss: 0.019861\n",
      "Train Epoch: 70 [7808/14860 (52%)]\tLoss: 0.020757\n",
      "Train Epoch: 70 [7936/14860 (53%)]\tLoss: 0.019563\n",
      "Train Epoch: 70 [8064/14860 (54%)]\tLoss: 0.017939\n",
      "Train Epoch: 70 [8192/14860 (55%)]\tLoss: 0.017695\n",
      "Train Epoch: 70 [8320/14860 (56%)]\tLoss: 0.014292\n",
      "Train Epoch: 70 [8448/14860 (56%)]\tLoss: 0.015100\n",
      "Train Epoch: 70 [8576/14860 (57%)]\tLoss: 0.020324\n",
      "Train Epoch: 70 [8704/14860 (58%)]\tLoss: 0.015632\n",
      "Train Epoch: 70 [8832/14860 (59%)]\tLoss: 0.023837\n",
      "Train Epoch: 70 [8960/14860 (60%)]\tLoss: 0.018685\n",
      "Train Epoch: 70 [9088/14860 (61%)]\tLoss: 0.016545\n",
      "Train Epoch: 70 [9216/14860 (62%)]\tLoss: 0.019246\n",
      "Train Epoch: 70 [9344/14860 (62%)]\tLoss: 0.025527\n",
      "Train Epoch: 70 [9472/14860 (63%)]\tLoss: 0.018884\n",
      "Train Epoch: 70 [9600/14860 (64%)]\tLoss: 0.014939\n",
      "Train Epoch: 70 [9728/14860 (65%)]\tLoss: 0.013181\n",
      "Train Epoch: 70 [9856/14860 (66%)]\tLoss: 0.019250\n",
      "Train Epoch: 70 [9984/14860 (67%)]\tLoss: 0.016447\n",
      "Train Epoch: 70 [10112/14860 (68%)]\tLoss: 0.024273\n",
      "Train Epoch: 70 [10240/14860 (68%)]\tLoss: 0.017665\n",
      "Train Epoch: 70 [10368/14860 (69%)]\tLoss: 0.020855\n",
      "Train Epoch: 70 [10496/14860 (70%)]\tLoss: 0.017321\n",
      "Train Epoch: 70 [10624/14860 (71%)]\tLoss: 0.029935\n",
      "Train Epoch: 70 [10752/14860 (72%)]\tLoss: 0.019447\n",
      "Train Epoch: 70 [10880/14860 (73%)]\tLoss: 0.017258\n",
      "Train Epoch: 70 [11008/14860 (74%)]\tLoss: 0.022741\n",
      "Train Epoch: 70 [11136/14860 (74%)]\tLoss: 0.020548\n",
      "Train Epoch: 70 [11264/14860 (75%)]\tLoss: 0.012602\n",
      "Train Epoch: 70 [11392/14860 (76%)]\tLoss: 0.026495\n",
      "Train Epoch: 70 [11520/14860 (77%)]\tLoss: 0.018413\n",
      "Train Epoch: 70 [11648/14860 (78%)]\tLoss: 0.019304\n",
      "Train Epoch: 70 [11776/14860 (79%)]\tLoss: 0.021723\n",
      "Train Epoch: 70 [11904/14860 (79%)]\tLoss: 0.017349\n",
      "Train Epoch: 70 [12032/14860 (80%)]\tLoss: 0.022851\n",
      "Train Epoch: 70 [12160/14860 (81%)]\tLoss: 0.021888\n",
      "Train Epoch: 70 [12288/14860 (82%)]\tLoss: 0.025759\n",
      "Train Epoch: 70 [12416/14860 (83%)]\tLoss: 0.017337\n",
      "Train Epoch: 70 [12544/14860 (84%)]\tLoss: 0.021482\n",
      "Train Epoch: 70 [12672/14860 (85%)]\tLoss: 0.019808\n",
      "Train Epoch: 70 [12800/14860 (85%)]\tLoss: 0.015334\n",
      "Train Epoch: 70 [12928/14860 (86%)]\tLoss: 0.017630\n",
      "Train Epoch: 70 [13056/14860 (87%)]\tLoss: 0.019076\n",
      "Train Epoch: 70 [13184/14860 (88%)]\tLoss: 0.020600\n",
      "Train Epoch: 70 [13312/14860 (89%)]\tLoss: 0.021942\n",
      "Train Epoch: 70 [13440/14860 (90%)]\tLoss: 0.022173\n",
      "Train Epoch: 70 [13568/14860 (91%)]\tLoss: 0.014222\n",
      "Train Epoch: 70 [13696/14860 (91%)]\tLoss: 0.033553\n",
      "Train Epoch: 70 [13824/14860 (92%)]\tLoss: 0.015735\n",
      "Train Epoch: 70 [13952/14860 (93%)]\tLoss: 0.016332\n",
      "Train Epoch: 70 [14080/14860 (94%)]\tLoss: 0.019718\n",
      "Train Epoch: 70 [14208/14860 (95%)]\tLoss: 0.017811\n",
      "Train Epoch: 70 [14336/14860 (96%)]\tLoss: 0.014153\n",
      "Train Epoch: 70 [14464/14860 (97%)]\tLoss: 0.018772\n",
      "Train Epoch: 70 [14592/14860 (97%)]\tLoss: 0.028978\n",
      "Train Epoch: 70 [14720/14860 (98%)]\tLoss: 0.021631\n",
      "Train Epoch: 70 [1392/14860 (99%)]\tLoss: 0.011441\n",
      "epoch 70 training loss: 0.01968903409746977\n",
      "epoch 70 validation loss: 0.020198625600366848\n",
      "Train Epoch: 71 [0/14860 (0%)]\tLoss: 0.016561\n",
      "Train Epoch: 71 [128/14860 (1%)]\tLoss: 0.018632\n",
      "Train Epoch: 71 [256/14860 (2%)]\tLoss: 0.025987\n",
      "Train Epoch: 71 [384/14860 (3%)]\tLoss: 0.019611\n",
      "Train Epoch: 71 [512/14860 (3%)]\tLoss: 0.017689\n",
      "Train Epoch: 71 [640/14860 (4%)]\tLoss: 0.019981\n",
      "Train Epoch: 71 [768/14860 (5%)]\tLoss: 0.018572\n",
      "Train Epoch: 71 [896/14860 (6%)]\tLoss: 0.023377\n",
      "Train Epoch: 71 [1024/14860 (7%)]\tLoss: 0.017421\n",
      "Train Epoch: 71 [1152/14860 (8%)]\tLoss: 0.016903\n",
      "Train Epoch: 71 [1280/14860 (9%)]\tLoss: 0.014981\n",
      "Train Epoch: 71 [1408/14860 (9%)]\tLoss: 0.025255\n",
      "Train Epoch: 71 [1536/14860 (10%)]\tLoss: 0.015871\n",
      "Train Epoch: 71 [1664/14860 (11%)]\tLoss: 0.021392\n",
      "Train Epoch: 71 [1792/14860 (12%)]\tLoss: 0.018765\n",
      "Train Epoch: 71 [1920/14860 (13%)]\tLoss: 0.016597\n",
      "Train Epoch: 71 [2048/14860 (14%)]\tLoss: 0.013501\n",
      "Train Epoch: 71 [2176/14860 (15%)]\tLoss: 0.018441\n",
      "Train Epoch: 71 [2304/14860 (15%)]\tLoss: 0.021589\n",
      "Train Epoch: 71 [2432/14860 (16%)]\tLoss: 0.020583\n",
      "Train Epoch: 71 [2560/14860 (17%)]\tLoss: 0.019703\n",
      "Train Epoch: 71 [2688/14860 (18%)]\tLoss: 0.020744\n",
      "Train Epoch: 71 [2816/14860 (19%)]\tLoss: 0.016639\n",
      "Train Epoch: 71 [2944/14860 (20%)]\tLoss: 0.014322\n",
      "Train Epoch: 71 [3072/14860 (21%)]\tLoss: 0.015044\n",
      "Train Epoch: 71 [3200/14860 (21%)]\tLoss: 0.014775\n",
      "Train Epoch: 71 [3328/14860 (22%)]\tLoss: 0.016502\n",
      "Train Epoch: 71 [3456/14860 (23%)]\tLoss: 0.024160\n",
      "Train Epoch: 71 [3584/14860 (24%)]\tLoss: 0.017752\n",
      "Train Epoch: 71 [3712/14860 (25%)]\tLoss: 0.026149\n",
      "Train Epoch: 71 [3840/14860 (26%)]\tLoss: 0.031615\n",
      "Train Epoch: 71 [3968/14860 (26%)]\tLoss: 0.023458\n",
      "Train Epoch: 71 [4096/14860 (27%)]\tLoss: 0.016725\n",
      "Train Epoch: 71 [4224/14860 (28%)]\tLoss: 0.018477\n",
      "Train Epoch: 71 [4352/14860 (29%)]\tLoss: 0.018974\n",
      "Train Epoch: 71 [4480/14860 (30%)]\tLoss: 0.013285\n",
      "Train Epoch: 71 [4608/14860 (31%)]\tLoss: 0.018456\n",
      "Train Epoch: 71 [4736/14860 (32%)]\tLoss: 0.020648\n",
      "Train Epoch: 71 [4864/14860 (32%)]\tLoss: 0.020528\n",
      "Train Epoch: 71 [4992/14860 (33%)]\tLoss: 0.011107\n",
      "Train Epoch: 71 [5120/14860 (34%)]\tLoss: 0.013135\n",
      "Train Epoch: 71 [5248/14860 (35%)]\tLoss: 0.014700\n",
      "Train Epoch: 71 [5376/14860 (36%)]\tLoss: 0.016502\n",
      "Train Epoch: 71 [5504/14860 (37%)]\tLoss: 0.020309\n",
      "Train Epoch: 71 [5632/14860 (38%)]\tLoss: 0.016443\n",
      "Train Epoch: 71 [5760/14860 (38%)]\tLoss: 0.013743\n",
      "Train Epoch: 71 [5888/14860 (39%)]\tLoss: 0.018947\n",
      "Train Epoch: 71 [6016/14860 (40%)]\tLoss: 0.017949\n",
      "Train Epoch: 71 [6144/14860 (41%)]\tLoss: 0.027963\n",
      "Train Epoch: 71 [6272/14860 (42%)]\tLoss: 0.026911\n",
      "Train Epoch: 71 [6400/14860 (43%)]\tLoss: 0.016997\n",
      "Train Epoch: 71 [6528/14860 (44%)]\tLoss: 0.017186\n",
      "Train Epoch: 71 [6656/14860 (44%)]\tLoss: 0.029740\n",
      "Train Epoch: 71 [6784/14860 (45%)]\tLoss: 0.011325\n",
      "Train Epoch: 71 [6912/14860 (46%)]\tLoss: 0.024909\n",
      "Train Epoch: 71 [7040/14860 (47%)]\tLoss: 0.015730\n",
      "Train Epoch: 71 [7168/14860 (48%)]\tLoss: 0.018166\n",
      "Train Epoch: 71 [7296/14860 (49%)]\tLoss: 0.018626\n",
      "Train Epoch: 71 [7424/14860 (50%)]\tLoss: 0.020127\n",
      "Train Epoch: 71 [7552/14860 (50%)]\tLoss: 0.018946\n",
      "Train Epoch: 71 [7680/14860 (51%)]\tLoss: 0.021347\n",
      "Train Epoch: 71 [7808/14860 (52%)]\tLoss: 0.023732\n",
      "Train Epoch: 71 [7936/14860 (53%)]\tLoss: 0.014923\n",
      "Train Epoch: 71 [8064/14860 (54%)]\tLoss: 0.022718\n",
      "Train Epoch: 71 [8192/14860 (55%)]\tLoss: 0.014327\n",
      "Train Epoch: 71 [8320/14860 (56%)]\tLoss: 0.017363\n",
      "Train Epoch: 71 [8448/14860 (56%)]\tLoss: 0.018398\n",
      "Train Epoch: 71 [8576/14860 (57%)]\tLoss: 0.019769\n",
      "Train Epoch: 71 [8704/14860 (58%)]\tLoss: 0.020338\n",
      "Train Epoch: 71 [8832/14860 (59%)]\tLoss: 0.020870\n",
      "Train Epoch: 71 [8960/14860 (60%)]\tLoss: 0.020136\n",
      "Train Epoch: 71 [9088/14860 (61%)]\tLoss: 0.012578\n",
      "Train Epoch: 71 [9216/14860 (62%)]\tLoss: 0.025801\n",
      "Train Epoch: 71 [9344/14860 (62%)]\tLoss: 0.020087\n",
      "Train Epoch: 71 [9472/14860 (63%)]\tLoss: 0.022921\n",
      "Train Epoch: 71 [9600/14860 (64%)]\tLoss: 0.018755\n",
      "Train Epoch: 71 [9728/14860 (65%)]\tLoss: 0.015421\n",
      "Train Epoch: 71 [9856/14860 (66%)]\tLoss: 0.020228\n",
      "Train Epoch: 71 [9984/14860 (67%)]\tLoss: 0.024334\n",
      "Train Epoch: 71 [10112/14860 (68%)]\tLoss: 0.013991\n",
      "Train Epoch: 71 [10240/14860 (68%)]\tLoss: 0.021192\n",
      "Train Epoch: 71 [10368/14860 (69%)]\tLoss: 0.018889\n",
      "Train Epoch: 71 [10496/14860 (70%)]\tLoss: 0.029764\n",
      "Train Epoch: 71 [10624/14860 (71%)]\tLoss: 0.016207\n",
      "Train Epoch: 71 [10752/14860 (72%)]\tLoss: 0.021233\n",
      "Train Epoch: 71 [10880/14860 (73%)]\tLoss: 0.018603\n",
      "Train Epoch: 71 [11008/14860 (74%)]\tLoss: 0.021493\n",
      "Train Epoch: 71 [11136/14860 (74%)]\tLoss: 0.017641\n",
      "Train Epoch: 71 [11264/14860 (75%)]\tLoss: 0.022280\n",
      "Train Epoch: 71 [11392/14860 (76%)]\tLoss: 0.013391\n",
      "Train Epoch: 71 [11520/14860 (77%)]\tLoss: 0.016128\n",
      "Train Epoch: 71 [11648/14860 (78%)]\tLoss: 0.028481\n",
      "Train Epoch: 71 [11776/14860 (79%)]\tLoss: 0.028703\n",
      "Train Epoch: 71 [11904/14860 (79%)]\tLoss: 0.023744\n",
      "Train Epoch: 71 [12032/14860 (80%)]\tLoss: 0.020736\n",
      "Train Epoch: 71 [12160/14860 (81%)]\tLoss: 0.022439\n",
      "Train Epoch: 71 [12288/14860 (82%)]\tLoss: 0.024744\n",
      "Train Epoch: 71 [12416/14860 (83%)]\tLoss: 0.018446\n",
      "Train Epoch: 71 [12544/14860 (84%)]\tLoss: 0.014354\n",
      "Train Epoch: 71 [12672/14860 (85%)]\tLoss: 0.017405\n",
      "Train Epoch: 71 [12800/14860 (85%)]\tLoss: 0.020016\n",
      "Train Epoch: 71 [12928/14860 (86%)]\tLoss: 0.014348\n",
      "Train Epoch: 71 [13056/14860 (87%)]\tLoss: 0.019087\n",
      "Train Epoch: 71 [13184/14860 (88%)]\tLoss: 0.017711\n",
      "Train Epoch: 71 [13312/14860 (89%)]\tLoss: 0.015342\n",
      "Train Epoch: 71 [13440/14860 (90%)]\tLoss: 0.016817\n",
      "Train Epoch: 71 [13568/14860 (91%)]\tLoss: 0.012521\n",
      "Train Epoch: 71 [13696/14860 (91%)]\tLoss: 0.021012\n",
      "Train Epoch: 71 [13824/14860 (92%)]\tLoss: 0.014046\n",
      "Train Epoch: 71 [13952/14860 (93%)]\tLoss: 0.017194\n",
      "Train Epoch: 71 [14080/14860 (94%)]\tLoss: 0.018680\n",
      "Train Epoch: 71 [14208/14860 (95%)]\tLoss: 0.018886\n",
      "Train Epoch: 71 [14336/14860 (96%)]\tLoss: 0.018422\n",
      "Train Epoch: 71 [14464/14860 (97%)]\tLoss: 0.012373\n",
      "Train Epoch: 71 [14592/14860 (97%)]\tLoss: 0.024225\n",
      "Train Epoch: 71 [14720/14860 (98%)]\tLoss: 0.019096\n",
      "Train Epoch: 71 [1392/14860 (99%)]\tLoss: 0.019111\n",
      "epoch 71 training loss: 0.0191617166925954\n",
      "epoch 71 validation loss: 0.023314493043082102\n",
      "Train Epoch: 72 [0/14860 (0%)]\tLoss: 0.022622\n",
      "Train Epoch: 72 [128/14860 (1%)]\tLoss: 0.019986\n",
      "Train Epoch: 72 [256/14860 (2%)]\tLoss: 0.021689\n",
      "Train Epoch: 72 [384/14860 (3%)]\tLoss: 0.023647\n",
      "Train Epoch: 72 [512/14860 (3%)]\tLoss: 0.020509\n",
      "Train Epoch: 72 [640/14860 (4%)]\tLoss: 0.018658\n",
      "Train Epoch: 72 [768/14860 (5%)]\tLoss: 0.022981\n",
      "Train Epoch: 72 [896/14860 (6%)]\tLoss: 0.012269\n",
      "Train Epoch: 72 [1024/14860 (7%)]\tLoss: 0.019459\n",
      "Train Epoch: 72 [1152/14860 (8%)]\tLoss: 0.022327\n",
      "Train Epoch: 72 [1280/14860 (9%)]\tLoss: 0.017700\n",
      "Train Epoch: 72 [1408/14860 (9%)]\tLoss: 0.019479\n",
      "Train Epoch: 72 [1536/14860 (10%)]\tLoss: 0.021227\n",
      "Train Epoch: 72 [1664/14860 (11%)]\tLoss: 0.021287\n",
      "Train Epoch: 72 [1792/14860 (12%)]\tLoss: 0.016961\n",
      "Train Epoch: 72 [1920/14860 (13%)]\tLoss: 0.018211\n",
      "Train Epoch: 72 [2048/14860 (14%)]\tLoss: 0.016949\n",
      "Train Epoch: 72 [2176/14860 (15%)]\tLoss: 0.019325\n",
      "Train Epoch: 72 [2304/14860 (15%)]\tLoss: 0.026854\n",
      "Train Epoch: 72 [2432/14860 (16%)]\tLoss: 0.023677\n",
      "Train Epoch: 72 [2560/14860 (17%)]\tLoss: 0.023939\n",
      "Train Epoch: 72 [2688/14860 (18%)]\tLoss: 0.016408\n",
      "Train Epoch: 72 [2816/14860 (19%)]\tLoss: 0.020451\n",
      "Train Epoch: 72 [2944/14860 (20%)]\tLoss: 0.017726\n",
      "Train Epoch: 72 [3072/14860 (21%)]\tLoss: 0.014165\n",
      "Train Epoch: 72 [3200/14860 (21%)]\tLoss: 0.026196\n",
      "Train Epoch: 72 [3328/14860 (22%)]\tLoss: 0.022023\n",
      "Train Epoch: 72 [3456/14860 (23%)]\tLoss: 0.023807\n",
      "Train Epoch: 72 [3584/14860 (24%)]\tLoss: 0.015837\n",
      "Train Epoch: 72 [3712/14860 (25%)]\tLoss: 0.017057\n",
      "Train Epoch: 72 [3840/14860 (26%)]\tLoss: 0.018554\n",
      "Train Epoch: 72 [3968/14860 (26%)]\tLoss: 0.018307\n",
      "Train Epoch: 72 [4096/14860 (27%)]\tLoss: 0.020834\n",
      "Train Epoch: 72 [4224/14860 (28%)]\tLoss: 0.017601\n",
      "Train Epoch: 72 [4352/14860 (29%)]\tLoss: 0.019772\n",
      "Train Epoch: 72 [4480/14860 (30%)]\tLoss: 0.014520\n",
      "Train Epoch: 72 [4608/14860 (31%)]\tLoss: 0.026223\n",
      "Train Epoch: 72 [4736/14860 (32%)]\tLoss: 0.021681\n",
      "Train Epoch: 72 [4864/14860 (32%)]\tLoss: 0.019050\n",
      "Train Epoch: 72 [4992/14860 (33%)]\tLoss: 0.022528\n",
      "Train Epoch: 72 [5120/14860 (34%)]\tLoss: 0.016481\n",
      "Train Epoch: 72 [5248/14860 (35%)]\tLoss: 0.014874\n",
      "Train Epoch: 72 [5376/14860 (36%)]\tLoss: 0.016125\n",
      "Train Epoch: 72 [5504/14860 (37%)]\tLoss: 0.020187\n",
      "Train Epoch: 72 [5632/14860 (38%)]\tLoss: 0.018524\n",
      "Train Epoch: 72 [5760/14860 (38%)]\tLoss: 0.016730\n",
      "Train Epoch: 72 [5888/14860 (39%)]\tLoss: 0.011408\n",
      "Train Epoch: 72 [6016/14860 (40%)]\tLoss: 0.019138\n",
      "Train Epoch: 72 [6144/14860 (41%)]\tLoss: 0.015538\n",
      "Train Epoch: 72 [6272/14860 (42%)]\tLoss: 0.023425\n",
      "Train Epoch: 72 [6400/14860 (43%)]\tLoss: 0.013972\n",
      "Train Epoch: 72 [6528/14860 (44%)]\tLoss: 0.015446\n",
      "Train Epoch: 72 [6656/14860 (44%)]\tLoss: 0.017351\n",
      "Train Epoch: 72 [6784/14860 (45%)]\tLoss: 0.023870\n",
      "Train Epoch: 72 [6912/14860 (46%)]\tLoss: 0.017373\n",
      "Train Epoch: 72 [7040/14860 (47%)]\tLoss: 0.010886\n",
      "Train Epoch: 72 [7168/14860 (48%)]\tLoss: 0.021380\n",
      "Train Epoch: 72 [7296/14860 (49%)]\tLoss: 0.027421\n",
      "Train Epoch: 72 [7424/14860 (50%)]\tLoss: 0.017270\n",
      "Train Epoch: 72 [7552/14860 (50%)]\tLoss: 0.028579\n",
      "Train Epoch: 72 [7680/14860 (51%)]\tLoss: 0.020851\n",
      "Train Epoch: 72 [7808/14860 (52%)]\tLoss: 0.018503\n",
      "Train Epoch: 72 [7936/14860 (53%)]\tLoss: 0.015697\n",
      "Train Epoch: 72 [8064/14860 (54%)]\tLoss: 0.018708\n",
      "Train Epoch: 72 [8192/14860 (55%)]\tLoss: 0.019376\n",
      "Train Epoch: 72 [8320/14860 (56%)]\tLoss: 0.012287\n",
      "Train Epoch: 72 [8448/14860 (56%)]\tLoss: 0.016784\n",
      "Train Epoch: 72 [8576/14860 (57%)]\tLoss: 0.020922\n",
      "Train Epoch: 72 [8704/14860 (58%)]\tLoss: 0.018726\n",
      "Train Epoch: 72 [8832/14860 (59%)]\tLoss: 0.020416\n",
      "Train Epoch: 72 [8960/14860 (60%)]\tLoss: 0.020298\n",
      "Train Epoch: 72 [9088/14860 (61%)]\tLoss: 0.019040\n",
      "Train Epoch: 72 [9216/14860 (62%)]\tLoss: 0.016415\n",
      "Train Epoch: 72 [9344/14860 (62%)]\tLoss: 0.015327\n",
      "Train Epoch: 72 [9472/14860 (63%)]\tLoss: 0.026565\n",
      "Train Epoch: 72 [9600/14860 (64%)]\tLoss: 0.016514\n",
      "Train Epoch: 72 [9728/14860 (65%)]\tLoss: 0.023230\n",
      "Train Epoch: 72 [9856/14860 (66%)]\tLoss: 0.015523\n",
      "Train Epoch: 72 [9984/14860 (67%)]\tLoss: 0.020980\n",
      "Train Epoch: 72 [10112/14860 (68%)]\tLoss: 0.022080\n",
      "Train Epoch: 72 [10240/14860 (68%)]\tLoss: 0.021262\n",
      "Train Epoch: 72 [10368/14860 (69%)]\tLoss: 0.017506\n",
      "Train Epoch: 72 [10496/14860 (70%)]\tLoss: 0.018881\n",
      "Train Epoch: 72 [10624/14860 (71%)]\tLoss: 0.024513\n",
      "Train Epoch: 72 [10752/14860 (72%)]\tLoss: 0.022368\n",
      "Train Epoch: 72 [10880/14860 (73%)]\tLoss: 0.013774\n",
      "Train Epoch: 72 [11008/14860 (74%)]\tLoss: 0.025243\n",
      "Train Epoch: 72 [11136/14860 (74%)]\tLoss: 0.021825\n",
      "Train Epoch: 72 [11264/14860 (75%)]\tLoss: 0.019458\n",
      "Train Epoch: 72 [11392/14860 (76%)]\tLoss: 0.019380\n",
      "Train Epoch: 72 [11520/14860 (77%)]\tLoss: 0.019019\n",
      "Train Epoch: 72 [11648/14860 (78%)]\tLoss: 0.016527\n",
      "Train Epoch: 72 [11776/14860 (79%)]\tLoss: 0.019087\n",
      "Train Epoch: 72 [11904/14860 (79%)]\tLoss: 0.010841\n",
      "Train Epoch: 72 [12032/14860 (80%)]\tLoss: 0.021158\n",
      "Train Epoch: 72 [12160/14860 (81%)]\tLoss: 0.022084\n",
      "Train Epoch: 72 [12288/14860 (82%)]\tLoss: 0.014498\n",
      "Train Epoch: 72 [12416/14860 (83%)]\tLoss: 0.016846\n",
      "Train Epoch: 72 [12544/14860 (84%)]\tLoss: 0.019065\n",
      "Train Epoch: 72 [12672/14860 (85%)]\tLoss: 0.020943\n",
      "Train Epoch: 72 [12800/14860 (85%)]\tLoss: 0.021190\n",
      "Train Epoch: 72 [12928/14860 (86%)]\tLoss: 0.021614\n",
      "Train Epoch: 72 [13056/14860 (87%)]\tLoss: 0.014899\n",
      "Train Epoch: 72 [13184/14860 (88%)]\tLoss: 0.018979\n",
      "Train Epoch: 72 [13312/14860 (89%)]\tLoss: 0.025778\n",
      "Train Epoch: 72 [13440/14860 (90%)]\tLoss: 0.021244\n",
      "Train Epoch: 72 [13568/14860 (91%)]\tLoss: 0.025638\n",
      "Train Epoch: 72 [13696/14860 (91%)]\tLoss: 0.020795\n",
      "Train Epoch: 72 [13824/14860 (92%)]\tLoss: 0.020798\n",
      "Train Epoch: 72 [13952/14860 (93%)]\tLoss: 0.025425\n",
      "Train Epoch: 72 [14080/14860 (94%)]\tLoss: 0.018589\n",
      "Train Epoch: 72 [14208/14860 (95%)]\tLoss: 0.022090\n",
      "Train Epoch: 72 [14336/14860 (96%)]\tLoss: 0.020357\n",
      "Train Epoch: 72 [14464/14860 (97%)]\tLoss: 0.018442\n",
      "Train Epoch: 72 [14592/14860 (97%)]\tLoss: 0.018699\n",
      "Train Epoch: 72 [14720/14860 (98%)]\tLoss: 0.016983\n",
      "Train Epoch: 72 [1392/14860 (99%)]\tLoss: 0.018302\n",
      "epoch 72 training loss: 0.01949418890966564\n",
      "epoch 72 validation loss: 0.019576407085030764\n",
      "Train Epoch: 73 [0/14860 (0%)]\tLoss: 0.022176\n",
      "Train Epoch: 73 [128/14860 (1%)]\tLoss: 0.032648\n",
      "Train Epoch: 73 [256/14860 (2%)]\tLoss: 0.020724\n",
      "Train Epoch: 73 [384/14860 (3%)]\tLoss: 0.019000\n",
      "Train Epoch: 73 [512/14860 (3%)]\tLoss: 0.020376\n",
      "Train Epoch: 73 [640/14860 (4%)]\tLoss: 0.020862\n",
      "Train Epoch: 73 [768/14860 (5%)]\tLoss: 0.018526\n",
      "Train Epoch: 73 [896/14860 (6%)]\tLoss: 0.014262\n",
      "Train Epoch: 73 [1024/14860 (7%)]\tLoss: 0.018370\n",
      "Train Epoch: 73 [1152/14860 (8%)]\tLoss: 0.015478\n",
      "Train Epoch: 73 [1280/14860 (9%)]\tLoss: 0.021203\n",
      "Train Epoch: 73 [1408/14860 (9%)]\tLoss: 0.018056\n",
      "Train Epoch: 73 [1536/14860 (10%)]\tLoss: 0.010757\n",
      "Train Epoch: 73 [1664/14860 (11%)]\tLoss: 0.018161\n",
      "Train Epoch: 73 [1792/14860 (12%)]\tLoss: 0.012962\n",
      "Train Epoch: 73 [1920/14860 (13%)]\tLoss: 0.016343\n",
      "Train Epoch: 73 [2048/14860 (14%)]\tLoss: 0.019772\n",
      "Train Epoch: 73 [2176/14860 (15%)]\tLoss: 0.026190\n",
      "Train Epoch: 73 [2304/14860 (15%)]\tLoss: 0.014790\n",
      "Train Epoch: 73 [2432/14860 (16%)]\tLoss: 0.015865\n",
      "Train Epoch: 73 [2560/14860 (17%)]\tLoss: 0.016238\n",
      "Train Epoch: 73 [2688/14860 (18%)]\tLoss: 0.021453\n",
      "Train Epoch: 73 [2816/14860 (19%)]\tLoss: 0.023402\n",
      "Train Epoch: 73 [2944/14860 (20%)]\tLoss: 0.016026\n",
      "Train Epoch: 73 [3072/14860 (21%)]\tLoss: 0.014102\n",
      "Train Epoch: 73 [3200/14860 (21%)]\tLoss: 0.021186\n",
      "Train Epoch: 73 [3328/14860 (22%)]\tLoss: 0.029514\n",
      "Train Epoch: 73 [3456/14860 (23%)]\tLoss: 0.021689\n",
      "Train Epoch: 73 [3584/14860 (24%)]\tLoss: 0.022805\n",
      "Train Epoch: 73 [3712/14860 (25%)]\tLoss: 0.026451\n",
      "Train Epoch: 73 [3840/14860 (26%)]\tLoss: 0.019262\n",
      "Train Epoch: 73 [3968/14860 (26%)]\tLoss: 0.021159\n",
      "Train Epoch: 73 [4096/14860 (27%)]\tLoss: 0.019254\n",
      "Train Epoch: 73 [4224/14860 (28%)]\tLoss: 0.023145\n",
      "Train Epoch: 73 [4352/14860 (29%)]\tLoss: 0.027681\n",
      "Train Epoch: 73 [4480/14860 (30%)]\tLoss: 0.027563\n",
      "Train Epoch: 73 [4608/14860 (31%)]\tLoss: 0.023272\n",
      "Train Epoch: 73 [4736/14860 (32%)]\tLoss: 0.020156\n",
      "Train Epoch: 73 [4864/14860 (32%)]\tLoss: 0.023692\n",
      "Train Epoch: 73 [4992/14860 (33%)]\tLoss: 0.014397\n",
      "Train Epoch: 73 [5120/14860 (34%)]\tLoss: 0.015426\n",
      "Train Epoch: 73 [5248/14860 (35%)]\tLoss: 0.015004\n",
      "Train Epoch: 73 [5376/14860 (36%)]\tLoss: 0.020767\n",
      "Train Epoch: 73 [5504/14860 (37%)]\tLoss: 0.020875\n",
      "Train Epoch: 73 [5632/14860 (38%)]\tLoss: 0.017751\n",
      "Train Epoch: 73 [5760/14860 (38%)]\tLoss: 0.013417\n",
      "Train Epoch: 73 [5888/14860 (39%)]\tLoss: 0.017092\n",
      "Train Epoch: 73 [6016/14860 (40%)]\tLoss: 0.015265\n",
      "Train Epoch: 73 [6144/14860 (41%)]\tLoss: 0.022894\n",
      "Train Epoch: 73 [6272/14860 (42%)]\tLoss: 0.016359\n",
      "Train Epoch: 73 [6400/14860 (43%)]\tLoss: 0.015616\n",
      "Train Epoch: 73 [6528/14860 (44%)]\tLoss: 0.016861\n",
      "Train Epoch: 73 [6656/14860 (44%)]\tLoss: 0.024703\n",
      "Train Epoch: 73 [6784/14860 (45%)]\tLoss: 0.012100\n",
      "Train Epoch: 73 [6912/14860 (46%)]\tLoss: 0.017332\n",
      "Train Epoch: 73 [7040/14860 (47%)]\tLoss: 0.022905\n",
      "Train Epoch: 73 [7168/14860 (48%)]\tLoss: 0.023328\n",
      "Train Epoch: 73 [7296/14860 (49%)]\tLoss: 0.020191\n",
      "Train Epoch: 73 [7424/14860 (50%)]\tLoss: 0.011993\n",
      "Train Epoch: 73 [7552/14860 (50%)]\tLoss: 0.022322\n",
      "Train Epoch: 73 [7680/14860 (51%)]\tLoss: 0.021522\n",
      "Train Epoch: 73 [7808/14860 (52%)]\tLoss: 0.022199\n",
      "Train Epoch: 73 [7936/14860 (53%)]\tLoss: 0.015293\n",
      "Train Epoch: 73 [8064/14860 (54%)]\tLoss: 0.023719\n",
      "Train Epoch: 73 [8192/14860 (55%)]\tLoss: 0.014184\n",
      "Train Epoch: 73 [8320/14860 (56%)]\tLoss: 0.017221\n",
      "Train Epoch: 73 [8448/14860 (56%)]\tLoss: 0.015646\n",
      "Train Epoch: 73 [8576/14860 (57%)]\tLoss: 0.028009\n",
      "Train Epoch: 73 [8704/14860 (58%)]\tLoss: 0.016748\n",
      "Train Epoch: 73 [8832/14860 (59%)]\tLoss: 0.020774\n",
      "Train Epoch: 73 [8960/14860 (60%)]\tLoss: 0.016287\n",
      "Train Epoch: 73 [9088/14860 (61%)]\tLoss: 0.016194\n",
      "Train Epoch: 73 [9216/14860 (62%)]\tLoss: 0.018020\n",
      "Train Epoch: 73 [9344/14860 (62%)]\tLoss: 0.019542\n",
      "Train Epoch: 73 [9472/14860 (63%)]\tLoss: 0.018778\n",
      "Train Epoch: 73 [9600/14860 (64%)]\tLoss: 0.020867\n",
      "Train Epoch: 73 [9728/14860 (65%)]\tLoss: 0.013840\n",
      "Train Epoch: 73 [9856/14860 (66%)]\tLoss: 0.016430\n",
      "Train Epoch: 73 [9984/14860 (67%)]\tLoss: 0.013072\n",
      "Train Epoch: 73 [10112/14860 (68%)]\tLoss: 0.016056\n",
      "Train Epoch: 73 [10240/14860 (68%)]\tLoss: 0.014501\n",
      "Train Epoch: 73 [10368/14860 (69%)]\tLoss: 0.013918\n",
      "Train Epoch: 73 [10496/14860 (70%)]\tLoss: 0.024648\n",
      "Train Epoch: 73 [10624/14860 (71%)]\tLoss: 0.030700\n",
      "Train Epoch: 73 [10752/14860 (72%)]\tLoss: 0.015049\n",
      "Train Epoch: 73 [10880/14860 (73%)]\tLoss: 0.018105\n",
      "Train Epoch: 73 [11008/14860 (74%)]\tLoss: 0.018126\n",
      "Train Epoch: 73 [11136/14860 (74%)]\tLoss: 0.030394\n",
      "Train Epoch: 73 [11264/14860 (75%)]\tLoss: 0.016980\n",
      "Train Epoch: 73 [11392/14860 (76%)]\tLoss: 0.011750\n",
      "Train Epoch: 73 [11520/14860 (77%)]\tLoss: 0.033089\n",
      "Train Epoch: 73 [11648/14860 (78%)]\tLoss: 0.020147\n",
      "Train Epoch: 73 [11776/14860 (79%)]\tLoss: 0.016318\n",
      "Train Epoch: 73 [11904/14860 (79%)]\tLoss: 0.020857\n",
      "Train Epoch: 73 [12032/14860 (80%)]\tLoss: 0.020932\n",
      "Train Epoch: 73 [12160/14860 (81%)]\tLoss: 0.019869\n",
      "Train Epoch: 73 [12288/14860 (82%)]\tLoss: 0.023810\n",
      "Train Epoch: 73 [12416/14860 (83%)]\tLoss: 0.023182\n",
      "Train Epoch: 73 [12544/14860 (84%)]\tLoss: 0.025925\n",
      "Train Epoch: 73 [12672/14860 (85%)]\tLoss: 0.016897\n",
      "Train Epoch: 73 [12800/14860 (85%)]\tLoss: 0.024802\n",
      "Train Epoch: 73 [12928/14860 (86%)]\tLoss: 0.016485\n",
      "Train Epoch: 73 [13056/14860 (87%)]\tLoss: 0.016353\n",
      "Train Epoch: 73 [13184/14860 (88%)]\tLoss: 0.020034\n",
      "Train Epoch: 73 [13312/14860 (89%)]\tLoss: 0.017499\n",
      "Train Epoch: 73 [13440/14860 (90%)]\tLoss: 0.011668\n",
      "Train Epoch: 73 [13568/14860 (91%)]\tLoss: 0.012308\n",
      "Train Epoch: 73 [13696/14860 (91%)]\tLoss: 0.019347\n",
      "Train Epoch: 73 [13824/14860 (92%)]\tLoss: 0.018781\n",
      "Train Epoch: 73 [13952/14860 (93%)]\tLoss: 0.012153\n",
      "Train Epoch: 73 [14080/14860 (94%)]\tLoss: 0.015619\n",
      "Train Epoch: 73 [14208/14860 (95%)]\tLoss: 0.024549\n",
      "Train Epoch: 73 [14336/14860 (96%)]\tLoss: 0.022179\n",
      "Train Epoch: 73 [14464/14860 (97%)]\tLoss: 0.011721\n",
      "Train Epoch: 73 [14592/14860 (97%)]\tLoss: 0.022936\n",
      "Train Epoch: 73 [14720/14860 (98%)]\tLoss: 0.014191\n",
      "Train Epoch: 73 [1392/14860 (99%)]\tLoss: 0.003629\n",
      "epoch 73 training loss: 0.01910275222462976\n",
      "epoch 73 validation loss: 0.01976008796230067\n",
      "Train Epoch: 74 [0/14860 (0%)]\tLoss: 0.017378\n",
      "Train Epoch: 74 [128/14860 (1%)]\tLoss: 0.017378\n",
      "Train Epoch: 74 [256/14860 (2%)]\tLoss: 0.017816\n",
      "Train Epoch: 74 [384/14860 (3%)]\tLoss: 0.015993\n",
      "Train Epoch: 74 [512/14860 (3%)]\tLoss: 0.011766\n",
      "Train Epoch: 74 [640/14860 (4%)]\tLoss: 0.022696\n",
      "Train Epoch: 74 [768/14860 (5%)]\tLoss: 0.021614\n",
      "Train Epoch: 74 [896/14860 (6%)]\tLoss: 0.016088\n",
      "Train Epoch: 74 [1024/14860 (7%)]\tLoss: 0.022001\n",
      "Train Epoch: 74 [1152/14860 (8%)]\tLoss: 0.020992\n",
      "Train Epoch: 74 [1280/14860 (9%)]\tLoss: 0.019668\n",
      "Train Epoch: 74 [1408/14860 (9%)]\tLoss: 0.016143\n",
      "Train Epoch: 74 [1536/14860 (10%)]\tLoss: 0.014016\n",
      "Train Epoch: 74 [1664/14860 (11%)]\tLoss: 0.016179\n",
      "Train Epoch: 74 [1792/14860 (12%)]\tLoss: 0.021569\n",
      "Train Epoch: 74 [1920/14860 (13%)]\tLoss: 0.017434\n",
      "Train Epoch: 74 [2048/14860 (14%)]\tLoss: 0.013170\n",
      "Train Epoch: 74 [2176/14860 (15%)]\tLoss: 0.010598\n",
      "Train Epoch: 74 [2304/14860 (15%)]\tLoss: 0.016801\n",
      "Train Epoch: 74 [2432/14860 (16%)]\tLoss: 0.024932\n",
      "Train Epoch: 74 [2560/14860 (17%)]\tLoss: 0.020553\n",
      "Train Epoch: 74 [2688/14860 (18%)]\tLoss: 0.025397\n",
      "Train Epoch: 74 [2816/14860 (19%)]\tLoss: 0.021141\n",
      "Train Epoch: 74 [2944/14860 (20%)]\tLoss: 0.017094\n",
      "Train Epoch: 74 [3072/14860 (21%)]\tLoss: 0.020995\n",
      "Train Epoch: 74 [3200/14860 (21%)]\tLoss: 0.015282\n",
      "Train Epoch: 74 [3328/14860 (22%)]\tLoss: 0.013845\n",
      "Train Epoch: 74 [3456/14860 (23%)]\tLoss: 0.021514\n",
      "Train Epoch: 74 [3584/14860 (24%)]\tLoss: 0.026707\n",
      "Train Epoch: 74 [3712/14860 (25%)]\tLoss: 0.018490\n",
      "Train Epoch: 74 [3840/14860 (26%)]\tLoss: 0.019269\n",
      "Train Epoch: 74 [3968/14860 (26%)]\tLoss: 0.017892\n",
      "Train Epoch: 74 [4096/14860 (27%)]\tLoss: 0.018658\n",
      "Train Epoch: 74 [4224/14860 (28%)]\tLoss: 0.015234\n",
      "Train Epoch: 74 [4352/14860 (29%)]\tLoss: 0.020005\n",
      "Train Epoch: 74 [4480/14860 (30%)]\tLoss: 0.024745\n",
      "Train Epoch: 74 [4608/14860 (31%)]\tLoss: 0.016400\n",
      "Train Epoch: 74 [4736/14860 (32%)]\tLoss: 0.022095\n",
      "Train Epoch: 74 [4864/14860 (32%)]\tLoss: 0.023634\n",
      "Train Epoch: 74 [4992/14860 (33%)]\tLoss: 0.024012\n",
      "Train Epoch: 74 [5120/14860 (34%)]\tLoss: 0.029215\n",
      "Train Epoch: 74 [5248/14860 (35%)]\tLoss: 0.019629\n",
      "Train Epoch: 74 [5376/14860 (36%)]\tLoss: 0.015099\n",
      "Train Epoch: 74 [5504/14860 (37%)]\tLoss: 0.022468\n",
      "Train Epoch: 74 [5632/14860 (38%)]\tLoss: 0.022425\n",
      "Train Epoch: 74 [5760/14860 (38%)]\tLoss: 0.021517\n",
      "Train Epoch: 74 [5888/14860 (39%)]\tLoss: 0.019493\n",
      "Train Epoch: 74 [6016/14860 (40%)]\tLoss: 0.014748\n",
      "Train Epoch: 74 [6144/14860 (41%)]\tLoss: 0.023152\n",
      "Train Epoch: 74 [6272/14860 (42%)]\tLoss: 0.020091\n",
      "Train Epoch: 74 [6400/14860 (43%)]\tLoss: 0.016482\n",
      "Train Epoch: 74 [6528/14860 (44%)]\tLoss: 0.015075\n",
      "Train Epoch: 74 [6656/14860 (44%)]\tLoss: 0.018764\n",
      "Train Epoch: 74 [6784/14860 (45%)]\tLoss: 0.017546\n",
      "Train Epoch: 74 [6912/14860 (46%)]\tLoss: 0.012793\n",
      "Train Epoch: 74 [7040/14860 (47%)]\tLoss: 0.014482\n",
      "Train Epoch: 74 [7168/14860 (48%)]\tLoss: 0.018604\n",
      "Train Epoch: 74 [7296/14860 (49%)]\tLoss: 0.018078\n",
      "Train Epoch: 74 [7424/14860 (50%)]\tLoss: 0.019731\n",
      "Train Epoch: 74 [7552/14860 (50%)]\tLoss: 0.016724\n",
      "Train Epoch: 74 [7680/14860 (51%)]\tLoss: 0.014227\n",
      "Train Epoch: 74 [7808/14860 (52%)]\tLoss: 0.016453\n",
      "Train Epoch: 74 [7936/14860 (53%)]\tLoss: 0.019089\n",
      "Train Epoch: 74 [8064/14860 (54%)]\tLoss: 0.021002\n",
      "Train Epoch: 74 [8192/14860 (55%)]\tLoss: 0.021770\n",
      "Train Epoch: 74 [8320/14860 (56%)]\tLoss: 0.019471\n",
      "Train Epoch: 74 [8448/14860 (56%)]\tLoss: 0.016107\n",
      "Train Epoch: 74 [8576/14860 (57%)]\tLoss: 0.023216\n",
      "Train Epoch: 74 [8704/14860 (58%)]\tLoss: 0.016272\n",
      "Train Epoch: 74 [8832/14860 (59%)]\tLoss: 0.014952\n",
      "Train Epoch: 74 [8960/14860 (60%)]\tLoss: 0.019556\n",
      "Train Epoch: 74 [9088/14860 (61%)]\tLoss: 0.016915\n",
      "Train Epoch: 74 [9216/14860 (62%)]\tLoss: 0.014405\n",
      "Train Epoch: 74 [9344/14860 (62%)]\tLoss: 0.012546\n",
      "Train Epoch: 74 [9472/14860 (63%)]\tLoss: 0.023432\n",
      "Train Epoch: 74 [9600/14860 (64%)]\tLoss: 0.020337\n",
      "Train Epoch: 74 [9728/14860 (65%)]\tLoss: 0.025563\n",
      "Train Epoch: 74 [9856/14860 (66%)]\tLoss: 0.016998\n",
      "Train Epoch: 74 [9984/14860 (67%)]\tLoss: 0.021244\n",
      "Train Epoch: 74 [10112/14860 (68%)]\tLoss: 0.020850\n",
      "Train Epoch: 74 [10240/14860 (68%)]\tLoss: 0.025008\n",
      "Train Epoch: 74 [10368/14860 (69%)]\tLoss: 0.014375\n",
      "Train Epoch: 74 [10496/14860 (70%)]\tLoss: 0.012632\n",
      "Train Epoch: 74 [10624/14860 (71%)]\tLoss: 0.017582\n",
      "Train Epoch: 74 [10752/14860 (72%)]\tLoss: 0.011511\n",
      "Train Epoch: 74 [10880/14860 (73%)]\tLoss: 0.021493\n",
      "Train Epoch: 74 [11008/14860 (74%)]\tLoss: 0.018497\n",
      "Train Epoch: 74 [11136/14860 (74%)]\tLoss: 0.020165\n",
      "Train Epoch: 74 [11264/14860 (75%)]\tLoss: 0.025393\n",
      "Train Epoch: 74 [11392/14860 (76%)]\tLoss: 0.021083\n",
      "Train Epoch: 74 [11520/14860 (77%)]\tLoss: 0.018375\n",
      "Train Epoch: 74 [11648/14860 (78%)]\tLoss: 0.014297\n",
      "Train Epoch: 74 [11776/14860 (79%)]\tLoss: 0.021012\n",
      "Train Epoch: 74 [11904/14860 (79%)]\tLoss: 0.017835\n",
      "Train Epoch: 74 [12032/14860 (80%)]\tLoss: 0.022918\n",
      "Train Epoch: 74 [12160/14860 (81%)]\tLoss: 0.018716\n",
      "Train Epoch: 74 [12288/14860 (82%)]\tLoss: 0.017124\n",
      "Train Epoch: 74 [12416/14860 (83%)]\tLoss: 0.024914\n",
      "Train Epoch: 74 [12544/14860 (84%)]\tLoss: 0.016251\n",
      "Train Epoch: 74 [12672/14860 (85%)]\tLoss: 0.016407\n",
      "Train Epoch: 74 [12800/14860 (85%)]\tLoss: 0.027681\n",
      "Train Epoch: 74 [12928/14860 (86%)]\tLoss: 0.022084\n",
      "Train Epoch: 74 [13056/14860 (87%)]\tLoss: 0.017889\n",
      "Train Epoch: 74 [13184/14860 (88%)]\tLoss: 0.013925\n",
      "Train Epoch: 74 [13312/14860 (89%)]\tLoss: 0.028563\n",
      "Train Epoch: 74 [13440/14860 (90%)]\tLoss: 0.017927\n",
      "Train Epoch: 74 [13568/14860 (91%)]\tLoss: 0.027688\n",
      "Train Epoch: 74 [13696/14860 (91%)]\tLoss: 0.014357\n",
      "Train Epoch: 74 [13824/14860 (92%)]\tLoss: 0.018368\n",
      "Train Epoch: 74 [13952/14860 (93%)]\tLoss: 0.023667\n",
      "Train Epoch: 74 [14080/14860 (94%)]\tLoss: 0.023801\n",
      "Train Epoch: 74 [14208/14860 (95%)]\tLoss: 0.014244\n",
      "Train Epoch: 74 [14336/14860 (96%)]\tLoss: 0.018036\n",
      "Train Epoch: 74 [14464/14860 (97%)]\tLoss: 0.020292\n",
      "Train Epoch: 74 [14592/14860 (97%)]\tLoss: 0.021381\n",
      "Train Epoch: 74 [14720/14860 (98%)]\tLoss: 0.022408\n",
      "Train Epoch: 74 [1392/14860 (99%)]\tLoss: 0.018737\n",
      "epoch 74 training loss: 0.01909703918151621\n",
      "epoch 74 validation loss: 0.020843882393317418\n",
      "Train Epoch: 75 [0/14860 (0%)]\tLoss: 0.016851\n",
      "Train Epoch: 75 [128/14860 (1%)]\tLoss: 0.013464\n",
      "Train Epoch: 75 [256/14860 (2%)]\tLoss: 0.022638\n",
      "Train Epoch: 75 [384/14860 (3%)]\tLoss: 0.018276\n",
      "Train Epoch: 75 [512/14860 (3%)]\tLoss: 0.017752\n",
      "Train Epoch: 75 [640/14860 (4%)]\tLoss: 0.024832\n",
      "Train Epoch: 75 [768/14860 (5%)]\tLoss: 0.027265\n",
      "Train Epoch: 75 [896/14860 (6%)]\tLoss: 0.013153\n",
      "Train Epoch: 75 [1024/14860 (7%)]\tLoss: 0.018610\n",
      "Train Epoch: 75 [1152/14860 (8%)]\tLoss: 0.017056\n",
      "Train Epoch: 75 [1280/14860 (9%)]\tLoss: 0.014661\n",
      "Train Epoch: 75 [1408/14860 (9%)]\tLoss: 0.020201\n",
      "Train Epoch: 75 [1536/14860 (10%)]\tLoss: 0.022338\n",
      "Train Epoch: 75 [1664/14860 (11%)]\tLoss: 0.018212\n",
      "Train Epoch: 75 [1792/14860 (12%)]\tLoss: 0.011722\n",
      "Train Epoch: 75 [1920/14860 (13%)]\tLoss: 0.018268\n",
      "Train Epoch: 75 [2048/14860 (14%)]\tLoss: 0.021321\n",
      "Train Epoch: 75 [2176/14860 (15%)]\tLoss: 0.019205\n",
      "Train Epoch: 75 [2304/14860 (15%)]\tLoss: 0.020436\n",
      "Train Epoch: 75 [2432/14860 (16%)]\tLoss: 0.019235\n",
      "Train Epoch: 75 [2560/14860 (17%)]\tLoss: 0.015202\n",
      "Train Epoch: 75 [2688/14860 (18%)]\tLoss: 0.030438\n",
      "Train Epoch: 75 [2816/14860 (19%)]\tLoss: 0.016554\n",
      "Train Epoch: 75 [2944/14860 (20%)]\tLoss: 0.018471\n",
      "Train Epoch: 75 [3072/14860 (21%)]\tLoss: 0.017600\n",
      "Train Epoch: 75 [3200/14860 (21%)]\tLoss: 0.014723\n",
      "Train Epoch: 75 [3328/14860 (22%)]\tLoss: 0.021906\n",
      "Train Epoch: 75 [3456/14860 (23%)]\tLoss: 0.016607\n",
      "Train Epoch: 75 [3584/14860 (24%)]\tLoss: 0.022905\n",
      "Train Epoch: 75 [3712/14860 (25%)]\tLoss: 0.022651\n",
      "Train Epoch: 75 [3840/14860 (26%)]\tLoss: 0.021095\n",
      "Train Epoch: 75 [3968/14860 (26%)]\tLoss: 0.023320\n",
      "Train Epoch: 75 [4096/14860 (27%)]\tLoss: 0.020451\n",
      "Train Epoch: 75 [4224/14860 (28%)]\tLoss: 0.017266\n",
      "Train Epoch: 75 [4352/14860 (29%)]\tLoss: 0.016398\n",
      "Train Epoch: 75 [4480/14860 (30%)]\tLoss: 0.016975\n",
      "Train Epoch: 75 [4608/14860 (31%)]\tLoss: 0.019782\n",
      "Train Epoch: 75 [4736/14860 (32%)]\tLoss: 0.024806\n",
      "Train Epoch: 75 [4864/14860 (32%)]\tLoss: 0.014633\n",
      "Train Epoch: 75 [4992/14860 (33%)]\tLoss: 0.017783\n",
      "Train Epoch: 75 [5120/14860 (34%)]\tLoss: 0.020963\n",
      "Train Epoch: 75 [5248/14860 (35%)]\tLoss: 0.013129\n",
      "Train Epoch: 75 [5376/14860 (36%)]\tLoss: 0.013596\n",
      "Train Epoch: 75 [5504/14860 (37%)]\tLoss: 0.014813\n",
      "Train Epoch: 75 [5632/14860 (38%)]\tLoss: 0.022581\n",
      "Train Epoch: 75 [5760/14860 (38%)]\tLoss: 0.018662\n",
      "Train Epoch: 75 [5888/14860 (39%)]\tLoss: 0.024078\n",
      "Train Epoch: 75 [6016/14860 (40%)]\tLoss: 0.018519\n",
      "Train Epoch: 75 [6144/14860 (41%)]\tLoss: 0.021658\n",
      "Train Epoch: 75 [6272/14860 (42%)]\tLoss: 0.016684\n",
      "Train Epoch: 75 [6400/14860 (43%)]\tLoss: 0.024876\n",
      "Train Epoch: 75 [6528/14860 (44%)]\tLoss: 0.020078\n",
      "Train Epoch: 75 [6656/14860 (44%)]\tLoss: 0.020758\n",
      "Train Epoch: 75 [6784/14860 (45%)]\tLoss: 0.018717\n",
      "Train Epoch: 75 [6912/14860 (46%)]\tLoss: 0.014001\n",
      "Train Epoch: 75 [7040/14860 (47%)]\tLoss: 0.019819\n",
      "Train Epoch: 75 [7168/14860 (48%)]\tLoss: 0.018761\n",
      "Train Epoch: 75 [7296/14860 (49%)]\tLoss: 0.018235\n",
      "Train Epoch: 75 [7424/14860 (50%)]\tLoss: 0.016590\n",
      "Train Epoch: 75 [7552/14860 (50%)]\tLoss: 0.016539\n",
      "Train Epoch: 75 [7680/14860 (51%)]\tLoss: 0.018612\n",
      "Train Epoch: 75 [7808/14860 (52%)]\tLoss: 0.014084\n",
      "Train Epoch: 75 [7936/14860 (53%)]\tLoss: 0.015537\n",
      "Train Epoch: 75 [8064/14860 (54%)]\tLoss: 0.018557\n",
      "Train Epoch: 75 [8192/14860 (55%)]\tLoss: 0.014705\n",
      "Train Epoch: 75 [8320/14860 (56%)]\tLoss: 0.018747\n",
      "Train Epoch: 75 [8448/14860 (56%)]\tLoss: 0.016175\n",
      "Train Epoch: 75 [8576/14860 (57%)]\tLoss: 0.020375\n",
      "Train Epoch: 75 [8704/14860 (58%)]\tLoss: 0.021463\n",
      "Train Epoch: 75 [8832/14860 (59%)]\tLoss: 0.019658\n",
      "Train Epoch: 75 [8960/14860 (60%)]\tLoss: 0.016256\n",
      "Train Epoch: 75 [9088/14860 (61%)]\tLoss: 0.020881\n",
      "Train Epoch: 75 [9216/14860 (62%)]\tLoss: 0.016688\n",
      "Train Epoch: 75 [9344/14860 (62%)]\tLoss: 0.021139\n",
      "Train Epoch: 75 [9472/14860 (63%)]\tLoss: 0.016205\n",
      "Train Epoch: 75 [9600/14860 (64%)]\tLoss: 0.019603\n",
      "Train Epoch: 75 [9728/14860 (65%)]\tLoss: 0.016800\n",
      "Train Epoch: 75 [9856/14860 (66%)]\tLoss: 0.022162\n",
      "Train Epoch: 75 [9984/14860 (67%)]\tLoss: 0.017737\n",
      "Train Epoch: 75 [10112/14860 (68%)]\tLoss: 0.015560\n",
      "Train Epoch: 75 [10240/14860 (68%)]\tLoss: 0.011033\n",
      "Train Epoch: 75 [10368/14860 (69%)]\tLoss: 0.021088\n",
      "Train Epoch: 75 [10496/14860 (70%)]\tLoss: 0.018094\n",
      "Train Epoch: 75 [10624/14860 (71%)]\tLoss: 0.018120\n",
      "Train Epoch: 75 [10752/14860 (72%)]\tLoss: 0.021904\n",
      "Train Epoch: 75 [10880/14860 (73%)]\tLoss: 0.018412\n",
      "Train Epoch: 75 [11008/14860 (74%)]\tLoss: 0.018854\n",
      "Train Epoch: 75 [11136/14860 (74%)]\tLoss: 0.016531\n",
      "Train Epoch: 75 [11264/14860 (75%)]\tLoss: 0.027398\n",
      "Train Epoch: 75 [11392/14860 (76%)]\tLoss: 0.020040\n",
      "Train Epoch: 75 [11520/14860 (77%)]\tLoss: 0.019270\n",
      "Train Epoch: 75 [11648/14860 (78%)]\tLoss: 0.017332\n",
      "Train Epoch: 75 [11776/14860 (79%)]\tLoss: 0.022589\n",
      "Train Epoch: 75 [11904/14860 (79%)]\tLoss: 0.022193\n",
      "Train Epoch: 75 [12032/14860 (80%)]\tLoss: 0.017967\n",
      "Train Epoch: 75 [12160/14860 (81%)]\tLoss: 0.014498\n",
      "Train Epoch: 75 [12288/14860 (82%)]\tLoss: 0.021403\n",
      "Train Epoch: 75 [12416/14860 (83%)]\tLoss: 0.013693\n",
      "Train Epoch: 75 [12544/14860 (84%)]\tLoss: 0.020561\n",
      "Train Epoch: 75 [12672/14860 (85%)]\tLoss: 0.018642\n",
      "Train Epoch: 75 [12800/14860 (85%)]\tLoss: 0.016993\n",
      "Train Epoch: 75 [12928/14860 (86%)]\tLoss: 0.017778\n",
      "Train Epoch: 75 [13056/14860 (87%)]\tLoss: 0.012864\n",
      "Train Epoch: 75 [13184/14860 (88%)]\tLoss: 0.027319\n",
      "Train Epoch: 75 [13312/14860 (89%)]\tLoss: 0.012535\n",
      "Train Epoch: 75 [13440/14860 (90%)]\tLoss: 0.018800\n",
      "Train Epoch: 75 [13568/14860 (91%)]\tLoss: 0.024122\n",
      "Train Epoch: 75 [13696/14860 (91%)]\tLoss: 0.017217\n",
      "Train Epoch: 75 [13824/14860 (92%)]\tLoss: 0.016948\n",
      "Train Epoch: 75 [13952/14860 (93%)]\tLoss: 0.021046\n",
      "Train Epoch: 75 [14080/14860 (94%)]\tLoss: 0.025579\n",
      "Train Epoch: 75 [14208/14860 (95%)]\tLoss: 0.021462\n",
      "Train Epoch: 75 [14336/14860 (96%)]\tLoss: 0.031976\n",
      "Train Epoch: 75 [14464/14860 (97%)]\tLoss: 0.016410\n",
      "Train Epoch: 75 [14592/14860 (97%)]\tLoss: 0.026640\n",
      "Train Epoch: 75 [14720/14860 (98%)]\tLoss: 0.027323\n",
      "Train Epoch: 75 [1392/14860 (99%)]\tLoss: 0.010260\n",
      "epoch 75 training loss: 0.019008139578195717\n",
      "epoch 75 validation loss: 0.02209994954577947\n",
      "Train Epoch: 76 [0/14860 (0%)]\tLoss: 0.018118\n",
      "Train Epoch: 76 [128/14860 (1%)]\tLoss: 0.027543\n",
      "Train Epoch: 76 [256/14860 (2%)]\tLoss: 0.017140\n",
      "Train Epoch: 76 [384/14860 (3%)]\tLoss: 0.021693\n",
      "Train Epoch: 76 [512/14860 (3%)]\tLoss: 0.018658\n",
      "Train Epoch: 76 [640/14860 (4%)]\tLoss: 0.014121\n",
      "Train Epoch: 76 [768/14860 (5%)]\tLoss: 0.018106\n",
      "Train Epoch: 76 [896/14860 (6%)]\tLoss: 0.019055\n",
      "Train Epoch: 76 [1024/14860 (7%)]\tLoss: 0.022255\n",
      "Train Epoch: 76 [1152/14860 (8%)]\tLoss: 0.015906\n",
      "Train Epoch: 76 [1280/14860 (9%)]\tLoss: 0.019479\n",
      "Train Epoch: 76 [1408/14860 (9%)]\tLoss: 0.024537\n",
      "Train Epoch: 76 [1536/14860 (10%)]\tLoss: 0.019849\n",
      "Train Epoch: 76 [1664/14860 (11%)]\tLoss: 0.018130\n",
      "Train Epoch: 76 [1792/14860 (12%)]\tLoss: 0.019201\n",
      "Train Epoch: 76 [1920/14860 (13%)]\tLoss: 0.017885\n",
      "Train Epoch: 76 [2048/14860 (14%)]\tLoss: 0.026454\n",
      "Train Epoch: 76 [2176/14860 (15%)]\tLoss: 0.014209\n",
      "Train Epoch: 76 [2304/14860 (15%)]\tLoss: 0.031308\n",
      "Train Epoch: 76 [2432/14860 (16%)]\tLoss: 0.014310\n",
      "Train Epoch: 76 [2560/14860 (17%)]\tLoss: 0.024120\n",
      "Train Epoch: 76 [2688/14860 (18%)]\tLoss: 0.023584\n",
      "Train Epoch: 76 [2816/14860 (19%)]\tLoss: 0.019634\n",
      "Train Epoch: 76 [2944/14860 (20%)]\tLoss: 0.014793\n",
      "Train Epoch: 76 [3072/14860 (21%)]\tLoss: 0.015306\n",
      "Train Epoch: 76 [3200/14860 (21%)]\tLoss: 0.017552\n",
      "Train Epoch: 76 [3328/14860 (22%)]\tLoss: 0.019644\n",
      "Train Epoch: 76 [3456/14860 (23%)]\tLoss: 0.021490\n",
      "Train Epoch: 76 [3584/14860 (24%)]\tLoss: 0.018492\n",
      "Train Epoch: 76 [3712/14860 (25%)]\tLoss: 0.021524\n",
      "Train Epoch: 76 [3840/14860 (26%)]\tLoss: 0.019049\n",
      "Train Epoch: 76 [3968/14860 (26%)]\tLoss: 0.022843\n",
      "Train Epoch: 76 [4096/14860 (27%)]\tLoss: 0.028925\n",
      "Train Epoch: 76 [4224/14860 (28%)]\tLoss: 0.021142\n",
      "Train Epoch: 76 [4352/14860 (29%)]\tLoss: 0.018401\n",
      "Train Epoch: 76 [4480/14860 (30%)]\tLoss: 0.020984\n",
      "Train Epoch: 76 [4608/14860 (31%)]\tLoss: 0.023692\n",
      "Train Epoch: 76 [4736/14860 (32%)]\tLoss: 0.020024\n",
      "Train Epoch: 76 [4864/14860 (32%)]\tLoss: 0.017033\n",
      "Train Epoch: 76 [4992/14860 (33%)]\tLoss: 0.023343\n",
      "Train Epoch: 76 [5120/14860 (34%)]\tLoss: 0.017342\n",
      "Train Epoch: 76 [5248/14860 (35%)]\tLoss: 0.018324\n",
      "Train Epoch: 76 [5376/14860 (36%)]\tLoss: 0.013361\n",
      "Train Epoch: 76 [5504/14860 (37%)]\tLoss: 0.016082\n",
      "Train Epoch: 76 [5632/14860 (38%)]\tLoss: 0.015420\n",
      "Train Epoch: 76 [5760/14860 (38%)]\tLoss: 0.018355\n",
      "Train Epoch: 76 [5888/14860 (39%)]\tLoss: 0.019013\n",
      "Train Epoch: 76 [6016/14860 (40%)]\tLoss: 0.021441\n",
      "Train Epoch: 76 [6144/14860 (41%)]\tLoss: 0.021672\n",
      "Train Epoch: 76 [6272/14860 (42%)]\tLoss: 0.014427\n",
      "Train Epoch: 76 [6400/14860 (43%)]\tLoss: 0.022043\n",
      "Train Epoch: 76 [6528/14860 (44%)]\tLoss: 0.024503\n",
      "Train Epoch: 76 [6656/14860 (44%)]\tLoss: 0.019102\n",
      "Train Epoch: 76 [6784/14860 (45%)]\tLoss: 0.020528\n",
      "Train Epoch: 76 [6912/14860 (46%)]\tLoss: 0.019205\n",
      "Train Epoch: 76 [7040/14860 (47%)]\tLoss: 0.028180\n",
      "Train Epoch: 76 [7168/14860 (48%)]\tLoss: 0.016804\n",
      "Train Epoch: 76 [7296/14860 (49%)]\tLoss: 0.023583\n",
      "Train Epoch: 76 [7424/14860 (50%)]\tLoss: 0.019428\n",
      "Train Epoch: 76 [7552/14860 (50%)]\tLoss: 0.016033\n",
      "Train Epoch: 76 [7680/14860 (51%)]\tLoss: 0.021932\n",
      "Train Epoch: 76 [7808/14860 (52%)]\tLoss: 0.013990\n",
      "Train Epoch: 76 [7936/14860 (53%)]\tLoss: 0.018404\n",
      "Train Epoch: 76 [8064/14860 (54%)]\tLoss: 0.020172\n",
      "Train Epoch: 76 [8192/14860 (55%)]\tLoss: 0.023908\n",
      "Train Epoch: 76 [8320/14860 (56%)]\tLoss: 0.022837\n",
      "Train Epoch: 76 [8448/14860 (56%)]\tLoss: 0.019973\n",
      "Train Epoch: 76 [8576/14860 (57%)]\tLoss: 0.015929\n",
      "Train Epoch: 76 [8704/14860 (58%)]\tLoss: 0.027476\n",
      "Train Epoch: 76 [8832/14860 (59%)]\tLoss: 0.017634\n",
      "Train Epoch: 76 [8960/14860 (60%)]\tLoss: 0.017818\n",
      "Train Epoch: 76 [9088/14860 (61%)]\tLoss: 0.018988\n",
      "Train Epoch: 76 [9216/14860 (62%)]\tLoss: 0.014844\n",
      "Train Epoch: 76 [9344/14860 (62%)]\tLoss: 0.012196\n",
      "Train Epoch: 76 [9472/14860 (63%)]\tLoss: 0.025276\n",
      "Train Epoch: 76 [9600/14860 (64%)]\tLoss: 0.018552\n",
      "Train Epoch: 76 [9728/14860 (65%)]\tLoss: 0.014574\n",
      "Train Epoch: 76 [9856/14860 (66%)]\tLoss: 0.014456\n",
      "Train Epoch: 76 [9984/14860 (67%)]\tLoss: 0.019054\n",
      "Train Epoch: 76 [10112/14860 (68%)]\tLoss: 0.017827\n",
      "Train Epoch: 76 [10240/14860 (68%)]\tLoss: 0.017315\n",
      "Train Epoch: 76 [10368/14860 (69%)]\tLoss: 0.017011\n",
      "Train Epoch: 76 [10496/14860 (70%)]\tLoss: 0.022516\n",
      "Train Epoch: 76 [10624/14860 (71%)]\tLoss: 0.019770\n",
      "Train Epoch: 76 [10752/14860 (72%)]\tLoss: 0.021154\n",
      "Train Epoch: 76 [10880/14860 (73%)]\tLoss: 0.014754\n",
      "Train Epoch: 76 [11008/14860 (74%)]\tLoss: 0.012330\n",
      "Train Epoch: 76 [11136/14860 (74%)]\tLoss: 0.018207\n",
      "Train Epoch: 76 [11264/14860 (75%)]\tLoss: 0.028235\n",
      "Train Epoch: 76 [11392/14860 (76%)]\tLoss: 0.016907\n",
      "Train Epoch: 76 [11520/14860 (77%)]\tLoss: 0.017894\n",
      "Train Epoch: 76 [11648/14860 (78%)]\tLoss: 0.020777\n",
      "Train Epoch: 76 [11776/14860 (79%)]\tLoss: 0.019246\n",
      "Train Epoch: 76 [11904/14860 (79%)]\tLoss: 0.020013\n",
      "Train Epoch: 76 [12032/14860 (80%)]\tLoss: 0.018609\n",
      "Train Epoch: 76 [12160/14860 (81%)]\tLoss: 0.019766\n",
      "Train Epoch: 76 [12288/14860 (82%)]\tLoss: 0.021250\n",
      "Train Epoch: 76 [12416/14860 (83%)]\tLoss: 0.022312\n",
      "Train Epoch: 76 [12544/14860 (84%)]\tLoss: 0.012527\n",
      "Train Epoch: 76 [12672/14860 (85%)]\tLoss: 0.019030\n",
      "Train Epoch: 76 [12800/14860 (85%)]\tLoss: 0.017778\n",
      "Train Epoch: 76 [12928/14860 (86%)]\tLoss: 0.018057\n",
      "Train Epoch: 76 [13056/14860 (87%)]\tLoss: 0.019802\n",
      "Train Epoch: 76 [13184/14860 (88%)]\tLoss: 0.022201\n",
      "Train Epoch: 76 [13312/14860 (89%)]\tLoss: 0.015935\n",
      "Train Epoch: 76 [13440/14860 (90%)]\tLoss: 0.023048\n",
      "Train Epoch: 76 [13568/14860 (91%)]\tLoss: 0.023735\n",
      "Train Epoch: 76 [13696/14860 (91%)]\tLoss: 0.020743\n",
      "Train Epoch: 76 [13824/14860 (92%)]\tLoss: 0.016712\n",
      "Train Epoch: 76 [13952/14860 (93%)]\tLoss: 0.030330\n",
      "Train Epoch: 76 [14080/14860 (94%)]\tLoss: 0.015282\n",
      "Train Epoch: 76 [14208/14860 (95%)]\tLoss: 0.017065\n",
      "Train Epoch: 76 [14336/14860 (96%)]\tLoss: 0.012853\n",
      "Train Epoch: 76 [14464/14860 (97%)]\tLoss: 0.012957\n",
      "Train Epoch: 76 [14592/14860 (97%)]\tLoss: 0.020730\n",
      "Train Epoch: 76 [14720/14860 (98%)]\tLoss: 0.024996\n",
      "Train Epoch: 76 [1392/14860 (99%)]\tLoss: 0.012998\n",
      "epoch 76 training loss: 0.019444987790770512\n",
      "epoch 76 validation loss: 0.01988558114007945\n",
      "Train Epoch: 77 [0/14860 (0%)]\tLoss: 0.016927\n",
      "Train Epoch: 77 [128/14860 (1%)]\tLoss: 0.022053\n",
      "Train Epoch: 77 [256/14860 (2%)]\tLoss: 0.019627\n",
      "Train Epoch: 77 [384/14860 (3%)]\tLoss: 0.014360\n",
      "Train Epoch: 77 [512/14860 (3%)]\tLoss: 0.018890\n",
      "Train Epoch: 77 [640/14860 (4%)]\tLoss: 0.012889\n",
      "Train Epoch: 77 [768/14860 (5%)]\tLoss: 0.011633\n",
      "Train Epoch: 77 [896/14860 (6%)]\tLoss: 0.021049\n",
      "Train Epoch: 77 [1024/14860 (7%)]\tLoss: 0.025359\n",
      "Train Epoch: 77 [1152/14860 (8%)]\tLoss: 0.031070\n",
      "Train Epoch: 77 [1280/14860 (9%)]\tLoss: 0.014878\n",
      "Train Epoch: 77 [1408/14860 (9%)]\tLoss: 0.016819\n",
      "Train Epoch: 77 [1536/14860 (10%)]\tLoss: 0.024942\n",
      "Train Epoch: 77 [1664/14860 (11%)]\tLoss: 0.024821\n",
      "Train Epoch: 77 [1792/14860 (12%)]\tLoss: 0.016374\n",
      "Train Epoch: 77 [1920/14860 (13%)]\tLoss: 0.019837\n",
      "Train Epoch: 77 [2048/14860 (14%)]\tLoss: 0.018738\n",
      "Train Epoch: 77 [2176/14860 (15%)]\tLoss: 0.016513\n",
      "Train Epoch: 77 [2304/14860 (15%)]\tLoss: 0.015539\n",
      "Train Epoch: 77 [2432/14860 (16%)]\tLoss: 0.014902\n",
      "Train Epoch: 77 [2560/14860 (17%)]\tLoss: 0.022536\n",
      "Train Epoch: 77 [2688/14860 (18%)]\tLoss: 0.016497\n",
      "Train Epoch: 77 [2816/14860 (19%)]\tLoss: 0.019607\n",
      "Train Epoch: 77 [2944/14860 (20%)]\tLoss: 0.025005\n",
      "Train Epoch: 77 [3072/14860 (21%)]\tLoss: 0.018054\n",
      "Train Epoch: 77 [3200/14860 (21%)]\tLoss: 0.020122\n",
      "Train Epoch: 77 [3328/14860 (22%)]\tLoss: 0.014745\n",
      "Train Epoch: 77 [3456/14860 (23%)]\tLoss: 0.016077\n",
      "Train Epoch: 77 [3584/14860 (24%)]\tLoss: 0.016596\n",
      "Train Epoch: 77 [3712/14860 (25%)]\tLoss: 0.019831\n",
      "Train Epoch: 77 [3840/14860 (26%)]\tLoss: 0.015680\n",
      "Train Epoch: 77 [3968/14860 (26%)]\tLoss: 0.014203\n",
      "Train Epoch: 77 [4096/14860 (27%)]\tLoss: 0.018296\n",
      "Train Epoch: 77 [4224/14860 (28%)]\tLoss: 0.022732\n",
      "Train Epoch: 77 [4352/14860 (29%)]\tLoss: 0.020343\n",
      "Train Epoch: 77 [4480/14860 (30%)]\tLoss: 0.012399\n",
      "Train Epoch: 77 [4608/14860 (31%)]\tLoss: 0.020049\n",
      "Train Epoch: 77 [4736/14860 (32%)]\tLoss: 0.020507\n",
      "Train Epoch: 77 [4864/14860 (32%)]\tLoss: 0.022899\n",
      "Train Epoch: 77 [4992/14860 (33%)]\tLoss: 0.019326\n",
      "Train Epoch: 77 [5120/14860 (34%)]\tLoss: 0.025846\n",
      "Train Epoch: 77 [5248/14860 (35%)]\tLoss: 0.015707\n",
      "Train Epoch: 77 [5376/14860 (36%)]\tLoss: 0.016249\n",
      "Train Epoch: 77 [5504/14860 (37%)]\tLoss: 0.016514\n",
      "Train Epoch: 77 [5632/14860 (38%)]\tLoss: 0.023285\n",
      "Train Epoch: 77 [5760/14860 (38%)]\tLoss: 0.020456\n",
      "Train Epoch: 77 [5888/14860 (39%)]\tLoss: 0.025432\n",
      "Train Epoch: 77 [6016/14860 (40%)]\tLoss: 0.015477\n",
      "Train Epoch: 77 [6144/14860 (41%)]\tLoss: 0.027247\n",
      "Train Epoch: 77 [6272/14860 (42%)]\tLoss: 0.026686\n",
      "Train Epoch: 77 [6400/14860 (43%)]\tLoss: 0.019437\n",
      "Train Epoch: 77 [6528/14860 (44%)]\tLoss: 0.016155\n",
      "Train Epoch: 77 [6656/14860 (44%)]\tLoss: 0.015014\n",
      "Train Epoch: 77 [6784/14860 (45%)]\tLoss: 0.021457\n",
      "Train Epoch: 77 [6912/14860 (46%)]\tLoss: 0.021502\n",
      "Train Epoch: 77 [7040/14860 (47%)]\tLoss: 0.021629\n",
      "Train Epoch: 77 [7168/14860 (48%)]\tLoss: 0.014766\n",
      "Train Epoch: 77 [7296/14860 (49%)]\tLoss: 0.017625\n",
      "Train Epoch: 77 [7424/14860 (50%)]\tLoss: 0.018357\n",
      "Train Epoch: 77 [7552/14860 (50%)]\tLoss: 0.017702\n",
      "Train Epoch: 77 [7680/14860 (51%)]\tLoss: 0.019068\n",
      "Train Epoch: 77 [7808/14860 (52%)]\tLoss: 0.016647\n",
      "Train Epoch: 77 [7936/14860 (53%)]\tLoss: 0.020023\n",
      "Train Epoch: 77 [8064/14860 (54%)]\tLoss: 0.017280\n",
      "Train Epoch: 77 [8192/14860 (55%)]\tLoss: 0.020578\n",
      "Train Epoch: 77 [8320/14860 (56%)]\tLoss: 0.023158\n",
      "Train Epoch: 77 [8448/14860 (56%)]\tLoss: 0.019369\n",
      "Train Epoch: 77 [8576/14860 (57%)]\tLoss: 0.018050\n",
      "Train Epoch: 77 [8704/14860 (58%)]\tLoss: 0.019162\n",
      "Train Epoch: 77 [8832/14860 (59%)]\tLoss: 0.018736\n",
      "Train Epoch: 77 [8960/14860 (60%)]\tLoss: 0.019893\n",
      "Train Epoch: 77 [9088/14860 (61%)]\tLoss: 0.021699\n",
      "Train Epoch: 77 [9216/14860 (62%)]\tLoss: 0.017402\n",
      "Train Epoch: 77 [9344/14860 (62%)]\tLoss: 0.019164\n",
      "Train Epoch: 77 [9472/14860 (63%)]\tLoss: 0.017031\n",
      "Train Epoch: 77 [9600/14860 (64%)]\tLoss: 0.016393\n",
      "Train Epoch: 77 [9728/14860 (65%)]\tLoss: 0.013308\n",
      "Train Epoch: 77 [9856/14860 (66%)]\tLoss: 0.012518\n",
      "Train Epoch: 77 [9984/14860 (67%)]\tLoss: 0.019048\n",
      "Train Epoch: 77 [10112/14860 (68%)]\tLoss: 0.023848\n",
      "Train Epoch: 77 [10240/14860 (68%)]\tLoss: 0.023265\n",
      "Train Epoch: 77 [10368/14860 (69%)]\tLoss: 0.025473\n",
      "Train Epoch: 77 [10496/14860 (70%)]\tLoss: 0.017830\n",
      "Train Epoch: 77 [10624/14860 (71%)]\tLoss: 0.019893\n",
      "Train Epoch: 77 [10752/14860 (72%)]\tLoss: 0.028600\n",
      "Train Epoch: 77 [10880/14860 (73%)]\tLoss: 0.013921\n",
      "Train Epoch: 77 [11008/14860 (74%)]\tLoss: 0.020438\n",
      "Train Epoch: 77 [11136/14860 (74%)]\tLoss: 0.023273\n",
      "Train Epoch: 77 [11264/14860 (75%)]\tLoss: 0.020113\n",
      "Train Epoch: 77 [11392/14860 (76%)]\tLoss: 0.024084\n",
      "Train Epoch: 77 [11520/14860 (77%)]\tLoss: 0.024608\n",
      "Train Epoch: 77 [11648/14860 (78%)]\tLoss: 0.017215\n",
      "Train Epoch: 77 [11776/14860 (79%)]\tLoss: 0.019194\n",
      "Train Epoch: 77 [11904/14860 (79%)]\tLoss: 0.017618\n",
      "Train Epoch: 77 [12032/14860 (80%)]\tLoss: 0.017437\n",
      "Train Epoch: 77 [12160/14860 (81%)]\tLoss: 0.015678\n",
      "Train Epoch: 77 [12288/14860 (82%)]\tLoss: 0.025509\n",
      "Train Epoch: 77 [12416/14860 (83%)]\tLoss: 0.017816\n",
      "Train Epoch: 77 [12544/14860 (84%)]\tLoss: 0.021189\n",
      "Train Epoch: 77 [12672/14860 (85%)]\tLoss: 0.025819\n",
      "Train Epoch: 77 [12800/14860 (85%)]\tLoss: 0.023682\n",
      "Train Epoch: 77 [12928/14860 (86%)]\tLoss: 0.017055\n",
      "Train Epoch: 77 [13056/14860 (87%)]\tLoss: 0.017504\n",
      "Train Epoch: 77 [13184/14860 (88%)]\tLoss: 0.014725\n",
      "Train Epoch: 77 [13312/14860 (89%)]\tLoss: 0.023436\n",
      "Train Epoch: 77 [13440/14860 (90%)]\tLoss: 0.017244\n",
      "Train Epoch: 77 [13568/14860 (91%)]\tLoss: 0.021730\n",
      "Train Epoch: 77 [13696/14860 (91%)]\tLoss: 0.035242\n",
      "Train Epoch: 77 [13824/14860 (92%)]\tLoss: 0.021778\n",
      "Train Epoch: 77 [13952/14860 (93%)]\tLoss: 0.012667\n",
      "Train Epoch: 77 [14080/14860 (94%)]\tLoss: 0.023871\n",
      "Train Epoch: 77 [14208/14860 (95%)]\tLoss: 0.026767\n",
      "Train Epoch: 77 [14336/14860 (96%)]\tLoss: 0.012735\n",
      "Train Epoch: 77 [14464/14860 (97%)]\tLoss: 0.019531\n",
      "Train Epoch: 77 [14592/14860 (97%)]\tLoss: 0.021752\n",
      "Train Epoch: 77 [14720/14860 (98%)]\tLoss: 0.018637\n",
      "Train Epoch: 77 [1392/14860 (99%)]\tLoss: 0.007958\n",
      "epoch 77 training loss: 0.019460922735942226\n",
      "epoch 77 validation loss: 0.025538525194579116\n",
      "Train Epoch: 78 [0/14860 (0%)]\tLoss: 0.030811\n",
      "Train Epoch: 78 [128/14860 (1%)]\tLoss: 0.021896\n",
      "Train Epoch: 78 [256/14860 (2%)]\tLoss: 0.022931\n",
      "Train Epoch: 78 [384/14860 (3%)]\tLoss: 0.012746\n",
      "Train Epoch: 78 [512/14860 (3%)]\tLoss: 0.019154\n",
      "Train Epoch: 78 [640/14860 (4%)]\tLoss: 0.030675\n",
      "Train Epoch: 78 [768/14860 (5%)]\tLoss: 0.023526\n",
      "Train Epoch: 78 [896/14860 (6%)]\tLoss: 0.023593\n",
      "Train Epoch: 78 [1024/14860 (7%)]\tLoss: 0.021452\n",
      "Train Epoch: 78 [1152/14860 (8%)]\tLoss: 0.022233\n",
      "Train Epoch: 78 [1280/14860 (9%)]\tLoss: 0.015158\n",
      "Train Epoch: 78 [1408/14860 (9%)]\tLoss: 0.021171\n",
      "Train Epoch: 78 [1536/14860 (10%)]\tLoss: 0.012621\n",
      "Train Epoch: 78 [1664/14860 (11%)]\tLoss: 0.018151\n",
      "Train Epoch: 78 [1792/14860 (12%)]\tLoss: 0.021465\n",
      "Train Epoch: 78 [1920/14860 (13%)]\tLoss: 0.017986\n",
      "Train Epoch: 78 [2048/14860 (14%)]\tLoss: 0.014842\n",
      "Train Epoch: 78 [2176/14860 (15%)]\tLoss: 0.017912\n",
      "Train Epoch: 78 [2304/14860 (15%)]\tLoss: 0.024207\n",
      "Train Epoch: 78 [2432/14860 (16%)]\tLoss: 0.014579\n",
      "Train Epoch: 78 [2560/14860 (17%)]\tLoss: 0.018178\n",
      "Train Epoch: 78 [2688/14860 (18%)]\tLoss: 0.016823\n",
      "Train Epoch: 78 [2816/14860 (19%)]\tLoss: 0.016125\n",
      "Train Epoch: 78 [2944/14860 (20%)]\tLoss: 0.015247\n",
      "Train Epoch: 78 [3072/14860 (21%)]\tLoss: 0.024355\n",
      "Train Epoch: 78 [3200/14860 (21%)]\tLoss: 0.019016\n",
      "Train Epoch: 78 [3328/14860 (22%)]\tLoss: 0.022047\n",
      "Train Epoch: 78 [3456/14860 (23%)]\tLoss: 0.015767\n",
      "Train Epoch: 78 [3584/14860 (24%)]\tLoss: 0.020404\n",
      "Train Epoch: 78 [3712/14860 (25%)]\tLoss: 0.022851\n",
      "Train Epoch: 78 [3840/14860 (26%)]\tLoss: 0.017163\n",
      "Train Epoch: 78 [3968/14860 (26%)]\tLoss: 0.019963\n",
      "Train Epoch: 78 [4096/14860 (27%)]\tLoss: 0.018531\n",
      "Train Epoch: 78 [4224/14860 (28%)]\tLoss: 0.017835\n",
      "Train Epoch: 78 [4352/14860 (29%)]\tLoss: 0.018318\n",
      "Train Epoch: 78 [4480/14860 (30%)]\tLoss: 0.025649\n",
      "Train Epoch: 78 [4608/14860 (31%)]\tLoss: 0.024969\n",
      "Train Epoch: 78 [4736/14860 (32%)]\tLoss: 0.022586\n",
      "Train Epoch: 78 [4864/14860 (32%)]\tLoss: 0.020538\n",
      "Train Epoch: 78 [4992/14860 (33%)]\tLoss: 0.016019\n",
      "Train Epoch: 78 [5120/14860 (34%)]\tLoss: 0.017280\n",
      "Train Epoch: 78 [5248/14860 (35%)]\tLoss: 0.017929\n",
      "Train Epoch: 78 [5376/14860 (36%)]\tLoss: 0.017968\n",
      "Train Epoch: 78 [5504/14860 (37%)]\tLoss: 0.025124\n",
      "Train Epoch: 78 [5632/14860 (38%)]\tLoss: 0.023470\n",
      "Train Epoch: 78 [5760/14860 (38%)]\tLoss: 0.020538\n",
      "Train Epoch: 78 [5888/14860 (39%)]\tLoss: 0.018261\n",
      "Train Epoch: 78 [6016/14860 (40%)]\tLoss: 0.015329\n",
      "Train Epoch: 78 [6144/14860 (41%)]\tLoss: 0.025540\n",
      "Train Epoch: 78 [6272/14860 (42%)]\tLoss: 0.020023\n",
      "Train Epoch: 78 [6400/14860 (43%)]\tLoss: 0.019563\n",
      "Train Epoch: 78 [6528/14860 (44%)]\tLoss: 0.014018\n",
      "Train Epoch: 78 [6656/14860 (44%)]\tLoss: 0.017490\n",
      "Train Epoch: 78 [6784/14860 (45%)]\tLoss: 0.019239\n",
      "Train Epoch: 78 [6912/14860 (46%)]\tLoss: 0.015586\n",
      "Train Epoch: 78 [7040/14860 (47%)]\tLoss: 0.016537\n",
      "Train Epoch: 78 [7168/14860 (48%)]\tLoss: 0.020361\n",
      "Train Epoch: 78 [7296/14860 (49%)]\tLoss: 0.020361\n",
      "Train Epoch: 78 [7424/14860 (50%)]\tLoss: 0.019248\n",
      "Train Epoch: 78 [7552/14860 (50%)]\tLoss: 0.017328\n",
      "Train Epoch: 78 [7680/14860 (51%)]\tLoss: 0.012157\n",
      "Train Epoch: 78 [7808/14860 (52%)]\tLoss: 0.012858\n",
      "Train Epoch: 78 [7936/14860 (53%)]\tLoss: 0.022873\n",
      "Train Epoch: 78 [8064/14860 (54%)]\tLoss: 0.019547\n",
      "Train Epoch: 78 [8192/14860 (55%)]\tLoss: 0.015705\n",
      "Train Epoch: 78 [8320/14860 (56%)]\tLoss: 0.012976\n",
      "Train Epoch: 78 [8448/14860 (56%)]\tLoss: 0.015541\n",
      "Train Epoch: 78 [8576/14860 (57%)]\tLoss: 0.014952\n",
      "Train Epoch: 78 [8704/14860 (58%)]\tLoss: 0.017390\n",
      "Train Epoch: 78 [8832/14860 (59%)]\tLoss: 0.017106\n",
      "Train Epoch: 78 [8960/14860 (60%)]\tLoss: 0.018918\n",
      "Train Epoch: 78 [9088/14860 (61%)]\tLoss: 0.019862\n",
      "Train Epoch: 78 [9216/14860 (62%)]\tLoss: 0.016152\n",
      "Train Epoch: 78 [9344/14860 (62%)]\tLoss: 0.023196\n",
      "Train Epoch: 78 [9472/14860 (63%)]\tLoss: 0.016056\n",
      "Train Epoch: 78 [9600/14860 (64%)]\tLoss: 0.020568\n",
      "Train Epoch: 78 [9728/14860 (65%)]\tLoss: 0.016836\n",
      "Train Epoch: 78 [9856/14860 (66%)]\tLoss: 0.026430\n",
      "Train Epoch: 78 [9984/14860 (67%)]\tLoss: 0.014493\n",
      "Train Epoch: 78 [10112/14860 (68%)]\tLoss: 0.016680\n",
      "Train Epoch: 78 [10240/14860 (68%)]\tLoss: 0.021683\n",
      "Train Epoch: 78 [10368/14860 (69%)]\tLoss: 0.015374\n",
      "Train Epoch: 78 [10496/14860 (70%)]\tLoss: 0.020449\n",
      "Train Epoch: 78 [10624/14860 (71%)]\tLoss: 0.014597\n",
      "Train Epoch: 78 [10752/14860 (72%)]\tLoss: 0.020269\n",
      "Train Epoch: 78 [10880/14860 (73%)]\tLoss: 0.014038\n",
      "Train Epoch: 78 [11008/14860 (74%)]\tLoss: 0.014681\n",
      "Train Epoch: 78 [11136/14860 (74%)]\tLoss: 0.015032\n",
      "Train Epoch: 78 [11264/14860 (75%)]\tLoss: 0.018146\n",
      "Train Epoch: 78 [11392/14860 (76%)]\tLoss: 0.023575\n",
      "Train Epoch: 78 [11520/14860 (77%)]\tLoss: 0.016414\n",
      "Train Epoch: 78 [11648/14860 (78%)]\tLoss: 0.012835\n",
      "Train Epoch: 78 [11776/14860 (79%)]\tLoss: 0.028698\n",
      "Train Epoch: 78 [11904/14860 (79%)]\tLoss: 0.015522\n",
      "Train Epoch: 78 [12032/14860 (80%)]\tLoss: 0.019940\n",
      "Train Epoch: 78 [12160/14860 (81%)]\tLoss: 0.021388\n",
      "Train Epoch: 78 [12288/14860 (82%)]\tLoss: 0.023679\n",
      "Train Epoch: 78 [12416/14860 (83%)]\tLoss: 0.018725\n",
      "Train Epoch: 78 [12544/14860 (84%)]\tLoss: 0.020867\n",
      "Train Epoch: 78 [12672/14860 (85%)]\tLoss: 0.021023\n",
      "Train Epoch: 78 [12800/14860 (85%)]\tLoss: 0.015759\n",
      "Train Epoch: 78 [12928/14860 (86%)]\tLoss: 0.026191\n",
      "Train Epoch: 78 [13056/14860 (87%)]\tLoss: 0.017113\n",
      "Train Epoch: 78 [13184/14860 (88%)]\tLoss: 0.020275\n",
      "Train Epoch: 78 [13312/14860 (89%)]\tLoss: 0.016357\n",
      "Train Epoch: 78 [13440/14860 (90%)]\tLoss: 0.019752\n",
      "Train Epoch: 78 [13568/14860 (91%)]\tLoss: 0.017841\n",
      "Train Epoch: 78 [13696/14860 (91%)]\tLoss: 0.014123\n",
      "Train Epoch: 78 [13824/14860 (92%)]\tLoss: 0.019266\n",
      "Train Epoch: 78 [13952/14860 (93%)]\tLoss: 0.020751\n",
      "Train Epoch: 78 [14080/14860 (94%)]\tLoss: 0.015744\n",
      "Train Epoch: 78 [14208/14860 (95%)]\tLoss: 0.020462\n",
      "Train Epoch: 78 [14336/14860 (96%)]\tLoss: 0.017435\n",
      "Train Epoch: 78 [14464/14860 (97%)]\tLoss: 0.021394\n",
      "Train Epoch: 78 [14592/14860 (97%)]\tLoss: 0.024213\n",
      "Train Epoch: 78 [14720/14860 (98%)]\tLoss: 0.014091\n",
      "Train Epoch: 78 [1392/14860 (99%)]\tLoss: 0.014925\n",
      "epoch 78 training loss: 0.01900515164861567\n",
      "epoch 78 validation loss: 0.019890138225463053\n",
      "Train Epoch: 79 [0/14860 (0%)]\tLoss: 0.015867\n",
      "Train Epoch: 79 [128/14860 (1%)]\tLoss: 0.020165\n",
      "Train Epoch: 79 [256/14860 (2%)]\tLoss: 0.016816\n",
      "Train Epoch: 79 [384/14860 (3%)]\tLoss: 0.017632\n",
      "Train Epoch: 79 [512/14860 (3%)]\tLoss: 0.016044\n",
      "Train Epoch: 79 [640/14860 (4%)]\tLoss: 0.018597\n",
      "Train Epoch: 79 [768/14860 (5%)]\tLoss: 0.023506\n",
      "Train Epoch: 79 [896/14860 (6%)]\tLoss: 0.018096\n",
      "Train Epoch: 79 [1024/14860 (7%)]\tLoss: 0.020131\n",
      "Train Epoch: 79 [1152/14860 (8%)]\tLoss: 0.031238\n",
      "Train Epoch: 79 [1280/14860 (9%)]\tLoss: 0.017886\n",
      "Train Epoch: 79 [1408/14860 (9%)]\tLoss: 0.023619\n",
      "Train Epoch: 79 [1536/14860 (10%)]\tLoss: 0.019448\n",
      "Train Epoch: 79 [1664/14860 (11%)]\tLoss: 0.017838\n",
      "Train Epoch: 79 [1792/14860 (12%)]\tLoss: 0.022047\n",
      "Train Epoch: 79 [1920/14860 (13%)]\tLoss: 0.017814\n",
      "Train Epoch: 79 [2048/14860 (14%)]\tLoss: 0.014553\n",
      "Train Epoch: 79 [2176/14860 (15%)]\tLoss: 0.028814\n",
      "Train Epoch: 79 [2304/14860 (15%)]\tLoss: 0.019124\n",
      "Train Epoch: 79 [2432/14860 (16%)]\tLoss: 0.018763\n",
      "Train Epoch: 79 [2560/14860 (17%)]\tLoss: 0.029653\n",
      "Train Epoch: 79 [2688/14860 (18%)]\tLoss: 0.020867\n",
      "Train Epoch: 79 [2816/14860 (19%)]\tLoss: 0.016642\n",
      "Train Epoch: 79 [2944/14860 (20%)]\tLoss: 0.020923\n",
      "Train Epoch: 79 [3072/14860 (21%)]\tLoss: 0.013574\n",
      "Train Epoch: 79 [3200/14860 (21%)]\tLoss: 0.018703\n",
      "Train Epoch: 79 [3328/14860 (22%)]\tLoss: 0.018859\n",
      "Train Epoch: 79 [3456/14860 (23%)]\tLoss: 0.017714\n",
      "Train Epoch: 79 [3584/14860 (24%)]\tLoss: 0.016495\n",
      "Train Epoch: 79 [3712/14860 (25%)]\tLoss: 0.015130\n",
      "Train Epoch: 79 [3840/14860 (26%)]\tLoss: 0.018581\n",
      "Train Epoch: 79 [3968/14860 (26%)]\tLoss: 0.019353\n",
      "Train Epoch: 79 [4096/14860 (27%)]\tLoss: 0.016702\n",
      "Train Epoch: 79 [4224/14860 (28%)]\tLoss: 0.012339\n",
      "Train Epoch: 79 [4352/14860 (29%)]\tLoss: 0.020119\n",
      "Train Epoch: 79 [4480/14860 (30%)]\tLoss: 0.018508\n",
      "Train Epoch: 79 [4608/14860 (31%)]\tLoss: 0.020658\n",
      "Train Epoch: 79 [4736/14860 (32%)]\tLoss: 0.023169\n",
      "Train Epoch: 79 [4864/14860 (32%)]\tLoss: 0.018726\n",
      "Train Epoch: 79 [4992/14860 (33%)]\tLoss: 0.019655\n",
      "Train Epoch: 79 [5120/14860 (34%)]\tLoss: 0.015285\n",
      "Train Epoch: 79 [5248/14860 (35%)]\tLoss: 0.018722\n",
      "Train Epoch: 79 [5376/14860 (36%)]\tLoss: 0.021188\n",
      "Train Epoch: 79 [5504/14860 (37%)]\tLoss: 0.011211\n",
      "Train Epoch: 79 [5632/14860 (38%)]\tLoss: 0.016832\n",
      "Train Epoch: 79 [5760/14860 (38%)]\tLoss: 0.016477\n",
      "Train Epoch: 79 [5888/14860 (39%)]\tLoss: 0.019774\n",
      "Train Epoch: 79 [6016/14860 (40%)]\tLoss: 0.016111\n",
      "Train Epoch: 79 [6144/14860 (41%)]\tLoss: 0.019585\n",
      "Train Epoch: 79 [6272/14860 (42%)]\tLoss: 0.016038\n",
      "Train Epoch: 79 [6400/14860 (43%)]\tLoss: 0.022559\n",
      "Train Epoch: 79 [6528/14860 (44%)]\tLoss: 0.028476\n",
      "Train Epoch: 79 [6656/14860 (44%)]\tLoss: 0.020615\n",
      "Train Epoch: 79 [6784/14860 (45%)]\tLoss: 0.020062\n",
      "Train Epoch: 79 [6912/14860 (46%)]\tLoss: 0.021206\n",
      "Train Epoch: 79 [7040/14860 (47%)]\tLoss: 0.016331\n",
      "Train Epoch: 79 [7168/14860 (48%)]\tLoss: 0.036585\n",
      "Train Epoch: 79 [7296/14860 (49%)]\tLoss: 0.016925\n",
      "Train Epoch: 79 [7424/14860 (50%)]\tLoss: 0.027386\n",
      "Train Epoch: 79 [7552/14860 (50%)]\tLoss: 0.028587\n",
      "Train Epoch: 79 [7680/14860 (51%)]\tLoss: 0.015209\n",
      "Train Epoch: 79 [7808/14860 (52%)]\tLoss: 0.028684\n",
      "Train Epoch: 79 [7936/14860 (53%)]\tLoss: 0.025576\n",
      "Train Epoch: 79 [8064/14860 (54%)]\tLoss: 0.019878\n",
      "Train Epoch: 79 [8192/14860 (55%)]\tLoss: 0.021963\n",
      "Train Epoch: 79 [8320/14860 (56%)]\tLoss: 0.024686\n",
      "Train Epoch: 79 [8448/14860 (56%)]\tLoss: 0.014791\n",
      "Train Epoch: 79 [8576/14860 (57%)]\tLoss: 0.017906\n",
      "Train Epoch: 79 [8704/14860 (58%)]\tLoss: 0.026968\n",
      "Train Epoch: 79 [8832/14860 (59%)]\tLoss: 0.017447\n",
      "Train Epoch: 79 [8960/14860 (60%)]\tLoss: 0.012973\n",
      "Train Epoch: 79 [9088/14860 (61%)]\tLoss: 0.026727\n",
      "Train Epoch: 79 [9216/14860 (62%)]\tLoss: 0.019240\n",
      "Train Epoch: 79 [9344/14860 (62%)]\tLoss: 0.016945\n",
      "Train Epoch: 79 [9472/14860 (63%)]\tLoss: 0.019197\n",
      "Train Epoch: 79 [9600/14860 (64%)]\tLoss: 0.022721\n",
      "Train Epoch: 79 [9728/14860 (65%)]\tLoss: 0.022543\n",
      "Train Epoch: 79 [9856/14860 (66%)]\tLoss: 0.032921\n",
      "Train Epoch: 79 [9984/14860 (67%)]\tLoss: 0.020785\n",
      "Train Epoch: 79 [10112/14860 (68%)]\tLoss: 0.020429\n",
      "Train Epoch: 79 [10240/14860 (68%)]\tLoss: 0.013305\n",
      "Train Epoch: 79 [10368/14860 (69%)]\tLoss: 0.021392\n",
      "Train Epoch: 79 [10496/14860 (70%)]\tLoss: 0.023755\n",
      "Train Epoch: 79 [10624/14860 (71%)]\tLoss: 0.023034\n",
      "Train Epoch: 79 [10752/14860 (72%)]\tLoss: 0.012135\n",
      "Train Epoch: 79 [10880/14860 (73%)]\tLoss: 0.022889\n",
      "Train Epoch: 79 [11008/14860 (74%)]\tLoss: 0.022751\n",
      "Train Epoch: 79 [11136/14860 (74%)]\tLoss: 0.013721\n",
      "Train Epoch: 79 [11264/14860 (75%)]\tLoss: 0.017401\n",
      "Train Epoch: 79 [11392/14860 (76%)]\tLoss: 0.018492\n",
      "Train Epoch: 79 [11520/14860 (77%)]\tLoss: 0.019760\n",
      "Train Epoch: 79 [11648/14860 (78%)]\tLoss: 0.021613\n",
      "Train Epoch: 79 [11776/14860 (79%)]\tLoss: 0.019141\n",
      "Train Epoch: 79 [11904/14860 (79%)]\tLoss: 0.019272\n",
      "Train Epoch: 79 [12032/14860 (80%)]\tLoss: 0.014475\n",
      "Train Epoch: 79 [12160/14860 (81%)]\tLoss: 0.015489\n",
      "Train Epoch: 79 [12288/14860 (82%)]\tLoss: 0.025070\n",
      "Train Epoch: 79 [12416/14860 (83%)]\tLoss: 0.017633\n",
      "Train Epoch: 79 [12544/14860 (84%)]\tLoss: 0.019370\n",
      "Train Epoch: 79 [12672/14860 (85%)]\tLoss: 0.018174\n",
      "Train Epoch: 79 [12800/14860 (85%)]\tLoss: 0.020479\n",
      "Train Epoch: 79 [12928/14860 (86%)]\tLoss: 0.015081\n",
      "Train Epoch: 79 [13056/14860 (87%)]\tLoss: 0.024827\n",
      "Train Epoch: 79 [13184/14860 (88%)]\tLoss: 0.021553\n",
      "Train Epoch: 79 [13312/14860 (89%)]\tLoss: 0.019439\n",
      "Train Epoch: 79 [13440/14860 (90%)]\tLoss: 0.015426\n",
      "Train Epoch: 79 [13568/14860 (91%)]\tLoss: 0.015791\n",
      "Train Epoch: 79 [13696/14860 (91%)]\tLoss: 0.016914\n",
      "Train Epoch: 79 [13824/14860 (92%)]\tLoss: 0.019502\n",
      "Train Epoch: 79 [13952/14860 (93%)]\tLoss: 0.035167\n",
      "Train Epoch: 79 [14080/14860 (94%)]\tLoss: 0.020901\n",
      "Train Epoch: 79 [14208/14860 (95%)]\tLoss: 0.015170\n",
      "Train Epoch: 79 [14336/14860 (96%)]\tLoss: 0.016416\n",
      "Train Epoch: 79 [14464/14860 (97%)]\tLoss: 0.022725\n",
      "Train Epoch: 79 [14592/14860 (97%)]\tLoss: 0.018180\n",
      "Train Epoch: 79 [14720/14860 (98%)]\tLoss: 0.020359\n",
      "Train Epoch: 79 [1392/14860 (99%)]\tLoss: 0.009698\n",
      "epoch 79 training loss: 0.019815528709600624\n",
      "epoch 79 validation loss: 0.019816962339110292\n",
      "Train Epoch: 80 [0/14860 (0%)]\tLoss: 0.020045\n",
      "Train Epoch: 80 [128/14860 (1%)]\tLoss: 0.016257\n",
      "Train Epoch: 80 [256/14860 (2%)]\tLoss: 0.015889\n",
      "Train Epoch: 80 [384/14860 (3%)]\tLoss: 0.018566\n",
      "Train Epoch: 80 [512/14860 (3%)]\tLoss: 0.018967\n",
      "Train Epoch: 80 [640/14860 (4%)]\tLoss: 0.020434\n",
      "Train Epoch: 80 [768/14860 (5%)]\tLoss: 0.017360\n",
      "Train Epoch: 80 [896/14860 (6%)]\tLoss: 0.026270\n",
      "Train Epoch: 80 [1024/14860 (7%)]\tLoss: 0.016102\n",
      "Train Epoch: 80 [1152/14860 (8%)]\tLoss: 0.014203\n",
      "Train Epoch: 80 [1280/14860 (9%)]\tLoss: 0.018367\n",
      "Train Epoch: 80 [1408/14860 (9%)]\tLoss: 0.023138\n",
      "Train Epoch: 80 [1536/14860 (10%)]\tLoss: 0.018675\n",
      "Train Epoch: 80 [1664/14860 (11%)]\tLoss: 0.017145\n",
      "Train Epoch: 80 [1792/14860 (12%)]\tLoss: 0.017184\n",
      "Train Epoch: 80 [1920/14860 (13%)]\tLoss: 0.013406\n",
      "Train Epoch: 80 [2048/14860 (14%)]\tLoss: 0.024099\n",
      "Train Epoch: 80 [2176/14860 (15%)]\tLoss: 0.017038\n",
      "Train Epoch: 80 [2304/14860 (15%)]\tLoss: 0.023585\n",
      "Train Epoch: 80 [2432/14860 (16%)]\tLoss: 0.023818\n",
      "Train Epoch: 80 [2560/14860 (17%)]\tLoss: 0.012559\n",
      "Train Epoch: 80 [2688/14860 (18%)]\tLoss: 0.023894\n",
      "Train Epoch: 80 [2816/14860 (19%)]\tLoss: 0.023496\n",
      "Train Epoch: 80 [2944/14860 (20%)]\tLoss: 0.017183\n",
      "Train Epoch: 80 [3072/14860 (21%)]\tLoss: 0.016741\n",
      "Train Epoch: 80 [3200/14860 (21%)]\tLoss: 0.023497\n",
      "Train Epoch: 80 [3328/14860 (22%)]\tLoss: 0.019479\n",
      "Train Epoch: 80 [3456/14860 (23%)]\tLoss: 0.015758\n",
      "Train Epoch: 80 [3584/14860 (24%)]\tLoss: 0.011324\n",
      "Train Epoch: 80 [3712/14860 (25%)]\tLoss: 0.023142\n",
      "Train Epoch: 80 [3840/14860 (26%)]\tLoss: 0.018395\n",
      "Train Epoch: 80 [3968/14860 (26%)]\tLoss: 0.023537\n",
      "Train Epoch: 80 [4096/14860 (27%)]\tLoss: 0.015996\n",
      "Train Epoch: 80 [4224/14860 (28%)]\tLoss: 0.016368\n",
      "Train Epoch: 80 [4352/14860 (29%)]\tLoss: 0.017027\n",
      "Train Epoch: 80 [4480/14860 (30%)]\tLoss: 0.020130\n",
      "Train Epoch: 80 [4608/14860 (31%)]\tLoss: 0.014086\n",
      "Train Epoch: 80 [4736/14860 (32%)]\tLoss: 0.017644\n",
      "Train Epoch: 80 [4864/14860 (32%)]\tLoss: 0.020066\n",
      "Train Epoch: 80 [4992/14860 (33%)]\tLoss: 0.029675\n",
      "Train Epoch: 80 [5120/14860 (34%)]\tLoss: 0.017125\n",
      "Train Epoch: 80 [5248/14860 (35%)]\tLoss: 0.012957\n",
      "Train Epoch: 80 [5376/14860 (36%)]\tLoss: 0.018137\n",
      "Train Epoch: 80 [5504/14860 (37%)]\tLoss: 0.019394\n",
      "Train Epoch: 80 [5632/14860 (38%)]\tLoss: 0.014229\n",
      "Train Epoch: 80 [5760/14860 (38%)]\tLoss: 0.018425\n",
      "Train Epoch: 80 [5888/14860 (39%)]\tLoss: 0.020660\n",
      "Train Epoch: 80 [6016/14860 (40%)]\tLoss: 0.018518\n",
      "Train Epoch: 80 [6144/14860 (41%)]\tLoss: 0.023225\n",
      "Train Epoch: 80 [6272/14860 (42%)]\tLoss: 0.013491\n",
      "Train Epoch: 80 [6400/14860 (43%)]\tLoss: 0.020987\n",
      "Train Epoch: 80 [6528/14860 (44%)]\tLoss: 0.017562\n",
      "Train Epoch: 80 [6656/14860 (44%)]\tLoss: 0.014353\n",
      "Train Epoch: 80 [6784/14860 (45%)]\tLoss: 0.020734\n",
      "Train Epoch: 80 [6912/14860 (46%)]\tLoss: 0.011151\n",
      "Train Epoch: 80 [7040/14860 (47%)]\tLoss: 0.014076\n",
      "Train Epoch: 80 [7168/14860 (48%)]\tLoss: 0.018687\n",
      "Train Epoch: 80 [7296/14860 (49%)]\tLoss: 0.013441\n",
      "Train Epoch: 80 [7424/14860 (50%)]\tLoss: 0.014234\n",
      "Train Epoch: 80 [7552/14860 (50%)]\tLoss: 0.020506\n",
      "Train Epoch: 80 [7680/14860 (51%)]\tLoss: 0.015054\n",
      "Train Epoch: 80 [7808/14860 (52%)]\tLoss: 0.020752\n",
      "Train Epoch: 80 [7936/14860 (53%)]\tLoss: 0.012645\n",
      "Train Epoch: 80 [8064/14860 (54%)]\tLoss: 0.019216\n",
      "Train Epoch: 80 [8192/14860 (55%)]\tLoss: 0.015694\n",
      "Train Epoch: 80 [8320/14860 (56%)]\tLoss: 0.026162\n",
      "Train Epoch: 80 [8448/14860 (56%)]\tLoss: 0.019525\n",
      "Train Epoch: 80 [8576/14860 (57%)]\tLoss: 0.017210\n",
      "Train Epoch: 80 [8704/14860 (58%)]\tLoss: 0.018224\n",
      "Train Epoch: 80 [8832/14860 (59%)]\tLoss: 0.022976\n",
      "Train Epoch: 80 [8960/14860 (60%)]\tLoss: 0.022581\n",
      "Train Epoch: 80 [9088/14860 (61%)]\tLoss: 0.022388\n",
      "Train Epoch: 80 [9216/14860 (62%)]\tLoss: 0.014735\n",
      "Train Epoch: 80 [9344/14860 (62%)]\tLoss: 0.013156\n",
      "Train Epoch: 80 [9472/14860 (63%)]\tLoss: 0.028641\n",
      "Train Epoch: 80 [9600/14860 (64%)]\tLoss: 0.032088\n",
      "Train Epoch: 80 [9728/14860 (65%)]\tLoss: 0.018818\n",
      "Train Epoch: 80 [9856/14860 (66%)]\tLoss: 0.019119\n",
      "Train Epoch: 80 [9984/14860 (67%)]\tLoss: 0.020162\n",
      "Train Epoch: 80 [10112/14860 (68%)]\tLoss: 0.016651\n",
      "Train Epoch: 80 [10240/14860 (68%)]\tLoss: 0.023223\n",
      "Train Epoch: 80 [10368/14860 (69%)]\tLoss: 0.025423\n",
      "Train Epoch: 80 [10496/14860 (70%)]\tLoss: 0.022966\n",
      "Train Epoch: 80 [10624/14860 (71%)]\tLoss: 0.020781\n",
      "Train Epoch: 80 [10752/14860 (72%)]\tLoss: 0.019903\n",
      "Train Epoch: 80 [10880/14860 (73%)]\tLoss: 0.017008\n",
      "Train Epoch: 80 [11008/14860 (74%)]\tLoss: 0.024413\n",
      "Train Epoch: 80 [11136/14860 (74%)]\tLoss: 0.019320\n",
      "Train Epoch: 80 [11264/14860 (75%)]\tLoss: 0.012991\n",
      "Train Epoch: 80 [11392/14860 (76%)]\tLoss: 0.015788\n",
      "Train Epoch: 80 [11520/14860 (77%)]\tLoss: 0.019843\n",
      "Train Epoch: 80 [11648/14860 (78%)]\tLoss: 0.022030\n",
      "Train Epoch: 80 [11776/14860 (79%)]\tLoss: 0.021829\n",
      "Train Epoch: 80 [11904/14860 (79%)]\tLoss: 0.032468\n",
      "Train Epoch: 80 [12032/14860 (80%)]\tLoss: 0.018283\n",
      "Train Epoch: 80 [12160/14860 (81%)]\tLoss: 0.016240\n",
      "Train Epoch: 80 [12288/14860 (82%)]\tLoss: 0.019162\n",
      "Train Epoch: 80 [12416/14860 (83%)]\tLoss: 0.015490\n",
      "Train Epoch: 80 [12544/14860 (84%)]\tLoss: 0.011435\n",
      "Train Epoch: 80 [12672/14860 (85%)]\tLoss: 0.026173\n",
      "Train Epoch: 80 [12800/14860 (85%)]\tLoss: 0.020659\n",
      "Train Epoch: 80 [12928/14860 (86%)]\tLoss: 0.020026\n",
      "Train Epoch: 80 [13056/14860 (87%)]\tLoss: 0.018255\n",
      "Train Epoch: 80 [13184/14860 (88%)]\tLoss: 0.022190\n",
      "Train Epoch: 80 [13312/14860 (89%)]\tLoss: 0.023057\n",
      "Train Epoch: 80 [13440/14860 (90%)]\tLoss: 0.018957\n",
      "Train Epoch: 80 [13568/14860 (91%)]\tLoss: 0.017995\n",
      "Train Epoch: 80 [13696/14860 (91%)]\tLoss: 0.021650\n",
      "Train Epoch: 80 [13824/14860 (92%)]\tLoss: 0.014103\n",
      "Train Epoch: 80 [13952/14860 (93%)]\tLoss: 0.012562\n",
      "Train Epoch: 80 [14080/14860 (94%)]\tLoss: 0.021387\n",
      "Train Epoch: 80 [14208/14860 (95%)]\tLoss: 0.015727\n",
      "Train Epoch: 80 [14336/14860 (96%)]\tLoss: 0.016337\n",
      "Train Epoch: 80 [14464/14860 (97%)]\tLoss: 0.016858\n",
      "Train Epoch: 80 [14592/14860 (97%)]\tLoss: 0.015739\n",
      "Train Epoch: 80 [14720/14860 (98%)]\tLoss: 0.013917\n",
      "Train Epoch: 80 [1392/14860 (99%)]\tLoss: 0.004957\n",
      "epoch 80 training loss: 0.018781012505229212\n",
      "epoch 80 validation loss: 0.023158135339076524\n",
      "Train Epoch: 81 [0/14860 (0%)]\tLoss: 0.020249\n",
      "Train Epoch: 81 [128/14860 (1%)]\tLoss: 0.029577\n",
      "Train Epoch: 81 [256/14860 (2%)]\tLoss: 0.028549\n",
      "Train Epoch: 81 [384/14860 (3%)]\tLoss: 0.015353\n",
      "Train Epoch: 81 [512/14860 (3%)]\tLoss: 0.022661\n",
      "Train Epoch: 81 [640/14860 (4%)]\tLoss: 0.031662\n",
      "Train Epoch: 81 [768/14860 (5%)]\tLoss: 0.015166\n",
      "Train Epoch: 81 [896/14860 (6%)]\tLoss: 0.019996\n",
      "Train Epoch: 81 [1024/14860 (7%)]\tLoss: 0.024307\n",
      "Train Epoch: 81 [1152/14860 (8%)]\tLoss: 0.023041\n",
      "Train Epoch: 81 [1280/14860 (9%)]\tLoss: 0.012889\n",
      "Train Epoch: 81 [1408/14860 (9%)]\tLoss: 0.023493\n",
      "Train Epoch: 81 [1536/14860 (10%)]\tLoss: 0.029517\n",
      "Train Epoch: 81 [1664/14860 (11%)]\tLoss: 0.020757\n",
      "Train Epoch: 81 [1792/14860 (12%)]\tLoss: 0.020336\n",
      "Train Epoch: 81 [1920/14860 (13%)]\tLoss: 0.023462\n",
      "Train Epoch: 81 [2048/14860 (14%)]\tLoss: 0.014464\n",
      "Train Epoch: 81 [2176/14860 (15%)]\tLoss: 0.022353\n",
      "Train Epoch: 81 [2304/14860 (15%)]\tLoss: 0.021725\n",
      "Train Epoch: 81 [2432/14860 (16%)]\tLoss: 0.022300\n",
      "Train Epoch: 81 [2560/14860 (17%)]\tLoss: 0.018766\n",
      "Train Epoch: 81 [2688/14860 (18%)]\tLoss: 0.014059\n",
      "Train Epoch: 81 [2816/14860 (19%)]\tLoss: 0.027865\n",
      "Train Epoch: 81 [2944/14860 (20%)]\tLoss: 0.017303\n",
      "Train Epoch: 81 [3072/14860 (21%)]\tLoss: 0.016282\n",
      "Train Epoch: 81 [3200/14860 (21%)]\tLoss: 0.024025\n",
      "Train Epoch: 81 [3328/14860 (22%)]\tLoss: 0.018200\n",
      "Train Epoch: 81 [3456/14860 (23%)]\tLoss: 0.020333\n",
      "Train Epoch: 81 [3584/14860 (24%)]\tLoss: 0.022896\n",
      "Train Epoch: 81 [3712/14860 (25%)]\tLoss: 0.025526\n",
      "Train Epoch: 81 [3840/14860 (26%)]\tLoss: 0.015895\n",
      "Train Epoch: 81 [3968/14860 (26%)]\tLoss: 0.021745\n",
      "Train Epoch: 81 [4096/14860 (27%)]\tLoss: 0.019841\n",
      "Train Epoch: 81 [4224/14860 (28%)]\tLoss: 0.019763\n",
      "Train Epoch: 81 [4352/14860 (29%)]\tLoss: 0.021466\n",
      "Train Epoch: 81 [4480/14860 (30%)]\tLoss: 0.019328\n",
      "Train Epoch: 81 [4608/14860 (31%)]\tLoss: 0.017576\n",
      "Train Epoch: 81 [4736/14860 (32%)]\tLoss: 0.022866\n",
      "Train Epoch: 81 [4864/14860 (32%)]\tLoss: 0.017404\n",
      "Train Epoch: 81 [4992/14860 (33%)]\tLoss: 0.018530\n",
      "Train Epoch: 81 [5120/14860 (34%)]\tLoss: 0.016199\n",
      "Train Epoch: 81 [5248/14860 (35%)]\tLoss: 0.014079\n",
      "Train Epoch: 81 [5376/14860 (36%)]\tLoss: 0.017399\n",
      "Train Epoch: 81 [5504/14860 (37%)]\tLoss: 0.027051\n",
      "Train Epoch: 81 [5632/14860 (38%)]\tLoss: 0.014873\n",
      "Train Epoch: 81 [5760/14860 (38%)]\tLoss: 0.022109\n",
      "Train Epoch: 81 [5888/14860 (39%)]\tLoss: 0.017006\n",
      "Train Epoch: 81 [6016/14860 (40%)]\tLoss: 0.017217\n",
      "Train Epoch: 81 [6144/14860 (41%)]\tLoss: 0.015676\n",
      "Train Epoch: 81 [6272/14860 (42%)]\tLoss: 0.019742\n",
      "Train Epoch: 81 [6400/14860 (43%)]\tLoss: 0.018239\n",
      "Train Epoch: 81 [6528/14860 (44%)]\tLoss: 0.019413\n",
      "Train Epoch: 81 [6656/14860 (44%)]\tLoss: 0.025074\n",
      "Train Epoch: 81 [6784/14860 (45%)]\tLoss: 0.029433\n",
      "Train Epoch: 81 [6912/14860 (46%)]\tLoss: 0.023075\n",
      "Train Epoch: 81 [7040/14860 (47%)]\tLoss: 0.014272\n",
      "Train Epoch: 81 [7168/14860 (48%)]\tLoss: 0.016201\n",
      "Train Epoch: 81 [7296/14860 (49%)]\tLoss: 0.018243\n",
      "Train Epoch: 81 [7424/14860 (50%)]\tLoss: 0.015470\n",
      "Train Epoch: 81 [7552/14860 (50%)]\tLoss: 0.014538\n",
      "Train Epoch: 81 [7680/14860 (51%)]\tLoss: 0.017355\n",
      "Train Epoch: 81 [7808/14860 (52%)]\tLoss: 0.011303\n",
      "Train Epoch: 81 [7936/14860 (53%)]\tLoss: 0.029977\n",
      "Train Epoch: 81 [8064/14860 (54%)]\tLoss: 0.012531\n",
      "Train Epoch: 81 [8192/14860 (55%)]\tLoss: 0.025502\n",
      "Train Epoch: 81 [8320/14860 (56%)]\tLoss: 0.018690\n",
      "Train Epoch: 81 [8448/14860 (56%)]\tLoss: 0.017453\n",
      "Train Epoch: 81 [8576/14860 (57%)]\tLoss: 0.021934\n",
      "Train Epoch: 81 [8704/14860 (58%)]\tLoss: 0.014665\n",
      "Train Epoch: 81 [8832/14860 (59%)]\tLoss: 0.022604\n",
      "Train Epoch: 81 [8960/14860 (60%)]\tLoss: 0.017142\n",
      "Train Epoch: 81 [9088/14860 (61%)]\tLoss: 0.020410\n",
      "Train Epoch: 81 [9216/14860 (62%)]\tLoss: 0.018283\n",
      "Train Epoch: 81 [9344/14860 (62%)]\tLoss: 0.018430\n",
      "Train Epoch: 81 [9472/14860 (63%)]\tLoss: 0.015578\n",
      "Train Epoch: 81 [9600/14860 (64%)]\tLoss: 0.015584\n",
      "Train Epoch: 81 [9728/14860 (65%)]\tLoss: 0.021080\n",
      "Train Epoch: 81 [9856/14860 (66%)]\tLoss: 0.019789\n",
      "Train Epoch: 81 [9984/14860 (67%)]\tLoss: 0.020058\n",
      "Train Epoch: 81 [10112/14860 (68%)]\tLoss: 0.025421\n",
      "Train Epoch: 81 [10240/14860 (68%)]\tLoss: 0.022581\n",
      "Train Epoch: 81 [10368/14860 (69%)]\tLoss: 0.010561\n",
      "Train Epoch: 81 [10496/14860 (70%)]\tLoss: 0.020024\n",
      "Train Epoch: 81 [10624/14860 (71%)]\tLoss: 0.020387\n",
      "Train Epoch: 81 [10752/14860 (72%)]\tLoss: 0.018001\n",
      "Train Epoch: 81 [10880/14860 (73%)]\tLoss: 0.024630\n",
      "Train Epoch: 81 [11008/14860 (74%)]\tLoss: 0.012653\n",
      "Train Epoch: 81 [11136/14860 (74%)]\tLoss: 0.020548\n",
      "Train Epoch: 81 [11264/14860 (75%)]\tLoss: 0.018616\n",
      "Train Epoch: 81 [11392/14860 (76%)]\tLoss: 0.017477\n",
      "Train Epoch: 81 [11520/14860 (77%)]\tLoss: 0.024828\n",
      "Train Epoch: 81 [11648/14860 (78%)]\tLoss: 0.018345\n",
      "Train Epoch: 81 [11776/14860 (79%)]\tLoss: 0.023256\n",
      "Train Epoch: 81 [11904/14860 (79%)]\tLoss: 0.020460\n",
      "Train Epoch: 81 [12032/14860 (80%)]\tLoss: 0.022993\n",
      "Train Epoch: 81 [12160/14860 (81%)]\tLoss: 0.018708\n",
      "Train Epoch: 81 [12288/14860 (82%)]\tLoss: 0.018466\n",
      "Train Epoch: 81 [12416/14860 (83%)]\tLoss: 0.015330\n",
      "Train Epoch: 81 [12544/14860 (84%)]\tLoss: 0.015806\n",
      "Train Epoch: 81 [12672/14860 (85%)]\tLoss: 0.023055\n",
      "Train Epoch: 81 [12800/14860 (85%)]\tLoss: 0.017775\n",
      "Train Epoch: 81 [12928/14860 (86%)]\tLoss: 0.018803\n",
      "Train Epoch: 81 [13056/14860 (87%)]\tLoss: 0.014310\n",
      "Train Epoch: 81 [13184/14860 (88%)]\tLoss: 0.014426\n",
      "Train Epoch: 81 [13312/14860 (89%)]\tLoss: 0.023565\n",
      "Train Epoch: 81 [13440/14860 (90%)]\tLoss: 0.020652\n",
      "Train Epoch: 81 [13568/14860 (91%)]\tLoss: 0.021569\n",
      "Train Epoch: 81 [13696/14860 (91%)]\tLoss: 0.019543\n",
      "Train Epoch: 81 [13824/14860 (92%)]\tLoss: 0.024620\n",
      "Train Epoch: 81 [13952/14860 (93%)]\tLoss: 0.014600\n",
      "Train Epoch: 81 [14080/14860 (94%)]\tLoss: 0.013444\n",
      "Train Epoch: 81 [14208/14860 (95%)]\tLoss: 0.022659\n",
      "Train Epoch: 81 [14336/14860 (96%)]\tLoss: 0.035564\n",
      "Train Epoch: 81 [14464/14860 (97%)]\tLoss: 0.015046\n",
      "Train Epoch: 81 [14592/14860 (97%)]\tLoss: 0.021709\n",
      "Train Epoch: 81 [14720/14860 (98%)]\tLoss: 0.025453\n",
      "Train Epoch: 81 [1392/14860 (99%)]\tLoss: 0.012858\n",
      "epoch 81 training loss: 0.019862768789514516\n",
      "epoch 81 validation loss: 0.02115037012619776\n",
      "Train Epoch: 82 [0/14860 (0%)]\tLoss: 0.023774\n",
      "Train Epoch: 82 [128/14860 (1%)]\tLoss: 0.019857\n",
      "Train Epoch: 82 [256/14860 (2%)]\tLoss: 0.018972\n",
      "Train Epoch: 82 [384/14860 (3%)]\tLoss: 0.022517\n",
      "Train Epoch: 82 [512/14860 (3%)]\tLoss: 0.021569\n",
      "Train Epoch: 82 [640/14860 (4%)]\tLoss: 0.022370\n",
      "Train Epoch: 82 [768/14860 (5%)]\tLoss: 0.012597\n",
      "Train Epoch: 82 [896/14860 (6%)]\tLoss: 0.017400\n",
      "Train Epoch: 82 [1024/14860 (7%)]\tLoss: 0.015159\n",
      "Train Epoch: 82 [1152/14860 (8%)]\tLoss: 0.021456\n",
      "Train Epoch: 82 [1280/14860 (9%)]\tLoss: 0.018230\n",
      "Train Epoch: 82 [1408/14860 (9%)]\tLoss: 0.013080\n",
      "Train Epoch: 82 [1536/14860 (10%)]\tLoss: 0.021735\n",
      "Train Epoch: 82 [1664/14860 (11%)]\tLoss: 0.023062\n",
      "Train Epoch: 82 [1792/14860 (12%)]\tLoss: 0.017144\n",
      "Train Epoch: 82 [1920/14860 (13%)]\tLoss: 0.019389\n",
      "Train Epoch: 82 [2048/14860 (14%)]\tLoss: 0.014388\n",
      "Train Epoch: 82 [2176/14860 (15%)]\tLoss: 0.012849\n",
      "Train Epoch: 82 [2304/14860 (15%)]\tLoss: 0.022893\n",
      "Train Epoch: 82 [2432/14860 (16%)]\tLoss: 0.018899\n",
      "Train Epoch: 82 [2560/14860 (17%)]\tLoss: 0.018274\n",
      "Train Epoch: 82 [2688/14860 (18%)]\tLoss: 0.025931\n",
      "Train Epoch: 82 [2816/14860 (19%)]\tLoss: 0.024711\n",
      "Train Epoch: 82 [2944/14860 (20%)]\tLoss: 0.017569\n",
      "Train Epoch: 82 [3072/14860 (21%)]\tLoss: 0.017640\n",
      "Train Epoch: 82 [3200/14860 (21%)]\tLoss: 0.012318\n",
      "Train Epoch: 82 [3328/14860 (22%)]\tLoss: 0.020825\n",
      "Train Epoch: 82 [3456/14860 (23%)]\tLoss: 0.018727\n",
      "Train Epoch: 82 [3584/14860 (24%)]\tLoss: 0.024508\n",
      "Train Epoch: 82 [3712/14860 (25%)]\tLoss: 0.018638\n",
      "Train Epoch: 82 [3840/14860 (26%)]\tLoss: 0.018710\n",
      "Train Epoch: 82 [3968/14860 (26%)]\tLoss: 0.025693\n",
      "Train Epoch: 82 [4096/14860 (27%)]\tLoss: 0.017464\n",
      "Train Epoch: 82 [4224/14860 (28%)]\tLoss: 0.017484\n",
      "Train Epoch: 82 [4352/14860 (29%)]\tLoss: 0.024503\n",
      "Train Epoch: 82 [4480/14860 (30%)]\tLoss: 0.017640\n",
      "Train Epoch: 82 [4608/14860 (31%)]\tLoss: 0.015001\n",
      "Train Epoch: 82 [4736/14860 (32%)]\tLoss: 0.022691\n",
      "Train Epoch: 82 [4864/14860 (32%)]\tLoss: 0.021203\n",
      "Train Epoch: 82 [4992/14860 (33%)]\tLoss: 0.012774\n",
      "Train Epoch: 82 [5120/14860 (34%)]\tLoss: 0.028583\n",
      "Train Epoch: 82 [5248/14860 (35%)]\tLoss: 0.025682\n",
      "Train Epoch: 82 [5376/14860 (36%)]\tLoss: 0.026733\n",
      "Train Epoch: 82 [5504/14860 (37%)]\tLoss: 0.013025\n",
      "Train Epoch: 82 [5632/14860 (38%)]\tLoss: 0.018811\n",
      "Train Epoch: 82 [5760/14860 (38%)]\tLoss: 0.027627\n",
      "Train Epoch: 82 [5888/14860 (39%)]\tLoss: 0.028208\n",
      "Train Epoch: 82 [6016/14860 (40%)]\tLoss: 0.016330\n",
      "Train Epoch: 82 [6144/14860 (41%)]\tLoss: 0.013810\n",
      "Train Epoch: 82 [6272/14860 (42%)]\tLoss: 0.018639\n",
      "Train Epoch: 82 [6400/14860 (43%)]\tLoss: 0.018855\n",
      "Train Epoch: 82 [6528/14860 (44%)]\tLoss: 0.021226\n",
      "Train Epoch: 82 [6656/14860 (44%)]\tLoss: 0.024710\n",
      "Train Epoch: 82 [6784/14860 (45%)]\tLoss: 0.022040\n",
      "Train Epoch: 82 [6912/14860 (46%)]\tLoss: 0.015903\n",
      "Train Epoch: 82 [7040/14860 (47%)]\tLoss: 0.019009\n",
      "Train Epoch: 82 [7168/14860 (48%)]\tLoss: 0.023072\n",
      "Train Epoch: 82 [7296/14860 (49%)]\tLoss: 0.015768\n",
      "Train Epoch: 82 [7424/14860 (50%)]\tLoss: 0.022263\n",
      "Train Epoch: 82 [7552/14860 (50%)]\tLoss: 0.017370\n",
      "Train Epoch: 82 [7680/14860 (51%)]\tLoss: 0.024050\n",
      "Train Epoch: 82 [7808/14860 (52%)]\tLoss: 0.024830\n",
      "Train Epoch: 82 [7936/14860 (53%)]\tLoss: 0.021268\n",
      "Train Epoch: 82 [8064/14860 (54%)]\tLoss: 0.019829\n",
      "Train Epoch: 82 [8192/14860 (55%)]\tLoss: 0.019354\n",
      "Train Epoch: 82 [8320/14860 (56%)]\tLoss: 0.021733\n",
      "Train Epoch: 82 [8448/14860 (56%)]\tLoss: 0.018167\n",
      "Train Epoch: 82 [8576/14860 (57%)]\tLoss: 0.022134\n",
      "Train Epoch: 82 [8704/14860 (58%)]\tLoss: 0.016875\n",
      "Train Epoch: 82 [8832/14860 (59%)]\tLoss: 0.014187\n",
      "Train Epoch: 82 [8960/14860 (60%)]\tLoss: 0.019920\n",
      "Train Epoch: 82 [9088/14860 (61%)]\tLoss: 0.015709\n",
      "Train Epoch: 82 [9216/14860 (62%)]\tLoss: 0.019366\n",
      "Train Epoch: 82 [9344/14860 (62%)]\tLoss: 0.022584\n",
      "Train Epoch: 82 [9472/14860 (63%)]\tLoss: 0.017314\n",
      "Train Epoch: 82 [9600/14860 (64%)]\tLoss: 0.017985\n",
      "Train Epoch: 82 [9728/14860 (65%)]\tLoss: 0.019075\n",
      "Train Epoch: 82 [9856/14860 (66%)]\tLoss: 0.025653\n",
      "Train Epoch: 82 [9984/14860 (67%)]\tLoss: 0.016565\n",
      "Train Epoch: 82 [10112/14860 (68%)]\tLoss: 0.016351\n",
      "Train Epoch: 82 [10240/14860 (68%)]\tLoss: 0.017834\n",
      "Train Epoch: 82 [10368/14860 (69%)]\tLoss: 0.015982\n",
      "Train Epoch: 82 [10496/14860 (70%)]\tLoss: 0.013894\n",
      "Train Epoch: 82 [10624/14860 (71%)]\tLoss: 0.027112\n",
      "Train Epoch: 82 [10752/14860 (72%)]\tLoss: 0.019030\n",
      "Train Epoch: 82 [10880/14860 (73%)]\tLoss: 0.022280\n",
      "Train Epoch: 82 [11008/14860 (74%)]\tLoss: 0.029852\n",
      "Train Epoch: 82 [11136/14860 (74%)]\tLoss: 0.019297\n",
      "Train Epoch: 82 [11264/14860 (75%)]\tLoss: 0.022917\n",
      "Train Epoch: 82 [11392/14860 (76%)]\tLoss: 0.024040\n",
      "Train Epoch: 82 [11520/14860 (77%)]\tLoss: 0.020449\n",
      "Train Epoch: 82 [11648/14860 (78%)]\tLoss: 0.015995\n",
      "Train Epoch: 82 [11776/14860 (79%)]\tLoss: 0.017182\n",
      "Train Epoch: 82 [11904/14860 (79%)]\tLoss: 0.021937\n",
      "Train Epoch: 82 [12032/14860 (80%)]\tLoss: 0.023214\n",
      "Train Epoch: 82 [12160/14860 (81%)]\tLoss: 0.019030\n",
      "Train Epoch: 82 [12288/14860 (82%)]\tLoss: 0.016517\n",
      "Train Epoch: 82 [12416/14860 (83%)]\tLoss: 0.014352\n",
      "Train Epoch: 82 [12544/14860 (84%)]\tLoss: 0.013570\n",
      "Train Epoch: 82 [12672/14860 (85%)]\tLoss: 0.017263\n",
      "Train Epoch: 82 [12800/14860 (85%)]\tLoss: 0.026282\n",
      "Train Epoch: 82 [12928/14860 (86%)]\tLoss: 0.018418\n",
      "Train Epoch: 82 [13056/14860 (87%)]\tLoss: 0.027389\n",
      "Train Epoch: 82 [13184/14860 (88%)]\tLoss: 0.019938\n",
      "Train Epoch: 82 [13312/14860 (89%)]\tLoss: 0.014155\n",
      "Train Epoch: 82 [13440/14860 (90%)]\tLoss: 0.013284\n",
      "Train Epoch: 82 [13568/14860 (91%)]\tLoss: 0.020967\n",
      "Train Epoch: 82 [13696/14860 (91%)]\tLoss: 0.014506\n",
      "Train Epoch: 82 [13824/14860 (92%)]\tLoss: 0.015598\n",
      "Train Epoch: 82 [13952/14860 (93%)]\tLoss: 0.016433\n",
      "Train Epoch: 82 [14080/14860 (94%)]\tLoss: 0.019955\n",
      "Train Epoch: 82 [14208/14860 (95%)]\tLoss: 0.015206\n",
      "Train Epoch: 82 [14336/14860 (96%)]\tLoss: 0.014258\n",
      "Train Epoch: 82 [14464/14860 (97%)]\tLoss: 0.012842\n",
      "Train Epoch: 82 [14592/14860 (97%)]\tLoss: 0.013193\n",
      "Train Epoch: 82 [14720/14860 (98%)]\tLoss: 0.017052\n",
      "Train Epoch: 82 [1392/14860 (99%)]\tLoss: 0.019493\n",
      "epoch 82 training loss: 0.01941003894003538\n",
      "epoch 82 validation loss: 0.02282129101834055\n",
      "Train Epoch: 83 [0/14860 (0%)]\tLoss: 0.019824\n",
      "Train Epoch: 83 [128/14860 (1%)]\tLoss: 0.020035\n",
      "Train Epoch: 83 [256/14860 (2%)]\tLoss: 0.015619\n",
      "Train Epoch: 83 [384/14860 (3%)]\tLoss: 0.027740\n",
      "Train Epoch: 83 [512/14860 (3%)]\tLoss: 0.016368\n",
      "Train Epoch: 83 [640/14860 (4%)]\tLoss: 0.012708\n",
      "Train Epoch: 83 [768/14860 (5%)]\tLoss: 0.023112\n",
      "Train Epoch: 83 [896/14860 (6%)]\tLoss: 0.021066\n",
      "Train Epoch: 83 [1024/14860 (7%)]\tLoss: 0.012182\n",
      "Train Epoch: 83 [1152/14860 (8%)]\tLoss: 0.031951\n",
      "Train Epoch: 83 [1280/14860 (9%)]\tLoss: 0.021380\n",
      "Train Epoch: 83 [1408/14860 (9%)]\tLoss: 0.020946\n",
      "Train Epoch: 83 [1536/14860 (10%)]\tLoss: 0.026163\n",
      "Train Epoch: 83 [1664/14860 (11%)]\tLoss: 0.012902\n",
      "Train Epoch: 83 [1792/14860 (12%)]\tLoss: 0.020081\n",
      "Train Epoch: 83 [1920/14860 (13%)]\tLoss: 0.021974\n",
      "Train Epoch: 83 [2048/14860 (14%)]\tLoss: 0.018801\n",
      "Train Epoch: 83 [2176/14860 (15%)]\tLoss: 0.014553\n",
      "Train Epoch: 83 [2304/14860 (15%)]\tLoss: 0.013441\n",
      "Train Epoch: 83 [2432/14860 (16%)]\tLoss: 0.020397\n",
      "Train Epoch: 83 [2560/14860 (17%)]\tLoss: 0.021969\n",
      "Train Epoch: 83 [2688/14860 (18%)]\tLoss: 0.015754\n",
      "Train Epoch: 83 [2816/14860 (19%)]\tLoss: 0.018937\n",
      "Train Epoch: 83 [2944/14860 (20%)]\tLoss: 0.014332\n",
      "Train Epoch: 83 [3072/14860 (21%)]\tLoss: 0.021214\n",
      "Train Epoch: 83 [3200/14860 (21%)]\tLoss: 0.021847\n",
      "Train Epoch: 83 [3328/14860 (22%)]\tLoss: 0.020267\n",
      "Train Epoch: 83 [3456/14860 (23%)]\tLoss: 0.024481\n",
      "Train Epoch: 83 [3584/14860 (24%)]\tLoss: 0.020944\n",
      "Train Epoch: 83 [3712/14860 (25%)]\tLoss: 0.020408\n",
      "Train Epoch: 83 [3840/14860 (26%)]\tLoss: 0.021863\n",
      "Train Epoch: 83 [3968/14860 (26%)]\tLoss: 0.019935\n",
      "Train Epoch: 83 [4096/14860 (27%)]\tLoss: 0.017150\n",
      "Train Epoch: 83 [4224/14860 (28%)]\tLoss: 0.018449\n",
      "Train Epoch: 83 [4352/14860 (29%)]\tLoss: 0.017759\n",
      "Train Epoch: 83 [4480/14860 (30%)]\tLoss: 0.019644\n",
      "Train Epoch: 83 [4608/14860 (31%)]\tLoss: 0.015028\n",
      "Train Epoch: 83 [4736/14860 (32%)]\tLoss: 0.017582\n",
      "Train Epoch: 83 [4864/14860 (32%)]\tLoss: 0.019261\n",
      "Train Epoch: 83 [4992/14860 (33%)]\tLoss: 0.012625\n",
      "Train Epoch: 83 [5120/14860 (34%)]\tLoss: 0.015014\n",
      "Train Epoch: 83 [5248/14860 (35%)]\tLoss: 0.017975\n",
      "Train Epoch: 83 [5376/14860 (36%)]\tLoss: 0.015400\n",
      "Train Epoch: 83 [5504/14860 (37%)]\tLoss: 0.019649\n",
      "Train Epoch: 83 [5632/14860 (38%)]\tLoss: 0.024007\n",
      "Train Epoch: 83 [5760/14860 (38%)]\tLoss: 0.017623\n",
      "Train Epoch: 83 [5888/14860 (39%)]\tLoss: 0.013882\n",
      "Train Epoch: 83 [6016/14860 (40%)]\tLoss: 0.018110\n",
      "Train Epoch: 83 [6144/14860 (41%)]\tLoss: 0.018179\n",
      "Train Epoch: 83 [6272/14860 (42%)]\tLoss: 0.017272\n",
      "Train Epoch: 83 [6400/14860 (43%)]\tLoss: 0.023835\n",
      "Train Epoch: 83 [6528/14860 (44%)]\tLoss: 0.017647\n",
      "Train Epoch: 83 [6656/14860 (44%)]\tLoss: 0.016531\n",
      "Train Epoch: 83 [6784/14860 (45%)]\tLoss: 0.014359\n",
      "Train Epoch: 83 [6912/14860 (46%)]\tLoss: 0.021701\n",
      "Train Epoch: 83 [7040/14860 (47%)]\tLoss: 0.015830\n",
      "Train Epoch: 83 [7168/14860 (48%)]\tLoss: 0.019542\n",
      "Train Epoch: 83 [7296/14860 (49%)]\tLoss: 0.018985\n",
      "Train Epoch: 83 [7424/14860 (50%)]\tLoss: 0.017121\n",
      "Train Epoch: 83 [7552/14860 (50%)]\tLoss: 0.018779\n",
      "Train Epoch: 83 [7680/14860 (51%)]\tLoss: 0.015398\n",
      "Train Epoch: 83 [7808/14860 (52%)]\tLoss: 0.018409\n",
      "Train Epoch: 83 [7936/14860 (53%)]\tLoss: 0.020227\n",
      "Train Epoch: 83 [8064/14860 (54%)]\tLoss: 0.021267\n",
      "Train Epoch: 83 [8192/14860 (55%)]\tLoss: 0.018772\n",
      "Train Epoch: 83 [8320/14860 (56%)]\tLoss: 0.012920\n",
      "Train Epoch: 83 [8448/14860 (56%)]\tLoss: 0.020594\n",
      "Train Epoch: 83 [8576/14860 (57%)]\tLoss: 0.022135\n",
      "Train Epoch: 83 [8704/14860 (58%)]\tLoss: 0.016107\n",
      "Train Epoch: 83 [8832/14860 (59%)]\tLoss: 0.018685\n",
      "Train Epoch: 83 [8960/14860 (60%)]\tLoss: 0.024770\n",
      "Train Epoch: 83 [9088/14860 (61%)]\tLoss: 0.019078\n",
      "Train Epoch: 83 [9216/14860 (62%)]\tLoss: 0.025096\n",
      "Train Epoch: 83 [9344/14860 (62%)]\tLoss: 0.020431\n",
      "Train Epoch: 83 [9472/14860 (63%)]\tLoss: 0.017841\n",
      "Train Epoch: 83 [9600/14860 (64%)]\tLoss: 0.012474\n",
      "Train Epoch: 83 [9728/14860 (65%)]\tLoss: 0.017881\n",
      "Train Epoch: 83 [9856/14860 (66%)]\tLoss: 0.018561\n",
      "Train Epoch: 83 [9984/14860 (67%)]\tLoss: 0.022059\n",
      "Train Epoch: 83 [10112/14860 (68%)]\tLoss: 0.026116\n",
      "Train Epoch: 83 [10240/14860 (68%)]\tLoss: 0.025084\n",
      "Train Epoch: 83 [10368/14860 (69%)]\tLoss: 0.026182\n",
      "Train Epoch: 83 [10496/14860 (70%)]\tLoss: 0.015976\n",
      "Train Epoch: 83 [10624/14860 (71%)]\tLoss: 0.026129\n",
      "Train Epoch: 83 [10752/14860 (72%)]\tLoss: 0.020005\n",
      "Train Epoch: 83 [10880/14860 (73%)]\tLoss: 0.019777\n",
      "Train Epoch: 83 [11008/14860 (74%)]\tLoss: 0.021019\n",
      "Train Epoch: 83 [11136/14860 (74%)]\tLoss: 0.019636\n",
      "Train Epoch: 83 [11264/14860 (75%)]\tLoss: 0.020089\n",
      "Train Epoch: 83 [11392/14860 (76%)]\tLoss: 0.021278\n",
      "Train Epoch: 83 [11520/14860 (77%)]\tLoss: 0.013824\n",
      "Train Epoch: 83 [11648/14860 (78%)]\tLoss: 0.023110\n",
      "Train Epoch: 83 [11776/14860 (79%)]\tLoss: 0.019419\n",
      "Train Epoch: 83 [11904/14860 (79%)]\tLoss: 0.015683\n",
      "Train Epoch: 83 [12032/14860 (80%)]\tLoss: 0.018917\n",
      "Train Epoch: 83 [12160/14860 (81%)]\tLoss: 0.018177\n",
      "Train Epoch: 83 [12288/14860 (82%)]\tLoss: 0.018862\n",
      "Train Epoch: 83 [12416/14860 (83%)]\tLoss: 0.017693\n",
      "Train Epoch: 83 [12544/14860 (84%)]\tLoss: 0.017666\n",
      "Train Epoch: 83 [12672/14860 (85%)]\tLoss: 0.019196\n",
      "Train Epoch: 83 [12800/14860 (85%)]\tLoss: 0.016995\n",
      "Train Epoch: 83 [12928/14860 (86%)]\tLoss: 0.015958\n",
      "Train Epoch: 83 [13056/14860 (87%)]\tLoss: 0.016372\n",
      "Train Epoch: 83 [13184/14860 (88%)]\tLoss: 0.016727\n",
      "Train Epoch: 83 [13312/14860 (89%)]\tLoss: 0.018960\n",
      "Train Epoch: 83 [13440/14860 (90%)]\tLoss: 0.015348\n",
      "Train Epoch: 83 [13568/14860 (91%)]\tLoss: 0.016470\n",
      "Train Epoch: 83 [13696/14860 (91%)]\tLoss: 0.021037\n",
      "Train Epoch: 83 [13824/14860 (92%)]\tLoss: 0.020190\n",
      "Train Epoch: 83 [13952/14860 (93%)]\tLoss: 0.015857\n",
      "Train Epoch: 83 [14080/14860 (94%)]\tLoss: 0.016753\n",
      "Train Epoch: 83 [14208/14860 (95%)]\tLoss: 0.020982\n",
      "Train Epoch: 83 [14336/14860 (96%)]\tLoss: 0.021692\n",
      "Train Epoch: 83 [14464/14860 (97%)]\tLoss: 0.021623\n",
      "Train Epoch: 83 [14592/14860 (97%)]\tLoss: 0.021360\n",
      "Train Epoch: 83 [14720/14860 (98%)]\tLoss: 0.027526\n",
      "Train Epoch: 83 [1392/14860 (99%)]\tLoss: 0.023614\n",
      "epoch 83 training loss: 0.01919776129607971\n",
      "epoch 83 validation loss: 0.020702402037512016\n",
      "Train Epoch: 84 [0/14860 (0%)]\tLoss: 0.011682\n",
      "Train Epoch: 84 [128/14860 (1%)]\tLoss: 0.021467\n",
      "Train Epoch: 84 [256/14860 (2%)]\tLoss: 0.016558\n",
      "Train Epoch: 84 [384/14860 (3%)]\tLoss: 0.023511\n",
      "Train Epoch: 84 [512/14860 (3%)]\tLoss: 0.014274\n",
      "Train Epoch: 84 [640/14860 (4%)]\tLoss: 0.017213\n",
      "Train Epoch: 84 [768/14860 (5%)]\tLoss: 0.014834\n",
      "Train Epoch: 84 [896/14860 (6%)]\tLoss: 0.023336\n",
      "Train Epoch: 84 [1024/14860 (7%)]\tLoss: 0.016929\n",
      "Train Epoch: 84 [1152/14860 (8%)]\tLoss: 0.023694\n",
      "Train Epoch: 84 [1280/14860 (9%)]\tLoss: 0.025149\n",
      "Train Epoch: 84 [1408/14860 (9%)]\tLoss: 0.017361\n",
      "Train Epoch: 84 [1536/14860 (10%)]\tLoss: 0.020499\n",
      "Train Epoch: 84 [1664/14860 (11%)]\tLoss: 0.014250\n",
      "Train Epoch: 84 [1792/14860 (12%)]\tLoss: 0.015590\n",
      "Train Epoch: 84 [1920/14860 (13%)]\tLoss: 0.022880\n",
      "Train Epoch: 84 [2048/14860 (14%)]\tLoss: 0.024078\n",
      "Train Epoch: 84 [2176/14860 (15%)]\tLoss: 0.023970\n",
      "Train Epoch: 84 [2304/14860 (15%)]\tLoss: 0.019577\n",
      "Train Epoch: 84 [2432/14860 (16%)]\tLoss: 0.016272\n",
      "Train Epoch: 84 [2560/14860 (17%)]\tLoss: 0.016970\n",
      "Train Epoch: 84 [2688/14860 (18%)]\tLoss: 0.017931\n",
      "Train Epoch: 84 [2816/14860 (19%)]\tLoss: 0.017832\n",
      "Train Epoch: 84 [2944/14860 (20%)]\tLoss: 0.022068\n",
      "Train Epoch: 84 [3072/14860 (21%)]\tLoss: 0.019131\n",
      "Train Epoch: 84 [3200/14860 (21%)]\tLoss: 0.022690\n",
      "Train Epoch: 84 [3328/14860 (22%)]\tLoss: 0.020929\n",
      "Train Epoch: 84 [3456/14860 (23%)]\tLoss: 0.024983\n",
      "Train Epoch: 84 [3584/14860 (24%)]\tLoss: 0.012285\n",
      "Train Epoch: 84 [3712/14860 (25%)]\tLoss: 0.016124\n",
      "Train Epoch: 84 [3840/14860 (26%)]\tLoss: 0.020915\n",
      "Train Epoch: 84 [3968/14860 (26%)]\tLoss: 0.023269\n",
      "Train Epoch: 84 [4096/14860 (27%)]\tLoss: 0.017424\n",
      "Train Epoch: 84 [4224/14860 (28%)]\tLoss: 0.012922\n",
      "Train Epoch: 84 [4352/14860 (29%)]\tLoss: 0.023966\n",
      "Train Epoch: 84 [4480/14860 (30%)]\tLoss: 0.020957\n",
      "Train Epoch: 84 [4608/14860 (31%)]\tLoss: 0.016502\n",
      "Train Epoch: 84 [4736/14860 (32%)]\tLoss: 0.021715\n",
      "Train Epoch: 84 [4864/14860 (32%)]\tLoss: 0.022211\n",
      "Train Epoch: 84 [4992/14860 (33%)]\tLoss: 0.019694\n",
      "Train Epoch: 84 [5120/14860 (34%)]\tLoss: 0.015148\n",
      "Train Epoch: 84 [5248/14860 (35%)]\tLoss: 0.019223\n",
      "Train Epoch: 84 [5376/14860 (36%)]\tLoss: 0.016783\n",
      "Train Epoch: 84 [5504/14860 (37%)]\tLoss: 0.018203\n",
      "Train Epoch: 84 [5632/14860 (38%)]\tLoss: 0.015770\n",
      "Train Epoch: 84 [5760/14860 (38%)]\tLoss: 0.015805\n",
      "Train Epoch: 84 [5888/14860 (39%)]\tLoss: 0.021304\n",
      "Train Epoch: 84 [6016/14860 (40%)]\tLoss: 0.013929\n",
      "Train Epoch: 84 [6144/14860 (41%)]\tLoss: 0.020123\n",
      "Train Epoch: 84 [6272/14860 (42%)]\tLoss: 0.025077\n",
      "Train Epoch: 84 [6400/14860 (43%)]\tLoss: 0.026745\n",
      "Train Epoch: 84 [6528/14860 (44%)]\tLoss: 0.015453\n",
      "Train Epoch: 84 [6656/14860 (44%)]\tLoss: 0.016080\n",
      "Train Epoch: 84 [6784/14860 (45%)]\tLoss: 0.025318\n",
      "Train Epoch: 84 [6912/14860 (46%)]\tLoss: 0.019104\n",
      "Train Epoch: 84 [7040/14860 (47%)]\tLoss: 0.029424\n",
      "Train Epoch: 84 [7168/14860 (48%)]\tLoss: 0.018851\n",
      "Train Epoch: 84 [7296/14860 (49%)]\tLoss: 0.022194\n",
      "Train Epoch: 84 [7424/14860 (50%)]\tLoss: 0.021925\n",
      "Train Epoch: 84 [7552/14860 (50%)]\tLoss: 0.019747\n",
      "Train Epoch: 84 [7680/14860 (51%)]\tLoss: 0.016726\n",
      "Train Epoch: 84 [7808/14860 (52%)]\tLoss: 0.014487\n",
      "Train Epoch: 84 [7936/14860 (53%)]\tLoss: 0.020471\n",
      "Train Epoch: 84 [8064/14860 (54%)]\tLoss: 0.018828\n",
      "Train Epoch: 84 [8192/14860 (55%)]\tLoss: 0.021435\n",
      "Train Epoch: 84 [8320/14860 (56%)]\tLoss: 0.014870\n",
      "Train Epoch: 84 [8448/14860 (56%)]\tLoss: 0.019081\n",
      "Train Epoch: 84 [8576/14860 (57%)]\tLoss: 0.018869\n",
      "Train Epoch: 84 [8704/14860 (58%)]\tLoss: 0.026603\n",
      "Train Epoch: 84 [8832/14860 (59%)]\tLoss: 0.020983\n",
      "Train Epoch: 84 [8960/14860 (60%)]\tLoss: 0.024734\n",
      "Train Epoch: 84 [9088/14860 (61%)]\tLoss: 0.019238\n",
      "Train Epoch: 84 [9216/14860 (62%)]\tLoss: 0.016070\n",
      "Train Epoch: 84 [9344/14860 (62%)]\tLoss: 0.019736\n",
      "Train Epoch: 84 [9472/14860 (63%)]\tLoss: 0.013592\n",
      "Train Epoch: 84 [9600/14860 (64%)]\tLoss: 0.011977\n",
      "Train Epoch: 84 [9728/14860 (65%)]\tLoss: 0.029655\n",
      "Train Epoch: 84 [9856/14860 (66%)]\tLoss: 0.019095\n",
      "Train Epoch: 84 [9984/14860 (67%)]\tLoss: 0.026619\n",
      "Train Epoch: 84 [10112/14860 (68%)]\tLoss: 0.024051\n",
      "Train Epoch: 84 [10240/14860 (68%)]\tLoss: 0.022130\n",
      "Train Epoch: 84 [10368/14860 (69%)]\tLoss: 0.024865\n",
      "Train Epoch: 84 [10496/14860 (70%)]\tLoss: 0.025041\n",
      "Train Epoch: 84 [10624/14860 (71%)]\tLoss: 0.017324\n",
      "Train Epoch: 84 [10752/14860 (72%)]\tLoss: 0.029367\n",
      "Train Epoch: 84 [10880/14860 (73%)]\tLoss: 0.023602\n",
      "Train Epoch: 84 [11008/14860 (74%)]\tLoss: 0.017275\n",
      "Train Epoch: 84 [11136/14860 (74%)]\tLoss: 0.030326\n",
      "Train Epoch: 84 [11264/14860 (75%)]\tLoss: 0.009579\n",
      "Train Epoch: 84 [11392/14860 (76%)]\tLoss: 0.018202\n",
      "Train Epoch: 84 [11520/14860 (77%)]\tLoss: 0.020619\n",
      "Train Epoch: 84 [11648/14860 (78%)]\tLoss: 0.026993\n",
      "Train Epoch: 84 [11776/14860 (79%)]\tLoss: 0.021041\n",
      "Train Epoch: 84 [11904/14860 (79%)]\tLoss: 0.023099\n",
      "Train Epoch: 84 [12032/14860 (80%)]\tLoss: 0.016864\n",
      "Train Epoch: 84 [12160/14860 (81%)]\tLoss: 0.022340\n",
      "Train Epoch: 84 [12288/14860 (82%)]\tLoss: 0.023398\n",
      "Train Epoch: 84 [12416/14860 (83%)]\tLoss: 0.018653\n",
      "Train Epoch: 84 [12544/14860 (84%)]\tLoss: 0.022382\n",
      "Train Epoch: 84 [12672/14860 (85%)]\tLoss: 0.020803\n",
      "Train Epoch: 84 [12800/14860 (85%)]\tLoss: 0.023278\n",
      "Train Epoch: 84 [12928/14860 (86%)]\tLoss: 0.022011\n",
      "Train Epoch: 84 [13056/14860 (87%)]\tLoss: 0.018702\n",
      "Train Epoch: 84 [13184/14860 (88%)]\tLoss: 0.015393\n",
      "Train Epoch: 84 [13312/14860 (89%)]\tLoss: 0.017098\n",
      "Train Epoch: 84 [13440/14860 (90%)]\tLoss: 0.011409\n",
      "Train Epoch: 84 [13568/14860 (91%)]\tLoss: 0.016502\n",
      "Train Epoch: 84 [13696/14860 (91%)]\tLoss: 0.017827\n",
      "Train Epoch: 84 [13824/14860 (92%)]\tLoss: 0.015366\n",
      "Train Epoch: 84 [13952/14860 (93%)]\tLoss: 0.017329\n",
      "Train Epoch: 84 [14080/14860 (94%)]\tLoss: 0.016956\n",
      "Train Epoch: 84 [14208/14860 (95%)]\tLoss: 0.010889\n",
      "Train Epoch: 84 [14336/14860 (96%)]\tLoss: 0.020885\n",
      "Train Epoch: 84 [14464/14860 (97%)]\tLoss: 0.017594\n",
      "Train Epoch: 84 [14592/14860 (97%)]\tLoss: 0.017303\n",
      "Train Epoch: 84 [14720/14860 (98%)]\tLoss: 0.023769\n",
      "Train Epoch: 84 [1392/14860 (99%)]\tLoss: 0.017228\n",
      "epoch 84 training loss: 0.019661597127461027\n",
      "epoch 84 validation loss: 0.020961162830380492\n",
      "Train Epoch: 85 [0/14860 (0%)]\tLoss: 0.016855\n",
      "Train Epoch: 85 [128/14860 (1%)]\tLoss: 0.023798\n",
      "Train Epoch: 85 [256/14860 (2%)]\tLoss: 0.017354\n",
      "Train Epoch: 85 [384/14860 (3%)]\tLoss: 0.019121\n",
      "Train Epoch: 85 [512/14860 (3%)]\tLoss: 0.023275\n",
      "Train Epoch: 85 [640/14860 (4%)]\tLoss: 0.019763\n",
      "Train Epoch: 85 [768/14860 (5%)]\tLoss: 0.014439\n",
      "Train Epoch: 85 [896/14860 (6%)]\tLoss: 0.013728\n",
      "Train Epoch: 85 [1024/14860 (7%)]\tLoss: 0.019459\n",
      "Train Epoch: 85 [1152/14860 (8%)]\tLoss: 0.013994\n",
      "Train Epoch: 85 [1280/14860 (9%)]\tLoss: 0.015895\n",
      "Train Epoch: 85 [1408/14860 (9%)]\tLoss: 0.022962\n",
      "Train Epoch: 85 [1536/14860 (10%)]\tLoss: 0.017253\n",
      "Train Epoch: 85 [1664/14860 (11%)]\tLoss: 0.012768\n",
      "Train Epoch: 85 [1792/14860 (12%)]\tLoss: 0.018931\n",
      "Train Epoch: 85 [1920/14860 (13%)]\tLoss: 0.022403\n",
      "Train Epoch: 85 [2048/14860 (14%)]\tLoss: 0.017980\n",
      "Train Epoch: 85 [2176/14860 (15%)]\tLoss: 0.015288\n",
      "Train Epoch: 85 [2304/14860 (15%)]\tLoss: 0.014959\n",
      "Train Epoch: 85 [2432/14860 (16%)]\tLoss: 0.020560\n",
      "Train Epoch: 85 [2560/14860 (17%)]\tLoss: 0.022424\n",
      "Train Epoch: 85 [2688/14860 (18%)]\tLoss: 0.015481\n",
      "Train Epoch: 85 [2816/14860 (19%)]\tLoss: 0.015298\n",
      "Train Epoch: 85 [2944/14860 (20%)]\tLoss: 0.017051\n",
      "Train Epoch: 85 [3072/14860 (21%)]\tLoss: 0.021169\n",
      "Train Epoch: 85 [3200/14860 (21%)]\tLoss: 0.015725\n",
      "Train Epoch: 85 [3328/14860 (22%)]\tLoss: 0.016857\n",
      "Train Epoch: 85 [3456/14860 (23%)]\tLoss: 0.018051\n",
      "Train Epoch: 85 [3584/14860 (24%)]\tLoss: 0.015902\n",
      "Train Epoch: 85 [3712/14860 (25%)]\tLoss: 0.018308\n",
      "Train Epoch: 85 [3840/14860 (26%)]\tLoss: 0.017780\n",
      "Train Epoch: 85 [3968/14860 (26%)]\tLoss: 0.021614\n",
      "Train Epoch: 85 [4096/14860 (27%)]\tLoss: 0.019441\n",
      "Train Epoch: 85 [4224/14860 (28%)]\tLoss: 0.018121\n",
      "Train Epoch: 85 [4352/14860 (29%)]\tLoss: 0.022150\n",
      "Train Epoch: 85 [4480/14860 (30%)]\tLoss: 0.014518\n",
      "Train Epoch: 85 [4608/14860 (31%)]\tLoss: 0.018677\n",
      "Train Epoch: 85 [4736/14860 (32%)]\tLoss: 0.026354\n",
      "Train Epoch: 85 [4864/14860 (32%)]\tLoss: 0.013573\n",
      "Train Epoch: 85 [4992/14860 (33%)]\tLoss: 0.018242\n",
      "Train Epoch: 85 [5120/14860 (34%)]\tLoss: 0.015798\n",
      "Train Epoch: 85 [5248/14860 (35%)]\tLoss: 0.012835\n",
      "Train Epoch: 85 [5376/14860 (36%)]\tLoss: 0.017994\n",
      "Train Epoch: 85 [5504/14860 (37%)]\tLoss: 0.014163\n",
      "Train Epoch: 85 [5632/14860 (38%)]\tLoss: 0.018862\n",
      "Train Epoch: 85 [5760/14860 (38%)]\tLoss: 0.019120\n",
      "Train Epoch: 85 [5888/14860 (39%)]\tLoss: 0.018347\n",
      "Train Epoch: 85 [6016/14860 (40%)]\tLoss: 0.011563\n",
      "Train Epoch: 85 [6144/14860 (41%)]\tLoss: 0.017908\n",
      "Train Epoch: 85 [6272/14860 (42%)]\tLoss: 0.017905\n",
      "Train Epoch: 85 [6400/14860 (43%)]\tLoss: 0.025114\n",
      "Train Epoch: 85 [6528/14860 (44%)]\tLoss: 0.021534\n",
      "Train Epoch: 85 [6656/14860 (44%)]\tLoss: 0.017611\n",
      "Train Epoch: 85 [6784/14860 (45%)]\tLoss: 0.019311\n",
      "Train Epoch: 85 [6912/14860 (46%)]\tLoss: 0.024254\n",
      "Train Epoch: 85 [7040/14860 (47%)]\tLoss: 0.020786\n",
      "Train Epoch: 85 [7168/14860 (48%)]\tLoss: 0.019422\n",
      "Train Epoch: 85 [7296/14860 (49%)]\tLoss: 0.014833\n",
      "Train Epoch: 85 [7424/14860 (50%)]\tLoss: 0.019335\n",
      "Train Epoch: 85 [7552/14860 (50%)]\tLoss: 0.022042\n",
      "Train Epoch: 85 [7680/14860 (51%)]\tLoss: 0.015923\n",
      "Train Epoch: 85 [7808/14860 (52%)]\tLoss: 0.014178\n",
      "Train Epoch: 85 [7936/14860 (53%)]\tLoss: 0.012967\n",
      "Train Epoch: 85 [8064/14860 (54%)]\tLoss: 0.018897\n",
      "Train Epoch: 85 [8192/14860 (55%)]\tLoss: 0.018261\n",
      "Train Epoch: 85 [8320/14860 (56%)]\tLoss: 0.020828\n",
      "Train Epoch: 85 [8448/14860 (56%)]\tLoss: 0.023282\n",
      "Train Epoch: 85 [8576/14860 (57%)]\tLoss: 0.015844\n",
      "Train Epoch: 85 [8704/14860 (58%)]\tLoss: 0.017131\n",
      "Train Epoch: 85 [8832/14860 (59%)]\tLoss: 0.013301\n",
      "Train Epoch: 85 [8960/14860 (60%)]\tLoss: 0.019875\n",
      "Train Epoch: 85 [9088/14860 (61%)]\tLoss: 0.027021\n",
      "Train Epoch: 85 [9216/14860 (62%)]\tLoss: 0.031418\n",
      "Train Epoch: 85 [9344/14860 (62%)]\tLoss: 0.027571\n",
      "Train Epoch: 85 [9472/14860 (63%)]\tLoss: 0.019346\n",
      "Train Epoch: 85 [9600/14860 (64%)]\tLoss: 0.029659\n",
      "Train Epoch: 85 [9728/14860 (65%)]\tLoss: 0.020939\n",
      "Train Epoch: 85 [9856/14860 (66%)]\tLoss: 0.024883\n",
      "Train Epoch: 85 [9984/14860 (67%)]\tLoss: 0.020823\n",
      "Train Epoch: 85 [10112/14860 (68%)]\tLoss: 0.013687\n",
      "Train Epoch: 85 [10240/14860 (68%)]\tLoss: 0.016165\n",
      "Train Epoch: 85 [10368/14860 (69%)]\tLoss: 0.020302\n",
      "Train Epoch: 85 [10496/14860 (70%)]\tLoss: 0.014859\n",
      "Train Epoch: 85 [10624/14860 (71%)]\tLoss: 0.022178\n",
      "Train Epoch: 85 [10752/14860 (72%)]\tLoss: 0.021915\n",
      "Train Epoch: 85 [10880/14860 (73%)]\tLoss: 0.011730\n",
      "Train Epoch: 85 [11008/14860 (74%)]\tLoss: 0.021046\n",
      "Train Epoch: 85 [11136/14860 (74%)]\tLoss: 0.026721\n",
      "Train Epoch: 85 [11264/14860 (75%)]\tLoss: 0.028229\n",
      "Train Epoch: 85 [11392/14860 (76%)]\tLoss: 0.016280\n",
      "Train Epoch: 85 [11520/14860 (77%)]\tLoss: 0.025584\n",
      "Train Epoch: 85 [11648/14860 (78%)]\tLoss: 0.018377\n",
      "Train Epoch: 85 [11776/14860 (79%)]\tLoss: 0.015384\n",
      "Train Epoch: 85 [11904/14860 (79%)]\tLoss: 0.018869\n",
      "Train Epoch: 85 [12032/14860 (80%)]\tLoss: 0.020883\n",
      "Train Epoch: 85 [12160/14860 (81%)]\tLoss: 0.019936\n",
      "Train Epoch: 85 [12288/14860 (82%)]\tLoss: 0.018653\n",
      "Train Epoch: 85 [12416/14860 (83%)]\tLoss: 0.023151\n",
      "Train Epoch: 85 [12544/14860 (84%)]\tLoss: 0.017182\n",
      "Train Epoch: 85 [12672/14860 (85%)]\tLoss: 0.020541\n",
      "Train Epoch: 85 [12800/14860 (85%)]\tLoss: 0.019144\n",
      "Train Epoch: 85 [12928/14860 (86%)]\tLoss: 0.018439\n",
      "Train Epoch: 85 [13056/14860 (87%)]\tLoss: 0.022799\n",
      "Train Epoch: 85 [13184/14860 (88%)]\tLoss: 0.014841\n",
      "Train Epoch: 85 [13312/14860 (89%)]\tLoss: 0.014353\n",
      "Train Epoch: 85 [13440/14860 (90%)]\tLoss: 0.013206\n",
      "Train Epoch: 85 [13568/14860 (91%)]\tLoss: 0.022904\n",
      "Train Epoch: 85 [13696/14860 (91%)]\tLoss: 0.022887\n",
      "Train Epoch: 85 [13824/14860 (92%)]\tLoss: 0.019859\n",
      "Train Epoch: 85 [13952/14860 (93%)]\tLoss: 0.014079\n",
      "Train Epoch: 85 [14080/14860 (94%)]\tLoss: 0.023515\n",
      "Train Epoch: 85 [14208/14860 (95%)]\tLoss: 0.025612\n",
      "Train Epoch: 85 [14336/14860 (96%)]\tLoss: 0.017232\n",
      "Train Epoch: 85 [14464/14860 (97%)]\tLoss: 0.018522\n",
      "Train Epoch: 85 [14592/14860 (97%)]\tLoss: 0.016507\n",
      "Train Epoch: 85 [14720/14860 (98%)]\tLoss: 0.012125\n",
      "Train Epoch: 85 [1392/14860 (99%)]\tLoss: 0.010292\n",
      "epoch 85 training loss: 0.018858015577062074\n",
      "epoch 85 validation loss: 0.02053804049768979\n",
      "Train Epoch: 86 [0/14860 (0%)]\tLoss: 0.012952\n",
      "Train Epoch: 86 [128/14860 (1%)]\tLoss: 0.013581\n",
      "Train Epoch: 86 [256/14860 (2%)]\tLoss: 0.024208\n",
      "Train Epoch: 86 [384/14860 (3%)]\tLoss: 0.012109\n",
      "Train Epoch: 86 [512/14860 (3%)]\tLoss: 0.014135\n",
      "Train Epoch: 86 [640/14860 (4%)]\tLoss: 0.020586\n",
      "Train Epoch: 86 [768/14860 (5%)]\tLoss: 0.016089\n",
      "Train Epoch: 86 [896/14860 (6%)]\tLoss: 0.023570\n",
      "Train Epoch: 86 [1024/14860 (7%)]\tLoss: 0.020511\n",
      "Train Epoch: 86 [1152/14860 (8%)]\tLoss: 0.021450\n",
      "Train Epoch: 86 [1280/14860 (9%)]\tLoss: 0.020383\n",
      "Train Epoch: 86 [1408/14860 (9%)]\tLoss: 0.018057\n",
      "Train Epoch: 86 [1536/14860 (10%)]\tLoss: 0.018436\n",
      "Train Epoch: 86 [1664/14860 (11%)]\tLoss: 0.017990\n",
      "Train Epoch: 86 [1792/14860 (12%)]\tLoss: 0.019064\n",
      "Train Epoch: 86 [1920/14860 (13%)]\tLoss: 0.024654\n",
      "Train Epoch: 86 [2048/14860 (14%)]\tLoss: 0.019566\n",
      "Train Epoch: 86 [2176/14860 (15%)]\tLoss: 0.021860\n",
      "Train Epoch: 86 [2304/14860 (15%)]\tLoss: 0.025559\n",
      "Train Epoch: 86 [2432/14860 (16%)]\tLoss: 0.020577\n",
      "Train Epoch: 86 [2560/14860 (17%)]\tLoss: 0.021524\n",
      "Train Epoch: 86 [2688/14860 (18%)]\tLoss: 0.020021\n",
      "Train Epoch: 86 [2816/14860 (19%)]\tLoss: 0.021156\n",
      "Train Epoch: 86 [2944/14860 (20%)]\tLoss: 0.016656\n",
      "Train Epoch: 86 [3072/14860 (21%)]\tLoss: 0.016376\n",
      "Train Epoch: 86 [3200/14860 (21%)]\tLoss: 0.016363\n",
      "Train Epoch: 86 [3328/14860 (22%)]\tLoss: 0.017353\n",
      "Train Epoch: 86 [3456/14860 (23%)]\tLoss: 0.023110\n",
      "Train Epoch: 86 [3584/14860 (24%)]\tLoss: 0.023451\n",
      "Train Epoch: 86 [3712/14860 (25%)]\tLoss: 0.018144\n",
      "Train Epoch: 86 [3840/14860 (26%)]\tLoss: 0.023744\n",
      "Train Epoch: 86 [3968/14860 (26%)]\tLoss: 0.016954\n",
      "Train Epoch: 86 [4096/14860 (27%)]\tLoss: 0.013793\n",
      "Train Epoch: 86 [4224/14860 (28%)]\tLoss: 0.015891\n",
      "Train Epoch: 86 [4352/14860 (29%)]\tLoss: 0.027734\n",
      "Train Epoch: 86 [4480/14860 (30%)]\tLoss: 0.017097\n",
      "Train Epoch: 86 [4608/14860 (31%)]\tLoss: 0.013248\n",
      "Train Epoch: 86 [4736/14860 (32%)]\tLoss: 0.021422\n",
      "Train Epoch: 86 [4864/14860 (32%)]\tLoss: 0.022278\n",
      "Train Epoch: 86 [4992/14860 (33%)]\tLoss: 0.025505\n",
      "Train Epoch: 86 [5120/14860 (34%)]\tLoss: 0.021727\n",
      "Train Epoch: 86 [5248/14860 (35%)]\tLoss: 0.015065\n",
      "Train Epoch: 86 [5376/14860 (36%)]\tLoss: 0.018634\n",
      "Train Epoch: 86 [5504/14860 (37%)]\tLoss: 0.015954\n",
      "Train Epoch: 86 [5632/14860 (38%)]\tLoss: 0.017188\n",
      "Train Epoch: 86 [5760/14860 (38%)]\tLoss: 0.017750\n",
      "Train Epoch: 86 [5888/14860 (39%)]\tLoss: 0.018465\n",
      "Train Epoch: 86 [6016/14860 (40%)]\tLoss: 0.018903\n",
      "Train Epoch: 86 [6144/14860 (41%)]\tLoss: 0.018267\n",
      "Train Epoch: 86 [6272/14860 (42%)]\tLoss: 0.018979\n",
      "Train Epoch: 86 [6400/14860 (43%)]\tLoss: 0.022234\n",
      "Train Epoch: 86 [6528/14860 (44%)]\tLoss: 0.019028\n",
      "Train Epoch: 86 [6656/14860 (44%)]\tLoss: 0.016480\n",
      "Train Epoch: 86 [6784/14860 (45%)]\tLoss: 0.024032\n",
      "Train Epoch: 86 [6912/14860 (46%)]\tLoss: 0.016573\n",
      "Train Epoch: 86 [7040/14860 (47%)]\tLoss: 0.016299\n",
      "Train Epoch: 86 [7168/14860 (48%)]\tLoss: 0.018863\n",
      "Train Epoch: 86 [7296/14860 (49%)]\tLoss: 0.019371\n",
      "Train Epoch: 86 [7424/14860 (50%)]\tLoss: 0.020332\n",
      "Train Epoch: 86 [7552/14860 (50%)]\tLoss: 0.018606\n",
      "Train Epoch: 86 [7680/14860 (51%)]\tLoss: 0.016127\n",
      "Train Epoch: 86 [7808/14860 (52%)]\tLoss: 0.016585\n",
      "Train Epoch: 86 [7936/14860 (53%)]\tLoss: 0.016803\n",
      "Train Epoch: 86 [8064/14860 (54%)]\tLoss: 0.015483\n",
      "Train Epoch: 86 [8192/14860 (55%)]\tLoss: 0.015614\n",
      "Train Epoch: 86 [8320/14860 (56%)]\tLoss: 0.016321\n",
      "Train Epoch: 86 [8448/14860 (56%)]\tLoss: 0.024700\n",
      "Train Epoch: 86 [8576/14860 (57%)]\tLoss: 0.018209\n",
      "Train Epoch: 86 [8704/14860 (58%)]\tLoss: 0.019638\n",
      "Train Epoch: 86 [8832/14860 (59%)]\tLoss: 0.019557\n",
      "Train Epoch: 86 [8960/14860 (60%)]\tLoss: 0.018735\n",
      "Train Epoch: 86 [9088/14860 (61%)]\tLoss: 0.020566\n",
      "Train Epoch: 86 [9216/14860 (62%)]\tLoss: 0.018963\n",
      "Train Epoch: 86 [9344/14860 (62%)]\tLoss: 0.028349\n",
      "Train Epoch: 86 [9472/14860 (63%)]\tLoss: 0.020587\n",
      "Train Epoch: 86 [9600/14860 (64%)]\tLoss: 0.025143\n",
      "Train Epoch: 86 [9728/14860 (65%)]\tLoss: 0.020905\n",
      "Train Epoch: 86 [9856/14860 (66%)]\tLoss: 0.021394\n",
      "Train Epoch: 86 [9984/14860 (67%)]\tLoss: 0.020081\n",
      "Train Epoch: 86 [10112/14860 (68%)]\tLoss: 0.022038\n",
      "Train Epoch: 86 [10240/14860 (68%)]\tLoss: 0.023594\n",
      "Train Epoch: 86 [10368/14860 (69%)]\tLoss: 0.014661\n",
      "Train Epoch: 86 [10496/14860 (70%)]\tLoss: 0.020117\n",
      "Train Epoch: 86 [10624/14860 (71%)]\tLoss: 0.023142\n",
      "Train Epoch: 86 [10752/14860 (72%)]\tLoss: 0.020074\n",
      "Train Epoch: 86 [10880/14860 (73%)]\tLoss: 0.017544\n",
      "Train Epoch: 86 [11008/14860 (74%)]\tLoss: 0.025922\n",
      "Train Epoch: 86 [11136/14860 (74%)]\tLoss: 0.019306\n",
      "Train Epoch: 86 [11264/14860 (75%)]\tLoss: 0.021271\n",
      "Train Epoch: 86 [11392/14860 (76%)]\tLoss: 0.016260\n",
      "Train Epoch: 86 [11520/14860 (77%)]\tLoss: 0.021089\n",
      "Train Epoch: 86 [11648/14860 (78%)]\tLoss: 0.017608\n",
      "Train Epoch: 86 [11776/14860 (79%)]\tLoss: 0.014617\n",
      "Train Epoch: 86 [11904/14860 (79%)]\tLoss: 0.017935\n",
      "Train Epoch: 86 [12032/14860 (80%)]\tLoss: 0.020972\n",
      "Train Epoch: 86 [12160/14860 (81%)]\tLoss: 0.020156\n",
      "Train Epoch: 86 [12288/14860 (82%)]\tLoss: 0.017925\n",
      "Train Epoch: 86 [12416/14860 (83%)]\tLoss: 0.015024\n",
      "Train Epoch: 86 [12544/14860 (84%)]\tLoss: 0.017597\n",
      "Train Epoch: 86 [12672/14860 (85%)]\tLoss: 0.014234\n",
      "Train Epoch: 86 [12800/14860 (85%)]\tLoss: 0.023018\n",
      "Train Epoch: 86 [12928/14860 (86%)]\tLoss: 0.021631\n",
      "Train Epoch: 86 [13056/14860 (87%)]\tLoss: 0.021182\n",
      "Train Epoch: 86 [13184/14860 (88%)]\tLoss: 0.013684\n",
      "Train Epoch: 86 [13312/14860 (89%)]\tLoss: 0.014736\n",
      "Train Epoch: 86 [13440/14860 (90%)]\tLoss: 0.019567\n",
      "Train Epoch: 86 [13568/14860 (91%)]\tLoss: 0.015614\n",
      "Train Epoch: 86 [13696/14860 (91%)]\tLoss: 0.018164\n",
      "Train Epoch: 86 [13824/14860 (92%)]\tLoss: 0.021435\n",
      "Train Epoch: 86 [13952/14860 (93%)]\tLoss: 0.026689\n",
      "Train Epoch: 86 [14080/14860 (94%)]\tLoss: 0.019270\n",
      "Train Epoch: 86 [14208/14860 (95%)]\tLoss: 0.013949\n",
      "Train Epoch: 86 [14336/14860 (96%)]\tLoss: 0.019531\n",
      "Train Epoch: 86 [14464/14860 (97%)]\tLoss: 0.025831\n",
      "Train Epoch: 86 [14592/14860 (97%)]\tLoss: 0.021401\n",
      "Train Epoch: 86 [14720/14860 (98%)]\tLoss: 0.014177\n",
      "Train Epoch: 86 [1392/14860 (99%)]\tLoss: 0.026890\n",
      "epoch 86 training loss: 0.019329234862174742\n",
      "epoch 86 validation loss: 0.01967677257540151\n",
      "Train Epoch: 87 [0/14860 (0%)]\tLoss: 0.018493\n",
      "Train Epoch: 87 [128/14860 (1%)]\tLoss: 0.019536\n",
      "Train Epoch: 87 [256/14860 (2%)]\tLoss: 0.020873\n",
      "Train Epoch: 87 [384/14860 (3%)]\tLoss: 0.027838\n",
      "Train Epoch: 87 [512/14860 (3%)]\tLoss: 0.017115\n",
      "Train Epoch: 87 [640/14860 (4%)]\tLoss: 0.017316\n",
      "Train Epoch: 87 [768/14860 (5%)]\tLoss: 0.023248\n",
      "Train Epoch: 87 [896/14860 (6%)]\tLoss: 0.017219\n",
      "Train Epoch: 87 [1024/14860 (7%)]\tLoss: 0.020257\n",
      "Train Epoch: 87 [1152/14860 (8%)]\tLoss: 0.018656\n",
      "Train Epoch: 87 [1280/14860 (9%)]\tLoss: 0.015200\n",
      "Train Epoch: 87 [1408/14860 (9%)]\tLoss: 0.015368\n",
      "Train Epoch: 87 [1536/14860 (10%)]\tLoss: 0.014394\n",
      "Train Epoch: 87 [1664/14860 (11%)]\tLoss: 0.029253\n",
      "Train Epoch: 87 [1792/14860 (12%)]\tLoss: 0.022582\n",
      "Train Epoch: 87 [1920/14860 (13%)]\tLoss: 0.020677\n",
      "Train Epoch: 87 [2048/14860 (14%)]\tLoss: 0.030485\n",
      "Train Epoch: 87 [2176/14860 (15%)]\tLoss: 0.015006\n",
      "Train Epoch: 87 [2304/14860 (15%)]\tLoss: 0.019329\n",
      "Train Epoch: 87 [2432/14860 (16%)]\tLoss: 0.025523\n",
      "Train Epoch: 87 [2560/14860 (17%)]\tLoss: 0.019554\n",
      "Train Epoch: 87 [2688/14860 (18%)]\tLoss: 0.016877\n",
      "Train Epoch: 87 [2816/14860 (19%)]\tLoss: 0.024061\n",
      "Train Epoch: 87 [2944/14860 (20%)]\tLoss: 0.018626\n",
      "Train Epoch: 87 [3072/14860 (21%)]\tLoss: 0.015730\n",
      "Train Epoch: 87 [3200/14860 (21%)]\tLoss: 0.034419\n",
      "Train Epoch: 87 [3328/14860 (22%)]\tLoss: 0.025222\n",
      "Train Epoch: 87 [3456/14860 (23%)]\tLoss: 0.013117\n",
      "Train Epoch: 87 [3584/14860 (24%)]\tLoss: 0.020358\n",
      "Train Epoch: 87 [3712/14860 (25%)]\tLoss: 0.017558\n",
      "Train Epoch: 87 [3840/14860 (26%)]\tLoss: 0.017966\n",
      "Train Epoch: 87 [3968/14860 (26%)]\tLoss: 0.017002\n",
      "Train Epoch: 87 [4096/14860 (27%)]\tLoss: 0.018521\n",
      "Train Epoch: 87 [4224/14860 (28%)]\tLoss: 0.023260\n",
      "Train Epoch: 87 [4352/14860 (29%)]\tLoss: 0.016177\n",
      "Train Epoch: 87 [4480/14860 (30%)]\tLoss: 0.020964\n",
      "Train Epoch: 87 [4608/14860 (31%)]\tLoss: 0.025854\n",
      "Train Epoch: 87 [4736/14860 (32%)]\tLoss: 0.021828\n",
      "Train Epoch: 87 [4864/14860 (32%)]\tLoss: 0.019890\n",
      "Train Epoch: 87 [4992/14860 (33%)]\tLoss: 0.015999\n",
      "Train Epoch: 87 [5120/14860 (34%)]\tLoss: 0.016407\n",
      "Train Epoch: 87 [5248/14860 (35%)]\tLoss: 0.019900\n",
      "Train Epoch: 87 [5376/14860 (36%)]\tLoss: 0.019223\n",
      "Train Epoch: 87 [5504/14860 (37%)]\tLoss: 0.019934\n",
      "Train Epoch: 87 [5632/14860 (38%)]\tLoss: 0.019800\n",
      "Train Epoch: 87 [5760/14860 (38%)]\tLoss: 0.018011\n",
      "Train Epoch: 87 [5888/14860 (39%)]\tLoss: 0.025069\n",
      "Train Epoch: 87 [6016/14860 (40%)]\tLoss: 0.020093\n",
      "Train Epoch: 87 [6144/14860 (41%)]\tLoss: 0.018206\n",
      "Train Epoch: 87 [6272/14860 (42%)]\tLoss: 0.023193\n",
      "Train Epoch: 87 [6400/14860 (43%)]\tLoss: 0.018637\n",
      "Train Epoch: 87 [6528/14860 (44%)]\tLoss: 0.018219\n",
      "Train Epoch: 87 [6656/14860 (44%)]\tLoss: 0.022931\n",
      "Train Epoch: 87 [6784/14860 (45%)]\tLoss: 0.029095\n",
      "Train Epoch: 87 [6912/14860 (46%)]\tLoss: 0.025624\n",
      "Train Epoch: 87 [7040/14860 (47%)]\tLoss: 0.017259\n",
      "Train Epoch: 87 [7168/14860 (48%)]\tLoss: 0.027903\n",
      "Train Epoch: 87 [7296/14860 (49%)]\tLoss: 0.019354\n",
      "Train Epoch: 87 [7424/14860 (50%)]\tLoss: 0.017246\n",
      "Train Epoch: 87 [7552/14860 (50%)]\tLoss: 0.017244\n",
      "Train Epoch: 87 [7680/14860 (51%)]\tLoss: 0.036766\n",
      "Train Epoch: 87 [7808/14860 (52%)]\tLoss: 0.023117\n",
      "Train Epoch: 87 [7936/14860 (53%)]\tLoss: 0.019516\n",
      "Train Epoch: 87 [8064/14860 (54%)]\tLoss: 0.020334\n",
      "Train Epoch: 87 [8192/14860 (55%)]\tLoss: 0.024785\n",
      "Train Epoch: 87 [8320/14860 (56%)]\tLoss: 0.019816\n",
      "Train Epoch: 87 [8448/14860 (56%)]\tLoss: 0.023556\n",
      "Train Epoch: 87 [8576/14860 (57%)]\tLoss: 0.024595\n",
      "Train Epoch: 87 [8704/14860 (58%)]\tLoss: 0.021372\n",
      "Train Epoch: 87 [8832/14860 (59%)]\tLoss: 0.020676\n",
      "Train Epoch: 87 [8960/14860 (60%)]\tLoss: 0.015236\n",
      "Train Epoch: 87 [9088/14860 (61%)]\tLoss: 0.022245\n",
      "Train Epoch: 87 [9216/14860 (62%)]\tLoss: 0.021683\n",
      "Train Epoch: 87 [9344/14860 (62%)]\tLoss: 0.018055\n",
      "Train Epoch: 87 [9472/14860 (63%)]\tLoss: 0.012385\n",
      "Train Epoch: 87 [9600/14860 (64%)]\tLoss: 0.020840\n",
      "Train Epoch: 87 [9728/14860 (65%)]\tLoss: 0.030941\n",
      "Train Epoch: 87 [9856/14860 (66%)]\tLoss: 0.015708\n",
      "Train Epoch: 87 [9984/14860 (67%)]\tLoss: 0.019611\n",
      "Train Epoch: 87 [10112/14860 (68%)]\tLoss: 0.015596\n",
      "Train Epoch: 87 [10240/14860 (68%)]\tLoss: 0.018179\n",
      "Train Epoch: 87 [10368/14860 (69%)]\tLoss: 0.020999\n",
      "Train Epoch: 87 [10496/14860 (70%)]\tLoss: 0.017165\n",
      "Train Epoch: 87 [10624/14860 (71%)]\tLoss: 0.016226\n",
      "Train Epoch: 87 [10752/14860 (72%)]\tLoss: 0.013905\n",
      "Train Epoch: 87 [10880/14860 (73%)]\tLoss: 0.011235\n",
      "Train Epoch: 87 [11008/14860 (74%)]\tLoss: 0.016712\n",
      "Train Epoch: 87 [11136/14860 (74%)]\tLoss: 0.016230\n",
      "Train Epoch: 87 [11264/14860 (75%)]\tLoss: 0.018678\n",
      "Train Epoch: 87 [11392/14860 (76%)]\tLoss: 0.022416\n",
      "Train Epoch: 87 [11520/14860 (77%)]\tLoss: 0.020170\n",
      "Train Epoch: 87 [11648/14860 (78%)]\tLoss: 0.013738\n",
      "Train Epoch: 87 [11776/14860 (79%)]\tLoss: 0.016402\n",
      "Train Epoch: 87 [11904/14860 (79%)]\tLoss: 0.022745\n",
      "Train Epoch: 87 [12032/14860 (80%)]\tLoss: 0.013418\n",
      "Train Epoch: 87 [12160/14860 (81%)]\tLoss: 0.023152\n",
      "Train Epoch: 87 [12288/14860 (82%)]\tLoss: 0.017480\n",
      "Train Epoch: 87 [12416/14860 (83%)]\tLoss: 0.015741\n",
      "Train Epoch: 87 [12544/14860 (84%)]\tLoss: 0.028887\n",
      "Train Epoch: 87 [12672/14860 (85%)]\tLoss: 0.014030\n",
      "Train Epoch: 87 [12800/14860 (85%)]\tLoss: 0.016241\n",
      "Train Epoch: 87 [12928/14860 (86%)]\tLoss: 0.018646\n",
      "Train Epoch: 87 [13056/14860 (87%)]\tLoss: 0.014385\n",
      "Train Epoch: 87 [13184/14860 (88%)]\tLoss: 0.018212\n",
      "Train Epoch: 87 [13312/14860 (89%)]\tLoss: 0.019695\n",
      "Train Epoch: 87 [13440/14860 (90%)]\tLoss: 0.021985\n",
      "Train Epoch: 87 [13568/14860 (91%)]\tLoss: 0.025492\n",
      "Train Epoch: 87 [13696/14860 (91%)]\tLoss: 0.021650\n",
      "Train Epoch: 87 [13824/14860 (92%)]\tLoss: 0.016739\n",
      "Train Epoch: 87 [13952/14860 (93%)]\tLoss: 0.020753\n",
      "Train Epoch: 87 [14080/14860 (94%)]\tLoss: 0.027093\n",
      "Train Epoch: 87 [14208/14860 (95%)]\tLoss: 0.019601\n",
      "Train Epoch: 87 [14336/14860 (96%)]\tLoss: 0.016260\n",
      "Train Epoch: 87 [14464/14860 (97%)]\tLoss: 0.022393\n",
      "Train Epoch: 87 [14592/14860 (97%)]\tLoss: 0.017782\n",
      "Train Epoch: 87 [14720/14860 (98%)]\tLoss: 0.020668\n",
      "Train Epoch: 87 [1392/14860 (99%)]\tLoss: 0.052283\n",
      "epoch 87 training loss: 0.020332615719073348\n",
      "epoch 87 validation loss: 0.0212867326366988\n",
      "Train Epoch: 88 [0/14860 (0%)]\tLoss: 0.017598\n",
      "Train Epoch: 88 [128/14860 (1%)]\tLoss: 0.022456\n",
      "Train Epoch: 88 [256/14860 (2%)]\tLoss: 0.018868\n",
      "Train Epoch: 88 [384/14860 (3%)]\tLoss: 0.016848\n",
      "Train Epoch: 88 [512/14860 (3%)]\tLoss: 0.021074\n",
      "Train Epoch: 88 [640/14860 (4%)]\tLoss: 0.017321\n",
      "Train Epoch: 88 [768/14860 (5%)]\tLoss: 0.015536\n",
      "Train Epoch: 88 [896/14860 (6%)]\tLoss: 0.018298\n",
      "Train Epoch: 88 [1024/14860 (7%)]\tLoss: 0.015550\n",
      "Train Epoch: 88 [1152/14860 (8%)]\tLoss: 0.022595\n",
      "Train Epoch: 88 [1280/14860 (9%)]\tLoss: 0.022312\n",
      "Train Epoch: 88 [1408/14860 (9%)]\tLoss: 0.018345\n",
      "Train Epoch: 88 [1536/14860 (10%)]\tLoss: 0.016299\n",
      "Train Epoch: 88 [1664/14860 (11%)]\tLoss: 0.029149\n",
      "Train Epoch: 88 [1792/14860 (12%)]\tLoss: 0.022654\n",
      "Train Epoch: 88 [1920/14860 (13%)]\tLoss: 0.020170\n",
      "Train Epoch: 88 [2048/14860 (14%)]\tLoss: 0.019274\n",
      "Train Epoch: 88 [2176/14860 (15%)]\tLoss: 0.022715\n",
      "Train Epoch: 88 [2304/14860 (15%)]\tLoss: 0.021048\n",
      "Train Epoch: 88 [2432/14860 (16%)]\tLoss: 0.019301\n",
      "Train Epoch: 88 [2560/14860 (17%)]\tLoss: 0.012548\n",
      "Train Epoch: 88 [2688/14860 (18%)]\tLoss: 0.018350\n",
      "Train Epoch: 88 [2816/14860 (19%)]\tLoss: 0.019353\n",
      "Train Epoch: 88 [2944/14860 (20%)]\tLoss: 0.018045\n",
      "Train Epoch: 88 [3072/14860 (21%)]\tLoss: 0.023915\n",
      "Train Epoch: 88 [3200/14860 (21%)]\tLoss: 0.020006\n",
      "Train Epoch: 88 [3328/14860 (22%)]\tLoss: 0.019494\n",
      "Train Epoch: 88 [3456/14860 (23%)]\tLoss: 0.019036\n",
      "Train Epoch: 88 [3584/14860 (24%)]\tLoss: 0.015651\n",
      "Train Epoch: 88 [3712/14860 (25%)]\tLoss: 0.015967\n",
      "Train Epoch: 88 [3840/14860 (26%)]\tLoss: 0.014575\n",
      "Train Epoch: 88 [3968/14860 (26%)]\tLoss: 0.013823\n",
      "Train Epoch: 88 [4096/14860 (27%)]\tLoss: 0.019628\n",
      "Train Epoch: 88 [4224/14860 (28%)]\tLoss: 0.022195\n",
      "Train Epoch: 88 [4352/14860 (29%)]\tLoss: 0.014075\n",
      "Train Epoch: 88 [4480/14860 (30%)]\tLoss: 0.013913\n",
      "Train Epoch: 88 [4608/14860 (31%)]\tLoss: 0.017841\n",
      "Train Epoch: 88 [4736/14860 (32%)]\tLoss: 0.025861\n",
      "Train Epoch: 88 [4864/14860 (32%)]\tLoss: 0.020354\n",
      "Train Epoch: 88 [4992/14860 (33%)]\tLoss: 0.013717\n",
      "Train Epoch: 88 [5120/14860 (34%)]\tLoss: 0.013899\n",
      "Train Epoch: 88 [5248/14860 (35%)]\tLoss: 0.020184\n",
      "Train Epoch: 88 [5376/14860 (36%)]\tLoss: 0.015211\n",
      "Train Epoch: 88 [5504/14860 (37%)]\tLoss: 0.018706\n",
      "Train Epoch: 88 [5632/14860 (38%)]\tLoss: 0.015986\n",
      "Train Epoch: 88 [5760/14860 (38%)]\tLoss: 0.026872\n",
      "Train Epoch: 88 [5888/14860 (39%)]\tLoss: 0.023646\n",
      "Train Epoch: 88 [6016/14860 (40%)]\tLoss: 0.025771\n",
      "Train Epoch: 88 [6144/14860 (41%)]\tLoss: 0.025510\n",
      "Train Epoch: 88 [6272/14860 (42%)]\tLoss: 0.022063\n",
      "Train Epoch: 88 [6400/14860 (43%)]\tLoss: 0.025370\n",
      "Train Epoch: 88 [6528/14860 (44%)]\tLoss: 0.014912\n",
      "Train Epoch: 88 [6656/14860 (44%)]\tLoss: 0.022052\n",
      "Train Epoch: 88 [6784/14860 (45%)]\tLoss: 0.016092\n",
      "Train Epoch: 88 [6912/14860 (46%)]\tLoss: 0.019494\n",
      "Train Epoch: 88 [7040/14860 (47%)]\tLoss: 0.019330\n",
      "Train Epoch: 88 [7168/14860 (48%)]\tLoss: 0.024518\n",
      "Train Epoch: 88 [7296/14860 (49%)]\tLoss: 0.020911\n",
      "Train Epoch: 88 [7424/14860 (50%)]\tLoss: 0.011837\n",
      "Train Epoch: 88 [7552/14860 (50%)]\tLoss: 0.029334\n",
      "Train Epoch: 88 [7680/14860 (51%)]\tLoss: 0.013767\n",
      "Train Epoch: 88 [7808/14860 (52%)]\tLoss: 0.021623\n",
      "Train Epoch: 88 [7936/14860 (53%)]\tLoss: 0.020353\n",
      "Train Epoch: 88 [8064/14860 (54%)]\tLoss: 0.012642\n",
      "Train Epoch: 88 [8192/14860 (55%)]\tLoss: 0.021652\n",
      "Train Epoch: 88 [8320/14860 (56%)]\tLoss: 0.013805\n",
      "Train Epoch: 88 [8448/14860 (56%)]\tLoss: 0.016736\n",
      "Train Epoch: 88 [8576/14860 (57%)]\tLoss: 0.023686\n",
      "Train Epoch: 88 [8704/14860 (58%)]\tLoss: 0.013805\n",
      "Train Epoch: 88 [8832/14860 (59%)]\tLoss: 0.020015\n",
      "Train Epoch: 88 [8960/14860 (60%)]\tLoss: 0.021270\n",
      "Train Epoch: 88 [9088/14860 (61%)]\tLoss: 0.016588\n",
      "Train Epoch: 88 [9216/14860 (62%)]\tLoss: 0.014795\n",
      "Train Epoch: 88 [9344/14860 (62%)]\tLoss: 0.019378\n",
      "Train Epoch: 88 [9472/14860 (63%)]\tLoss: 0.018624\n",
      "Train Epoch: 88 [9600/14860 (64%)]\tLoss: 0.013502\n",
      "Train Epoch: 88 [9728/14860 (65%)]\tLoss: 0.013578\n",
      "Train Epoch: 88 [9856/14860 (66%)]\tLoss: 0.016462\n",
      "Train Epoch: 88 [9984/14860 (67%)]\tLoss: 0.019769\n",
      "Train Epoch: 88 [10112/14860 (68%)]\tLoss: 0.025259\n",
      "Train Epoch: 88 [10240/14860 (68%)]\tLoss: 0.025452\n",
      "Train Epoch: 88 [10368/14860 (69%)]\tLoss: 0.016988\n",
      "Train Epoch: 88 [10496/14860 (70%)]\tLoss: 0.027501\n",
      "Train Epoch: 88 [10624/14860 (71%)]\tLoss: 0.014157\n",
      "Train Epoch: 88 [10752/14860 (72%)]\tLoss: 0.033206\n",
      "Train Epoch: 88 [10880/14860 (73%)]\tLoss: 0.013928\n",
      "Train Epoch: 88 [11008/14860 (74%)]\tLoss: 0.020613\n",
      "Train Epoch: 88 [11136/14860 (74%)]\tLoss: 0.021028\n",
      "Train Epoch: 88 [11264/14860 (75%)]\tLoss: 0.017023\n",
      "Train Epoch: 88 [11392/14860 (76%)]\tLoss: 0.027213\n",
      "Train Epoch: 88 [11520/14860 (77%)]\tLoss: 0.017767\n",
      "Train Epoch: 88 [11648/14860 (78%)]\tLoss: 0.021950\n",
      "Train Epoch: 88 [11776/14860 (79%)]\tLoss: 0.015663\n",
      "Train Epoch: 88 [11904/14860 (79%)]\tLoss: 0.020882\n",
      "Train Epoch: 88 [12032/14860 (80%)]\tLoss: 0.018940\n",
      "Train Epoch: 88 [12160/14860 (81%)]\tLoss: 0.020226\n",
      "Train Epoch: 88 [12288/14860 (82%)]\tLoss: 0.019651\n",
      "Train Epoch: 88 [12416/14860 (83%)]\tLoss: 0.018383\n",
      "Train Epoch: 88 [12544/14860 (84%)]\tLoss: 0.013253\n",
      "Train Epoch: 88 [12672/14860 (85%)]\tLoss: 0.023968\n",
      "Train Epoch: 88 [12800/14860 (85%)]\tLoss: 0.017304\n",
      "Train Epoch: 88 [12928/14860 (86%)]\tLoss: 0.016601\n",
      "Train Epoch: 88 [13056/14860 (87%)]\tLoss: 0.013890\n",
      "Train Epoch: 88 [13184/14860 (88%)]\tLoss: 0.017151\n",
      "Train Epoch: 88 [13312/14860 (89%)]\tLoss: 0.021353\n",
      "Train Epoch: 88 [13440/14860 (90%)]\tLoss: 0.019945\n",
      "Train Epoch: 88 [13568/14860 (91%)]\tLoss: 0.017623\n",
      "Train Epoch: 88 [13696/14860 (91%)]\tLoss: 0.017881\n",
      "Train Epoch: 88 [13824/14860 (92%)]\tLoss: 0.022622\n",
      "Train Epoch: 88 [13952/14860 (93%)]\tLoss: 0.021931\n",
      "Train Epoch: 88 [14080/14860 (94%)]\tLoss: 0.016149\n",
      "Train Epoch: 88 [14208/14860 (95%)]\tLoss: 0.020922\n",
      "Train Epoch: 88 [14336/14860 (96%)]\tLoss: 0.020196\n",
      "Train Epoch: 88 [14464/14860 (97%)]\tLoss: 0.015252\n",
      "Train Epoch: 88 [14592/14860 (97%)]\tLoss: 0.016173\n",
      "Train Epoch: 88 [14720/14860 (98%)]\tLoss: 0.021967\n",
      "Train Epoch: 88 [1392/14860 (99%)]\tLoss: 0.011784\n",
      "epoch 88 training loss: 0.01915643838608367\n",
      "epoch 88 validation loss: 0.019499117540100874\n",
      "Train Epoch: 89 [0/14860 (0%)]\tLoss: 0.018421\n",
      "Train Epoch: 89 [128/14860 (1%)]\tLoss: 0.018893\n",
      "Train Epoch: 89 [256/14860 (2%)]\tLoss: 0.022065\n",
      "Train Epoch: 89 [384/14860 (3%)]\tLoss: 0.019403\n",
      "Train Epoch: 89 [512/14860 (3%)]\tLoss: 0.017852\n",
      "Train Epoch: 89 [640/14860 (4%)]\tLoss: 0.018760\n",
      "Train Epoch: 89 [768/14860 (5%)]\tLoss: 0.021904\n",
      "Train Epoch: 89 [896/14860 (6%)]\tLoss: 0.017986\n",
      "Train Epoch: 89 [1024/14860 (7%)]\tLoss: 0.022757\n",
      "Train Epoch: 89 [1152/14860 (8%)]\tLoss: 0.022109\n",
      "Train Epoch: 89 [1280/14860 (9%)]\tLoss: 0.020515\n",
      "Train Epoch: 89 [1408/14860 (9%)]\tLoss: 0.013933\n",
      "Train Epoch: 89 [1536/14860 (10%)]\tLoss: 0.018457\n",
      "Train Epoch: 89 [1664/14860 (11%)]\tLoss: 0.015051\n",
      "Train Epoch: 89 [1792/14860 (12%)]\tLoss: 0.021794\n",
      "Train Epoch: 89 [1920/14860 (13%)]\tLoss: 0.022601\n",
      "Train Epoch: 89 [2048/14860 (14%)]\tLoss: 0.018777\n",
      "Train Epoch: 89 [2176/14860 (15%)]\tLoss: 0.023332\n",
      "Train Epoch: 89 [2304/14860 (15%)]\tLoss: 0.020220\n",
      "Train Epoch: 89 [2432/14860 (16%)]\tLoss: 0.017221\n",
      "Train Epoch: 89 [2560/14860 (17%)]\tLoss: 0.020828\n",
      "Train Epoch: 89 [2688/14860 (18%)]\tLoss: 0.017404\n",
      "Train Epoch: 89 [2816/14860 (19%)]\tLoss: 0.015543\n",
      "Train Epoch: 89 [2944/14860 (20%)]\tLoss: 0.023085\n",
      "Train Epoch: 89 [3072/14860 (21%)]\tLoss: 0.021035\n",
      "Train Epoch: 89 [3200/14860 (21%)]\tLoss: 0.016338\n",
      "Train Epoch: 89 [3328/14860 (22%)]\tLoss: 0.016590\n",
      "Train Epoch: 89 [3456/14860 (23%)]\tLoss: 0.014457\n",
      "Train Epoch: 89 [3584/14860 (24%)]\tLoss: 0.017205\n",
      "Train Epoch: 89 [3712/14860 (25%)]\tLoss: 0.021603\n",
      "Train Epoch: 89 [3840/14860 (26%)]\tLoss: 0.022338\n",
      "Train Epoch: 89 [3968/14860 (26%)]\tLoss: 0.017373\n",
      "Train Epoch: 89 [4096/14860 (27%)]\tLoss: 0.011762\n",
      "Train Epoch: 89 [4224/14860 (28%)]\tLoss: 0.024336\n",
      "Train Epoch: 89 [4352/14860 (29%)]\tLoss: 0.018358\n",
      "Train Epoch: 89 [4480/14860 (30%)]\tLoss: 0.019726\n",
      "Train Epoch: 89 [4608/14860 (31%)]\tLoss: 0.016799\n",
      "Train Epoch: 89 [4736/14860 (32%)]\tLoss: 0.017855\n",
      "Train Epoch: 89 [4864/14860 (32%)]\tLoss: 0.021656\n",
      "Train Epoch: 89 [4992/14860 (33%)]\tLoss: 0.020464\n",
      "Train Epoch: 89 [5120/14860 (34%)]\tLoss: 0.018210\n",
      "Train Epoch: 89 [5248/14860 (35%)]\tLoss: 0.022102\n",
      "Train Epoch: 89 [5376/14860 (36%)]\tLoss: 0.016022\n",
      "Train Epoch: 89 [5504/14860 (37%)]\tLoss: 0.019923\n",
      "Train Epoch: 89 [5632/14860 (38%)]\tLoss: 0.014622\n",
      "Train Epoch: 89 [5760/14860 (38%)]\tLoss: 0.019468\n",
      "Train Epoch: 89 [5888/14860 (39%)]\tLoss: 0.016150\n",
      "Train Epoch: 89 [6016/14860 (40%)]\tLoss: 0.016745\n",
      "Train Epoch: 89 [6144/14860 (41%)]\tLoss: 0.022665\n",
      "Train Epoch: 89 [6272/14860 (42%)]\tLoss: 0.018127\n",
      "Train Epoch: 89 [6400/14860 (43%)]\tLoss: 0.013587\n",
      "Train Epoch: 89 [6528/14860 (44%)]\tLoss: 0.019042\n",
      "Train Epoch: 89 [6656/14860 (44%)]\tLoss: 0.019331\n",
      "Train Epoch: 89 [6784/14860 (45%)]\tLoss: 0.018066\n",
      "Train Epoch: 89 [6912/14860 (46%)]\tLoss: 0.020319\n",
      "Train Epoch: 89 [7040/14860 (47%)]\tLoss: 0.014398\n",
      "Train Epoch: 89 [7168/14860 (48%)]\tLoss: 0.016210\n",
      "Train Epoch: 89 [7296/14860 (49%)]\tLoss: 0.027756\n",
      "Train Epoch: 89 [7424/14860 (50%)]\tLoss: 0.020506\n",
      "Train Epoch: 89 [7552/14860 (50%)]\tLoss: 0.018645\n",
      "Train Epoch: 89 [7680/14860 (51%)]\tLoss: 0.025718\n",
      "Train Epoch: 89 [7808/14860 (52%)]\tLoss: 0.014438\n",
      "Train Epoch: 89 [7936/14860 (53%)]\tLoss: 0.012213\n",
      "Train Epoch: 89 [8064/14860 (54%)]\tLoss: 0.017804\n",
      "Train Epoch: 89 [8192/14860 (55%)]\tLoss: 0.015906\n",
      "Train Epoch: 89 [8320/14860 (56%)]\tLoss: 0.018686\n",
      "Train Epoch: 89 [8448/14860 (56%)]\tLoss: 0.014390\n",
      "Train Epoch: 89 [8576/14860 (57%)]\tLoss: 0.017094\n",
      "Train Epoch: 89 [8704/14860 (58%)]\tLoss: 0.015474\n",
      "Train Epoch: 89 [8832/14860 (59%)]\tLoss: 0.020801\n",
      "Train Epoch: 89 [8960/14860 (60%)]\tLoss: 0.018744\n",
      "Train Epoch: 89 [9088/14860 (61%)]\tLoss: 0.017384\n",
      "Train Epoch: 89 [9216/14860 (62%)]\tLoss: 0.015892\n",
      "Train Epoch: 89 [9344/14860 (62%)]\tLoss: 0.019635\n",
      "Train Epoch: 89 [9472/14860 (63%)]\tLoss: 0.019447\n",
      "Train Epoch: 89 [9600/14860 (64%)]\tLoss: 0.020515\n",
      "Train Epoch: 89 [9728/14860 (65%)]\tLoss: 0.021059\n",
      "Train Epoch: 89 [9856/14860 (66%)]\tLoss: 0.013062\n",
      "Train Epoch: 89 [9984/14860 (67%)]\tLoss: 0.027874\n",
      "Train Epoch: 89 [10112/14860 (68%)]\tLoss: 0.017494\n",
      "Train Epoch: 89 [10240/14860 (68%)]\tLoss: 0.019775\n",
      "Train Epoch: 89 [10368/14860 (69%)]\tLoss: 0.020861\n",
      "Train Epoch: 89 [10496/14860 (70%)]\tLoss: 0.017876\n",
      "Train Epoch: 89 [10624/14860 (71%)]\tLoss: 0.019085\n",
      "Train Epoch: 89 [10752/14860 (72%)]\tLoss: 0.015719\n",
      "Train Epoch: 89 [10880/14860 (73%)]\tLoss: 0.018527\n",
      "Train Epoch: 89 [11008/14860 (74%)]\tLoss: 0.023865\n",
      "Train Epoch: 89 [11136/14860 (74%)]\tLoss: 0.020075\n",
      "Train Epoch: 89 [11264/14860 (75%)]\tLoss: 0.014016\n",
      "Train Epoch: 89 [11392/14860 (76%)]\tLoss: 0.022707\n",
      "Train Epoch: 89 [11520/14860 (77%)]\tLoss: 0.026832\n",
      "Train Epoch: 89 [11648/14860 (78%)]\tLoss: 0.024298\n",
      "Train Epoch: 89 [11776/14860 (79%)]\tLoss: 0.022023\n",
      "Train Epoch: 89 [11904/14860 (79%)]\tLoss: 0.025339\n",
      "Train Epoch: 89 [12032/14860 (80%)]\tLoss: 0.020767\n",
      "Train Epoch: 89 [12160/14860 (81%)]\tLoss: 0.027421\n",
      "Train Epoch: 89 [12288/14860 (82%)]\tLoss: 0.025384\n",
      "Train Epoch: 89 [12416/14860 (83%)]\tLoss: 0.019893\n",
      "Train Epoch: 89 [12544/14860 (84%)]\tLoss: 0.011479\n",
      "Train Epoch: 89 [12672/14860 (85%)]\tLoss: 0.020126\n",
      "Train Epoch: 89 [12800/14860 (85%)]\tLoss: 0.019341\n",
      "Train Epoch: 89 [12928/14860 (86%)]\tLoss: 0.017993\n",
      "Train Epoch: 89 [13056/14860 (87%)]\tLoss: 0.023505\n",
      "Train Epoch: 89 [13184/14860 (88%)]\tLoss: 0.022000\n",
      "Train Epoch: 89 [13312/14860 (89%)]\tLoss: 0.012558\n",
      "Train Epoch: 89 [13440/14860 (90%)]\tLoss: 0.017588\n",
      "Train Epoch: 89 [13568/14860 (91%)]\tLoss: 0.015353\n",
      "Train Epoch: 89 [13696/14860 (91%)]\tLoss: 0.017623\n",
      "Train Epoch: 89 [13824/14860 (92%)]\tLoss: 0.022088\n",
      "Train Epoch: 89 [13952/14860 (93%)]\tLoss: 0.018956\n",
      "Train Epoch: 89 [14080/14860 (94%)]\tLoss: 0.016291\n",
      "Train Epoch: 89 [14208/14860 (95%)]\tLoss: 0.011522\n",
      "Train Epoch: 89 [14336/14860 (96%)]\tLoss: 0.020420\n",
      "Train Epoch: 89 [14464/14860 (97%)]\tLoss: 0.018450\n",
      "Train Epoch: 89 [14592/14860 (97%)]\tLoss: 0.020384\n",
      "Train Epoch: 89 [14720/14860 (98%)]\tLoss: 0.018632\n",
      "Train Epoch: 89 [1392/14860 (99%)]\tLoss: 0.013396\n",
      "epoch 89 training loss: 0.01901281946617314\n",
      "epoch 89 validation loss: 0.020091333487420624\n",
      "Train Epoch: 90 [0/14860 (0%)]\tLoss: 0.015585\n",
      "Train Epoch: 90 [128/14860 (1%)]\tLoss: 0.015225\n",
      "Train Epoch: 90 [256/14860 (2%)]\tLoss: 0.014519\n",
      "Train Epoch: 90 [384/14860 (3%)]\tLoss: 0.018588\n",
      "Train Epoch: 90 [512/14860 (3%)]\tLoss: 0.014457\n",
      "Train Epoch: 90 [640/14860 (4%)]\tLoss: 0.015966\n",
      "Train Epoch: 90 [768/14860 (5%)]\tLoss: 0.028690\n",
      "Train Epoch: 90 [896/14860 (6%)]\tLoss: 0.013902\n",
      "Train Epoch: 90 [1024/14860 (7%)]\tLoss: 0.012942\n",
      "Train Epoch: 90 [1152/14860 (8%)]\tLoss: 0.021727\n",
      "Train Epoch: 90 [1280/14860 (9%)]\tLoss: 0.015145\n",
      "Train Epoch: 90 [1408/14860 (9%)]\tLoss: 0.016501\n",
      "Train Epoch: 90 [1536/14860 (10%)]\tLoss: 0.022066\n",
      "Train Epoch: 90 [1664/14860 (11%)]\tLoss: 0.021531\n",
      "Train Epoch: 90 [1792/14860 (12%)]\tLoss: 0.019744\n",
      "Train Epoch: 90 [1920/14860 (13%)]\tLoss: 0.023738\n",
      "Train Epoch: 90 [2048/14860 (14%)]\tLoss: 0.015108\n",
      "Train Epoch: 90 [2176/14860 (15%)]\tLoss: 0.016955\n",
      "Train Epoch: 90 [2304/14860 (15%)]\tLoss: 0.015904\n",
      "Train Epoch: 90 [2432/14860 (16%)]\tLoss: 0.034049\n",
      "Train Epoch: 90 [2560/14860 (17%)]\tLoss: 0.016668\n",
      "Train Epoch: 90 [2688/14860 (18%)]\tLoss: 0.018153\n",
      "Train Epoch: 90 [2816/14860 (19%)]\tLoss: 0.019037\n",
      "Train Epoch: 90 [2944/14860 (20%)]\tLoss: 0.019422\n",
      "Train Epoch: 90 [3072/14860 (21%)]\tLoss: 0.014301\n",
      "Train Epoch: 90 [3200/14860 (21%)]\tLoss: 0.012569\n",
      "Train Epoch: 90 [3328/14860 (22%)]\tLoss: 0.022118\n",
      "Train Epoch: 90 [3456/14860 (23%)]\tLoss: 0.023939\n",
      "Train Epoch: 90 [3584/14860 (24%)]\tLoss: 0.025944\n",
      "Train Epoch: 90 [3712/14860 (25%)]\tLoss: 0.019040\n",
      "Train Epoch: 90 [3840/14860 (26%)]\tLoss: 0.016150\n",
      "Train Epoch: 90 [3968/14860 (26%)]\tLoss: 0.024460\n",
      "Train Epoch: 90 [4096/14860 (27%)]\tLoss: 0.023252\n",
      "Train Epoch: 90 [4224/14860 (28%)]\tLoss: 0.021321\n",
      "Train Epoch: 90 [4352/14860 (29%)]\tLoss: 0.018328\n",
      "Train Epoch: 90 [4480/14860 (30%)]\tLoss: 0.023636\n",
      "Train Epoch: 90 [4608/14860 (31%)]\tLoss: 0.015960\n",
      "Train Epoch: 90 [4736/14860 (32%)]\tLoss: 0.021232\n",
      "Train Epoch: 90 [4864/14860 (32%)]\tLoss: 0.018223\n",
      "Train Epoch: 90 [4992/14860 (33%)]\tLoss: 0.010240\n",
      "Train Epoch: 90 [5120/14860 (34%)]\tLoss: 0.023614\n",
      "Train Epoch: 90 [5248/14860 (35%)]\tLoss: 0.020244\n",
      "Train Epoch: 90 [5376/14860 (36%)]\tLoss: 0.017385\n",
      "Train Epoch: 90 [5504/14860 (37%)]\tLoss: 0.015109\n",
      "Train Epoch: 90 [5632/14860 (38%)]\tLoss: 0.014520\n",
      "Train Epoch: 90 [5760/14860 (38%)]\tLoss: 0.017131\n",
      "Train Epoch: 90 [5888/14860 (39%)]\tLoss: 0.015649\n",
      "Train Epoch: 90 [6016/14860 (40%)]\tLoss: 0.021890\n",
      "Train Epoch: 90 [6144/14860 (41%)]\tLoss: 0.020685\n",
      "Train Epoch: 90 [6272/14860 (42%)]\tLoss: 0.021210\n",
      "Train Epoch: 90 [6400/14860 (43%)]\tLoss: 0.020382\n",
      "Train Epoch: 90 [6528/14860 (44%)]\tLoss: 0.015067\n",
      "Train Epoch: 90 [6656/14860 (44%)]\tLoss: 0.022752\n",
      "Train Epoch: 90 [6784/14860 (45%)]\tLoss: 0.017279\n",
      "Train Epoch: 90 [6912/14860 (46%)]\tLoss: 0.023935\n",
      "Train Epoch: 90 [7040/14860 (47%)]\tLoss: 0.023531\n",
      "Train Epoch: 90 [7168/14860 (48%)]\tLoss: 0.018078\n",
      "Train Epoch: 90 [7296/14860 (49%)]\tLoss: 0.019917\n",
      "Train Epoch: 90 [7424/14860 (50%)]\tLoss: 0.021554\n",
      "Train Epoch: 90 [7552/14860 (50%)]\tLoss: 0.021736\n",
      "Train Epoch: 90 [7680/14860 (51%)]\tLoss: 0.014931\n",
      "Train Epoch: 90 [7808/14860 (52%)]\tLoss: 0.020833\n",
      "Train Epoch: 90 [7936/14860 (53%)]\tLoss: 0.020511\n",
      "Train Epoch: 90 [8064/14860 (54%)]\tLoss: 0.027019\n",
      "Train Epoch: 90 [8192/14860 (55%)]\tLoss: 0.019952\n",
      "Train Epoch: 90 [8320/14860 (56%)]\tLoss: 0.019049\n",
      "Train Epoch: 90 [8448/14860 (56%)]\tLoss: 0.020006\n",
      "Train Epoch: 90 [8576/14860 (57%)]\tLoss: 0.020007\n",
      "Train Epoch: 90 [8704/14860 (58%)]\tLoss: 0.021006\n",
      "Train Epoch: 90 [8832/14860 (59%)]\tLoss: 0.015631\n",
      "Train Epoch: 90 [8960/14860 (60%)]\tLoss: 0.019925\n",
      "Train Epoch: 90 [9088/14860 (61%)]\tLoss: 0.024932\n",
      "Train Epoch: 90 [9216/14860 (62%)]\tLoss: 0.014744\n",
      "Train Epoch: 90 [9344/14860 (62%)]\tLoss: 0.018128\n",
      "Train Epoch: 90 [9472/14860 (63%)]\tLoss: 0.017578\n",
      "Train Epoch: 90 [9600/14860 (64%)]\tLoss: 0.016001\n",
      "Train Epoch: 90 [9728/14860 (65%)]\tLoss: 0.022523\n",
      "Train Epoch: 90 [9856/14860 (66%)]\tLoss: 0.018345\n",
      "Train Epoch: 90 [9984/14860 (67%)]\tLoss: 0.020958\n",
      "Train Epoch: 90 [10112/14860 (68%)]\tLoss: 0.014663\n",
      "Train Epoch: 90 [10240/14860 (68%)]\tLoss: 0.012775\n",
      "Train Epoch: 90 [10368/14860 (69%)]\tLoss: 0.029588\n",
      "Train Epoch: 90 [10496/14860 (70%)]\tLoss: 0.022032\n",
      "Train Epoch: 90 [10624/14860 (71%)]\tLoss: 0.016625\n",
      "Train Epoch: 90 [10752/14860 (72%)]\tLoss: 0.024351\n",
      "Train Epoch: 90 [10880/14860 (73%)]\tLoss: 0.020021\n",
      "Train Epoch: 90 [11008/14860 (74%)]\tLoss: 0.033054\n",
      "Train Epoch: 90 [11136/14860 (74%)]\tLoss: 0.021432\n",
      "Train Epoch: 90 [11264/14860 (75%)]\tLoss: 0.018200\n",
      "Train Epoch: 90 [11392/14860 (76%)]\tLoss: 0.013223\n",
      "Train Epoch: 90 [11520/14860 (77%)]\tLoss: 0.020459\n",
      "Train Epoch: 90 [11648/14860 (78%)]\tLoss: 0.022082\n",
      "Train Epoch: 90 [11776/14860 (79%)]\tLoss: 0.016895\n",
      "Train Epoch: 90 [11904/14860 (79%)]\tLoss: 0.014205\n",
      "Train Epoch: 90 [12032/14860 (80%)]\tLoss: 0.024402\n",
      "Train Epoch: 90 [12160/14860 (81%)]\tLoss: 0.016920\n",
      "Train Epoch: 90 [12288/14860 (82%)]\tLoss: 0.018305\n",
      "Train Epoch: 90 [12416/14860 (83%)]\tLoss: 0.016223\n",
      "Train Epoch: 90 [12544/14860 (84%)]\tLoss: 0.018706\n",
      "Train Epoch: 90 [12672/14860 (85%)]\tLoss: 0.017523\n",
      "Train Epoch: 90 [12800/14860 (85%)]\tLoss: 0.017749\n",
      "Train Epoch: 90 [12928/14860 (86%)]\tLoss: 0.018606\n",
      "Train Epoch: 90 [13056/14860 (87%)]\tLoss: 0.019687\n",
      "Train Epoch: 90 [13184/14860 (88%)]\tLoss: 0.019566\n",
      "Train Epoch: 90 [13312/14860 (89%)]\tLoss: 0.021128\n",
      "Train Epoch: 90 [13440/14860 (90%)]\tLoss: 0.019193\n",
      "Train Epoch: 90 [13568/14860 (91%)]\tLoss: 0.023317\n",
      "Train Epoch: 90 [13696/14860 (91%)]\tLoss: 0.016115\n",
      "Train Epoch: 90 [13824/14860 (92%)]\tLoss: 0.016690\n",
      "Train Epoch: 90 [13952/14860 (93%)]\tLoss: 0.016381\n",
      "Train Epoch: 90 [14080/14860 (94%)]\tLoss: 0.015708\n",
      "Train Epoch: 90 [14208/14860 (95%)]\tLoss: 0.015804\n",
      "Train Epoch: 90 [14336/14860 (96%)]\tLoss: 0.017351\n",
      "Train Epoch: 90 [14464/14860 (97%)]\tLoss: 0.017670\n",
      "Train Epoch: 90 [14592/14860 (97%)]\tLoss: 0.022924\n",
      "Train Epoch: 90 [14720/14860 (98%)]\tLoss: 0.024254\n",
      "Train Epoch: 90 [1392/14860 (99%)]\tLoss: 0.019157\n",
      "epoch 90 training loss: 0.019257004866296917\n",
      "epoch 90 validation loss: 0.019698298872238788\n",
      "Train Epoch: 91 [0/14860 (0%)]\tLoss: 0.019219\n",
      "Train Epoch: 91 [128/14860 (1%)]\tLoss: 0.020791\n",
      "Train Epoch: 91 [256/14860 (2%)]\tLoss: 0.020378\n",
      "Train Epoch: 91 [384/14860 (3%)]\tLoss: 0.020545\n",
      "Train Epoch: 91 [512/14860 (3%)]\tLoss: 0.014675\n",
      "Train Epoch: 91 [640/14860 (4%)]\tLoss: 0.014607\n",
      "Train Epoch: 91 [768/14860 (5%)]\tLoss: 0.015834\n",
      "Train Epoch: 91 [896/14860 (6%)]\tLoss: 0.019323\n",
      "Train Epoch: 91 [1024/14860 (7%)]\tLoss: 0.016007\n",
      "Train Epoch: 91 [1152/14860 (8%)]\tLoss: 0.025708\n",
      "Train Epoch: 91 [1280/14860 (9%)]\tLoss: 0.019477\n",
      "Train Epoch: 91 [1408/14860 (9%)]\tLoss: 0.022095\n",
      "Train Epoch: 91 [1536/14860 (10%)]\tLoss: 0.022270\n",
      "Train Epoch: 91 [1664/14860 (11%)]\tLoss: 0.014398\n",
      "Train Epoch: 91 [1792/14860 (12%)]\tLoss: 0.019553\n",
      "Train Epoch: 91 [1920/14860 (13%)]\tLoss: 0.015874\n",
      "Train Epoch: 91 [2048/14860 (14%)]\tLoss: 0.023558\n",
      "Train Epoch: 91 [2176/14860 (15%)]\tLoss: 0.016882\n",
      "Train Epoch: 91 [2304/14860 (15%)]\tLoss: 0.016908\n",
      "Train Epoch: 91 [2432/14860 (16%)]\tLoss: 0.025945\n",
      "Train Epoch: 91 [2560/14860 (17%)]\tLoss: 0.019865\n",
      "Train Epoch: 91 [2688/14860 (18%)]\tLoss: 0.016357\n",
      "Train Epoch: 91 [2816/14860 (19%)]\tLoss: 0.015814\n",
      "Train Epoch: 91 [2944/14860 (20%)]\tLoss: 0.025180\n",
      "Train Epoch: 91 [3072/14860 (21%)]\tLoss: 0.020504\n",
      "Train Epoch: 91 [3200/14860 (21%)]\tLoss: 0.022797\n",
      "Train Epoch: 91 [3328/14860 (22%)]\tLoss: 0.022665\n",
      "Train Epoch: 91 [3456/14860 (23%)]\tLoss: 0.015398\n",
      "Train Epoch: 91 [3584/14860 (24%)]\tLoss: 0.016891\n",
      "Train Epoch: 91 [3712/14860 (25%)]\tLoss: 0.026719\n",
      "Train Epoch: 91 [3840/14860 (26%)]\tLoss: 0.015148\n",
      "Train Epoch: 91 [3968/14860 (26%)]\tLoss: 0.013784\n",
      "Train Epoch: 91 [4096/14860 (27%)]\tLoss: 0.023137\n",
      "Train Epoch: 91 [4224/14860 (28%)]\tLoss: 0.019353\n",
      "Train Epoch: 91 [4352/14860 (29%)]\tLoss: 0.017546\n",
      "Train Epoch: 91 [4480/14860 (30%)]\tLoss: 0.014459\n",
      "Train Epoch: 91 [4608/14860 (31%)]\tLoss: 0.024916\n",
      "Train Epoch: 91 [4736/14860 (32%)]\tLoss: 0.015579\n",
      "Train Epoch: 91 [4864/14860 (32%)]\tLoss: 0.017030\n",
      "Train Epoch: 91 [4992/14860 (33%)]\tLoss: 0.014083\n",
      "Train Epoch: 91 [5120/14860 (34%)]\tLoss: 0.015674\n",
      "Train Epoch: 91 [5248/14860 (35%)]\tLoss: 0.030823\n",
      "Train Epoch: 91 [5376/14860 (36%)]\tLoss: 0.018226\n",
      "Train Epoch: 91 [5504/14860 (37%)]\tLoss: 0.021479\n",
      "Train Epoch: 91 [5632/14860 (38%)]\tLoss: 0.021168\n",
      "Train Epoch: 91 [5760/14860 (38%)]\tLoss: 0.016939\n",
      "Train Epoch: 91 [5888/14860 (39%)]\tLoss: 0.016669\n",
      "Train Epoch: 91 [6016/14860 (40%)]\tLoss: 0.017815\n",
      "Train Epoch: 91 [6144/14860 (41%)]\tLoss: 0.014729\n",
      "Train Epoch: 91 [6272/14860 (42%)]\tLoss: 0.019078\n",
      "Train Epoch: 91 [6400/14860 (43%)]\tLoss: 0.017735\n",
      "Train Epoch: 91 [6528/14860 (44%)]\tLoss: 0.017479\n",
      "Train Epoch: 91 [6656/14860 (44%)]\tLoss: 0.021676\n",
      "Train Epoch: 91 [6784/14860 (45%)]\tLoss: 0.017246\n",
      "Train Epoch: 91 [6912/14860 (46%)]\tLoss: 0.017576\n",
      "Train Epoch: 91 [7040/14860 (47%)]\tLoss: 0.015623\n",
      "Train Epoch: 91 [7168/14860 (48%)]\tLoss: 0.015731\n",
      "Train Epoch: 91 [7296/14860 (49%)]\tLoss: 0.018824\n",
      "Train Epoch: 91 [7424/14860 (50%)]\tLoss: 0.014777\n",
      "Train Epoch: 91 [7552/14860 (50%)]\tLoss: 0.020267\n",
      "Train Epoch: 91 [7680/14860 (51%)]\tLoss: 0.015270\n",
      "Train Epoch: 91 [7808/14860 (52%)]\tLoss: 0.015949\n",
      "Train Epoch: 91 [7936/14860 (53%)]\tLoss: 0.014807\n",
      "Train Epoch: 91 [8064/14860 (54%)]\tLoss: 0.017032\n",
      "Train Epoch: 91 [8192/14860 (55%)]\tLoss: 0.019003\n",
      "Train Epoch: 91 [8320/14860 (56%)]\tLoss: 0.018812\n",
      "Train Epoch: 91 [8448/14860 (56%)]\tLoss: 0.015292\n",
      "Train Epoch: 91 [8576/14860 (57%)]\tLoss: 0.022024\n",
      "Train Epoch: 91 [8704/14860 (58%)]\tLoss: 0.022322\n",
      "Train Epoch: 91 [8832/14860 (59%)]\tLoss: 0.019252\n",
      "Train Epoch: 91 [8960/14860 (60%)]\tLoss: 0.022520\n",
      "Train Epoch: 91 [9088/14860 (61%)]\tLoss: 0.021345\n",
      "Train Epoch: 91 [9216/14860 (62%)]\tLoss: 0.024698\n",
      "Train Epoch: 91 [9344/14860 (62%)]\tLoss: 0.017181\n",
      "Train Epoch: 91 [9472/14860 (63%)]\tLoss: 0.009643\n",
      "Train Epoch: 91 [9600/14860 (64%)]\tLoss: 0.016713\n",
      "Train Epoch: 91 [9728/14860 (65%)]\tLoss: 0.011865\n",
      "Train Epoch: 91 [9856/14860 (66%)]\tLoss: 0.019942\n",
      "Train Epoch: 91 [9984/14860 (67%)]\tLoss: 0.016618\n",
      "Train Epoch: 91 [10112/14860 (68%)]\tLoss: 0.022155\n",
      "Train Epoch: 91 [10240/14860 (68%)]\tLoss: 0.015992\n",
      "Train Epoch: 91 [10368/14860 (69%)]\tLoss: 0.024199\n",
      "Train Epoch: 91 [10496/14860 (70%)]\tLoss: 0.016816\n",
      "Train Epoch: 91 [10624/14860 (71%)]\tLoss: 0.019268\n",
      "Train Epoch: 91 [10752/14860 (72%)]\tLoss: 0.019914\n",
      "Train Epoch: 91 [10880/14860 (73%)]\tLoss: 0.018028\n",
      "Train Epoch: 91 [11008/14860 (74%)]\tLoss: 0.024004\n",
      "Train Epoch: 91 [11136/14860 (74%)]\tLoss: 0.023805\n",
      "Train Epoch: 91 [11264/14860 (75%)]\tLoss: 0.024706\n",
      "Train Epoch: 91 [11392/14860 (76%)]\tLoss: 0.016103\n",
      "Train Epoch: 91 [11520/14860 (77%)]\tLoss: 0.027104\n",
      "Train Epoch: 91 [11648/14860 (78%)]\tLoss: 0.016819\n",
      "Train Epoch: 91 [11776/14860 (79%)]\tLoss: 0.021104\n",
      "Train Epoch: 91 [11904/14860 (79%)]\tLoss: 0.019471\n",
      "Train Epoch: 91 [12032/14860 (80%)]\tLoss: 0.016645\n",
      "Train Epoch: 91 [12160/14860 (81%)]\tLoss: 0.015609\n",
      "Train Epoch: 91 [12288/14860 (82%)]\tLoss: 0.014357\n",
      "Train Epoch: 91 [12416/14860 (83%)]\tLoss: 0.015214\n",
      "Train Epoch: 91 [12544/14860 (84%)]\tLoss: 0.015437\n",
      "Train Epoch: 91 [12672/14860 (85%)]\tLoss: 0.014196\n",
      "Train Epoch: 91 [12800/14860 (85%)]\tLoss: 0.017579\n",
      "Train Epoch: 91 [12928/14860 (86%)]\tLoss: 0.020984\n",
      "Train Epoch: 91 [13056/14860 (87%)]\tLoss: 0.019118\n",
      "Train Epoch: 91 [13184/14860 (88%)]\tLoss: 0.021053\n",
      "Train Epoch: 91 [13312/14860 (89%)]\tLoss: 0.018330\n",
      "Train Epoch: 91 [13440/14860 (90%)]\tLoss: 0.016741\n",
      "Train Epoch: 91 [13568/14860 (91%)]\tLoss: 0.022009\n",
      "Train Epoch: 91 [13696/14860 (91%)]\tLoss: 0.021339\n",
      "Train Epoch: 91 [13824/14860 (92%)]\tLoss: 0.022828\n",
      "Train Epoch: 91 [13952/14860 (93%)]\tLoss: 0.015350\n",
      "Train Epoch: 91 [14080/14860 (94%)]\tLoss: 0.011000\n",
      "Train Epoch: 91 [14208/14860 (95%)]\tLoss: 0.013218\n",
      "Train Epoch: 91 [14336/14860 (96%)]\tLoss: 0.021175\n",
      "Train Epoch: 91 [14464/14860 (97%)]\tLoss: 0.018980\n",
      "Train Epoch: 91 [14592/14860 (97%)]\tLoss: 0.022727\n",
      "Train Epoch: 91 [14720/14860 (98%)]\tLoss: 0.022765\n",
      "Train Epoch: 91 [1392/14860 (99%)]\tLoss: 0.042394\n",
      "epoch 91 training loss: 0.01897121675344359\n",
      "epoch 91 validation loss: 0.019533213056605894\n",
      "Train Epoch: 92 [0/14860 (0%)]\tLoss: 0.018378\n",
      "Train Epoch: 92 [128/14860 (1%)]\tLoss: 0.015380\n",
      "Train Epoch: 92 [256/14860 (2%)]\tLoss: 0.016806\n",
      "Train Epoch: 92 [384/14860 (3%)]\tLoss: 0.017920\n",
      "Train Epoch: 92 [512/14860 (3%)]\tLoss: 0.024001\n",
      "Train Epoch: 92 [640/14860 (4%)]\tLoss: 0.014471\n",
      "Train Epoch: 92 [768/14860 (5%)]\tLoss: 0.019079\n",
      "Train Epoch: 92 [896/14860 (6%)]\tLoss: 0.017718\n",
      "Train Epoch: 92 [1024/14860 (7%)]\tLoss: 0.016955\n",
      "Train Epoch: 92 [1152/14860 (8%)]\tLoss: 0.019576\n",
      "Train Epoch: 92 [1280/14860 (9%)]\tLoss: 0.027658\n",
      "Train Epoch: 92 [1408/14860 (9%)]\tLoss: 0.016739\n",
      "Train Epoch: 92 [1536/14860 (10%)]\tLoss: 0.017547\n",
      "Train Epoch: 92 [1664/14860 (11%)]\tLoss: 0.016932\n",
      "Train Epoch: 92 [1792/14860 (12%)]\tLoss: 0.015598\n",
      "Train Epoch: 92 [1920/14860 (13%)]\tLoss: 0.018919\n",
      "Train Epoch: 92 [2048/14860 (14%)]\tLoss: 0.026424\n",
      "Train Epoch: 92 [2176/14860 (15%)]\tLoss: 0.018019\n",
      "Train Epoch: 92 [2304/14860 (15%)]\tLoss: 0.022489\n",
      "Train Epoch: 92 [2432/14860 (16%)]\tLoss: 0.018081\n",
      "Train Epoch: 92 [2560/14860 (17%)]\tLoss: 0.014961\n",
      "Train Epoch: 92 [2688/14860 (18%)]\tLoss: 0.023956\n",
      "Train Epoch: 92 [2816/14860 (19%)]\tLoss: 0.012689\n",
      "Train Epoch: 92 [2944/14860 (20%)]\tLoss: 0.016204\n",
      "Train Epoch: 92 [3072/14860 (21%)]\tLoss: 0.011907\n",
      "Train Epoch: 92 [3200/14860 (21%)]\tLoss: 0.029141\n",
      "Train Epoch: 92 [3328/14860 (22%)]\tLoss: 0.018625\n",
      "Train Epoch: 92 [3456/14860 (23%)]\tLoss: 0.031170\n",
      "Train Epoch: 92 [3584/14860 (24%)]\tLoss: 0.019697\n",
      "Train Epoch: 92 [3712/14860 (25%)]\tLoss: 0.019599\n",
      "Train Epoch: 92 [3840/14860 (26%)]\tLoss: 0.017747\n",
      "Train Epoch: 92 [3968/14860 (26%)]\tLoss: 0.015767\n",
      "Train Epoch: 92 [4096/14860 (27%)]\tLoss: 0.017832\n",
      "Train Epoch: 92 [4224/14860 (28%)]\tLoss: 0.017927\n",
      "Train Epoch: 92 [4352/14860 (29%)]\tLoss: 0.014330\n",
      "Train Epoch: 92 [4480/14860 (30%)]\tLoss: 0.027697\n",
      "Train Epoch: 92 [4608/14860 (31%)]\tLoss: 0.018557\n",
      "Train Epoch: 92 [4736/14860 (32%)]\tLoss: 0.015981\n",
      "Train Epoch: 92 [4864/14860 (32%)]\tLoss: 0.012777\n",
      "Train Epoch: 92 [4992/14860 (33%)]\tLoss: 0.012820\n",
      "Train Epoch: 92 [5120/14860 (34%)]\tLoss: 0.016272\n",
      "Train Epoch: 92 [5248/14860 (35%)]\tLoss: 0.017335\n",
      "Train Epoch: 92 [5376/14860 (36%)]\tLoss: 0.012881\n",
      "Train Epoch: 92 [5504/14860 (37%)]\tLoss: 0.019117\n",
      "Train Epoch: 92 [5632/14860 (38%)]\tLoss: 0.018107\n",
      "Train Epoch: 92 [5760/14860 (38%)]\tLoss: 0.020359\n",
      "Train Epoch: 92 [5888/14860 (39%)]\tLoss: 0.018499\n",
      "Train Epoch: 92 [6016/14860 (40%)]\tLoss: 0.021053\n",
      "Train Epoch: 92 [6144/14860 (41%)]\tLoss: 0.017086\n",
      "Train Epoch: 92 [6272/14860 (42%)]\tLoss: 0.012921\n",
      "Train Epoch: 92 [6400/14860 (43%)]\tLoss: 0.016396\n",
      "Train Epoch: 92 [6528/14860 (44%)]\tLoss: 0.018411\n",
      "Train Epoch: 92 [6656/14860 (44%)]\tLoss: 0.012859\n",
      "Train Epoch: 92 [6784/14860 (45%)]\tLoss: 0.016950\n",
      "Train Epoch: 92 [6912/14860 (46%)]\tLoss: 0.021763\n",
      "Train Epoch: 92 [7040/14860 (47%)]\tLoss: 0.029317\n",
      "Train Epoch: 92 [7168/14860 (48%)]\tLoss: 0.025231\n",
      "Train Epoch: 92 [7296/14860 (49%)]\tLoss: 0.016214\n",
      "Train Epoch: 92 [7424/14860 (50%)]\tLoss: 0.023130\n",
      "Train Epoch: 92 [7552/14860 (50%)]\tLoss: 0.022233\n",
      "Train Epoch: 92 [7680/14860 (51%)]\tLoss: 0.022216\n",
      "Train Epoch: 92 [7808/14860 (52%)]\tLoss: 0.022349\n",
      "Train Epoch: 92 [7936/14860 (53%)]\tLoss: 0.016996\n",
      "Train Epoch: 92 [8064/14860 (54%)]\tLoss: 0.019098\n",
      "Train Epoch: 92 [8192/14860 (55%)]\tLoss: 0.029112\n",
      "Train Epoch: 92 [8320/14860 (56%)]\tLoss: 0.017201\n",
      "Train Epoch: 92 [8448/14860 (56%)]\tLoss: 0.021729\n",
      "Train Epoch: 92 [8576/14860 (57%)]\tLoss: 0.016981\n",
      "Train Epoch: 92 [8704/14860 (58%)]\tLoss: 0.019692\n",
      "Train Epoch: 92 [8832/14860 (59%)]\tLoss: 0.021461\n",
      "Train Epoch: 92 [8960/14860 (60%)]\tLoss: 0.028351\n",
      "Train Epoch: 92 [9088/14860 (61%)]\tLoss: 0.015973\n",
      "Train Epoch: 92 [9216/14860 (62%)]\tLoss: 0.025947\n",
      "Train Epoch: 92 [9344/14860 (62%)]\tLoss: 0.017000\n",
      "Train Epoch: 92 [9472/14860 (63%)]\tLoss: 0.016351\n",
      "Train Epoch: 92 [9600/14860 (64%)]\tLoss: 0.020112\n",
      "Train Epoch: 92 [9728/14860 (65%)]\tLoss: 0.017462\n",
      "Train Epoch: 92 [9856/14860 (66%)]\tLoss: 0.021126\n",
      "Train Epoch: 92 [9984/14860 (67%)]\tLoss: 0.018029\n",
      "Train Epoch: 92 [10112/14860 (68%)]\tLoss: 0.013116\n",
      "Train Epoch: 92 [10240/14860 (68%)]\tLoss: 0.017441\n",
      "Train Epoch: 92 [10368/14860 (69%)]\tLoss: 0.019925\n",
      "Train Epoch: 92 [10496/14860 (70%)]\tLoss: 0.023588\n",
      "Train Epoch: 92 [10624/14860 (71%)]\tLoss: 0.023855\n",
      "Train Epoch: 92 [10752/14860 (72%)]\tLoss: 0.016090\n",
      "Train Epoch: 92 [10880/14860 (73%)]\tLoss: 0.018053\n",
      "Train Epoch: 92 [11008/14860 (74%)]\tLoss: 0.024879\n",
      "Train Epoch: 92 [11136/14860 (74%)]\tLoss: 0.012893\n",
      "Train Epoch: 92 [11264/14860 (75%)]\tLoss: 0.025955\n",
      "Train Epoch: 92 [11392/14860 (76%)]\tLoss: 0.029301\n",
      "Train Epoch: 92 [11520/14860 (77%)]\tLoss: 0.025146\n",
      "Train Epoch: 92 [11648/14860 (78%)]\tLoss: 0.018220\n",
      "Train Epoch: 92 [11776/14860 (79%)]\tLoss: 0.014888\n",
      "Train Epoch: 92 [11904/14860 (79%)]\tLoss: 0.019223\n",
      "Train Epoch: 92 [12032/14860 (80%)]\tLoss: 0.017587\n",
      "Train Epoch: 92 [12160/14860 (81%)]\tLoss: 0.017628\n",
      "Train Epoch: 92 [12288/14860 (82%)]\tLoss: 0.015055\n",
      "Train Epoch: 92 [12416/14860 (83%)]\tLoss: 0.011174\n",
      "Train Epoch: 92 [12544/14860 (84%)]\tLoss: 0.014205\n",
      "Train Epoch: 92 [12672/14860 (85%)]\tLoss: 0.018265\n",
      "Train Epoch: 92 [12800/14860 (85%)]\tLoss: 0.015457\n",
      "Train Epoch: 92 [12928/14860 (86%)]\tLoss: 0.017134\n",
      "Train Epoch: 92 [13056/14860 (87%)]\tLoss: 0.016844\n",
      "Train Epoch: 92 [13184/14860 (88%)]\tLoss: 0.013467\n",
      "Train Epoch: 92 [13312/14860 (89%)]\tLoss: 0.017236\n",
      "Train Epoch: 92 [13440/14860 (90%)]\tLoss: 0.023556\n",
      "Train Epoch: 92 [13568/14860 (91%)]\tLoss: 0.014685\n",
      "Train Epoch: 92 [13696/14860 (91%)]\tLoss: 0.025156\n",
      "Train Epoch: 92 [13824/14860 (92%)]\tLoss: 0.023712\n",
      "Train Epoch: 92 [13952/14860 (93%)]\tLoss: 0.010563\n",
      "Train Epoch: 92 [14080/14860 (94%)]\tLoss: 0.018165\n",
      "Train Epoch: 92 [14208/14860 (95%)]\tLoss: 0.023672\n",
      "Train Epoch: 92 [14336/14860 (96%)]\tLoss: 0.015042\n",
      "Train Epoch: 92 [14464/14860 (97%)]\tLoss: 0.020127\n",
      "Train Epoch: 92 [14592/14860 (97%)]\tLoss: 0.024588\n",
      "Train Epoch: 92 [14720/14860 (98%)]\tLoss: 0.017393\n",
      "Train Epoch: 92 [1392/14860 (99%)]\tLoss: 0.003904\n",
      "epoch 92 training loss: 0.0188767839059966\n",
      "epoch 92 validation loss: 0.031554791742606544\n",
      "Train Epoch: 93 [0/14860 (0%)]\tLoss: 0.033699\n",
      "Train Epoch: 93 [128/14860 (1%)]\tLoss: 0.027790\n",
      "Train Epoch: 93 [256/14860 (2%)]\tLoss: 0.020357\n",
      "Train Epoch: 93 [384/14860 (3%)]\tLoss: 0.019603\n",
      "Train Epoch: 93 [512/14860 (3%)]\tLoss: 0.029351\n",
      "Train Epoch: 93 [640/14860 (4%)]\tLoss: 0.024061\n",
      "Train Epoch: 93 [768/14860 (5%)]\tLoss: 0.018614\n",
      "Train Epoch: 93 [896/14860 (6%)]\tLoss: 0.031969\n",
      "Train Epoch: 93 [1024/14860 (7%)]\tLoss: 0.034908\n",
      "Train Epoch: 93 [1152/14860 (8%)]\tLoss: 0.022100\n",
      "Train Epoch: 93 [1280/14860 (9%)]\tLoss: 0.021349\n",
      "Train Epoch: 93 [1408/14860 (9%)]\tLoss: 0.030151\n",
      "Train Epoch: 93 [1536/14860 (10%)]\tLoss: 0.028358\n",
      "Train Epoch: 93 [1664/14860 (11%)]\tLoss: 0.020186\n",
      "Train Epoch: 93 [1792/14860 (12%)]\tLoss: 0.021799\n",
      "Train Epoch: 93 [1920/14860 (13%)]\tLoss: 0.034134\n",
      "Train Epoch: 93 [2048/14860 (14%)]\tLoss: 0.019669\n",
      "Train Epoch: 93 [2176/14860 (15%)]\tLoss: 0.016791\n",
      "Train Epoch: 93 [2304/14860 (15%)]\tLoss: 0.018518\n",
      "Train Epoch: 93 [2432/14860 (16%)]\tLoss: 0.018195\n",
      "Train Epoch: 93 [2560/14860 (17%)]\tLoss: 0.017729\n",
      "Train Epoch: 93 [2688/14860 (18%)]\tLoss: 0.024559\n",
      "Train Epoch: 93 [2816/14860 (19%)]\tLoss: 0.021910\n",
      "Train Epoch: 93 [2944/14860 (20%)]\tLoss: 0.022780\n",
      "Train Epoch: 93 [3072/14860 (21%)]\tLoss: 0.014304\n",
      "Train Epoch: 93 [3200/14860 (21%)]\tLoss: 0.014507\n",
      "Train Epoch: 93 [3328/14860 (22%)]\tLoss: 0.016700\n",
      "Train Epoch: 93 [3456/14860 (23%)]\tLoss: 0.018836\n",
      "Train Epoch: 93 [3584/14860 (24%)]\tLoss: 0.017091\n",
      "Train Epoch: 93 [3712/14860 (25%)]\tLoss: 0.018047\n",
      "Train Epoch: 93 [3840/14860 (26%)]\tLoss: 0.025471\n",
      "Train Epoch: 93 [3968/14860 (26%)]\tLoss: 0.015529\n",
      "Train Epoch: 93 [4096/14860 (27%)]\tLoss: 0.017809\n",
      "Train Epoch: 93 [4224/14860 (28%)]\tLoss: 0.021308\n",
      "Train Epoch: 93 [4352/14860 (29%)]\tLoss: 0.016175\n",
      "Train Epoch: 93 [4480/14860 (30%)]\tLoss: 0.016573\n",
      "Train Epoch: 93 [4608/14860 (31%)]\tLoss: 0.013258\n",
      "Train Epoch: 93 [4736/14860 (32%)]\tLoss: 0.014910\n",
      "Train Epoch: 93 [4864/14860 (32%)]\tLoss: 0.015323\n",
      "Train Epoch: 93 [4992/14860 (33%)]\tLoss: 0.018381\n",
      "Train Epoch: 93 [5120/14860 (34%)]\tLoss: 0.022130\n",
      "Train Epoch: 93 [5248/14860 (35%)]\tLoss: 0.017377\n",
      "Train Epoch: 93 [5376/14860 (36%)]\tLoss: 0.018884\n",
      "Train Epoch: 93 [5504/14860 (37%)]\tLoss: 0.023404\n",
      "Train Epoch: 93 [5632/14860 (38%)]\tLoss: 0.017400\n",
      "Train Epoch: 93 [5760/14860 (38%)]\tLoss: 0.020819\n",
      "Train Epoch: 93 [5888/14860 (39%)]\tLoss: 0.015573\n",
      "Train Epoch: 93 [6016/14860 (40%)]\tLoss: 0.017921\n",
      "Train Epoch: 93 [6144/14860 (41%)]\tLoss: 0.018439\n",
      "Train Epoch: 93 [6272/14860 (42%)]\tLoss: 0.015369\n",
      "Train Epoch: 93 [6400/14860 (43%)]\tLoss: 0.024837\n",
      "Train Epoch: 93 [6528/14860 (44%)]\tLoss: 0.015480\n",
      "Train Epoch: 93 [6656/14860 (44%)]\tLoss: 0.021609\n",
      "Train Epoch: 93 [6784/14860 (45%)]\tLoss: 0.022741\n",
      "Train Epoch: 93 [6912/14860 (46%)]\tLoss: 0.018445\n",
      "Train Epoch: 93 [7040/14860 (47%)]\tLoss: 0.017233\n",
      "Train Epoch: 93 [7168/14860 (48%)]\tLoss: 0.016205\n",
      "Train Epoch: 93 [7296/14860 (49%)]\tLoss: 0.012180\n",
      "Train Epoch: 93 [7424/14860 (50%)]\tLoss: 0.018922\n",
      "Train Epoch: 93 [7552/14860 (50%)]\tLoss: 0.012339\n",
      "Train Epoch: 93 [7680/14860 (51%)]\tLoss: 0.014306\n",
      "Train Epoch: 93 [7808/14860 (52%)]\tLoss: 0.023109\n",
      "Train Epoch: 93 [7936/14860 (53%)]\tLoss: 0.019876\n",
      "Train Epoch: 93 [8064/14860 (54%)]\tLoss: 0.016561\n",
      "Train Epoch: 93 [8192/14860 (55%)]\tLoss: 0.018226\n",
      "Train Epoch: 93 [8320/14860 (56%)]\tLoss: 0.014598\n",
      "Train Epoch: 93 [8448/14860 (56%)]\tLoss: 0.018744\n",
      "Train Epoch: 93 [8576/14860 (57%)]\tLoss: 0.026457\n",
      "Train Epoch: 93 [8704/14860 (58%)]\tLoss: 0.017542\n",
      "Train Epoch: 93 [8832/14860 (59%)]\tLoss: 0.024352\n",
      "Train Epoch: 93 [8960/14860 (60%)]\tLoss: 0.025205\n",
      "Train Epoch: 93 [9088/14860 (61%)]\tLoss: 0.019263\n",
      "Train Epoch: 93 [9216/14860 (62%)]\tLoss: 0.017447\n",
      "Train Epoch: 93 [9344/14860 (62%)]\tLoss: 0.018739\n",
      "Train Epoch: 93 [9472/14860 (63%)]\tLoss: 0.018109\n",
      "Train Epoch: 93 [9600/14860 (64%)]\tLoss: 0.013968\n",
      "Train Epoch: 93 [9728/14860 (65%)]\tLoss: 0.018594\n",
      "Train Epoch: 93 [9856/14860 (66%)]\tLoss: 0.018415\n",
      "Train Epoch: 93 [9984/14860 (67%)]\tLoss: 0.022618\n",
      "Train Epoch: 93 [10112/14860 (68%)]\tLoss: 0.016404\n",
      "Train Epoch: 93 [10240/14860 (68%)]\tLoss: 0.016697\n",
      "Train Epoch: 93 [10368/14860 (69%)]\tLoss: 0.020707\n",
      "Train Epoch: 93 [10496/14860 (70%)]\tLoss: 0.015899\n",
      "Train Epoch: 93 [10624/14860 (71%)]\tLoss: 0.014922\n",
      "Train Epoch: 93 [10752/14860 (72%)]\tLoss: 0.012650\n",
      "Train Epoch: 93 [10880/14860 (73%)]\tLoss: 0.015057\n",
      "Train Epoch: 93 [11008/14860 (74%)]\tLoss: 0.016075\n",
      "Train Epoch: 93 [11136/14860 (74%)]\tLoss: 0.014541\n",
      "Train Epoch: 93 [11264/14860 (75%)]\tLoss: 0.023699\n",
      "Train Epoch: 93 [11392/14860 (76%)]\tLoss: 0.033303\n",
      "Train Epoch: 93 [11520/14860 (77%)]\tLoss: 0.019488\n",
      "Train Epoch: 93 [11648/14860 (78%)]\tLoss: 0.023432\n",
      "Train Epoch: 93 [11776/14860 (79%)]\tLoss: 0.016567\n",
      "Train Epoch: 93 [11904/14860 (79%)]\tLoss: 0.019792\n",
      "Train Epoch: 93 [12032/14860 (80%)]\tLoss: 0.025925\n",
      "Train Epoch: 93 [12160/14860 (81%)]\tLoss: 0.014706\n",
      "Train Epoch: 93 [12288/14860 (82%)]\tLoss: 0.019479\n",
      "Train Epoch: 93 [12416/14860 (83%)]\tLoss: 0.016315\n",
      "Train Epoch: 93 [12544/14860 (84%)]\tLoss: 0.018923\n",
      "Train Epoch: 93 [12672/14860 (85%)]\tLoss: 0.020486\n",
      "Train Epoch: 93 [12800/14860 (85%)]\tLoss: 0.011046\n",
      "Train Epoch: 93 [12928/14860 (86%)]\tLoss: 0.015852\n",
      "Train Epoch: 93 [13056/14860 (87%)]\tLoss: 0.013727\n",
      "Train Epoch: 93 [13184/14860 (88%)]\tLoss: 0.014545\n",
      "Train Epoch: 93 [13312/14860 (89%)]\tLoss: 0.018846\n",
      "Train Epoch: 93 [13440/14860 (90%)]\tLoss: 0.016503\n",
      "Train Epoch: 93 [13568/14860 (91%)]\tLoss: 0.024968\n",
      "Train Epoch: 93 [13696/14860 (91%)]\tLoss: 0.019465\n",
      "Train Epoch: 93 [13824/14860 (92%)]\tLoss: 0.019508\n",
      "Train Epoch: 93 [13952/14860 (93%)]\tLoss: 0.022758\n",
      "Train Epoch: 93 [14080/14860 (94%)]\tLoss: 0.017230\n",
      "Train Epoch: 93 [14208/14860 (95%)]\tLoss: 0.021244\n",
      "Train Epoch: 93 [14336/14860 (96%)]\tLoss: 0.020500\n",
      "Train Epoch: 93 [14464/14860 (97%)]\tLoss: 0.017741\n",
      "Train Epoch: 93 [14592/14860 (97%)]\tLoss: 0.025018\n",
      "Train Epoch: 93 [14720/14860 (98%)]\tLoss: 0.021239\n",
      "Train Epoch: 93 [1392/14860 (99%)]\tLoss: 0.016594\n",
      "epoch 93 training loss: 0.019641827425768234\n",
      "epoch 93 validation loss: 0.023593056577169865\n",
      "Train Epoch: 94 [0/14860 (0%)]\tLoss: 0.019725\n",
      "Train Epoch: 94 [128/14860 (1%)]\tLoss: 0.020764\n",
      "Train Epoch: 94 [256/14860 (2%)]\tLoss: 0.017173\n",
      "Train Epoch: 94 [384/14860 (3%)]\tLoss: 0.026019\n",
      "Train Epoch: 94 [512/14860 (3%)]\tLoss: 0.030002\n",
      "Train Epoch: 94 [640/14860 (4%)]\tLoss: 0.029877\n",
      "Train Epoch: 94 [768/14860 (5%)]\tLoss: 0.016760\n",
      "Train Epoch: 94 [896/14860 (6%)]\tLoss: 0.023057\n",
      "Train Epoch: 94 [1024/14860 (7%)]\tLoss: 0.028229\n",
      "Train Epoch: 94 [1152/14860 (8%)]\tLoss: 0.020639\n",
      "Train Epoch: 94 [1280/14860 (9%)]\tLoss: 0.022753\n",
      "Train Epoch: 94 [1408/14860 (9%)]\tLoss: 0.018352\n",
      "Train Epoch: 94 [1536/14860 (10%)]\tLoss: 0.023543\n",
      "Train Epoch: 94 [1664/14860 (11%)]\tLoss: 0.023412\n",
      "Train Epoch: 94 [1792/14860 (12%)]\tLoss: 0.014247\n",
      "Train Epoch: 94 [1920/14860 (13%)]\tLoss: 0.019962\n",
      "Train Epoch: 94 [2048/14860 (14%)]\tLoss: 0.014920\n",
      "Train Epoch: 94 [2176/14860 (15%)]\tLoss: 0.024496\n",
      "Train Epoch: 94 [2304/14860 (15%)]\tLoss: 0.013630\n",
      "Train Epoch: 94 [2432/14860 (16%)]\tLoss: 0.020116\n",
      "Train Epoch: 94 [2560/14860 (17%)]\tLoss: 0.021112\n",
      "Train Epoch: 94 [2688/14860 (18%)]\tLoss: 0.016537\n",
      "Train Epoch: 94 [2816/14860 (19%)]\tLoss: 0.012805\n",
      "Train Epoch: 94 [2944/14860 (20%)]\tLoss: 0.026342\n",
      "Train Epoch: 94 [3072/14860 (21%)]\tLoss: 0.010941\n",
      "Train Epoch: 94 [3200/14860 (21%)]\tLoss: 0.015829\n",
      "Train Epoch: 94 [3328/14860 (22%)]\tLoss: 0.025459\n",
      "Train Epoch: 94 [3456/14860 (23%)]\tLoss: 0.023135\n",
      "Train Epoch: 94 [3584/14860 (24%)]\tLoss: 0.014354\n",
      "Train Epoch: 94 [3712/14860 (25%)]\tLoss: 0.014214\n",
      "Train Epoch: 94 [3840/14860 (26%)]\tLoss: 0.016087\n",
      "Train Epoch: 94 [3968/14860 (26%)]\tLoss: 0.019801\n",
      "Train Epoch: 94 [4096/14860 (27%)]\tLoss: 0.011627\n",
      "Train Epoch: 94 [4224/14860 (28%)]\tLoss: 0.016089\n",
      "Train Epoch: 94 [4352/14860 (29%)]\tLoss: 0.018711\n",
      "Train Epoch: 94 [4480/14860 (30%)]\tLoss: 0.020892\n",
      "Train Epoch: 94 [4608/14860 (31%)]\tLoss: 0.016515\n",
      "Train Epoch: 94 [4736/14860 (32%)]\tLoss: 0.025851\n",
      "Train Epoch: 94 [4864/14860 (32%)]\tLoss: 0.020273\n",
      "Train Epoch: 94 [4992/14860 (33%)]\tLoss: 0.021915\n",
      "Train Epoch: 94 [5120/14860 (34%)]\tLoss: 0.024592\n",
      "Train Epoch: 94 [5248/14860 (35%)]\tLoss: 0.020590\n",
      "Train Epoch: 94 [5376/14860 (36%)]\tLoss: 0.016236\n",
      "Train Epoch: 94 [5504/14860 (37%)]\tLoss: 0.020476\n",
      "Train Epoch: 94 [5632/14860 (38%)]\tLoss: 0.031754\n",
      "Train Epoch: 94 [5760/14860 (38%)]\tLoss: 0.015030\n",
      "Train Epoch: 94 [5888/14860 (39%)]\tLoss: 0.026074\n",
      "Train Epoch: 94 [6016/14860 (40%)]\tLoss: 0.021346\n",
      "Train Epoch: 94 [6144/14860 (41%)]\tLoss: 0.016838\n",
      "Train Epoch: 94 [6272/14860 (42%)]\tLoss: 0.021439\n",
      "Train Epoch: 94 [6400/14860 (43%)]\tLoss: 0.020378\n",
      "Train Epoch: 94 [6528/14860 (44%)]\tLoss: 0.017179\n",
      "Train Epoch: 94 [6656/14860 (44%)]\tLoss: 0.014688\n",
      "Train Epoch: 94 [6784/14860 (45%)]\tLoss: 0.023077\n",
      "Train Epoch: 94 [6912/14860 (46%)]\tLoss: 0.019836\n",
      "Train Epoch: 94 [7040/14860 (47%)]\tLoss: 0.021893\n",
      "Train Epoch: 94 [7168/14860 (48%)]\tLoss: 0.018811\n",
      "Train Epoch: 94 [7296/14860 (49%)]\tLoss: 0.021623\n",
      "Train Epoch: 94 [7424/14860 (50%)]\tLoss: 0.020903\n",
      "Train Epoch: 94 [7552/14860 (50%)]\tLoss: 0.017978\n",
      "Train Epoch: 94 [7680/14860 (51%)]\tLoss: 0.015253\n",
      "Train Epoch: 94 [7808/14860 (52%)]\tLoss: 0.017880\n",
      "Train Epoch: 94 [7936/14860 (53%)]\tLoss: 0.018209\n",
      "Train Epoch: 94 [8064/14860 (54%)]\tLoss: 0.023844\n",
      "Train Epoch: 94 [8192/14860 (55%)]\tLoss: 0.014558\n",
      "Train Epoch: 94 [8320/14860 (56%)]\tLoss: 0.018939\n",
      "Train Epoch: 94 [8448/14860 (56%)]\tLoss: 0.017104\n",
      "Train Epoch: 94 [8576/14860 (57%)]\tLoss: 0.019176\n",
      "Train Epoch: 94 [8704/14860 (58%)]\tLoss: 0.016479\n",
      "Train Epoch: 94 [8832/14860 (59%)]\tLoss: 0.023574\n",
      "Train Epoch: 94 [8960/14860 (60%)]\tLoss: 0.018172\n",
      "Train Epoch: 94 [9088/14860 (61%)]\tLoss: 0.012665\n",
      "Train Epoch: 94 [9216/14860 (62%)]\tLoss: 0.017192\n",
      "Train Epoch: 94 [9344/14860 (62%)]\tLoss: 0.018478\n",
      "Train Epoch: 94 [9472/14860 (63%)]\tLoss: 0.012650\n",
      "Train Epoch: 94 [9600/14860 (64%)]\tLoss: 0.017578\n",
      "Train Epoch: 94 [9728/14860 (65%)]\tLoss: 0.014527\n",
      "Train Epoch: 94 [9856/14860 (66%)]\tLoss: 0.023184\n",
      "Train Epoch: 94 [9984/14860 (67%)]\tLoss: 0.014356\n",
      "Train Epoch: 94 [10112/14860 (68%)]\tLoss: 0.022548\n",
      "Train Epoch: 94 [10240/14860 (68%)]\tLoss: 0.019716\n",
      "Train Epoch: 94 [10368/14860 (69%)]\tLoss: 0.014074\n",
      "Train Epoch: 94 [10496/14860 (70%)]\tLoss: 0.016746\n",
      "Train Epoch: 94 [10624/14860 (71%)]\tLoss: 0.023974\n",
      "Train Epoch: 94 [10752/14860 (72%)]\tLoss: 0.020248\n",
      "Train Epoch: 94 [10880/14860 (73%)]\tLoss: 0.014858\n",
      "Train Epoch: 94 [11008/14860 (74%)]\tLoss: 0.017111\n",
      "Train Epoch: 94 [11136/14860 (74%)]\tLoss: 0.017885\n",
      "Train Epoch: 94 [11264/14860 (75%)]\tLoss: 0.018774\n",
      "Train Epoch: 94 [11392/14860 (76%)]\tLoss: 0.018249\n",
      "Train Epoch: 94 [11520/14860 (77%)]\tLoss: 0.023506\n",
      "Train Epoch: 94 [11648/14860 (78%)]\tLoss: 0.032643\n",
      "Train Epoch: 94 [11776/14860 (79%)]\tLoss: 0.020616\n",
      "Train Epoch: 94 [11904/14860 (79%)]\tLoss: 0.019933\n",
      "Train Epoch: 94 [12032/14860 (80%)]\tLoss: 0.024659\n",
      "Train Epoch: 94 [12160/14860 (81%)]\tLoss: 0.018558\n",
      "Train Epoch: 94 [12288/14860 (82%)]\tLoss: 0.017080\n",
      "Train Epoch: 94 [12416/14860 (83%)]\tLoss: 0.026204\n",
      "Train Epoch: 94 [12544/14860 (84%)]\tLoss: 0.011638\n",
      "Train Epoch: 94 [12672/14860 (85%)]\tLoss: 0.018823\n",
      "Train Epoch: 94 [12800/14860 (85%)]\tLoss: 0.013933\n",
      "Train Epoch: 94 [12928/14860 (86%)]\tLoss: 0.020808\n",
      "Train Epoch: 94 [13056/14860 (87%)]\tLoss: 0.012595\n",
      "Train Epoch: 94 [13184/14860 (88%)]\tLoss: 0.018149\n",
      "Train Epoch: 94 [13312/14860 (89%)]\tLoss: 0.015440\n",
      "Train Epoch: 94 [13440/14860 (90%)]\tLoss: 0.014004\n",
      "Train Epoch: 94 [13568/14860 (91%)]\tLoss: 0.023306\n",
      "Train Epoch: 94 [13696/14860 (91%)]\tLoss: 0.018503\n",
      "Train Epoch: 94 [13824/14860 (92%)]\tLoss: 0.020107\n",
      "Train Epoch: 94 [13952/14860 (93%)]\tLoss: 0.023328\n",
      "Train Epoch: 94 [14080/14860 (94%)]\tLoss: 0.018729\n",
      "Train Epoch: 94 [14208/14860 (95%)]\tLoss: 0.015860\n",
      "Train Epoch: 94 [14336/14860 (96%)]\tLoss: 0.016261\n",
      "Train Epoch: 94 [14464/14860 (97%)]\tLoss: 0.013460\n",
      "Train Epoch: 94 [14592/14860 (97%)]\tLoss: 0.026244\n",
      "Train Epoch: 94 [14720/14860 (98%)]\tLoss: 0.014735\n",
      "Train Epoch: 94 [1392/14860 (99%)]\tLoss: 0.006571\n",
      "epoch 94 training loss: 0.01923588512895199\n",
      "epoch 94 validation loss: 0.01984894102479875\n",
      "Train Epoch: 95 [0/14860 (0%)]\tLoss: 0.017000\n",
      "Train Epoch: 95 [128/14860 (1%)]\tLoss: 0.019035\n",
      "Train Epoch: 95 [256/14860 (2%)]\tLoss: 0.017573\n",
      "Train Epoch: 95 [384/14860 (3%)]\tLoss: 0.016150\n",
      "Train Epoch: 95 [512/14860 (3%)]\tLoss: 0.016428\n",
      "Train Epoch: 95 [640/14860 (4%)]\tLoss: 0.014944\n",
      "Train Epoch: 95 [768/14860 (5%)]\tLoss: 0.016934\n",
      "Train Epoch: 95 [896/14860 (6%)]\tLoss: 0.017388\n",
      "Train Epoch: 95 [1024/14860 (7%)]\tLoss: 0.016688\n",
      "Train Epoch: 95 [1152/14860 (8%)]\tLoss: 0.014844\n",
      "Train Epoch: 95 [1280/14860 (9%)]\tLoss: 0.013149\n",
      "Train Epoch: 95 [1408/14860 (9%)]\tLoss: 0.015545\n",
      "Train Epoch: 95 [1536/14860 (10%)]\tLoss: 0.018834\n",
      "Train Epoch: 95 [1664/14860 (11%)]\tLoss: 0.025215\n",
      "Train Epoch: 95 [1792/14860 (12%)]\tLoss: 0.014478\n",
      "Train Epoch: 95 [1920/14860 (13%)]\tLoss: 0.017136\n",
      "Train Epoch: 95 [2048/14860 (14%)]\tLoss: 0.023437\n",
      "Train Epoch: 95 [2176/14860 (15%)]\tLoss: 0.017619\n",
      "Train Epoch: 95 [2304/14860 (15%)]\tLoss: 0.023353\n",
      "Train Epoch: 95 [2432/14860 (16%)]\tLoss: 0.019571\n",
      "Train Epoch: 95 [2560/14860 (17%)]\tLoss: 0.028486\n",
      "Train Epoch: 95 [2688/14860 (18%)]\tLoss: 0.016744\n",
      "Train Epoch: 95 [2816/14860 (19%)]\tLoss: 0.014702\n",
      "Train Epoch: 95 [2944/14860 (20%)]\tLoss: 0.020742\n",
      "Train Epoch: 95 [3072/14860 (21%)]\tLoss: 0.019345\n",
      "Train Epoch: 95 [3200/14860 (21%)]\tLoss: 0.014797\n",
      "Train Epoch: 95 [3328/14860 (22%)]\tLoss: 0.016994\n",
      "Train Epoch: 95 [3456/14860 (23%)]\tLoss: 0.015615\n",
      "Train Epoch: 95 [3584/14860 (24%)]\tLoss: 0.022826\n",
      "Train Epoch: 95 [3712/14860 (25%)]\tLoss: 0.015977\n",
      "Train Epoch: 95 [3840/14860 (26%)]\tLoss: 0.021011\n",
      "Train Epoch: 95 [3968/14860 (26%)]\tLoss: 0.016995\n",
      "Train Epoch: 95 [4096/14860 (27%)]\tLoss: 0.017579\n",
      "Train Epoch: 95 [4224/14860 (28%)]\tLoss: 0.016770\n",
      "Train Epoch: 95 [4352/14860 (29%)]\tLoss: 0.010792\n",
      "Train Epoch: 95 [4480/14860 (30%)]\tLoss: 0.020297\n",
      "Train Epoch: 95 [4608/14860 (31%)]\tLoss: 0.017989\n",
      "Train Epoch: 95 [4736/14860 (32%)]\tLoss: 0.016995\n",
      "Train Epoch: 95 [4864/14860 (32%)]\tLoss: 0.021981\n",
      "Train Epoch: 95 [4992/14860 (33%)]\tLoss: 0.010963\n",
      "Train Epoch: 95 [5120/14860 (34%)]\tLoss: 0.017076\n",
      "Train Epoch: 95 [5248/14860 (35%)]\tLoss: 0.024896\n",
      "Train Epoch: 95 [5376/14860 (36%)]\tLoss: 0.023005\n",
      "Train Epoch: 95 [5504/14860 (37%)]\tLoss: 0.023533\n",
      "Train Epoch: 95 [5632/14860 (38%)]\tLoss: 0.021010\n",
      "Train Epoch: 95 [5760/14860 (38%)]\tLoss: 0.020208\n",
      "Train Epoch: 95 [5888/14860 (39%)]\tLoss: 0.021919\n",
      "Train Epoch: 95 [6016/14860 (40%)]\tLoss: 0.015981\n",
      "Train Epoch: 95 [6144/14860 (41%)]\tLoss: 0.017236\n",
      "Train Epoch: 95 [6272/14860 (42%)]\tLoss: 0.019308\n",
      "Train Epoch: 95 [6400/14860 (43%)]\tLoss: 0.016402\n",
      "Train Epoch: 95 [6528/14860 (44%)]\tLoss: 0.015992\n",
      "Train Epoch: 95 [6656/14860 (44%)]\tLoss: 0.014362\n",
      "Train Epoch: 95 [6784/14860 (45%)]\tLoss: 0.017823\n",
      "Train Epoch: 95 [6912/14860 (46%)]\tLoss: 0.014151\n",
      "Train Epoch: 95 [7040/14860 (47%)]\tLoss: 0.019821\n",
      "Train Epoch: 95 [7168/14860 (48%)]\tLoss: 0.017312\n",
      "Train Epoch: 95 [7296/14860 (49%)]\tLoss: 0.021913\n",
      "Train Epoch: 95 [7424/14860 (50%)]\tLoss: 0.019661\n",
      "Train Epoch: 95 [7552/14860 (50%)]\tLoss: 0.017439\n",
      "Train Epoch: 95 [7680/14860 (51%)]\tLoss: 0.019709\n",
      "Train Epoch: 95 [7808/14860 (52%)]\tLoss: 0.016098\n",
      "Train Epoch: 95 [7936/14860 (53%)]\tLoss: 0.027229\n",
      "Train Epoch: 95 [8064/14860 (54%)]\tLoss: 0.018882\n",
      "Train Epoch: 95 [8192/14860 (55%)]\tLoss: 0.022819\n",
      "Train Epoch: 95 [8320/14860 (56%)]\tLoss: 0.018704\n",
      "Train Epoch: 95 [8448/14860 (56%)]\tLoss: 0.021577\n",
      "Train Epoch: 95 [8576/14860 (57%)]\tLoss: 0.011313\n",
      "Train Epoch: 95 [8704/14860 (58%)]\tLoss: 0.018089\n",
      "Train Epoch: 95 [8832/14860 (59%)]\tLoss: 0.018354\n",
      "Train Epoch: 95 [8960/14860 (60%)]\tLoss: 0.016489\n",
      "Train Epoch: 95 [9088/14860 (61%)]\tLoss: 0.015195\n",
      "Train Epoch: 95 [9216/14860 (62%)]\tLoss: 0.016957\n",
      "Train Epoch: 95 [9344/14860 (62%)]\tLoss: 0.015612\n",
      "Train Epoch: 95 [9472/14860 (63%)]\tLoss: 0.023930\n",
      "Train Epoch: 95 [9600/14860 (64%)]\tLoss: 0.016142\n",
      "Train Epoch: 95 [9728/14860 (65%)]\tLoss: 0.017490\n",
      "Train Epoch: 95 [9856/14860 (66%)]\tLoss: 0.019799\n",
      "Train Epoch: 95 [9984/14860 (67%)]\tLoss: 0.021185\n",
      "Train Epoch: 95 [10112/14860 (68%)]\tLoss: 0.020696\n",
      "Train Epoch: 95 [10240/14860 (68%)]\tLoss: 0.024964\n",
      "Train Epoch: 95 [10368/14860 (69%)]\tLoss: 0.018401\n",
      "Train Epoch: 95 [10496/14860 (70%)]\tLoss: 0.020616\n",
      "Train Epoch: 95 [10624/14860 (71%)]\tLoss: 0.014972\n",
      "Train Epoch: 95 [10752/14860 (72%)]\tLoss: 0.020477\n",
      "Train Epoch: 95 [10880/14860 (73%)]\tLoss: 0.013105\n",
      "Train Epoch: 95 [11008/14860 (74%)]\tLoss: 0.021952\n",
      "Train Epoch: 95 [11136/14860 (74%)]\tLoss: 0.015414\n",
      "Train Epoch: 95 [11264/14860 (75%)]\tLoss: 0.015685\n",
      "Train Epoch: 95 [11392/14860 (76%)]\tLoss: 0.015031\n",
      "Train Epoch: 95 [11520/14860 (77%)]\tLoss: 0.024596\n",
      "Train Epoch: 95 [11648/14860 (78%)]\tLoss: 0.027242\n",
      "Train Epoch: 95 [11776/14860 (79%)]\tLoss: 0.012765\n",
      "Train Epoch: 95 [11904/14860 (79%)]\tLoss: 0.016197\n",
      "Train Epoch: 95 [12032/14860 (80%)]\tLoss: 0.024236\n",
      "Train Epoch: 95 [12160/14860 (81%)]\tLoss: 0.021153\n",
      "Train Epoch: 95 [12288/14860 (82%)]\tLoss: 0.028489\n",
      "Train Epoch: 95 [12416/14860 (83%)]\tLoss: 0.026890\n",
      "Train Epoch: 95 [12544/14860 (84%)]\tLoss: 0.017822\n",
      "Train Epoch: 95 [12672/14860 (85%)]\tLoss: 0.017341\n",
      "Train Epoch: 95 [12800/14860 (85%)]\tLoss: 0.028928\n",
      "Train Epoch: 95 [12928/14860 (86%)]\tLoss: 0.016910\n",
      "Train Epoch: 95 [13056/14860 (87%)]\tLoss: 0.018000\n",
      "Train Epoch: 95 [13184/14860 (88%)]\tLoss: 0.022567\n",
      "Train Epoch: 95 [13312/14860 (89%)]\tLoss: 0.024886\n",
      "Train Epoch: 95 [13440/14860 (90%)]\tLoss: 0.012630\n",
      "Train Epoch: 95 [13568/14860 (91%)]\tLoss: 0.028222\n",
      "Train Epoch: 95 [13696/14860 (91%)]\tLoss: 0.029421\n",
      "Train Epoch: 95 [13824/14860 (92%)]\tLoss: 0.016932\n",
      "Train Epoch: 95 [13952/14860 (93%)]\tLoss: 0.018256\n",
      "Train Epoch: 95 [14080/14860 (94%)]\tLoss: 0.021023\n",
      "Train Epoch: 95 [14208/14860 (95%)]\tLoss: 0.032555\n",
      "Train Epoch: 95 [14336/14860 (96%)]\tLoss: 0.030127\n",
      "Train Epoch: 95 [14464/14860 (97%)]\tLoss: 0.016493\n",
      "Train Epoch: 95 [14592/14860 (97%)]\tLoss: 0.023848\n",
      "Train Epoch: 95 [14720/14860 (98%)]\tLoss: 0.015101\n",
      "Train Epoch: 95 [1392/14860 (99%)]\tLoss: 0.020864\n",
      "epoch 95 training loss: 0.01916539076811228\n",
      "epoch 95 validation loss: 0.021328635567902942\n",
      "Train Epoch: 96 [0/14860 (0%)]\tLoss: 0.021193\n",
      "Train Epoch: 96 [128/14860 (1%)]\tLoss: 0.022335\n",
      "Train Epoch: 96 [256/14860 (2%)]\tLoss: 0.019306\n",
      "Train Epoch: 96 [384/14860 (3%)]\tLoss: 0.015448\n",
      "Train Epoch: 96 [512/14860 (3%)]\tLoss: 0.020104\n",
      "Train Epoch: 96 [640/14860 (4%)]\tLoss: 0.020801\n",
      "Train Epoch: 96 [768/14860 (5%)]\tLoss: 0.021466\n",
      "Train Epoch: 96 [896/14860 (6%)]\tLoss: 0.020949\n",
      "Train Epoch: 96 [1024/14860 (7%)]\tLoss: 0.023826\n",
      "Train Epoch: 96 [1152/14860 (8%)]\tLoss: 0.016383\n",
      "Train Epoch: 96 [1280/14860 (9%)]\tLoss: 0.033751\n",
      "Train Epoch: 96 [1408/14860 (9%)]\tLoss: 0.023553\n",
      "Train Epoch: 96 [1536/14860 (10%)]\tLoss: 0.013545\n",
      "Train Epoch: 96 [1664/14860 (11%)]\tLoss: 0.015358\n",
      "Train Epoch: 96 [1792/14860 (12%)]\tLoss: 0.016505\n",
      "Train Epoch: 96 [1920/14860 (13%)]\tLoss: 0.017263\n",
      "Train Epoch: 96 [2048/14860 (14%)]\tLoss: 0.017521\n",
      "Train Epoch: 96 [2176/14860 (15%)]\tLoss: 0.018671\n",
      "Train Epoch: 96 [2304/14860 (15%)]\tLoss: 0.013403\n",
      "Train Epoch: 96 [2432/14860 (16%)]\tLoss: 0.020237\n",
      "Train Epoch: 96 [2560/14860 (17%)]\tLoss: 0.022915\n",
      "Train Epoch: 96 [2688/14860 (18%)]\tLoss: 0.023152\n",
      "Train Epoch: 96 [2816/14860 (19%)]\tLoss: 0.014858\n",
      "Train Epoch: 96 [2944/14860 (20%)]\tLoss: 0.023005\n",
      "Train Epoch: 96 [3072/14860 (21%)]\tLoss: 0.025448\n",
      "Train Epoch: 96 [3200/14860 (21%)]\tLoss: 0.022949\n",
      "Train Epoch: 96 [3328/14860 (22%)]\tLoss: 0.013891\n",
      "Train Epoch: 96 [3456/14860 (23%)]\tLoss: 0.021858\n",
      "Train Epoch: 96 [3584/14860 (24%)]\tLoss: 0.018068\n",
      "Train Epoch: 96 [3712/14860 (25%)]\tLoss: 0.010398\n",
      "Train Epoch: 96 [3840/14860 (26%)]\tLoss: 0.014828\n",
      "Train Epoch: 96 [3968/14860 (26%)]\tLoss: 0.013800\n",
      "Train Epoch: 96 [4096/14860 (27%)]\tLoss: 0.017738\n",
      "Train Epoch: 96 [4224/14860 (28%)]\tLoss: 0.015947\n",
      "Train Epoch: 96 [4352/14860 (29%)]\tLoss: 0.021924\n",
      "Train Epoch: 96 [4480/14860 (30%)]\tLoss: 0.015814\n",
      "Train Epoch: 96 [4608/14860 (31%)]\tLoss: 0.020569\n",
      "Train Epoch: 96 [4736/14860 (32%)]\tLoss: 0.012464\n",
      "Train Epoch: 96 [4864/14860 (32%)]\tLoss: 0.017926\n",
      "Train Epoch: 96 [4992/14860 (33%)]\tLoss: 0.016787\n",
      "Train Epoch: 96 [5120/14860 (34%)]\tLoss: 0.011106\n",
      "Train Epoch: 96 [5248/14860 (35%)]\tLoss: 0.020337\n",
      "Train Epoch: 96 [5376/14860 (36%)]\tLoss: 0.020504\n",
      "Train Epoch: 96 [5504/14860 (37%)]\tLoss: 0.017389\n",
      "Train Epoch: 96 [5632/14860 (38%)]\tLoss: 0.023252\n",
      "Train Epoch: 96 [5760/14860 (38%)]\tLoss: 0.024610\n",
      "Train Epoch: 96 [5888/14860 (39%)]\tLoss: 0.016395\n",
      "Train Epoch: 96 [6016/14860 (40%)]\tLoss: 0.018293\n",
      "Train Epoch: 96 [6144/14860 (41%)]\tLoss: 0.021441\n",
      "Train Epoch: 96 [6272/14860 (42%)]\tLoss: 0.011984\n",
      "Train Epoch: 96 [6400/14860 (43%)]\tLoss: 0.019649\n",
      "Train Epoch: 96 [6528/14860 (44%)]\tLoss: 0.020869\n",
      "Train Epoch: 96 [6656/14860 (44%)]\tLoss: 0.023141\n",
      "Train Epoch: 96 [6784/14860 (45%)]\tLoss: 0.015730\n",
      "Train Epoch: 96 [6912/14860 (46%)]\tLoss: 0.023495\n",
      "Train Epoch: 96 [7040/14860 (47%)]\tLoss: 0.014238\n",
      "Train Epoch: 96 [7168/14860 (48%)]\tLoss: 0.026410\n",
      "Train Epoch: 96 [7296/14860 (49%)]\tLoss: 0.015462\n",
      "Train Epoch: 96 [7424/14860 (50%)]\tLoss: 0.018030\n",
      "Train Epoch: 96 [7552/14860 (50%)]\tLoss: 0.020835\n",
      "Train Epoch: 96 [7680/14860 (51%)]\tLoss: 0.017413\n",
      "Train Epoch: 96 [7808/14860 (52%)]\tLoss: 0.013212\n",
      "Train Epoch: 96 [7936/14860 (53%)]\tLoss: 0.014139\n",
      "Train Epoch: 96 [8064/14860 (54%)]\tLoss: 0.025185\n",
      "Train Epoch: 96 [8192/14860 (55%)]\tLoss: 0.014344\n",
      "Train Epoch: 96 [8320/14860 (56%)]\tLoss: 0.018897\n",
      "Train Epoch: 96 [8448/14860 (56%)]\tLoss: 0.017106\n",
      "Train Epoch: 96 [8576/14860 (57%)]\tLoss: 0.023073\n",
      "Train Epoch: 96 [8704/14860 (58%)]\tLoss: 0.018769\n",
      "Train Epoch: 96 [8832/14860 (59%)]\tLoss: 0.022717\n",
      "Train Epoch: 96 [8960/14860 (60%)]\tLoss: 0.015861\n",
      "Train Epoch: 96 [9088/14860 (61%)]\tLoss: 0.015642\n",
      "Train Epoch: 96 [9216/14860 (62%)]\tLoss: 0.020425\n",
      "Train Epoch: 96 [9344/14860 (62%)]\tLoss: 0.018668\n",
      "Train Epoch: 96 [9472/14860 (63%)]\tLoss: 0.015914\n",
      "Train Epoch: 96 [9600/14860 (64%)]\tLoss: 0.019764\n",
      "Train Epoch: 96 [9728/14860 (65%)]\tLoss: 0.018077\n",
      "Train Epoch: 96 [9856/14860 (66%)]\tLoss: 0.012729\n",
      "Train Epoch: 96 [9984/14860 (67%)]\tLoss: 0.020020\n",
      "Train Epoch: 96 [10112/14860 (68%)]\tLoss: 0.024610\n",
      "Train Epoch: 96 [10240/14860 (68%)]\tLoss: 0.020763\n",
      "Train Epoch: 96 [10368/14860 (69%)]\tLoss: 0.019716\n",
      "Train Epoch: 96 [10496/14860 (70%)]\tLoss: 0.014783\n",
      "Train Epoch: 96 [10624/14860 (71%)]\tLoss: 0.010868\n",
      "Train Epoch: 96 [10752/14860 (72%)]\tLoss: 0.025755\n",
      "Train Epoch: 96 [10880/14860 (73%)]\tLoss: 0.020773\n",
      "Train Epoch: 96 [11008/14860 (74%)]\tLoss: 0.016502\n",
      "Train Epoch: 96 [11136/14860 (74%)]\tLoss: 0.017116\n",
      "Train Epoch: 96 [11264/14860 (75%)]\tLoss: 0.019693\n",
      "Train Epoch: 96 [11392/14860 (76%)]\tLoss: 0.020101\n",
      "Train Epoch: 96 [11520/14860 (77%)]\tLoss: 0.018514\n",
      "Train Epoch: 96 [11648/14860 (78%)]\tLoss: 0.018100\n",
      "Train Epoch: 96 [11776/14860 (79%)]\tLoss: 0.021999\n",
      "Train Epoch: 96 [11904/14860 (79%)]\tLoss: 0.017757\n",
      "Train Epoch: 96 [12032/14860 (80%)]\tLoss: 0.014224\n",
      "Train Epoch: 96 [12160/14860 (81%)]\tLoss: 0.022238\n",
      "Train Epoch: 96 [12288/14860 (82%)]\tLoss: 0.014178\n",
      "Train Epoch: 96 [12416/14860 (83%)]\tLoss: 0.024572\n",
      "Train Epoch: 96 [12544/14860 (84%)]\tLoss: 0.018483\n",
      "Train Epoch: 96 [12672/14860 (85%)]\tLoss: 0.016349\n",
      "Train Epoch: 96 [12800/14860 (85%)]\tLoss: 0.021869\n",
      "Train Epoch: 96 [12928/14860 (86%)]\tLoss: 0.019214\n",
      "Train Epoch: 96 [13056/14860 (87%)]\tLoss: 0.022993\n",
      "Train Epoch: 96 [13184/14860 (88%)]\tLoss: 0.019443\n",
      "Train Epoch: 96 [13312/14860 (89%)]\tLoss: 0.021236\n",
      "Train Epoch: 96 [13440/14860 (90%)]\tLoss: 0.022273\n",
      "Train Epoch: 96 [13568/14860 (91%)]\tLoss: 0.013261\n",
      "Train Epoch: 96 [13696/14860 (91%)]\tLoss: 0.013378\n",
      "Train Epoch: 96 [13824/14860 (92%)]\tLoss: 0.017938\n",
      "Train Epoch: 96 [13952/14860 (93%)]\tLoss: 0.017072\n",
      "Train Epoch: 96 [14080/14860 (94%)]\tLoss: 0.022294\n",
      "Train Epoch: 96 [14208/14860 (95%)]\tLoss: 0.021998\n",
      "Train Epoch: 96 [14336/14860 (96%)]\tLoss: 0.016435\n",
      "Train Epoch: 96 [14464/14860 (97%)]\tLoss: 0.026834\n",
      "Train Epoch: 96 [14592/14860 (97%)]\tLoss: 0.017918\n",
      "Train Epoch: 96 [14720/14860 (98%)]\tLoss: 0.022001\n",
      "Train Epoch: 96 [1392/14860 (99%)]\tLoss: 0.009013\n",
      "epoch 96 training loss: 0.0188320386581696\n",
      "epoch 96 validation loss: 0.019703042276257753\n",
      "Train Epoch: 97 [0/14860 (0%)]\tLoss: 0.021953\n",
      "Train Epoch: 97 [128/14860 (1%)]\tLoss: 0.018776\n",
      "Train Epoch: 97 [256/14860 (2%)]\tLoss: 0.024708\n",
      "Train Epoch: 97 [384/14860 (3%)]\tLoss: 0.015530\n",
      "Train Epoch: 97 [512/14860 (3%)]\tLoss: 0.023415\n",
      "Train Epoch: 97 [640/14860 (4%)]\tLoss: 0.018404\n",
      "Train Epoch: 97 [768/14860 (5%)]\tLoss: 0.016848\n",
      "Train Epoch: 97 [896/14860 (6%)]\tLoss: 0.026356\n",
      "Train Epoch: 97 [1024/14860 (7%)]\tLoss: 0.015609\n",
      "Train Epoch: 97 [1152/14860 (8%)]\tLoss: 0.015787\n",
      "Train Epoch: 97 [1280/14860 (9%)]\tLoss: 0.017429\n",
      "Train Epoch: 97 [1408/14860 (9%)]\tLoss: 0.017724\n",
      "Train Epoch: 97 [1536/14860 (10%)]\tLoss: 0.017066\n",
      "Train Epoch: 97 [1664/14860 (11%)]\tLoss: 0.025886\n",
      "Train Epoch: 97 [1792/14860 (12%)]\tLoss: 0.023322\n",
      "Train Epoch: 97 [1920/14860 (13%)]\tLoss: 0.024051\n",
      "Train Epoch: 97 [2048/14860 (14%)]\tLoss: 0.024363\n",
      "Train Epoch: 97 [2176/14860 (15%)]\tLoss: 0.023310\n",
      "Train Epoch: 97 [2304/14860 (15%)]\tLoss: 0.017398\n",
      "Train Epoch: 97 [2432/14860 (16%)]\tLoss: 0.025501\n",
      "Train Epoch: 97 [2560/14860 (17%)]\tLoss: 0.026121\n",
      "Train Epoch: 97 [2688/14860 (18%)]\tLoss: 0.017977\n",
      "Train Epoch: 97 [2816/14860 (19%)]\tLoss: 0.017225\n",
      "Train Epoch: 97 [2944/14860 (20%)]\tLoss: 0.021489\n",
      "Train Epoch: 97 [3072/14860 (21%)]\tLoss: 0.012465\n",
      "Train Epoch: 97 [3200/14860 (21%)]\tLoss: 0.017743\n",
      "Train Epoch: 97 [3328/14860 (22%)]\tLoss: 0.021139\n",
      "Train Epoch: 97 [3456/14860 (23%)]\tLoss: 0.018021\n",
      "Train Epoch: 97 [3584/14860 (24%)]\tLoss: 0.015461\n",
      "Train Epoch: 97 [3712/14860 (25%)]\tLoss: 0.016570\n",
      "Train Epoch: 97 [3840/14860 (26%)]\tLoss: 0.015990\n",
      "Train Epoch: 97 [3968/14860 (26%)]\tLoss: 0.026048\n",
      "Train Epoch: 97 [4096/14860 (27%)]\tLoss: 0.021810\n",
      "Train Epoch: 97 [4224/14860 (28%)]\tLoss: 0.020041\n",
      "Train Epoch: 97 [4352/14860 (29%)]\tLoss: 0.019550\n",
      "Train Epoch: 97 [4480/14860 (30%)]\tLoss: 0.030887\n",
      "Train Epoch: 97 [4608/14860 (31%)]\tLoss: 0.012321\n",
      "Train Epoch: 97 [4736/14860 (32%)]\tLoss: 0.017426\n",
      "Train Epoch: 97 [4864/14860 (32%)]\tLoss: 0.022645\n",
      "Train Epoch: 97 [4992/14860 (33%)]\tLoss: 0.014032\n",
      "Train Epoch: 97 [5120/14860 (34%)]\tLoss: 0.022029\n",
      "Train Epoch: 97 [5248/14860 (35%)]\tLoss: 0.022385\n",
      "Train Epoch: 97 [5376/14860 (36%)]\tLoss: 0.015514\n",
      "Train Epoch: 97 [5504/14860 (37%)]\tLoss: 0.013096\n",
      "Train Epoch: 97 [5632/14860 (38%)]\tLoss: 0.014877\n",
      "Train Epoch: 97 [5760/14860 (38%)]\tLoss: 0.019897\n",
      "Train Epoch: 97 [5888/14860 (39%)]\tLoss: 0.015693\n",
      "Train Epoch: 97 [6016/14860 (40%)]\tLoss: 0.021833\n",
      "Train Epoch: 97 [6144/14860 (41%)]\tLoss: 0.014169\n",
      "Train Epoch: 97 [6272/14860 (42%)]\tLoss: 0.017574\n",
      "Train Epoch: 97 [6400/14860 (43%)]\tLoss: 0.017815\n",
      "Train Epoch: 97 [6528/14860 (44%)]\tLoss: 0.010964\n",
      "Train Epoch: 97 [6656/14860 (44%)]\tLoss: 0.022188\n",
      "Train Epoch: 97 [6784/14860 (45%)]\tLoss: 0.027522\n",
      "Train Epoch: 97 [6912/14860 (46%)]\tLoss: 0.014010\n",
      "Train Epoch: 97 [7040/14860 (47%)]\tLoss: 0.011347\n",
      "Train Epoch: 97 [7168/14860 (48%)]\tLoss: 0.010833\n",
      "Train Epoch: 97 [7296/14860 (49%)]\tLoss: 0.017709\n",
      "Train Epoch: 97 [7424/14860 (50%)]\tLoss: 0.016723\n",
      "Train Epoch: 97 [7552/14860 (50%)]\tLoss: 0.024913\n",
      "Train Epoch: 97 [7680/14860 (51%)]\tLoss: 0.019283\n",
      "Train Epoch: 97 [7808/14860 (52%)]\tLoss: 0.017771\n",
      "Train Epoch: 97 [7936/14860 (53%)]\tLoss: 0.027985\n",
      "Train Epoch: 97 [8064/14860 (54%)]\tLoss: 0.015817\n",
      "Train Epoch: 97 [8192/14860 (55%)]\tLoss: 0.013136\n",
      "Train Epoch: 97 [8320/14860 (56%)]\tLoss: 0.017494\n",
      "Train Epoch: 97 [8448/14860 (56%)]\tLoss: 0.012583\n",
      "Train Epoch: 97 [8576/14860 (57%)]\tLoss: 0.014738\n",
      "Train Epoch: 97 [8704/14860 (58%)]\tLoss: 0.020940\n",
      "Train Epoch: 97 [8832/14860 (59%)]\tLoss: 0.020625\n",
      "Train Epoch: 97 [8960/14860 (60%)]\tLoss: 0.023107\n",
      "Train Epoch: 97 [9088/14860 (61%)]\tLoss: 0.015611\n",
      "Train Epoch: 97 [9216/14860 (62%)]\tLoss: 0.016337\n",
      "Train Epoch: 97 [9344/14860 (62%)]\tLoss: 0.026826\n",
      "Train Epoch: 97 [9472/14860 (63%)]\tLoss: 0.018762\n",
      "Train Epoch: 97 [9600/14860 (64%)]\tLoss: 0.023689\n",
      "Train Epoch: 97 [9728/14860 (65%)]\tLoss: 0.017689\n",
      "Train Epoch: 97 [9856/14860 (66%)]\tLoss: 0.023006\n",
      "Train Epoch: 97 [9984/14860 (67%)]\tLoss: 0.024991\n",
      "Train Epoch: 97 [10112/14860 (68%)]\tLoss: 0.020579\n",
      "Train Epoch: 97 [10240/14860 (68%)]\tLoss: 0.023914\n",
      "Train Epoch: 97 [10368/14860 (69%)]\tLoss: 0.015176\n",
      "Train Epoch: 97 [10496/14860 (70%)]\tLoss: 0.014420\n",
      "Train Epoch: 97 [10624/14860 (71%)]\tLoss: 0.019635\n",
      "Train Epoch: 97 [10752/14860 (72%)]\tLoss: 0.027929\n",
      "Train Epoch: 97 [10880/14860 (73%)]\tLoss: 0.020450\n",
      "Train Epoch: 97 [11008/14860 (74%)]\tLoss: 0.017229\n",
      "Train Epoch: 97 [11136/14860 (74%)]\tLoss: 0.023159\n",
      "Train Epoch: 97 [11264/14860 (75%)]\tLoss: 0.017920\n",
      "Train Epoch: 97 [11392/14860 (76%)]\tLoss: 0.031167\n",
      "Train Epoch: 97 [11520/14860 (77%)]\tLoss: 0.015375\n",
      "Train Epoch: 97 [11648/14860 (78%)]\tLoss: 0.020057\n",
      "Train Epoch: 97 [11776/14860 (79%)]\tLoss: 0.022995\n",
      "Train Epoch: 97 [11904/14860 (79%)]\tLoss: 0.018392\n",
      "Train Epoch: 97 [12032/14860 (80%)]\tLoss: 0.026999\n",
      "Train Epoch: 97 [12160/14860 (81%)]\tLoss: 0.023241\n",
      "Train Epoch: 97 [12288/14860 (82%)]\tLoss: 0.014588\n",
      "Train Epoch: 97 [12416/14860 (83%)]\tLoss: 0.018413\n",
      "Train Epoch: 97 [12544/14860 (84%)]\tLoss: 0.016197\n",
      "Train Epoch: 97 [12672/14860 (85%)]\tLoss: 0.020319\n",
      "Train Epoch: 97 [12800/14860 (85%)]\tLoss: 0.015266\n",
      "Train Epoch: 97 [12928/14860 (86%)]\tLoss: 0.013161\n",
      "Train Epoch: 97 [13056/14860 (87%)]\tLoss: 0.020829\n",
      "Train Epoch: 97 [13184/14860 (88%)]\tLoss: 0.018702\n",
      "Train Epoch: 97 [13312/14860 (89%)]\tLoss: 0.022366\n",
      "Train Epoch: 97 [13440/14860 (90%)]\tLoss: 0.024454\n",
      "Train Epoch: 97 [13568/14860 (91%)]\tLoss: 0.015015\n",
      "Train Epoch: 97 [13696/14860 (91%)]\tLoss: 0.013922\n",
      "Train Epoch: 97 [13824/14860 (92%)]\tLoss: 0.012218\n",
      "Train Epoch: 97 [13952/14860 (93%)]\tLoss: 0.029904\n",
      "Train Epoch: 97 [14080/14860 (94%)]\tLoss: 0.015627\n",
      "Train Epoch: 97 [14208/14860 (95%)]\tLoss: 0.021541\n",
      "Train Epoch: 97 [14336/14860 (96%)]\tLoss: 0.022817\n",
      "Train Epoch: 97 [14464/14860 (97%)]\tLoss: 0.019412\n",
      "Train Epoch: 97 [14592/14860 (97%)]\tLoss: 0.015310\n",
      "Train Epoch: 97 [14720/14860 (98%)]\tLoss: 0.016253\n",
      "Train Epoch: 97 [1392/14860 (99%)]\tLoss: 0.024188\n",
      "epoch 97 training loss: 0.0193932852986404\n",
      "epoch 97 validation loss: 0.022417027205589607\n",
      "Train Epoch: 98 [0/14860 (0%)]\tLoss: 0.018039\n",
      "Train Epoch: 98 [128/14860 (1%)]\tLoss: 0.020725\n",
      "Train Epoch: 98 [256/14860 (2%)]\tLoss: 0.016557\n",
      "Train Epoch: 98 [384/14860 (3%)]\tLoss: 0.024339\n",
      "Train Epoch: 98 [512/14860 (3%)]\tLoss: 0.021329\n",
      "Train Epoch: 98 [640/14860 (4%)]\tLoss: 0.018681\n",
      "Train Epoch: 98 [768/14860 (5%)]\tLoss: 0.020509\n",
      "Train Epoch: 98 [896/14860 (6%)]\tLoss: 0.020954\n",
      "Train Epoch: 98 [1024/14860 (7%)]\tLoss: 0.021941\n",
      "Train Epoch: 98 [1152/14860 (8%)]\tLoss: 0.017358\n",
      "Train Epoch: 98 [1280/14860 (9%)]\tLoss: 0.016174\n",
      "Train Epoch: 98 [1408/14860 (9%)]\tLoss: 0.016232\n",
      "Train Epoch: 98 [1536/14860 (10%)]\tLoss: 0.012661\n",
      "Train Epoch: 98 [1664/14860 (11%)]\tLoss: 0.014043\n",
      "Train Epoch: 98 [1792/14860 (12%)]\tLoss: 0.022488\n",
      "Train Epoch: 98 [1920/14860 (13%)]\tLoss: 0.017717\n",
      "Train Epoch: 98 [2048/14860 (14%)]\tLoss: 0.021379\n",
      "Train Epoch: 98 [2176/14860 (15%)]\tLoss: 0.013684\n",
      "Train Epoch: 98 [2304/14860 (15%)]\tLoss: 0.017562\n",
      "Train Epoch: 98 [2432/14860 (16%)]\tLoss: 0.016043\n",
      "Train Epoch: 98 [2560/14860 (17%)]\tLoss: 0.014012\n",
      "Train Epoch: 98 [2688/14860 (18%)]\tLoss: 0.023991\n",
      "Train Epoch: 98 [2816/14860 (19%)]\tLoss: 0.018526\n",
      "Train Epoch: 98 [2944/14860 (20%)]\tLoss: 0.013600\n",
      "Train Epoch: 98 [3072/14860 (21%)]\tLoss: 0.020606\n",
      "Train Epoch: 98 [3200/14860 (21%)]\tLoss: 0.017950\n",
      "Train Epoch: 98 [3328/14860 (22%)]\tLoss: 0.024325\n",
      "Train Epoch: 98 [3456/14860 (23%)]\tLoss: 0.020671\n",
      "Train Epoch: 98 [3584/14860 (24%)]\tLoss: 0.025233\n",
      "Train Epoch: 98 [3712/14860 (25%)]\tLoss: 0.023733\n",
      "Train Epoch: 98 [3840/14860 (26%)]\tLoss: 0.021878\n",
      "Train Epoch: 98 [3968/14860 (26%)]\tLoss: 0.018351\n",
      "Train Epoch: 98 [4096/14860 (27%)]\tLoss: 0.019866\n",
      "Train Epoch: 98 [4224/14860 (28%)]\tLoss: 0.021324\n",
      "Train Epoch: 98 [4352/14860 (29%)]\tLoss: 0.026333\n",
      "Train Epoch: 98 [4480/14860 (30%)]\tLoss: 0.012253\n",
      "Train Epoch: 98 [4608/14860 (31%)]\tLoss: 0.011817\n",
      "Train Epoch: 98 [4736/14860 (32%)]\tLoss: 0.022882\n",
      "Train Epoch: 98 [4864/14860 (32%)]\tLoss: 0.021913\n",
      "Train Epoch: 98 [4992/14860 (33%)]\tLoss: 0.024616\n",
      "Train Epoch: 98 [5120/14860 (34%)]\tLoss: 0.020290\n",
      "Train Epoch: 98 [5248/14860 (35%)]\tLoss: 0.020939\n",
      "Train Epoch: 98 [5376/14860 (36%)]\tLoss: 0.017859\n",
      "Train Epoch: 98 [5504/14860 (37%)]\tLoss: 0.013174\n",
      "Train Epoch: 98 [5632/14860 (38%)]\tLoss: 0.020274\n",
      "Train Epoch: 98 [5760/14860 (38%)]\tLoss: 0.020431\n",
      "Train Epoch: 98 [5888/14860 (39%)]\tLoss: 0.024400\n",
      "Train Epoch: 98 [6016/14860 (40%)]\tLoss: 0.017299\n",
      "Train Epoch: 98 [6144/14860 (41%)]\tLoss: 0.022029\n",
      "Train Epoch: 98 [6272/14860 (42%)]\tLoss: 0.019597\n",
      "Train Epoch: 98 [6400/14860 (43%)]\tLoss: 0.015259\n",
      "Train Epoch: 98 [6528/14860 (44%)]\tLoss: 0.021774\n",
      "Train Epoch: 98 [6656/14860 (44%)]\tLoss: 0.022641\n",
      "Train Epoch: 98 [6784/14860 (45%)]\tLoss: 0.018971\n",
      "Train Epoch: 98 [6912/14860 (46%)]\tLoss: 0.012659\n",
      "Train Epoch: 98 [7040/14860 (47%)]\tLoss: 0.015072\n",
      "Train Epoch: 98 [7168/14860 (48%)]\tLoss: 0.023501\n",
      "Train Epoch: 98 [7296/14860 (49%)]\tLoss: 0.017442\n",
      "Train Epoch: 98 [7424/14860 (50%)]\tLoss: 0.015937\n",
      "Train Epoch: 98 [7552/14860 (50%)]\tLoss: 0.022916\n",
      "Train Epoch: 98 [7680/14860 (51%)]\tLoss: 0.020961\n",
      "Train Epoch: 98 [7808/14860 (52%)]\tLoss: 0.022514\n",
      "Train Epoch: 98 [7936/14860 (53%)]\tLoss: 0.015572\n",
      "Train Epoch: 98 [8064/14860 (54%)]\tLoss: 0.016659\n",
      "Train Epoch: 98 [8192/14860 (55%)]\tLoss: 0.019618\n",
      "Train Epoch: 98 [8320/14860 (56%)]\tLoss: 0.021733\n",
      "Train Epoch: 98 [8448/14860 (56%)]\tLoss: 0.014264\n",
      "Train Epoch: 98 [8576/14860 (57%)]\tLoss: 0.019297\n",
      "Train Epoch: 98 [8704/14860 (58%)]\tLoss: 0.023844\n",
      "Train Epoch: 98 [8832/14860 (59%)]\tLoss: 0.015440\n",
      "Train Epoch: 98 [8960/14860 (60%)]\tLoss: 0.018531\n",
      "Train Epoch: 98 [9088/14860 (61%)]\tLoss: 0.017186\n",
      "Train Epoch: 98 [9216/14860 (62%)]\tLoss: 0.017408\n",
      "Train Epoch: 98 [9344/14860 (62%)]\tLoss: 0.016113\n",
      "Train Epoch: 98 [9472/14860 (63%)]\tLoss: 0.023954\n",
      "Train Epoch: 98 [9600/14860 (64%)]\tLoss: 0.014988\n",
      "Train Epoch: 98 [9728/14860 (65%)]\tLoss: 0.020922\n",
      "Train Epoch: 98 [9856/14860 (66%)]\tLoss: 0.015840\n",
      "Train Epoch: 98 [9984/14860 (67%)]\tLoss: 0.017309\n",
      "Train Epoch: 98 [10112/14860 (68%)]\tLoss: 0.016943\n",
      "Train Epoch: 98 [10240/14860 (68%)]\tLoss: 0.020581\n",
      "Train Epoch: 98 [10368/14860 (69%)]\tLoss: 0.021859\n",
      "Train Epoch: 98 [10496/14860 (70%)]\tLoss: 0.015753\n",
      "Train Epoch: 98 [10624/14860 (71%)]\tLoss: 0.021923\n",
      "Train Epoch: 98 [10752/14860 (72%)]\tLoss: 0.022605\n",
      "Train Epoch: 98 [10880/14860 (73%)]\tLoss: 0.016611\n",
      "Train Epoch: 98 [11008/14860 (74%)]\tLoss: 0.019224\n",
      "Train Epoch: 98 [11136/14860 (74%)]\tLoss: 0.018909\n",
      "Train Epoch: 98 [11264/14860 (75%)]\tLoss: 0.014057\n",
      "Train Epoch: 98 [11392/14860 (76%)]\tLoss: 0.012801\n",
      "Train Epoch: 98 [11520/14860 (77%)]\tLoss: 0.016188\n",
      "Train Epoch: 98 [11648/14860 (78%)]\tLoss: 0.019475\n",
      "Train Epoch: 98 [11776/14860 (79%)]\tLoss: 0.018311\n",
      "Train Epoch: 98 [11904/14860 (79%)]\tLoss: 0.018259\n",
      "Train Epoch: 98 [12032/14860 (80%)]\tLoss: 0.018616\n",
      "Train Epoch: 98 [12160/14860 (81%)]\tLoss: 0.023585\n",
      "Train Epoch: 98 [12288/14860 (82%)]\tLoss: 0.022735\n",
      "Train Epoch: 98 [12416/14860 (83%)]\tLoss: 0.018834\n",
      "Train Epoch: 98 [12544/14860 (84%)]\tLoss: 0.023949\n",
      "Train Epoch: 98 [12672/14860 (85%)]\tLoss: 0.021871\n",
      "Train Epoch: 98 [12800/14860 (85%)]\tLoss: 0.011657\n",
      "Train Epoch: 98 [12928/14860 (86%)]\tLoss: 0.014699\n",
      "Train Epoch: 98 [13056/14860 (87%)]\tLoss: 0.022318\n",
      "Train Epoch: 98 [13184/14860 (88%)]\tLoss: 0.019021\n",
      "Train Epoch: 98 [13312/14860 (89%)]\tLoss: 0.017073\n",
      "Train Epoch: 98 [13440/14860 (90%)]\tLoss: 0.029196\n",
      "Train Epoch: 98 [13568/14860 (91%)]\tLoss: 0.029913\n",
      "Train Epoch: 98 [13696/14860 (91%)]\tLoss: 0.020479\n",
      "Train Epoch: 98 [13824/14860 (92%)]\tLoss: 0.023818\n",
      "Train Epoch: 98 [13952/14860 (93%)]\tLoss: 0.019712\n",
      "Train Epoch: 98 [14080/14860 (94%)]\tLoss: 0.020578\n",
      "Train Epoch: 98 [14208/14860 (95%)]\tLoss: 0.011653\n",
      "Train Epoch: 98 [14336/14860 (96%)]\tLoss: 0.021457\n",
      "Train Epoch: 98 [14464/14860 (97%)]\tLoss: 0.017749\n",
      "Train Epoch: 98 [14592/14860 (97%)]\tLoss: 0.019458\n",
      "Train Epoch: 98 [14720/14860 (98%)]\tLoss: 0.018479\n",
      "Train Epoch: 98 [1392/14860 (99%)]\tLoss: 0.012164\n",
      "epoch 98 training loss: 0.019140378293445986\n",
      "epoch 98 validation loss: 0.01989581387210412\n",
      "Train Epoch: 99 [0/14860 (0%)]\tLoss: 0.019173\n",
      "Train Epoch: 99 [128/14860 (1%)]\tLoss: 0.019449\n",
      "Train Epoch: 99 [256/14860 (2%)]\tLoss: 0.015904\n",
      "Train Epoch: 99 [384/14860 (3%)]\tLoss: 0.028196\n",
      "Train Epoch: 99 [512/14860 (3%)]\tLoss: 0.017906\n",
      "Train Epoch: 99 [640/14860 (4%)]\tLoss: 0.013864\n",
      "Train Epoch: 99 [768/14860 (5%)]\tLoss: 0.019123\n",
      "Train Epoch: 99 [896/14860 (6%)]\tLoss: 0.008441\n",
      "Train Epoch: 99 [1024/14860 (7%)]\tLoss: 0.021422\n",
      "Train Epoch: 99 [1152/14860 (8%)]\tLoss: 0.025818\n",
      "Train Epoch: 99 [1280/14860 (9%)]\tLoss: 0.011929\n",
      "Train Epoch: 99 [1408/14860 (9%)]\tLoss: 0.026088\n",
      "Train Epoch: 99 [1536/14860 (10%)]\tLoss: 0.024042\n",
      "Train Epoch: 99 [1664/14860 (11%)]\tLoss: 0.014572\n",
      "Train Epoch: 99 [1792/14860 (12%)]\tLoss: 0.016832\n",
      "Train Epoch: 99 [1920/14860 (13%)]\tLoss: 0.013845\n",
      "Train Epoch: 99 [2048/14860 (14%)]\tLoss: 0.020185\n",
      "Train Epoch: 99 [2176/14860 (15%)]\tLoss: 0.016279\n",
      "Train Epoch: 99 [2304/14860 (15%)]\tLoss: 0.013876\n",
      "Train Epoch: 99 [2432/14860 (16%)]\tLoss: 0.017836\n",
      "Train Epoch: 99 [2560/14860 (17%)]\tLoss: 0.018097\n",
      "Train Epoch: 99 [2688/14860 (18%)]\tLoss: 0.020629\n",
      "Train Epoch: 99 [2816/14860 (19%)]\tLoss: 0.017403\n",
      "Train Epoch: 99 [2944/14860 (20%)]\tLoss: 0.020415\n",
      "Train Epoch: 99 [3072/14860 (21%)]\tLoss: 0.021291\n",
      "Train Epoch: 99 [3200/14860 (21%)]\tLoss: 0.021104\n",
      "Train Epoch: 99 [3328/14860 (22%)]\tLoss: 0.021945\n",
      "Train Epoch: 99 [3456/14860 (23%)]\tLoss: 0.027446\n",
      "Train Epoch: 99 [3584/14860 (24%)]\tLoss: 0.031011\n",
      "Train Epoch: 99 [3712/14860 (25%)]\tLoss: 0.022867\n",
      "Train Epoch: 99 [3840/14860 (26%)]\tLoss: 0.019644\n",
      "Train Epoch: 99 [3968/14860 (26%)]\tLoss: 0.025742\n",
      "Train Epoch: 99 [4096/14860 (27%)]\tLoss: 0.018066\n",
      "Train Epoch: 99 [4224/14860 (28%)]\tLoss: 0.016932\n",
      "Train Epoch: 99 [4352/14860 (29%)]\tLoss: 0.020150\n",
      "Train Epoch: 99 [4480/14860 (30%)]\tLoss: 0.010369\n",
      "Train Epoch: 99 [4608/14860 (31%)]\tLoss: 0.025520\n",
      "Train Epoch: 99 [4736/14860 (32%)]\tLoss: 0.015225\n",
      "Train Epoch: 99 [4864/14860 (32%)]\tLoss: 0.021653\n",
      "Train Epoch: 99 [4992/14860 (33%)]\tLoss: 0.023018\n",
      "Train Epoch: 99 [5120/14860 (34%)]\tLoss: 0.016828\n",
      "Train Epoch: 99 [5248/14860 (35%)]\tLoss: 0.016573\n",
      "Train Epoch: 99 [5376/14860 (36%)]\tLoss: 0.017784\n",
      "Train Epoch: 99 [5504/14860 (37%)]\tLoss: 0.026268\n",
      "Train Epoch: 99 [5632/14860 (38%)]\tLoss: 0.021484\n",
      "Train Epoch: 99 [5760/14860 (38%)]\tLoss: 0.016530\n",
      "Train Epoch: 99 [5888/14860 (39%)]\tLoss: 0.019329\n",
      "Train Epoch: 99 [6016/14860 (40%)]\tLoss: 0.017764\n",
      "Train Epoch: 99 [6144/14860 (41%)]\tLoss: 0.019949\n",
      "Train Epoch: 99 [6272/14860 (42%)]\tLoss: 0.020338\n",
      "Train Epoch: 99 [6400/14860 (43%)]\tLoss: 0.015658\n",
      "Train Epoch: 99 [6528/14860 (44%)]\tLoss: 0.021785\n",
      "Train Epoch: 99 [6656/14860 (44%)]\tLoss: 0.019460\n",
      "Train Epoch: 99 [6784/14860 (45%)]\tLoss: 0.020734\n",
      "Train Epoch: 99 [6912/14860 (46%)]\tLoss: 0.014694\n",
      "Train Epoch: 99 [7040/14860 (47%)]\tLoss: 0.020512\n",
      "Train Epoch: 99 [7168/14860 (48%)]\tLoss: 0.011516\n",
      "Train Epoch: 99 [7296/14860 (49%)]\tLoss: 0.015199\n",
      "Train Epoch: 99 [7424/14860 (50%)]\tLoss: 0.017197\n",
      "Train Epoch: 99 [7552/14860 (50%)]\tLoss: 0.019191\n",
      "Train Epoch: 99 [7680/14860 (51%)]\tLoss: 0.025625\n",
      "Train Epoch: 99 [7808/14860 (52%)]\tLoss: 0.023845\n",
      "Train Epoch: 99 [7936/14860 (53%)]\tLoss: 0.021662\n",
      "Train Epoch: 99 [8064/14860 (54%)]\tLoss: 0.017843\n",
      "Train Epoch: 99 [8192/14860 (55%)]\tLoss: 0.016728\n",
      "Train Epoch: 99 [8320/14860 (56%)]\tLoss: 0.022980\n",
      "Train Epoch: 99 [8448/14860 (56%)]\tLoss: 0.013890\n",
      "Train Epoch: 99 [8576/14860 (57%)]\tLoss: 0.018648\n",
      "Train Epoch: 99 [8704/14860 (58%)]\tLoss: 0.023782\n",
      "Train Epoch: 99 [8832/14860 (59%)]\tLoss: 0.018834\n",
      "Train Epoch: 99 [8960/14860 (60%)]\tLoss: 0.021619\n",
      "Train Epoch: 99 [9088/14860 (61%)]\tLoss: 0.013831\n",
      "Train Epoch: 99 [9216/14860 (62%)]\tLoss: 0.023363\n",
      "Train Epoch: 99 [9344/14860 (62%)]\tLoss: 0.014199\n",
      "Train Epoch: 99 [9472/14860 (63%)]\tLoss: 0.020760\n",
      "Train Epoch: 99 [9600/14860 (64%)]\tLoss: 0.018746\n",
      "Train Epoch: 99 [9728/14860 (65%)]\tLoss: 0.021928\n",
      "Train Epoch: 99 [9856/14860 (66%)]\tLoss: 0.023796\n",
      "Train Epoch: 99 [9984/14860 (67%)]\tLoss: 0.018742\n",
      "Train Epoch: 99 [10112/14860 (68%)]\tLoss: 0.026784\n",
      "Train Epoch: 99 [10240/14860 (68%)]\tLoss: 0.014330\n",
      "Train Epoch: 99 [10368/14860 (69%)]\tLoss: 0.022202\n",
      "Train Epoch: 99 [10496/14860 (70%)]\tLoss: 0.020760\n",
      "Train Epoch: 99 [10624/14860 (71%)]\tLoss: 0.014131\n",
      "Train Epoch: 99 [10752/14860 (72%)]\tLoss: 0.019318\n",
      "Train Epoch: 99 [10880/14860 (73%)]\tLoss: 0.014688\n",
      "Train Epoch: 99 [11008/14860 (74%)]\tLoss: 0.015951\n",
      "Train Epoch: 99 [11136/14860 (74%)]\tLoss: 0.015745\n",
      "Train Epoch: 99 [11264/14860 (75%)]\tLoss: 0.014347\n",
      "Train Epoch: 99 [11392/14860 (76%)]\tLoss: 0.022211\n",
      "Train Epoch: 99 [11520/14860 (77%)]\tLoss: 0.023087\n",
      "Train Epoch: 99 [11648/14860 (78%)]\tLoss: 0.020497\n",
      "Train Epoch: 99 [11776/14860 (79%)]\tLoss: 0.011761\n",
      "Train Epoch: 99 [11904/14860 (79%)]\tLoss: 0.026226\n",
      "Train Epoch: 99 [12032/14860 (80%)]\tLoss: 0.011116\n",
      "Train Epoch: 99 [12160/14860 (81%)]\tLoss: 0.015894\n",
      "Train Epoch: 99 [12288/14860 (82%)]\tLoss: 0.015894\n",
      "Train Epoch: 99 [12416/14860 (83%)]\tLoss: 0.027284\n",
      "Train Epoch: 99 [12544/14860 (84%)]\tLoss: 0.020031\n",
      "Train Epoch: 99 [12672/14860 (85%)]\tLoss: 0.016585\n",
      "Train Epoch: 99 [12800/14860 (85%)]\tLoss: 0.017421\n",
      "Train Epoch: 99 [12928/14860 (86%)]\tLoss: 0.017673\n",
      "Train Epoch: 99 [13056/14860 (87%)]\tLoss: 0.013435\n",
      "Train Epoch: 99 [13184/14860 (88%)]\tLoss: 0.014743\n",
      "Train Epoch: 99 [13312/14860 (89%)]\tLoss: 0.016804\n",
      "Train Epoch: 99 [13440/14860 (90%)]\tLoss: 0.020865\n",
      "Train Epoch: 99 [13568/14860 (91%)]\tLoss: 0.011968\n",
      "Train Epoch: 99 [13696/14860 (91%)]\tLoss: 0.020900\n",
      "Train Epoch: 99 [13824/14860 (92%)]\tLoss: 0.015162\n",
      "Train Epoch: 99 [13952/14860 (93%)]\tLoss: 0.018390\n",
      "Train Epoch: 99 [14080/14860 (94%)]\tLoss: 0.020697\n",
      "Train Epoch: 99 [14208/14860 (95%)]\tLoss: 0.012088\n",
      "Train Epoch: 99 [14336/14860 (96%)]\tLoss: 0.021926\n",
      "Train Epoch: 99 [14464/14860 (97%)]\tLoss: 0.015947\n",
      "Train Epoch: 99 [14592/14860 (97%)]\tLoss: 0.017246\n",
      "Train Epoch: 99 [14720/14860 (98%)]\tLoss: 0.017526\n",
      "Train Epoch: 99 [1392/14860 (99%)]\tLoss: 0.028464\n",
      "epoch 99 training loss: 0.019000148719065208\n",
      "epoch 99 validation loss: 0.019530896413124214\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 100):    \n",
    "    \n",
    "    loss_train=train(model, optimizer, dataloader_train, device, epoch)    \n",
    "    loss_train_list.append(loss_train)\n",
    "    print('epoch', epoch, 'training loss:', loss_train)\n",
    "    \n",
    "   \n",
    "    loss_val, mae_val,mape_test = test(model, dataloader_val, device)\n",
    "    loss_val_list.append(loss_val)\n",
    "    print('epoch', epoch, 'validation loss:', loss_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot the loss vs epoch curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2317d5b25e0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(0,len(loss_train_list)), loss_train_list, '-b', label='training loss')\n",
    "ax.plot(np.arange(0,len(loss_val_list)), loss_val_list, '-r', label='validation loss')\n",
    "ax.set_xlabel('epoch',fontsize=16)\n",
    "ax.legend(fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain Yp_test\n",
    "# \"Yp_test=model(X_test)\"  may need lots of memory\n",
    "# we can use a for loop to get Yp_test, see the function test\n",
    "Yp_test=[]\n",
    "with torch.no_grad(): # tell Pytorch not to build graph in the 'with' section\n",
    "    for batch_idx, (X, Y) in enumerate(dataloader_test):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        Yp = model(X)#forward pass\n",
    "        Yp_test.append(Yp.detach().cpu().numpy())\n",
    "Yp_test=np.concatenate(Yp_test, axis=0).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate model on testing set\n",
      "MSE= 0.018212862067328868\n",
      "MAE= 0.09739768320275832\n",
      "MAPE= 0.2545065584108811\n"
     ]
    }
   ],
   "source": [
    "# compute MSE, MAE and MAPE on test set\n",
    "\n",
    "print('Evaluate model on testing set')\n",
    "mse_test, mae_test,mape_test = test(model, dataloader_test, device)\n",
    "print('MSE=', mse_test)\n",
    "print('MAE=', mae_test)\n",
    "print('MAPE=', mape_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot Yp_test vs Y_test\n",
    "# the red line is the 45-degree line\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(Y_test, Yp_test, '.')\n",
    "ax.plot(Y_test, Y_test, 'r-')\n",
    "ax.set_xlabel('Y_test', fontsize=16)\n",
    "ax.set_ylabel('Yp_test', fontsize=16)\n",
    "ax.grid(True)\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.set_title('Y_test_pred vs Y_test')\n",
    "#ax.plot(Y_test, Y_test_pred, '.')\n",
    "#ymax=np.max([Y_test.max(), Y_test_pred.max()])\n",
    "#ax.plot(np.linspace(0,ymax, 3), np.linspace(0, ymax, 3), '-r')\n",
    "#ax.set_xlabel('Y_test')\n",
    "#ax.set_ylabel('Y_test_pred')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change the structure of the MLP model and see if it can do better than XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The structure of the MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a new model\n",
    "#train, validate and test the model\n",
    "#compare it with XGBoost in homework #3\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset as torch_dataset\n",
    "class MyDataset(torch_dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X=X\n",
    "        self.Y=Y.reshape(-1, 1) #this is very important\n",
    "    def __len__(self):\n",
    "        #return the number of data points\n",
    "        return self.X.shape[0]\n",
    "    def __getitem__(self, idx):        \n",
    "        # use the notation DatasetName[idx]\n",
    "        # to get a data point (x,y) by idx\n",
    "        # we need to convert numpy array to torch tensor\n",
    "        x=torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "        y=torch.tensor(self.Y[idx], dtype=torch.float32)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train= MyDataset(X_train,Y_train)\n",
    "dataset_val = MyDataset(X_val, Y_val)\n",
    "dataset_test = MyDataset(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset as torch_dataset\n",
    "from torch.utils.data import DataLoader as torch_dataloader\n",
    "\n",
    "dataloader_train = torch_dataloader(dataset_train, batch_size=128, shuffle=True, num_workers=0)\n",
    "dataloader_val = torch_dataloader(dataset_val, batch_size=128, shuffle=False, num_workers=0) \n",
    "dataloader_test = torch_dataloader(dataset_test, batch_size=128, shuffle=False, num_workers=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "1 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "2 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "3 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "4 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "5 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "6 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "7 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "8 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "9 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "10 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "11 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "12 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "13 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "14 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "15 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "16 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "17 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "18 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "19 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "20 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "21 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "22 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "23 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "24 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "25 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "26 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "27 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "28 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "29 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "30 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "31 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "32 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "33 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "34 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "35 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "36 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "37 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "38 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "39 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "40 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "41 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "42 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "43 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "44 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "45 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "46 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "47 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "48 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "49 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "50 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "51 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "52 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "53 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "54 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "55 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "56 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "57 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "58 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "59 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "60 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "61 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "62 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "63 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "64 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "65 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "66 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "67 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "68 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "69 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "70 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "71 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "72 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "73 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "74 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "75 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "76 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "77 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "78 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "79 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "80 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "81 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "82 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "83 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "84 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "85 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "86 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "87 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "88 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "89 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "90 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "91 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "92 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "93 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "94 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "95 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "96 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "97 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "98 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "99 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "100 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "101 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "102 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "103 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "104 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "105 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "106 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "107 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "108 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "109 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "110 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "111 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "112 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "113 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "114 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "115 torch.Size([128, 13]) torch.Size([128, 1])\n",
      "116 torch.Size([12, 13]) torch.Size([12, 1])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (X, Y) in enumerate(dataloader_train):\n",
    "    print(batch_idx, X.size(), Y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnF\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, n_units):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, n_units)\n",
    "        self.layer2 = nn.Linear(n_units, n_units)\n",
    "        self.layer3 = nn.Linear(n_units, n_units)\n",
    "        self.layer4 = nn.Linear(n_units, output_dim)        \n",
    "    def forward(self, x):\n",
    "        x=self.layer1(x)\n",
    "        x=torch.sigmoid(x)\n",
    "        x=self.layer2(x)\n",
    "        x=torch.sigmoid(x)\n",
    "        x=self.layer3(x)\n",
    "        x=torch.sigmoid(x)\n",
    "        y=self.layer4(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Net(input_dim=13, output_dim=1, n_units=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (layer1): Linear(in_features=13, out_features=128, bias=True)\n",
       "  (layer2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (layer3): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (layer4): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, dataloader, device, epoch):    \n",
    "    model.train()\n",
    "    loss_train=0\n",
    "    for batch_idx, (X, Y) in enumerate(dataloader):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        Yp = model(X)\n",
    "        loss = torch.mean((Yp-Y)**2) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_train+=loss.item()\n",
    "        if batch_idx % 1 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * X.size(0), len(dataloader.dataset),\n",
    "                    100. * batch_idx / len(dataloader), loss.item()))\n",
    "    loss_train/=len(dataloader)\n",
    "    return loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, device):\n",
    "    model.eval()#set model to evaluation mode\n",
    "    loss_test=0\n",
    "    mae_test=0\n",
    "    mape_test=0\n",
    "    sample_count=0\n",
    "    with torch.no_grad(): # tell Pytorch not to build graph in the 'with' section\n",
    "        for batch_idx, (X, Y) in enumerate(dataloader):\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            Yp = model(X)#forward pass\n",
    "            loss_test+=torch.sum((Yp-Y)**2).item()\n",
    "            mae_test+= torch.sum((Yp-Y).abs()).item()\n",
    "            mape_test+= torch.sum(((Yp-Y)/Yp).abs()).item()\n",
    "            sample_count+=X.size(0)\n",
    "    loss_test/=sample_count\n",
    "    mae_test/=sample_count\n",
    "    mape_test/=sample_count\n",
    "    return loss_test, mae_test ,mape_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01,weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train_list=[]\n",
    "loss_val_list=[]\n",
    "mae_val_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/14860 (0%)]\tLoss: 0.268143\n",
      "Train Epoch: 0 [128/14860 (1%)]\tLoss: 1.273480\n",
      "Train Epoch: 0 [256/14860 (2%)]\tLoss: 0.239438\n",
      "Train Epoch: 0 [384/14860 (3%)]\tLoss: 0.100106\n",
      "Train Epoch: 0 [512/14860 (3%)]\tLoss: 0.392078\n",
      "Train Epoch: 0 [640/14860 (4%)]\tLoss: 0.409900\n",
      "Train Epoch: 0 [768/14860 (5%)]\tLoss: 0.276313\n",
      "Train Epoch: 0 [896/14860 (6%)]\tLoss: 0.140449\n",
      "Train Epoch: 0 [1024/14860 (7%)]\tLoss: 0.046743\n",
      "Train Epoch: 0 [1152/14860 (8%)]\tLoss: 0.084825\n",
      "Train Epoch: 0 [1280/14860 (9%)]\tLoss: 0.148598\n",
      "Train Epoch: 0 [1408/14860 (9%)]\tLoss: 0.208655\n",
      "Train Epoch: 0 [1536/14860 (10%)]\tLoss: 0.170824\n",
      "Train Epoch: 0 [1664/14860 (11%)]\tLoss: 0.130283\n",
      "Train Epoch: 0 [1792/14860 (12%)]\tLoss: 0.075355\n",
      "Train Epoch: 0 [1920/14860 (13%)]\tLoss: 0.053702\n",
      "Train Epoch: 0 [2048/14860 (14%)]\tLoss: 0.068754\n",
      "Train Epoch: 0 [2176/14860 (15%)]\tLoss: 0.083085\n",
      "Train Epoch: 0 [2304/14860 (15%)]\tLoss: 0.097037\n",
      "Train Epoch: 0 [2432/14860 (16%)]\tLoss: 0.121294\n",
      "Train Epoch: 0 [2560/14860 (17%)]\tLoss: 0.086439\n",
      "Train Epoch: 0 [2688/14860 (18%)]\tLoss: 0.077772\n",
      "Train Epoch: 0 [2816/14860 (19%)]\tLoss: 0.071280\n",
      "Train Epoch: 0 [2944/14860 (20%)]\tLoss: 0.061091\n",
      "Train Epoch: 0 [3072/14860 (21%)]\tLoss: 0.062717\n",
      "Train Epoch: 0 [3200/14860 (21%)]\tLoss: 0.078201\n",
      "Train Epoch: 0 [3328/14860 (22%)]\tLoss: 0.075307\n",
      "Train Epoch: 0 [3456/14860 (23%)]\tLoss: 0.088153\n",
      "Train Epoch: 0 [3584/14860 (24%)]\tLoss: 0.068729\n",
      "Train Epoch: 0 [3712/14860 (25%)]\tLoss: 0.052060\n",
      "Train Epoch: 0 [3840/14860 (26%)]\tLoss: 0.053835\n",
      "Train Epoch: 0 [3968/14860 (26%)]\tLoss: 0.055778\n",
      "Train Epoch: 0 [4096/14860 (27%)]\tLoss: 0.050570\n",
      "Train Epoch: 0 [4224/14860 (28%)]\tLoss: 0.063057\n",
      "Train Epoch: 0 [4352/14860 (29%)]\tLoss: 0.089926\n",
      "Train Epoch: 0 [4480/14860 (30%)]\tLoss: 0.068309\n",
      "Train Epoch: 0 [4608/14860 (31%)]\tLoss: 0.070997\n",
      "Train Epoch: 0 [4736/14860 (32%)]\tLoss: 0.072292\n",
      "Train Epoch: 0 [4864/14860 (32%)]\tLoss: 0.059902\n",
      "Train Epoch: 0 [4992/14860 (33%)]\tLoss: 0.066038\n",
      "Train Epoch: 0 [5120/14860 (34%)]\tLoss: 0.068976\n",
      "Train Epoch: 0 [5248/14860 (35%)]\tLoss: 0.064476\n",
      "Train Epoch: 0 [5376/14860 (36%)]\tLoss: 0.062981\n",
      "Train Epoch: 0 [5504/14860 (37%)]\tLoss: 0.060048\n",
      "Train Epoch: 0 [5632/14860 (38%)]\tLoss: 0.054930\n",
      "Train Epoch: 0 [5760/14860 (38%)]\tLoss: 0.043230\n",
      "Train Epoch: 0 [5888/14860 (39%)]\tLoss: 0.052208\n",
      "Train Epoch: 0 [6016/14860 (40%)]\tLoss: 0.065296\n",
      "Train Epoch: 0 [6144/14860 (41%)]\tLoss: 0.052589\n",
      "Train Epoch: 0 [6272/14860 (42%)]\tLoss: 0.046996\n",
      "Train Epoch: 0 [6400/14860 (43%)]\tLoss: 0.046337\n",
      "Train Epoch: 0 [6528/14860 (44%)]\tLoss: 0.070293\n",
      "Train Epoch: 0 [6656/14860 (44%)]\tLoss: 0.058947\n",
      "Train Epoch: 0 [6784/14860 (45%)]\tLoss: 0.059515\n",
      "Train Epoch: 0 [6912/14860 (46%)]\tLoss: 0.056888\n",
      "Train Epoch: 0 [7040/14860 (47%)]\tLoss: 0.055635\n",
      "Train Epoch: 0 [7168/14860 (48%)]\tLoss: 0.061912\n",
      "Train Epoch: 0 [7296/14860 (49%)]\tLoss: 0.051979\n",
      "Train Epoch: 0 [7424/14860 (50%)]\tLoss: 0.049176\n",
      "Train Epoch: 0 [7552/14860 (50%)]\tLoss: 0.044967\n",
      "Train Epoch: 0 [7680/14860 (51%)]\tLoss: 0.061628\n",
      "Train Epoch: 0 [7808/14860 (52%)]\tLoss: 0.050945\n",
      "Train Epoch: 0 [7936/14860 (53%)]\tLoss: 0.057930\n",
      "Train Epoch: 0 [8064/14860 (54%)]\tLoss: 0.051425\n",
      "Train Epoch: 0 [8192/14860 (55%)]\tLoss: 0.055997\n",
      "Train Epoch: 0 [8320/14860 (56%)]\tLoss: 0.047516\n",
      "Train Epoch: 0 [8448/14860 (56%)]\tLoss: 0.060343\n",
      "Train Epoch: 0 [8576/14860 (57%)]\tLoss: 0.062569\n",
      "Train Epoch: 0 [8704/14860 (58%)]\tLoss: 0.051087\n",
      "Train Epoch: 0 [8832/14860 (59%)]\tLoss: 0.054060\n",
      "Train Epoch: 0 [8960/14860 (60%)]\tLoss: 0.053251\n",
      "Train Epoch: 0 [9088/14860 (61%)]\tLoss: 0.050268\n",
      "Train Epoch: 0 [9216/14860 (62%)]\tLoss: 0.048310\n",
      "Train Epoch: 0 [9344/14860 (62%)]\tLoss: 0.049922\n",
      "Train Epoch: 0 [9472/14860 (63%)]\tLoss: 0.055414\n",
      "Train Epoch: 0 [9600/14860 (64%)]\tLoss: 0.060568\n",
      "Train Epoch: 0 [9728/14860 (65%)]\tLoss: 0.051779\n",
      "Train Epoch: 0 [9856/14860 (66%)]\tLoss: 0.051082\n",
      "Train Epoch: 0 [9984/14860 (67%)]\tLoss: 0.059229\n",
      "Train Epoch: 0 [10112/14860 (68%)]\tLoss: 0.054613\n",
      "Train Epoch: 0 [10240/14860 (68%)]\tLoss: 0.057388\n",
      "Train Epoch: 0 [10368/14860 (69%)]\tLoss: 0.056703\n",
      "Train Epoch: 0 [10496/14860 (70%)]\tLoss: 0.048339\n",
      "Train Epoch: 0 [10624/14860 (71%)]\tLoss: 0.061857\n",
      "Train Epoch: 0 [10752/14860 (72%)]\tLoss: 0.061319\n",
      "Train Epoch: 0 [10880/14860 (73%)]\tLoss: 0.064806\n",
      "Train Epoch: 0 [11008/14860 (74%)]\tLoss: 0.062635\n",
      "Train Epoch: 0 [11136/14860 (74%)]\tLoss: 0.065680\n",
      "Train Epoch: 0 [11264/14860 (75%)]\tLoss: 0.045954\n",
      "Train Epoch: 0 [11392/14860 (76%)]\tLoss: 0.054817\n",
      "Train Epoch: 0 [11520/14860 (77%)]\tLoss: 0.050080\n",
      "Train Epoch: 0 [11648/14860 (78%)]\tLoss: 0.050928\n",
      "Train Epoch: 0 [11776/14860 (79%)]\tLoss: 0.057246\n",
      "Train Epoch: 0 [11904/14860 (79%)]\tLoss: 0.054557\n",
      "Train Epoch: 0 [12032/14860 (80%)]\tLoss: 0.049201\n",
      "Train Epoch: 0 [12160/14860 (81%)]\tLoss: 0.049564\n",
      "Train Epoch: 0 [12288/14860 (82%)]\tLoss: 0.054797\n",
      "Train Epoch: 0 [12416/14860 (83%)]\tLoss: 0.052665\n",
      "Train Epoch: 0 [12544/14860 (84%)]\tLoss: 0.039859\n",
      "Train Epoch: 0 [12672/14860 (85%)]\tLoss: 0.051096\n",
      "Train Epoch: 0 [12800/14860 (85%)]\tLoss: 0.057310\n",
      "Train Epoch: 0 [12928/14860 (86%)]\tLoss: 0.044368\n",
      "Train Epoch: 0 [13056/14860 (87%)]\tLoss: 0.043921\n",
      "Train Epoch: 0 [13184/14860 (88%)]\tLoss: 0.048929\n",
      "Train Epoch: 0 [13312/14860 (89%)]\tLoss: 0.046959\n",
      "Train Epoch: 0 [13440/14860 (90%)]\tLoss: 0.047661\n",
      "Train Epoch: 0 [13568/14860 (91%)]\tLoss: 0.050241\n",
      "Train Epoch: 0 [13696/14860 (91%)]\tLoss: 0.057583\n",
      "Train Epoch: 0 [13824/14860 (92%)]\tLoss: 0.056351\n",
      "Train Epoch: 0 [13952/14860 (93%)]\tLoss: 0.037892\n",
      "Train Epoch: 0 [14080/14860 (94%)]\tLoss: 0.049704\n",
      "Train Epoch: 0 [14208/14860 (95%)]\tLoss: 0.055704\n",
      "Train Epoch: 0 [14336/14860 (96%)]\tLoss: 0.053963\n",
      "Train Epoch: 0 [14464/14860 (97%)]\tLoss: 0.048056\n",
      "Train Epoch: 0 [14592/14860 (97%)]\tLoss: 0.046379\n",
      "Train Epoch: 0 [14720/14860 (98%)]\tLoss: 0.060914\n",
      "Train Epoch: 0 [1392/14860 (99%)]\tLoss: 0.033146\n",
      "epoch 0 training loss: 0.08466153251182319\n",
      "epoch 0 validation loss: 0.04824421423110777\n",
      "Train Epoch: 1 [0/14860 (0%)]\tLoss: 0.053093\n",
      "Train Epoch: 1 [128/14860 (1%)]\tLoss: 0.034033\n",
      "Train Epoch: 1 [256/14860 (2%)]\tLoss: 0.040078\n",
      "Train Epoch: 1 [384/14860 (3%)]\tLoss: 0.036799\n",
      "Train Epoch: 1 [512/14860 (3%)]\tLoss: 0.043949\n",
      "Train Epoch: 1 [640/14860 (4%)]\tLoss: 0.043991\n",
      "Train Epoch: 1 [768/14860 (5%)]\tLoss: 0.036736\n",
      "Train Epoch: 1 [896/14860 (6%)]\tLoss: 0.047188\n",
      "Train Epoch: 1 [1024/14860 (7%)]\tLoss: 0.055829\n",
      "Train Epoch: 1 [1152/14860 (8%)]\tLoss: 0.039327\n",
      "Train Epoch: 1 [1280/14860 (9%)]\tLoss: 0.045146\n",
      "Train Epoch: 1 [1408/14860 (9%)]\tLoss: 0.053239\n",
      "Train Epoch: 1 [1536/14860 (10%)]\tLoss: 0.050085\n",
      "Train Epoch: 1 [1664/14860 (11%)]\tLoss: 0.054960\n",
      "Train Epoch: 1 [1792/14860 (12%)]\tLoss: 0.039254\n",
      "Train Epoch: 1 [1920/14860 (13%)]\tLoss: 0.035065\n",
      "Train Epoch: 1 [2048/14860 (14%)]\tLoss: 0.042506\n",
      "Train Epoch: 1 [2176/14860 (15%)]\tLoss: 0.031595\n",
      "Train Epoch: 1 [2304/14860 (15%)]\tLoss: 0.052946\n",
      "Train Epoch: 1 [2432/14860 (16%)]\tLoss: 0.045163\n",
      "Train Epoch: 1 [2560/14860 (17%)]\tLoss: 0.032596\n",
      "Train Epoch: 1 [2688/14860 (18%)]\tLoss: 0.041145\n",
      "Train Epoch: 1 [2816/14860 (19%)]\tLoss: 0.046272\n",
      "Train Epoch: 1 [2944/14860 (20%)]\tLoss: 0.030914\n",
      "Train Epoch: 1 [3072/14860 (21%)]\tLoss: 0.047415\n",
      "Train Epoch: 1 [3200/14860 (21%)]\tLoss: 0.034291\n",
      "Train Epoch: 1 [3328/14860 (22%)]\tLoss: 0.030696\n",
      "Train Epoch: 1 [3456/14860 (23%)]\tLoss: 0.042302\n",
      "Train Epoch: 1 [3584/14860 (24%)]\tLoss: 0.049305\n",
      "Train Epoch: 1 [3712/14860 (25%)]\tLoss: 0.036371\n",
      "Train Epoch: 1 [3840/14860 (26%)]\tLoss: 0.045185\n",
      "Train Epoch: 1 [3968/14860 (26%)]\tLoss: 0.037982\n",
      "Train Epoch: 1 [4096/14860 (27%)]\tLoss: 0.038520\n",
      "Train Epoch: 1 [4224/14860 (28%)]\tLoss: 0.037591\n",
      "Train Epoch: 1 [4352/14860 (29%)]\tLoss: 0.033672\n",
      "Train Epoch: 1 [4480/14860 (30%)]\tLoss: 0.031891\n",
      "Train Epoch: 1 [4608/14860 (31%)]\tLoss: 0.043169\n",
      "Train Epoch: 1 [4736/14860 (32%)]\tLoss: 0.045316\n",
      "Train Epoch: 1 [4864/14860 (32%)]\tLoss: 0.031920\n",
      "Train Epoch: 1 [4992/14860 (33%)]\tLoss: 0.037004\n",
      "Train Epoch: 1 [5120/14860 (34%)]\tLoss: 0.048174\n",
      "Train Epoch: 1 [5248/14860 (35%)]\tLoss: 0.042688\n",
      "Train Epoch: 1 [5376/14860 (36%)]\tLoss: 0.031834\n",
      "Train Epoch: 1 [5504/14860 (37%)]\tLoss: 0.032441\n",
      "Train Epoch: 1 [5632/14860 (38%)]\tLoss: 0.034807\n",
      "Train Epoch: 1 [5760/14860 (38%)]\tLoss: 0.034617\n",
      "Train Epoch: 1 [5888/14860 (39%)]\tLoss: 0.035132\n",
      "Train Epoch: 1 [6016/14860 (40%)]\tLoss: 0.039968\n",
      "Train Epoch: 1 [6144/14860 (41%)]\tLoss: 0.037955\n",
      "Train Epoch: 1 [6272/14860 (42%)]\tLoss: 0.040330\n",
      "Train Epoch: 1 [6400/14860 (43%)]\tLoss: 0.029393\n",
      "Train Epoch: 1 [6528/14860 (44%)]\tLoss: 0.050970\n",
      "Train Epoch: 1 [6656/14860 (44%)]\tLoss: 0.037505\n",
      "Train Epoch: 1 [6784/14860 (45%)]\tLoss: 0.037157\n",
      "Train Epoch: 1 [6912/14860 (46%)]\tLoss: 0.040526\n",
      "Train Epoch: 1 [7040/14860 (47%)]\tLoss: 0.038421\n",
      "Train Epoch: 1 [7168/14860 (48%)]\tLoss: 0.039402\n",
      "Train Epoch: 1 [7296/14860 (49%)]\tLoss: 0.038576\n",
      "Train Epoch: 1 [7424/14860 (50%)]\tLoss: 0.025922\n",
      "Train Epoch: 1 [7552/14860 (50%)]\tLoss: 0.025720\n",
      "Train Epoch: 1 [7680/14860 (51%)]\tLoss: 0.036164\n",
      "Train Epoch: 1 [7808/14860 (52%)]\tLoss: 0.032758\n",
      "Train Epoch: 1 [7936/14860 (53%)]\tLoss: 0.037588\n",
      "Train Epoch: 1 [8064/14860 (54%)]\tLoss: 0.025711\n",
      "Train Epoch: 1 [8192/14860 (55%)]\tLoss: 0.042263\n",
      "Train Epoch: 1 [8320/14860 (56%)]\tLoss: 0.039301\n",
      "Train Epoch: 1 [8448/14860 (56%)]\tLoss: 0.028151\n",
      "Train Epoch: 1 [8576/14860 (57%)]\tLoss: 0.029917\n",
      "Train Epoch: 1 [8704/14860 (58%)]\tLoss: 0.036309\n",
      "Train Epoch: 1 [8832/14860 (59%)]\tLoss: 0.032730\n",
      "Train Epoch: 1 [8960/14860 (60%)]\tLoss: 0.036406\n",
      "Train Epoch: 1 [9088/14860 (61%)]\tLoss: 0.037809\n",
      "Train Epoch: 1 [9216/14860 (62%)]\tLoss: 0.028197\n",
      "Train Epoch: 1 [9344/14860 (62%)]\tLoss: 0.043836\n",
      "Train Epoch: 1 [9472/14860 (63%)]\tLoss: 0.027234\n",
      "Train Epoch: 1 [9600/14860 (64%)]\tLoss: 0.030937\n",
      "Train Epoch: 1 [9728/14860 (65%)]\tLoss: 0.027741\n",
      "Train Epoch: 1 [9856/14860 (66%)]\tLoss: 0.030693\n",
      "Train Epoch: 1 [9984/14860 (67%)]\tLoss: 0.027725\n",
      "Train Epoch: 1 [10112/14860 (68%)]\tLoss: 0.030028\n",
      "Train Epoch: 1 [10240/14860 (68%)]\tLoss: 0.031700\n",
      "Train Epoch: 1 [10368/14860 (69%)]\tLoss: 0.027469\n",
      "Train Epoch: 1 [10496/14860 (70%)]\tLoss: 0.031747\n",
      "Train Epoch: 1 [10624/14860 (71%)]\tLoss: 0.025671\n",
      "Train Epoch: 1 [10752/14860 (72%)]\tLoss: 0.028637\n",
      "Train Epoch: 1 [10880/14860 (73%)]\tLoss: 0.035519\n",
      "Train Epoch: 1 [11008/14860 (74%)]\tLoss: 0.028194\n",
      "Train Epoch: 1 [11136/14860 (74%)]\tLoss: 0.026972\n",
      "Train Epoch: 1 [11264/14860 (75%)]\tLoss: 0.017631\n",
      "Train Epoch: 1 [11392/14860 (76%)]\tLoss: 0.033173\n",
      "Train Epoch: 1 [11520/14860 (77%)]\tLoss: 0.025495\n",
      "Train Epoch: 1 [11648/14860 (78%)]\tLoss: 0.029772\n",
      "Train Epoch: 1 [11776/14860 (79%)]\tLoss: 0.022416\n",
      "Train Epoch: 1 [11904/14860 (79%)]\tLoss: 0.034023\n",
      "Train Epoch: 1 [12032/14860 (80%)]\tLoss: 0.029116\n",
      "Train Epoch: 1 [12160/14860 (81%)]\tLoss: 0.029502\n",
      "Train Epoch: 1 [12288/14860 (82%)]\tLoss: 0.026394\n",
      "Train Epoch: 1 [12416/14860 (83%)]\tLoss: 0.026567\n",
      "Train Epoch: 1 [12544/14860 (84%)]\tLoss: 0.032325\n",
      "Train Epoch: 1 [12672/14860 (85%)]\tLoss: 0.024365\n",
      "Train Epoch: 1 [12800/14860 (85%)]\tLoss: 0.022546\n",
      "Train Epoch: 1 [12928/14860 (86%)]\tLoss: 0.033631\n",
      "Train Epoch: 1 [13056/14860 (87%)]\tLoss: 0.023122\n",
      "Train Epoch: 1 [13184/14860 (88%)]\tLoss: 0.031914\n",
      "Train Epoch: 1 [13312/14860 (89%)]\tLoss: 0.030265\n",
      "Train Epoch: 1 [13440/14860 (90%)]\tLoss: 0.037657\n",
      "Train Epoch: 1 [13568/14860 (91%)]\tLoss: 0.024458\n",
      "Train Epoch: 1 [13696/14860 (91%)]\tLoss: 0.029796\n",
      "Train Epoch: 1 [13824/14860 (92%)]\tLoss: 0.032398\n",
      "Train Epoch: 1 [13952/14860 (93%)]\tLoss: 0.025863\n",
      "Train Epoch: 1 [14080/14860 (94%)]\tLoss: 0.026290\n",
      "Train Epoch: 1 [14208/14860 (95%)]\tLoss: 0.026086\n",
      "Train Epoch: 1 [14336/14860 (96%)]\tLoss: 0.032734\n",
      "Train Epoch: 1 [14464/14860 (97%)]\tLoss: 0.025380\n",
      "Train Epoch: 1 [14592/14860 (97%)]\tLoss: 0.026410\n",
      "Train Epoch: 1 [14720/14860 (98%)]\tLoss: 0.019109\n",
      "Train Epoch: 1 [1392/14860 (99%)]\tLoss: 0.041804\n",
      "epoch 1 training loss: 0.035160055288519614\n",
      "epoch 1 validation loss: 0.02898641951724923\n",
      "Train Epoch: 2 [0/14860 (0%)]\tLoss: 0.024518\n",
      "Train Epoch: 2 [128/14860 (1%)]\tLoss: 0.036011\n",
      "Train Epoch: 2 [256/14860 (2%)]\tLoss: 0.033021\n",
      "Train Epoch: 2 [384/14860 (3%)]\tLoss: 0.027654\n",
      "Train Epoch: 2 [512/14860 (3%)]\tLoss: 0.028859\n",
      "Train Epoch: 2 [640/14860 (4%)]\tLoss: 0.028301\n",
      "Train Epoch: 2 [768/14860 (5%)]\tLoss: 0.023803\n",
      "Train Epoch: 2 [896/14860 (6%)]\tLoss: 0.029731\n",
      "Train Epoch: 2 [1024/14860 (7%)]\tLoss: 0.027295\n",
      "Train Epoch: 2 [1152/14860 (8%)]\tLoss: 0.023838\n",
      "Train Epoch: 2 [1280/14860 (9%)]\tLoss: 0.033894\n",
      "Train Epoch: 2 [1408/14860 (9%)]\tLoss: 0.028250\n",
      "Train Epoch: 2 [1536/14860 (10%)]\tLoss: 0.034755\n",
      "Train Epoch: 2 [1664/14860 (11%)]\tLoss: 0.025480\n",
      "Train Epoch: 2 [1792/14860 (12%)]\tLoss: 0.040682\n",
      "Train Epoch: 2 [1920/14860 (13%)]\tLoss: 0.027815\n",
      "Train Epoch: 2 [2048/14860 (14%)]\tLoss: 0.023966\n",
      "Train Epoch: 2 [2176/14860 (15%)]\tLoss: 0.025633\n",
      "Train Epoch: 2 [2304/14860 (15%)]\tLoss: 0.029528\n",
      "Train Epoch: 2 [2432/14860 (16%)]\tLoss: 0.025602\n",
      "Train Epoch: 2 [2560/14860 (17%)]\tLoss: 0.023007\n",
      "Train Epoch: 2 [2688/14860 (18%)]\tLoss: 0.014594\n",
      "Train Epoch: 2 [2816/14860 (19%)]\tLoss: 0.026853\n",
      "Train Epoch: 2 [2944/14860 (20%)]\tLoss: 0.015340\n",
      "Train Epoch: 2 [3072/14860 (21%)]\tLoss: 0.029447\n",
      "Train Epoch: 2 [3200/14860 (21%)]\tLoss: 0.023415\n",
      "Train Epoch: 2 [3328/14860 (22%)]\tLoss: 0.025971\n",
      "Train Epoch: 2 [3456/14860 (23%)]\tLoss: 0.044039\n",
      "Train Epoch: 2 [3584/14860 (24%)]\tLoss: 0.042266\n",
      "Train Epoch: 2 [3712/14860 (25%)]\tLoss: 0.034292\n",
      "Train Epoch: 2 [3840/14860 (26%)]\tLoss: 0.022679\n",
      "Train Epoch: 2 [3968/14860 (26%)]\tLoss: 0.025271\n",
      "Train Epoch: 2 [4096/14860 (27%)]\tLoss: 0.026941\n",
      "Train Epoch: 2 [4224/14860 (28%)]\tLoss: 0.032202\n",
      "Train Epoch: 2 [4352/14860 (29%)]\tLoss: 0.025343\n",
      "Train Epoch: 2 [4480/14860 (30%)]\tLoss: 0.022700\n",
      "Train Epoch: 2 [4608/14860 (31%)]\tLoss: 0.022273\n",
      "Train Epoch: 2 [4736/14860 (32%)]\tLoss: 0.021817\n",
      "Train Epoch: 2 [4864/14860 (32%)]\tLoss: 0.036027\n",
      "Train Epoch: 2 [4992/14860 (33%)]\tLoss: 0.025138\n",
      "Train Epoch: 2 [5120/14860 (34%)]\tLoss: 0.020844\n",
      "Train Epoch: 2 [5248/14860 (35%)]\tLoss: 0.033336\n",
      "Train Epoch: 2 [5376/14860 (36%)]\tLoss: 0.022307\n",
      "Train Epoch: 2 [5504/14860 (37%)]\tLoss: 0.030747\n",
      "Train Epoch: 2 [5632/14860 (38%)]\tLoss: 0.021194\n",
      "Train Epoch: 2 [5760/14860 (38%)]\tLoss: 0.034877\n",
      "Train Epoch: 2 [5888/14860 (39%)]\tLoss: 0.017836\n",
      "Train Epoch: 2 [6016/14860 (40%)]\tLoss: 0.020975\n",
      "Train Epoch: 2 [6144/14860 (41%)]\tLoss: 0.026508\n",
      "Train Epoch: 2 [6272/14860 (42%)]\tLoss: 0.024495\n",
      "Train Epoch: 2 [6400/14860 (43%)]\tLoss: 0.022978\n",
      "Train Epoch: 2 [6528/14860 (44%)]\tLoss: 0.027220\n",
      "Train Epoch: 2 [6656/14860 (44%)]\tLoss: 0.027410\n",
      "Train Epoch: 2 [6784/14860 (45%)]\tLoss: 0.021704\n",
      "Train Epoch: 2 [6912/14860 (46%)]\tLoss: 0.021426\n",
      "Train Epoch: 2 [7040/14860 (47%)]\tLoss: 0.028353\n",
      "Train Epoch: 2 [7168/14860 (48%)]\tLoss: 0.031228\n",
      "Train Epoch: 2 [7296/14860 (49%)]\tLoss: 0.025293\n",
      "Train Epoch: 2 [7424/14860 (50%)]\tLoss: 0.031603\n",
      "Train Epoch: 2 [7552/14860 (50%)]\tLoss: 0.031204\n",
      "Train Epoch: 2 [7680/14860 (51%)]\tLoss: 0.026621\n",
      "Train Epoch: 2 [7808/14860 (52%)]\tLoss: 0.024635\n",
      "Train Epoch: 2 [7936/14860 (53%)]\tLoss: 0.027933\n",
      "Train Epoch: 2 [8064/14860 (54%)]\tLoss: 0.023341\n",
      "Train Epoch: 2 [8192/14860 (55%)]\tLoss: 0.020949\n",
      "Train Epoch: 2 [8320/14860 (56%)]\tLoss: 0.025307\n",
      "Train Epoch: 2 [8448/14860 (56%)]\tLoss: 0.012302\n",
      "Train Epoch: 2 [8576/14860 (57%)]\tLoss: 0.020181\n",
      "Train Epoch: 2 [8704/14860 (58%)]\tLoss: 0.019561\n",
      "Train Epoch: 2 [8832/14860 (59%)]\tLoss: 0.017891\n",
      "Train Epoch: 2 [8960/14860 (60%)]\tLoss: 0.016482\n",
      "Train Epoch: 2 [9088/14860 (61%)]\tLoss: 0.021377\n",
      "Train Epoch: 2 [9216/14860 (62%)]\tLoss: 0.023613\n",
      "Train Epoch: 2 [9344/14860 (62%)]\tLoss: 0.018426\n",
      "Train Epoch: 2 [9472/14860 (63%)]\tLoss: 0.022208\n",
      "Train Epoch: 2 [9600/14860 (64%)]\tLoss: 0.023120\n",
      "Train Epoch: 2 [9728/14860 (65%)]\tLoss: 0.022898\n",
      "Train Epoch: 2 [9856/14860 (66%)]\tLoss: 0.016429\n",
      "Train Epoch: 2 [9984/14860 (67%)]\tLoss: 0.025833\n",
      "Train Epoch: 2 [10112/14860 (68%)]\tLoss: 0.022101\n",
      "Train Epoch: 2 [10240/14860 (68%)]\tLoss: 0.034095\n",
      "Train Epoch: 2 [10368/14860 (69%)]\tLoss: 0.029235\n",
      "Train Epoch: 2 [10496/14860 (70%)]\tLoss: 0.026085\n",
      "Train Epoch: 2 [10624/14860 (71%)]\tLoss: 0.016068\n",
      "Train Epoch: 2 [10752/14860 (72%)]\tLoss: 0.022569\n",
      "Train Epoch: 2 [10880/14860 (73%)]\tLoss: 0.030085\n",
      "Train Epoch: 2 [11008/14860 (74%)]\tLoss: 0.030848\n",
      "Train Epoch: 2 [11136/14860 (74%)]\tLoss: 0.032261\n",
      "Train Epoch: 2 [11264/14860 (75%)]\tLoss: 0.024192\n",
      "Train Epoch: 2 [11392/14860 (76%)]\tLoss: 0.028315\n",
      "Train Epoch: 2 [11520/14860 (77%)]\tLoss: 0.026220\n",
      "Train Epoch: 2 [11648/14860 (78%)]\tLoss: 0.038550\n",
      "Train Epoch: 2 [11776/14860 (79%)]\tLoss: 0.032287\n",
      "Train Epoch: 2 [11904/14860 (79%)]\tLoss: 0.026303\n",
      "Train Epoch: 2 [12032/14860 (80%)]\tLoss: 0.030783\n",
      "Train Epoch: 2 [12160/14860 (81%)]\tLoss: 0.018261\n",
      "Train Epoch: 2 [12288/14860 (82%)]\tLoss: 0.028784\n",
      "Train Epoch: 2 [12416/14860 (83%)]\tLoss: 0.018489\n",
      "Train Epoch: 2 [12544/14860 (84%)]\tLoss: 0.027824\n",
      "Train Epoch: 2 [12672/14860 (85%)]\tLoss: 0.018966\n",
      "Train Epoch: 2 [12800/14860 (85%)]\tLoss: 0.028746\n",
      "Train Epoch: 2 [12928/14860 (86%)]\tLoss: 0.029696\n",
      "Train Epoch: 2 [13056/14860 (87%)]\tLoss: 0.035774\n",
      "Train Epoch: 2 [13184/14860 (88%)]\tLoss: 0.017855\n",
      "Train Epoch: 2 [13312/14860 (89%)]\tLoss: 0.043628\n",
      "Train Epoch: 2 [13440/14860 (90%)]\tLoss: 0.022545\n",
      "Train Epoch: 2 [13568/14860 (91%)]\tLoss: 0.036937\n",
      "Train Epoch: 2 [13696/14860 (91%)]\tLoss: 0.023574\n",
      "Train Epoch: 2 [13824/14860 (92%)]\tLoss: 0.051464\n",
      "Train Epoch: 2 [13952/14860 (93%)]\tLoss: 0.027707\n",
      "Train Epoch: 2 [14080/14860 (94%)]\tLoss: 0.035023\n",
      "Train Epoch: 2 [14208/14860 (95%)]\tLoss: 0.029078\n",
      "Train Epoch: 2 [14336/14860 (96%)]\tLoss: 0.031010\n",
      "Train Epoch: 2 [14464/14860 (97%)]\tLoss: 0.033642\n",
      "Train Epoch: 2 [14592/14860 (97%)]\tLoss: 0.027158\n",
      "Train Epoch: 2 [14720/14860 (98%)]\tLoss: 0.045276\n",
      "Train Epoch: 2 [1392/14860 (99%)]\tLoss: 0.013866\n",
      "epoch 2 training loss: 0.02687346054893783\n",
      "epoch 2 validation loss: 0.03650653795237691\n",
      "Train Epoch: 3 [0/14860 (0%)]\tLoss: 0.041265\n",
      "Train Epoch: 3 [128/14860 (1%)]\tLoss: 0.021721\n",
      "Train Epoch: 3 [256/14860 (2%)]\tLoss: 0.022421\n",
      "Train Epoch: 3 [384/14860 (3%)]\tLoss: 0.018047\n",
      "Train Epoch: 3 [512/14860 (3%)]\tLoss: 0.028447\n",
      "Train Epoch: 3 [640/14860 (4%)]\tLoss: 0.014845\n",
      "Train Epoch: 3 [768/14860 (5%)]\tLoss: 0.024033\n",
      "Train Epoch: 3 [896/14860 (6%)]\tLoss: 0.024980\n",
      "Train Epoch: 3 [1024/14860 (7%)]\tLoss: 0.022758\n",
      "Train Epoch: 3 [1152/14860 (8%)]\tLoss: 0.033558\n",
      "Train Epoch: 3 [1280/14860 (9%)]\tLoss: 0.016294\n",
      "Train Epoch: 3 [1408/14860 (9%)]\tLoss: 0.029194\n",
      "Train Epoch: 3 [1536/14860 (10%)]\tLoss: 0.015576\n",
      "Train Epoch: 3 [1664/14860 (11%)]\tLoss: 0.022266\n",
      "Train Epoch: 3 [1792/14860 (12%)]\tLoss: 0.020086\n",
      "Train Epoch: 3 [1920/14860 (13%)]\tLoss: 0.023086\n",
      "Train Epoch: 3 [2048/14860 (14%)]\tLoss: 0.020657\n",
      "Train Epoch: 3 [2176/14860 (15%)]\tLoss: 0.022128\n",
      "Train Epoch: 3 [2304/14860 (15%)]\tLoss: 0.017469\n",
      "Train Epoch: 3 [2432/14860 (16%)]\tLoss: 0.028239\n",
      "Train Epoch: 3 [2560/14860 (17%)]\tLoss: 0.016903\n",
      "Train Epoch: 3 [2688/14860 (18%)]\tLoss: 0.023556\n",
      "Train Epoch: 3 [2816/14860 (19%)]\tLoss: 0.023937\n",
      "Train Epoch: 3 [2944/14860 (20%)]\tLoss: 0.019266\n",
      "Train Epoch: 3 [3072/14860 (21%)]\tLoss: 0.026844\n",
      "Train Epoch: 3 [3200/14860 (21%)]\tLoss: 0.031699\n",
      "Train Epoch: 3 [3328/14860 (22%)]\tLoss: 0.024254\n",
      "Train Epoch: 3 [3456/14860 (23%)]\tLoss: 0.025551\n",
      "Train Epoch: 3 [3584/14860 (24%)]\tLoss: 0.017531\n",
      "Train Epoch: 3 [3712/14860 (25%)]\tLoss: 0.027357\n",
      "Train Epoch: 3 [3840/14860 (26%)]\tLoss: 0.024848\n",
      "Train Epoch: 3 [3968/14860 (26%)]\tLoss: 0.020451\n",
      "Train Epoch: 3 [4096/14860 (27%)]\tLoss: 0.022774\n",
      "Train Epoch: 3 [4224/14860 (28%)]\tLoss: 0.026292\n",
      "Train Epoch: 3 [4352/14860 (29%)]\tLoss: 0.028315\n",
      "Train Epoch: 3 [4480/14860 (30%)]\tLoss: 0.023262\n",
      "Train Epoch: 3 [4608/14860 (31%)]\tLoss: 0.016201\n",
      "Train Epoch: 3 [4736/14860 (32%)]\tLoss: 0.017323\n",
      "Train Epoch: 3 [4864/14860 (32%)]\tLoss: 0.024565\n",
      "Train Epoch: 3 [4992/14860 (33%)]\tLoss: 0.023289\n",
      "Train Epoch: 3 [5120/14860 (34%)]\tLoss: 0.022096\n",
      "Train Epoch: 3 [5248/14860 (35%)]\tLoss: 0.018359\n",
      "Train Epoch: 3 [5376/14860 (36%)]\tLoss: 0.022282\n",
      "Train Epoch: 3 [5504/14860 (37%)]\tLoss: 0.028666\n",
      "Train Epoch: 3 [5632/14860 (38%)]\tLoss: 0.021580\n",
      "Train Epoch: 3 [5760/14860 (38%)]\tLoss: 0.025782\n",
      "Train Epoch: 3 [5888/14860 (39%)]\tLoss: 0.019426\n",
      "Train Epoch: 3 [6016/14860 (40%)]\tLoss: 0.025399\n",
      "Train Epoch: 3 [6144/14860 (41%)]\tLoss: 0.014115\n",
      "Train Epoch: 3 [6272/14860 (42%)]\tLoss: 0.022584\n",
      "Train Epoch: 3 [6400/14860 (43%)]\tLoss: 0.023132\n",
      "Train Epoch: 3 [6528/14860 (44%)]\tLoss: 0.028690\n",
      "Train Epoch: 3 [6656/14860 (44%)]\tLoss: 0.034778\n",
      "Train Epoch: 3 [6784/14860 (45%)]\tLoss: 0.020018\n",
      "Train Epoch: 3 [6912/14860 (46%)]\tLoss: 0.022738\n",
      "Train Epoch: 3 [7040/14860 (47%)]\tLoss: 0.016076\n",
      "Train Epoch: 3 [7168/14860 (48%)]\tLoss: 0.017458\n",
      "Train Epoch: 3 [7296/14860 (49%)]\tLoss: 0.013986\n",
      "Train Epoch: 3 [7424/14860 (50%)]\tLoss: 0.022455\n",
      "Train Epoch: 3 [7552/14860 (50%)]\tLoss: 0.017138\n",
      "Train Epoch: 3 [7680/14860 (51%)]\tLoss: 0.017404\n",
      "Train Epoch: 3 [7808/14860 (52%)]\tLoss: 0.019763\n",
      "Train Epoch: 3 [7936/14860 (53%)]\tLoss: 0.015725\n",
      "Train Epoch: 3 [8064/14860 (54%)]\tLoss: 0.020710\n",
      "Train Epoch: 3 [8192/14860 (55%)]\tLoss: 0.026978\n",
      "Train Epoch: 3 [8320/14860 (56%)]\tLoss: 0.019875\n",
      "Train Epoch: 3 [8448/14860 (56%)]\tLoss: 0.032743\n",
      "Train Epoch: 3 [8576/14860 (57%)]\tLoss: 0.019984\n",
      "Train Epoch: 3 [8704/14860 (58%)]\tLoss: 0.022100\n",
      "Train Epoch: 3 [8832/14860 (59%)]\tLoss: 0.036897\n",
      "Train Epoch: 3 [8960/14860 (60%)]\tLoss: 0.022333\n",
      "Train Epoch: 3 [9088/14860 (61%)]\tLoss: 0.015355\n",
      "Train Epoch: 3 [9216/14860 (62%)]\tLoss: 0.014556\n",
      "Train Epoch: 3 [9344/14860 (62%)]\tLoss: 0.028288\n",
      "Train Epoch: 3 [9472/14860 (63%)]\tLoss: 0.028736\n",
      "Train Epoch: 3 [9600/14860 (64%)]\tLoss: 0.026177\n",
      "Train Epoch: 3 [9728/14860 (65%)]\tLoss: 0.028239\n",
      "Train Epoch: 3 [9856/14860 (66%)]\tLoss: 0.033487\n",
      "Train Epoch: 3 [9984/14860 (67%)]\tLoss: 0.030372\n",
      "Train Epoch: 3 [10112/14860 (68%)]\tLoss: 0.021741\n",
      "Train Epoch: 3 [10240/14860 (68%)]\tLoss: 0.025639\n",
      "Train Epoch: 3 [10368/14860 (69%)]\tLoss: 0.029011\n",
      "Train Epoch: 3 [10496/14860 (70%)]\tLoss: 0.043306\n",
      "Train Epoch: 3 [10624/14860 (71%)]\tLoss: 0.024409\n",
      "Train Epoch: 3 [10752/14860 (72%)]\tLoss: 0.045271\n",
      "Train Epoch: 3 [10880/14860 (73%)]\tLoss: 0.030300\n",
      "Train Epoch: 3 [11008/14860 (74%)]\tLoss: 0.042863\n",
      "Train Epoch: 3 [11136/14860 (74%)]\tLoss: 0.017025\n",
      "Train Epoch: 3 [11264/14860 (75%)]\tLoss: 0.048762\n",
      "Train Epoch: 3 [11392/14860 (76%)]\tLoss: 0.016892\n",
      "Train Epoch: 3 [11520/14860 (77%)]\tLoss: 0.036082\n",
      "Train Epoch: 3 [11648/14860 (78%)]\tLoss: 0.025146\n",
      "Train Epoch: 3 [11776/14860 (79%)]\tLoss: 0.034944\n",
      "Train Epoch: 3 [11904/14860 (79%)]\tLoss: 0.021094\n",
      "Train Epoch: 3 [12032/14860 (80%)]\tLoss: 0.031696\n",
      "Train Epoch: 3 [12160/14860 (81%)]\tLoss: 0.020383\n",
      "Train Epoch: 3 [12288/14860 (82%)]\tLoss: 0.028674\n",
      "Train Epoch: 3 [12416/14860 (83%)]\tLoss: 0.023584\n",
      "Train Epoch: 3 [12544/14860 (84%)]\tLoss: 0.028466\n",
      "Train Epoch: 3 [12672/14860 (85%)]\tLoss: 0.024213\n",
      "Train Epoch: 3 [12800/14860 (85%)]\tLoss: 0.032742\n",
      "Train Epoch: 3 [12928/14860 (86%)]\tLoss: 0.024502\n",
      "Train Epoch: 3 [13056/14860 (87%)]\tLoss: 0.030121\n",
      "Train Epoch: 3 [13184/14860 (88%)]\tLoss: 0.021646\n",
      "Train Epoch: 3 [13312/14860 (89%)]\tLoss: 0.026301\n",
      "Train Epoch: 3 [13440/14860 (90%)]\tLoss: 0.021875\n",
      "Train Epoch: 3 [13568/14860 (91%)]\tLoss: 0.024499\n",
      "Train Epoch: 3 [13696/14860 (91%)]\tLoss: 0.021389\n",
      "Train Epoch: 3 [13824/14860 (92%)]\tLoss: 0.024126\n",
      "Train Epoch: 3 [13952/14860 (93%)]\tLoss: 0.023330\n",
      "Train Epoch: 3 [14080/14860 (94%)]\tLoss: 0.021120\n",
      "Train Epoch: 3 [14208/14860 (95%)]\tLoss: 0.020445\n",
      "Train Epoch: 3 [14336/14860 (96%)]\tLoss: 0.019472\n",
      "Train Epoch: 3 [14464/14860 (97%)]\tLoss: 0.019883\n",
      "Train Epoch: 3 [14592/14860 (97%)]\tLoss: 0.019144\n",
      "Train Epoch: 3 [14720/14860 (98%)]\tLoss: 0.023722\n",
      "Train Epoch: 3 [1392/14860 (99%)]\tLoss: 0.044237\n",
      "epoch 3 training loss: 0.024494199074295342\n",
      "epoch 3 validation loss: 0.024674856056601316\n",
      "Train Epoch: 4 [0/14860 (0%)]\tLoss: 0.022533\n",
      "Train Epoch: 4 [128/14860 (1%)]\tLoss: 0.019361\n",
      "Train Epoch: 4 [256/14860 (2%)]\tLoss: 0.028336\n",
      "Train Epoch: 4 [384/14860 (3%)]\tLoss: 0.025150\n",
      "Train Epoch: 4 [512/14860 (3%)]\tLoss: 0.022758\n",
      "Train Epoch: 4 [640/14860 (4%)]\tLoss: 0.024689\n",
      "Train Epoch: 4 [768/14860 (5%)]\tLoss: 0.022913\n",
      "Train Epoch: 4 [896/14860 (6%)]\tLoss: 0.023340\n",
      "Train Epoch: 4 [1024/14860 (7%)]\tLoss: 0.027072\n",
      "Train Epoch: 4 [1152/14860 (8%)]\tLoss: 0.017416\n",
      "Train Epoch: 4 [1280/14860 (9%)]\tLoss: 0.024923\n",
      "Train Epoch: 4 [1408/14860 (9%)]\tLoss: 0.022708\n",
      "Train Epoch: 4 [1536/14860 (10%)]\tLoss: 0.019928\n",
      "Train Epoch: 4 [1664/14860 (11%)]\tLoss: 0.019925\n",
      "Train Epoch: 4 [1792/14860 (12%)]\tLoss: 0.027249\n",
      "Train Epoch: 4 [1920/14860 (13%)]\tLoss: 0.024224\n",
      "Train Epoch: 4 [2048/14860 (14%)]\tLoss: 0.019730\n",
      "Train Epoch: 4 [2176/14860 (15%)]\tLoss: 0.022908\n",
      "Train Epoch: 4 [2304/14860 (15%)]\tLoss: 0.021642\n",
      "Train Epoch: 4 [2432/14860 (16%)]\tLoss: 0.020387\n",
      "Train Epoch: 4 [2560/14860 (17%)]\tLoss: 0.026145\n",
      "Train Epoch: 4 [2688/14860 (18%)]\tLoss: 0.019977\n",
      "Train Epoch: 4 [2816/14860 (19%)]\tLoss: 0.026522\n",
      "Train Epoch: 4 [2944/14860 (20%)]\tLoss: 0.014870\n",
      "Train Epoch: 4 [3072/14860 (21%)]\tLoss: 0.022332\n",
      "Train Epoch: 4 [3200/14860 (21%)]\tLoss: 0.019339\n",
      "Train Epoch: 4 [3328/14860 (22%)]\tLoss: 0.031236\n",
      "Train Epoch: 4 [3456/14860 (23%)]\tLoss: 0.023075\n",
      "Train Epoch: 4 [3584/14860 (24%)]\tLoss: 0.016880\n",
      "Train Epoch: 4 [3712/14860 (25%)]\tLoss: 0.020390\n",
      "Train Epoch: 4 [3840/14860 (26%)]\tLoss: 0.018045\n",
      "Train Epoch: 4 [3968/14860 (26%)]\tLoss: 0.026884\n",
      "Train Epoch: 4 [4096/14860 (27%)]\tLoss: 0.018800\n",
      "Train Epoch: 4 [4224/14860 (28%)]\tLoss: 0.025954\n",
      "Train Epoch: 4 [4352/14860 (29%)]\tLoss: 0.019180\n",
      "Train Epoch: 4 [4480/14860 (30%)]\tLoss: 0.021745\n",
      "Train Epoch: 4 [4608/14860 (31%)]\tLoss: 0.017353\n",
      "Train Epoch: 4 [4736/14860 (32%)]\tLoss: 0.018518\n",
      "Train Epoch: 4 [4864/14860 (32%)]\tLoss: 0.013155\n",
      "Train Epoch: 4 [4992/14860 (33%)]\tLoss: 0.019763\n",
      "Train Epoch: 4 [5120/14860 (34%)]\tLoss: 0.019306\n",
      "Train Epoch: 4 [5248/14860 (35%)]\tLoss: 0.025245\n",
      "Train Epoch: 4 [5376/14860 (36%)]\tLoss: 0.020647\n",
      "Train Epoch: 4 [5504/14860 (37%)]\tLoss: 0.022144\n",
      "Train Epoch: 4 [5632/14860 (38%)]\tLoss: 0.024845\n",
      "Train Epoch: 4 [5760/14860 (38%)]\tLoss: 0.023372\n",
      "Train Epoch: 4 [5888/14860 (39%)]\tLoss: 0.025418\n",
      "Train Epoch: 4 [6016/14860 (40%)]\tLoss: 0.019910\n",
      "Train Epoch: 4 [6144/14860 (41%)]\tLoss: 0.021784\n",
      "Train Epoch: 4 [6272/14860 (42%)]\tLoss: 0.024482\n",
      "Train Epoch: 4 [6400/14860 (43%)]\tLoss: 0.024654\n",
      "Train Epoch: 4 [6528/14860 (44%)]\tLoss: 0.018438\n",
      "Train Epoch: 4 [6656/14860 (44%)]\tLoss: 0.032817\n",
      "Train Epoch: 4 [6784/14860 (45%)]\tLoss: 0.038353\n",
      "Train Epoch: 4 [6912/14860 (46%)]\tLoss: 0.022971\n",
      "Train Epoch: 4 [7040/14860 (47%)]\tLoss: 0.028188\n",
      "Train Epoch: 4 [7168/14860 (48%)]\tLoss: 0.024502\n",
      "Train Epoch: 4 [7296/14860 (49%)]\tLoss: 0.027986\n",
      "Train Epoch: 4 [7424/14860 (50%)]\tLoss: 0.021746\n",
      "Train Epoch: 4 [7552/14860 (50%)]\tLoss: 0.031821\n",
      "Train Epoch: 4 [7680/14860 (51%)]\tLoss: 0.024083\n",
      "Train Epoch: 4 [7808/14860 (52%)]\tLoss: 0.024428\n",
      "Train Epoch: 4 [7936/14860 (53%)]\tLoss: 0.022220\n",
      "Train Epoch: 4 [8064/14860 (54%)]\tLoss: 0.021255\n",
      "Train Epoch: 4 [8192/14860 (55%)]\tLoss: 0.019802\n",
      "Train Epoch: 4 [8320/14860 (56%)]\tLoss: 0.025745\n",
      "Train Epoch: 4 [8448/14860 (56%)]\tLoss: 0.018138\n",
      "Train Epoch: 4 [8576/14860 (57%)]\tLoss: 0.025271\n",
      "Train Epoch: 4 [8704/14860 (58%)]\tLoss: 0.018182\n",
      "Train Epoch: 4 [8832/14860 (59%)]\tLoss: 0.026902\n",
      "Train Epoch: 4 [8960/14860 (60%)]\tLoss: 0.029855\n",
      "Train Epoch: 4 [9088/14860 (61%)]\tLoss: 0.033024\n",
      "Train Epoch: 4 [9216/14860 (62%)]\tLoss: 0.025578\n",
      "Train Epoch: 4 [9344/14860 (62%)]\tLoss: 0.024851\n",
      "Train Epoch: 4 [9472/14860 (63%)]\tLoss: 0.014229\n",
      "Train Epoch: 4 [9600/14860 (64%)]\tLoss: 0.028533\n",
      "Train Epoch: 4 [9728/14860 (65%)]\tLoss: 0.021550\n",
      "Train Epoch: 4 [9856/14860 (66%)]\tLoss: 0.023583\n",
      "Train Epoch: 4 [9984/14860 (67%)]\tLoss: 0.021703\n",
      "Train Epoch: 4 [10112/14860 (68%)]\tLoss: 0.022925\n",
      "Train Epoch: 4 [10240/14860 (68%)]\tLoss: 0.030018\n",
      "Train Epoch: 4 [10368/14860 (69%)]\tLoss: 0.027369\n",
      "Train Epoch: 4 [10496/14860 (70%)]\tLoss: 0.018330\n",
      "Train Epoch: 4 [10624/14860 (71%)]\tLoss: 0.019264\n",
      "Train Epoch: 4 [10752/14860 (72%)]\tLoss: 0.016631\n",
      "Train Epoch: 4 [10880/14860 (73%)]\tLoss: 0.019474\n",
      "Train Epoch: 4 [11008/14860 (74%)]\tLoss: 0.027548\n",
      "Train Epoch: 4 [11136/14860 (74%)]\tLoss: 0.022959\n",
      "Train Epoch: 4 [11264/14860 (75%)]\tLoss: 0.023652\n",
      "Train Epoch: 4 [11392/14860 (76%)]\tLoss: 0.026345\n",
      "Train Epoch: 4 [11520/14860 (77%)]\tLoss: 0.031551\n",
      "Train Epoch: 4 [11648/14860 (78%)]\tLoss: 0.031299\n",
      "Train Epoch: 4 [11776/14860 (79%)]\tLoss: 0.018347\n",
      "Train Epoch: 4 [11904/14860 (79%)]\tLoss: 0.050441\n",
      "Train Epoch: 4 [12032/14860 (80%)]\tLoss: 0.018820\n",
      "Train Epoch: 4 [12160/14860 (81%)]\tLoss: 0.044627\n",
      "Train Epoch: 4 [12288/14860 (82%)]\tLoss: 0.024206\n",
      "Train Epoch: 4 [12416/14860 (83%)]\tLoss: 0.033488\n",
      "Train Epoch: 4 [12544/14860 (84%)]\tLoss: 0.030481\n",
      "Train Epoch: 4 [12672/14860 (85%)]\tLoss: 0.047131\n",
      "Train Epoch: 4 [12800/14860 (85%)]\tLoss: 0.042972\n",
      "Train Epoch: 4 [12928/14860 (86%)]\tLoss: 0.034815\n",
      "Train Epoch: 4 [13056/14860 (87%)]\tLoss: 0.042116\n",
      "Train Epoch: 4 [13184/14860 (88%)]\tLoss: 0.026005\n",
      "Train Epoch: 4 [13312/14860 (89%)]\tLoss: 0.032663\n",
      "Train Epoch: 4 [13440/14860 (90%)]\tLoss: 0.023955\n",
      "Train Epoch: 4 [13568/14860 (91%)]\tLoss: 0.023407\n",
      "Train Epoch: 4 [13696/14860 (91%)]\tLoss: 0.023752\n",
      "Train Epoch: 4 [13824/14860 (92%)]\tLoss: 0.031956\n",
      "Train Epoch: 4 [13952/14860 (93%)]\tLoss: 0.018599\n",
      "Train Epoch: 4 [14080/14860 (94%)]\tLoss: 0.019673\n",
      "Train Epoch: 4 [14208/14860 (95%)]\tLoss: 0.021881\n",
      "Train Epoch: 4 [14336/14860 (96%)]\tLoss: 0.013963\n",
      "Train Epoch: 4 [14464/14860 (97%)]\tLoss: 0.029855\n",
      "Train Epoch: 4 [14592/14860 (97%)]\tLoss: 0.023187\n",
      "Train Epoch: 4 [14720/14860 (98%)]\tLoss: 0.027622\n",
      "Train Epoch: 4 [1392/14860 (99%)]\tLoss: 0.038199\n",
      "epoch 4 training loss: 0.024653368048433565\n",
      "epoch 4 validation loss: 0.02422620323610652\n",
      "Train Epoch: 5 [0/14860 (0%)]\tLoss: 0.018536\n",
      "Train Epoch: 5 [128/14860 (1%)]\tLoss: 0.023498\n",
      "Train Epoch: 5 [256/14860 (2%)]\tLoss: 0.023529\n",
      "Train Epoch: 5 [384/14860 (3%)]\tLoss: 0.020841\n",
      "Train Epoch: 5 [512/14860 (3%)]\tLoss: 0.021100\n",
      "Train Epoch: 5 [640/14860 (4%)]\tLoss: 0.018207\n",
      "Train Epoch: 5 [768/14860 (5%)]\tLoss: 0.019092\n",
      "Train Epoch: 5 [896/14860 (6%)]\tLoss: 0.027836\n",
      "Train Epoch: 5 [1024/14860 (7%)]\tLoss: 0.030980\n",
      "Train Epoch: 5 [1152/14860 (8%)]\tLoss: 0.020490\n",
      "Train Epoch: 5 [1280/14860 (9%)]\tLoss: 0.026459\n",
      "Train Epoch: 5 [1408/14860 (9%)]\tLoss: 0.020774\n",
      "Train Epoch: 5 [1536/14860 (10%)]\tLoss: 0.023823\n",
      "Train Epoch: 5 [1664/14860 (11%)]\tLoss: 0.021180\n",
      "Train Epoch: 5 [1792/14860 (12%)]\tLoss: 0.019283\n",
      "Train Epoch: 5 [1920/14860 (13%)]\tLoss: 0.026298\n",
      "Train Epoch: 5 [2048/14860 (14%)]\tLoss: 0.024559\n",
      "Train Epoch: 5 [2176/14860 (15%)]\tLoss: 0.019578\n",
      "Train Epoch: 5 [2304/14860 (15%)]\tLoss: 0.016606\n",
      "Train Epoch: 5 [2432/14860 (16%)]\tLoss: 0.023435\n",
      "Train Epoch: 5 [2560/14860 (17%)]\tLoss: 0.026689\n",
      "Train Epoch: 5 [2688/14860 (18%)]\tLoss: 0.025191\n",
      "Train Epoch: 5 [2816/14860 (19%)]\tLoss: 0.019246\n",
      "Train Epoch: 5 [2944/14860 (20%)]\tLoss: 0.038661\n",
      "Train Epoch: 5 [3072/14860 (21%)]\tLoss: 0.022131\n",
      "Train Epoch: 5 [3200/14860 (21%)]\tLoss: 0.022231\n",
      "Train Epoch: 5 [3328/14860 (22%)]\tLoss: 0.025538\n",
      "Train Epoch: 5 [3456/14860 (23%)]\tLoss: 0.028852\n",
      "Train Epoch: 5 [3584/14860 (24%)]\tLoss: 0.014555\n",
      "Train Epoch: 5 [3712/14860 (25%)]\tLoss: 0.016418\n",
      "Train Epoch: 5 [3840/14860 (26%)]\tLoss: 0.027517\n",
      "Train Epoch: 5 [3968/14860 (26%)]\tLoss: 0.021136\n",
      "Train Epoch: 5 [4096/14860 (27%)]\tLoss: 0.016574\n",
      "Train Epoch: 5 [4224/14860 (28%)]\tLoss: 0.023261\n",
      "Train Epoch: 5 [4352/14860 (29%)]\tLoss: 0.019092\n",
      "Train Epoch: 5 [4480/14860 (30%)]\tLoss: 0.016946\n",
      "Train Epoch: 5 [4608/14860 (31%)]\tLoss: 0.024359\n",
      "Train Epoch: 5 [4736/14860 (32%)]\tLoss: 0.020176\n",
      "Train Epoch: 5 [4864/14860 (32%)]\tLoss: 0.019794\n",
      "Train Epoch: 5 [4992/14860 (33%)]\tLoss: 0.018934\n",
      "Train Epoch: 5 [5120/14860 (34%)]\tLoss: 0.020990\n",
      "Train Epoch: 5 [5248/14860 (35%)]\tLoss: 0.018776\n",
      "Train Epoch: 5 [5376/14860 (36%)]\tLoss: 0.022798\n",
      "Train Epoch: 5 [5504/14860 (37%)]\tLoss: 0.017892\n",
      "Train Epoch: 5 [5632/14860 (38%)]\tLoss: 0.019955\n",
      "Train Epoch: 5 [5760/14860 (38%)]\tLoss: 0.014187\n",
      "Train Epoch: 5 [5888/14860 (39%)]\tLoss: 0.023986\n",
      "Train Epoch: 5 [6016/14860 (40%)]\tLoss: 0.023362\n",
      "Train Epoch: 5 [6144/14860 (41%)]\tLoss: 0.019299\n",
      "Train Epoch: 5 [6272/14860 (42%)]\tLoss: 0.014650\n",
      "Train Epoch: 5 [6400/14860 (43%)]\tLoss: 0.025891\n",
      "Train Epoch: 5 [6528/14860 (44%)]\tLoss: 0.018888\n",
      "Train Epoch: 5 [6656/14860 (44%)]\tLoss: 0.030578\n",
      "Train Epoch: 5 [6784/14860 (45%)]\tLoss: 0.022823\n",
      "Train Epoch: 5 [6912/14860 (46%)]\tLoss: 0.029115\n",
      "Train Epoch: 5 [7040/14860 (47%)]\tLoss: 0.017905\n",
      "Train Epoch: 5 [7168/14860 (48%)]\tLoss: 0.015694\n",
      "Train Epoch: 5 [7296/14860 (49%)]\tLoss: 0.016732\n",
      "Train Epoch: 5 [7424/14860 (50%)]\tLoss: 0.016925\n",
      "Train Epoch: 5 [7552/14860 (50%)]\tLoss: 0.022694\n",
      "Train Epoch: 5 [7680/14860 (51%)]\tLoss: 0.021234\n",
      "Train Epoch: 5 [7808/14860 (52%)]\tLoss: 0.019075\n",
      "Train Epoch: 5 [7936/14860 (53%)]\tLoss: 0.017429\n",
      "Train Epoch: 5 [8064/14860 (54%)]\tLoss: 0.019044\n",
      "Train Epoch: 5 [8192/14860 (55%)]\tLoss: 0.022242\n",
      "Train Epoch: 5 [8320/14860 (56%)]\tLoss: 0.022958\n",
      "Train Epoch: 5 [8448/14860 (56%)]\tLoss: 0.025266\n",
      "Train Epoch: 5 [8576/14860 (57%)]\tLoss: 0.019638\n",
      "Train Epoch: 5 [8704/14860 (58%)]\tLoss: 0.026915\n",
      "Train Epoch: 5 [8832/14860 (59%)]\tLoss: 0.021033\n",
      "Train Epoch: 5 [8960/14860 (60%)]\tLoss: 0.023615\n",
      "Train Epoch: 5 [9088/14860 (61%)]\tLoss: 0.024202\n",
      "Train Epoch: 5 [9216/14860 (62%)]\tLoss: 0.028030\n",
      "Train Epoch: 5 [9344/14860 (62%)]\tLoss: 0.027314\n",
      "Train Epoch: 5 [9472/14860 (63%)]\tLoss: 0.019145\n",
      "Train Epoch: 5 [9600/14860 (64%)]\tLoss: 0.023649\n",
      "Train Epoch: 5 [9728/14860 (65%)]\tLoss: 0.020504\n",
      "Train Epoch: 5 [9856/14860 (66%)]\tLoss: 0.018583\n",
      "Train Epoch: 5 [9984/14860 (67%)]\tLoss: 0.019476\n",
      "Train Epoch: 5 [10112/14860 (68%)]\tLoss: 0.027292\n",
      "Train Epoch: 5 [10240/14860 (68%)]\tLoss: 0.025938\n",
      "Train Epoch: 5 [10368/14860 (69%)]\tLoss: 0.027434\n",
      "Train Epoch: 5 [10496/14860 (70%)]\tLoss: 0.029560\n",
      "Train Epoch: 5 [10624/14860 (71%)]\tLoss: 0.024498\n",
      "Train Epoch: 5 [10752/14860 (72%)]\tLoss: 0.024346\n",
      "Train Epoch: 5 [10880/14860 (73%)]\tLoss: 0.028935\n",
      "Train Epoch: 5 [11008/14860 (74%)]\tLoss: 0.020413\n",
      "Train Epoch: 5 [11136/14860 (74%)]\tLoss: 0.037489\n",
      "Train Epoch: 5 [11264/14860 (75%)]\tLoss: 0.019031\n",
      "Train Epoch: 5 [11392/14860 (76%)]\tLoss: 0.033361\n",
      "Train Epoch: 5 [11520/14860 (77%)]\tLoss: 0.019313\n",
      "Train Epoch: 5 [11648/14860 (78%)]\tLoss: 0.025463\n",
      "Train Epoch: 5 [11776/14860 (79%)]\tLoss: 0.030241\n",
      "Train Epoch: 5 [11904/14860 (79%)]\tLoss: 0.019689\n",
      "Train Epoch: 5 [12032/14860 (80%)]\tLoss: 0.015989\n",
      "Train Epoch: 5 [12160/14860 (81%)]\tLoss: 0.013555\n",
      "Train Epoch: 5 [12288/14860 (82%)]\tLoss: 0.031798\n",
      "Train Epoch: 5 [12416/14860 (83%)]\tLoss: 0.026965\n",
      "Train Epoch: 5 [12544/14860 (84%)]\tLoss: 0.024073\n",
      "Train Epoch: 5 [12672/14860 (85%)]\tLoss: 0.028635\n",
      "Train Epoch: 5 [12800/14860 (85%)]\tLoss: 0.020972\n",
      "Train Epoch: 5 [12928/14860 (86%)]\tLoss: 0.022402\n",
      "Train Epoch: 5 [13056/14860 (87%)]\tLoss: 0.029396\n",
      "Train Epoch: 5 [13184/14860 (88%)]\tLoss: 0.020723\n",
      "Train Epoch: 5 [13312/14860 (89%)]\tLoss: 0.023143\n",
      "Train Epoch: 5 [13440/14860 (90%)]\tLoss: 0.025676\n",
      "Train Epoch: 5 [13568/14860 (91%)]\tLoss: 0.022621\n",
      "Train Epoch: 5 [13696/14860 (91%)]\tLoss: 0.031333\n",
      "Train Epoch: 5 [13824/14860 (92%)]\tLoss: 0.023685\n",
      "Train Epoch: 5 [13952/14860 (93%)]\tLoss: 0.019857\n",
      "Train Epoch: 5 [14080/14860 (94%)]\tLoss: 0.032822\n",
      "Train Epoch: 5 [14208/14860 (95%)]\tLoss: 0.023168\n",
      "Train Epoch: 5 [14336/14860 (96%)]\tLoss: 0.023230\n",
      "Train Epoch: 5 [14464/14860 (97%)]\tLoss: 0.015487\n",
      "Train Epoch: 5 [14592/14860 (97%)]\tLoss: 0.032824\n",
      "Train Epoch: 5 [14720/14860 (98%)]\tLoss: 0.019615\n",
      "Train Epoch: 5 [1392/14860 (99%)]\tLoss: 0.012673\n",
      "epoch 5 training loss: 0.02273109488380261\n",
      "epoch 5 validation loss: 0.02239346013519435\n",
      "Train Epoch: 6 [0/14860 (0%)]\tLoss: 0.014606\n",
      "Train Epoch: 6 [128/14860 (1%)]\tLoss: 0.028290\n",
      "Train Epoch: 6 [256/14860 (2%)]\tLoss: 0.021415\n",
      "Train Epoch: 6 [384/14860 (3%)]\tLoss: 0.025396\n",
      "Train Epoch: 6 [512/14860 (3%)]\tLoss: 0.021063\n",
      "Train Epoch: 6 [640/14860 (4%)]\tLoss: 0.020750\n",
      "Train Epoch: 6 [768/14860 (5%)]\tLoss: 0.019472\n",
      "Train Epoch: 6 [896/14860 (6%)]\tLoss: 0.016814\n",
      "Train Epoch: 6 [1024/14860 (7%)]\tLoss: 0.024207\n",
      "Train Epoch: 6 [1152/14860 (8%)]\tLoss: 0.015964\n",
      "Train Epoch: 6 [1280/14860 (9%)]\tLoss: 0.018147\n",
      "Train Epoch: 6 [1408/14860 (9%)]\tLoss: 0.022678\n",
      "Train Epoch: 6 [1536/14860 (10%)]\tLoss: 0.014855\n",
      "Train Epoch: 6 [1664/14860 (11%)]\tLoss: 0.022543\n",
      "Train Epoch: 6 [1792/14860 (12%)]\tLoss: 0.025013\n",
      "Train Epoch: 6 [1920/14860 (13%)]\tLoss: 0.020725\n",
      "Train Epoch: 6 [2048/14860 (14%)]\tLoss: 0.025070\n",
      "Train Epoch: 6 [2176/14860 (15%)]\tLoss: 0.020941\n",
      "Train Epoch: 6 [2304/14860 (15%)]\tLoss: 0.018471\n",
      "Train Epoch: 6 [2432/14860 (16%)]\tLoss: 0.032507\n",
      "Train Epoch: 6 [2560/14860 (17%)]\tLoss: 0.026723\n",
      "Train Epoch: 6 [2688/14860 (18%)]\tLoss: 0.030186\n",
      "Train Epoch: 6 [2816/14860 (19%)]\tLoss: 0.033064\n",
      "Train Epoch: 6 [2944/14860 (20%)]\tLoss: 0.017844\n",
      "Train Epoch: 6 [3072/14860 (21%)]\tLoss: 0.027787\n",
      "Train Epoch: 6 [3200/14860 (21%)]\tLoss: 0.021373\n",
      "Train Epoch: 6 [3328/14860 (22%)]\tLoss: 0.033311\n",
      "Train Epoch: 6 [3456/14860 (23%)]\tLoss: 0.021938\n",
      "Train Epoch: 6 [3584/14860 (24%)]\tLoss: 0.031904\n",
      "Train Epoch: 6 [3712/14860 (25%)]\tLoss: 0.020708\n",
      "Train Epoch: 6 [3840/14860 (26%)]\tLoss: 0.041366\n",
      "Train Epoch: 6 [3968/14860 (26%)]\tLoss: 0.026045\n",
      "Train Epoch: 6 [4096/14860 (27%)]\tLoss: 0.026115\n",
      "Train Epoch: 6 [4224/14860 (28%)]\tLoss: 0.019242\n",
      "Train Epoch: 6 [4352/14860 (29%)]\tLoss: 0.031374\n",
      "Train Epoch: 6 [4480/14860 (30%)]\tLoss: 0.025500\n",
      "Train Epoch: 6 [4608/14860 (31%)]\tLoss: 0.022802\n",
      "Train Epoch: 6 [4736/14860 (32%)]\tLoss: 0.035856\n",
      "Train Epoch: 6 [4864/14860 (32%)]\tLoss: 0.020116\n",
      "Train Epoch: 6 [4992/14860 (33%)]\tLoss: 0.031830\n",
      "Train Epoch: 6 [5120/14860 (34%)]\tLoss: 0.015778\n",
      "Train Epoch: 6 [5248/14860 (35%)]\tLoss: 0.045381\n",
      "Train Epoch: 6 [5376/14860 (36%)]\tLoss: 0.018749\n",
      "Train Epoch: 6 [5504/14860 (37%)]\tLoss: 0.028716\n",
      "Train Epoch: 6 [5632/14860 (38%)]\tLoss: 0.018578\n",
      "Train Epoch: 6 [5760/14860 (38%)]\tLoss: 0.030449\n",
      "Train Epoch: 6 [5888/14860 (39%)]\tLoss: 0.024234\n",
      "Train Epoch: 6 [6016/14860 (40%)]\tLoss: 0.024911\n",
      "Train Epoch: 6 [6144/14860 (41%)]\tLoss: 0.015367\n",
      "Train Epoch: 6 [6272/14860 (42%)]\tLoss: 0.017813\n",
      "Train Epoch: 6 [6400/14860 (43%)]\tLoss: 0.033601\n",
      "Train Epoch: 6 [6528/14860 (44%)]\tLoss: 0.027712\n",
      "Train Epoch: 6 [6656/14860 (44%)]\tLoss: 0.025547\n",
      "Train Epoch: 6 [6784/14860 (45%)]\tLoss: 0.034035\n",
      "Train Epoch: 6 [6912/14860 (46%)]\tLoss: 0.023184\n",
      "Train Epoch: 6 [7040/14860 (47%)]\tLoss: 0.021468\n",
      "Train Epoch: 6 [7168/14860 (48%)]\tLoss: 0.020086\n",
      "Train Epoch: 6 [7296/14860 (49%)]\tLoss: 0.023720\n",
      "Train Epoch: 6 [7424/14860 (50%)]\tLoss: 0.023006\n",
      "Train Epoch: 6 [7552/14860 (50%)]\tLoss: 0.026041\n",
      "Train Epoch: 6 [7680/14860 (51%)]\tLoss: 0.016544\n",
      "Train Epoch: 6 [7808/14860 (52%)]\tLoss: 0.029078\n",
      "Train Epoch: 6 [7936/14860 (53%)]\tLoss: 0.017506\n",
      "Train Epoch: 6 [8064/14860 (54%)]\tLoss: 0.032040\n",
      "Train Epoch: 6 [8192/14860 (55%)]\tLoss: 0.024950\n",
      "Train Epoch: 6 [8320/14860 (56%)]\tLoss: 0.028042\n",
      "Train Epoch: 6 [8448/14860 (56%)]\tLoss: 0.023294\n",
      "Train Epoch: 6 [8576/14860 (57%)]\tLoss: 0.018316\n",
      "Train Epoch: 6 [8704/14860 (58%)]\tLoss: 0.022813\n",
      "Train Epoch: 6 [8832/14860 (59%)]\tLoss: 0.019538\n",
      "Train Epoch: 6 [8960/14860 (60%)]\tLoss: 0.018803\n",
      "Train Epoch: 6 [9088/14860 (61%)]\tLoss: 0.023414\n",
      "Train Epoch: 6 [9216/14860 (62%)]\tLoss: 0.022388\n",
      "Train Epoch: 6 [9344/14860 (62%)]\tLoss: 0.018059\n",
      "Train Epoch: 6 [9472/14860 (63%)]\tLoss: 0.024148\n",
      "Train Epoch: 6 [9600/14860 (64%)]\tLoss: 0.019040\n",
      "Train Epoch: 6 [9728/14860 (65%)]\tLoss: 0.020102\n",
      "Train Epoch: 6 [9856/14860 (66%)]\tLoss: 0.016605\n",
      "Train Epoch: 6 [9984/14860 (67%)]\tLoss: 0.018673\n",
      "Train Epoch: 6 [10112/14860 (68%)]\tLoss: 0.023321\n",
      "Train Epoch: 6 [10240/14860 (68%)]\tLoss: 0.017261\n",
      "Train Epoch: 6 [10368/14860 (69%)]\tLoss: 0.021163\n",
      "Train Epoch: 6 [10496/14860 (70%)]\tLoss: 0.023982\n",
      "Train Epoch: 6 [10624/14860 (71%)]\tLoss: 0.018708\n",
      "Train Epoch: 6 [10752/14860 (72%)]\tLoss: 0.024704\n",
      "Train Epoch: 6 [10880/14860 (73%)]\tLoss: 0.022139\n",
      "Train Epoch: 6 [11008/14860 (74%)]\tLoss: 0.013344\n",
      "Train Epoch: 6 [11136/14860 (74%)]\tLoss: 0.018608\n",
      "Train Epoch: 6 [11264/14860 (75%)]\tLoss: 0.026272\n",
      "Train Epoch: 6 [11392/14860 (76%)]\tLoss: 0.017629\n",
      "Train Epoch: 6 [11520/14860 (77%)]\tLoss: 0.016302\n",
      "Train Epoch: 6 [11648/14860 (78%)]\tLoss: 0.035305\n",
      "Train Epoch: 6 [11776/14860 (79%)]\tLoss: 0.032424\n",
      "Train Epoch: 6 [11904/14860 (79%)]\tLoss: 0.016676\n",
      "Train Epoch: 6 [12032/14860 (80%)]\tLoss: 0.020783\n",
      "Train Epoch: 6 [12160/14860 (81%)]\tLoss: 0.025890\n",
      "Train Epoch: 6 [12288/14860 (82%)]\tLoss: 0.026015\n",
      "Train Epoch: 6 [12416/14860 (83%)]\tLoss: 0.022894\n",
      "Train Epoch: 6 [12544/14860 (84%)]\tLoss: 0.018407\n",
      "Train Epoch: 6 [12672/14860 (85%)]\tLoss: 0.030245\n",
      "Train Epoch: 6 [12800/14860 (85%)]\tLoss: 0.022898\n",
      "Train Epoch: 6 [12928/14860 (86%)]\tLoss: 0.021534\n",
      "Train Epoch: 6 [13056/14860 (87%)]\tLoss: 0.025175\n",
      "Train Epoch: 6 [13184/14860 (88%)]\tLoss: 0.027056\n",
      "Train Epoch: 6 [13312/14860 (89%)]\tLoss: 0.021317\n",
      "Train Epoch: 6 [13440/14860 (90%)]\tLoss: 0.028060\n",
      "Train Epoch: 6 [13568/14860 (91%)]\tLoss: 0.023646\n",
      "Train Epoch: 6 [13696/14860 (91%)]\tLoss: 0.016753\n",
      "Train Epoch: 6 [13824/14860 (92%)]\tLoss: 0.026340\n",
      "Train Epoch: 6 [13952/14860 (93%)]\tLoss: 0.016419\n",
      "Train Epoch: 6 [14080/14860 (94%)]\tLoss: 0.028316\n",
      "Train Epoch: 6 [14208/14860 (95%)]\tLoss: 0.017656\n",
      "Train Epoch: 6 [14336/14860 (96%)]\tLoss: 0.027881\n",
      "Train Epoch: 6 [14464/14860 (97%)]\tLoss: 0.019273\n",
      "Train Epoch: 6 [14592/14860 (97%)]\tLoss: 0.027679\n",
      "Train Epoch: 6 [14720/14860 (98%)]\tLoss: 0.019413\n",
      "Train Epoch: 6 [1392/14860 (99%)]\tLoss: 0.008835\n",
      "epoch 6 training loss: 0.023385166333845027\n",
      "epoch 6 validation loss: 0.02215847048286087\n",
      "Train Epoch: 7 [0/14860 (0%)]\tLoss: 0.016949\n",
      "Train Epoch: 7 [128/14860 (1%)]\tLoss: 0.023594\n",
      "Train Epoch: 7 [256/14860 (2%)]\tLoss: 0.026153\n",
      "Train Epoch: 7 [384/14860 (3%)]\tLoss: 0.033613\n",
      "Train Epoch: 7 [512/14860 (3%)]\tLoss: 0.022073\n",
      "Train Epoch: 7 [640/14860 (4%)]\tLoss: 0.039664\n",
      "Train Epoch: 7 [768/14860 (5%)]\tLoss: 0.030567\n",
      "Train Epoch: 7 [896/14860 (6%)]\tLoss: 0.027276\n",
      "Train Epoch: 7 [1024/14860 (7%)]\tLoss: 0.028384\n",
      "Train Epoch: 7 [1152/14860 (8%)]\tLoss: 0.031244\n",
      "Train Epoch: 7 [1280/14860 (9%)]\tLoss: 0.039794\n",
      "Train Epoch: 7 [1408/14860 (9%)]\tLoss: 0.019930\n",
      "Train Epoch: 7 [1536/14860 (10%)]\tLoss: 0.037692\n",
      "Train Epoch: 7 [1664/14860 (11%)]\tLoss: 0.019072\n",
      "Train Epoch: 7 [1792/14860 (12%)]\tLoss: 0.033872\n",
      "Train Epoch: 7 [1920/14860 (13%)]\tLoss: 0.019430\n",
      "Train Epoch: 7 [2048/14860 (14%)]\tLoss: 0.030576\n",
      "Train Epoch: 7 [2176/14860 (15%)]\tLoss: 0.026762\n",
      "Train Epoch: 7 [2304/14860 (15%)]\tLoss: 0.029962\n",
      "Train Epoch: 7 [2432/14860 (16%)]\tLoss: 0.030751\n",
      "Train Epoch: 7 [2560/14860 (17%)]\tLoss: 0.028231\n",
      "Train Epoch: 7 [2688/14860 (18%)]\tLoss: 0.019599\n",
      "Train Epoch: 7 [2816/14860 (19%)]\tLoss: 0.026337\n",
      "Train Epoch: 7 [2944/14860 (20%)]\tLoss: 0.017951\n",
      "Train Epoch: 7 [3072/14860 (21%)]\tLoss: 0.018401\n",
      "Train Epoch: 7 [3200/14860 (21%)]\tLoss: 0.023384\n",
      "Train Epoch: 7 [3328/14860 (22%)]\tLoss: 0.030781\n",
      "Train Epoch: 7 [3456/14860 (23%)]\tLoss: 0.016219\n",
      "Train Epoch: 7 [3584/14860 (24%)]\tLoss: 0.020658\n",
      "Train Epoch: 7 [3712/14860 (25%)]\tLoss: 0.022426\n",
      "Train Epoch: 7 [3840/14860 (26%)]\tLoss: 0.035487\n",
      "Train Epoch: 7 [3968/14860 (26%)]\tLoss: 0.015843\n",
      "Train Epoch: 7 [4096/14860 (27%)]\tLoss: 0.024031\n",
      "Train Epoch: 7 [4224/14860 (28%)]\tLoss: 0.018093\n",
      "Train Epoch: 7 [4352/14860 (29%)]\tLoss: 0.024453\n",
      "Train Epoch: 7 [4480/14860 (30%)]\tLoss: 0.024431\n",
      "Train Epoch: 7 [4608/14860 (31%)]\tLoss: 0.022520\n",
      "Train Epoch: 7 [4736/14860 (32%)]\tLoss: 0.020852\n",
      "Train Epoch: 7 [4864/14860 (32%)]\tLoss: 0.025357\n",
      "Train Epoch: 7 [4992/14860 (33%)]\tLoss: 0.022775\n",
      "Train Epoch: 7 [5120/14860 (34%)]\tLoss: 0.022980\n",
      "Train Epoch: 7 [5248/14860 (35%)]\tLoss: 0.019923\n",
      "Train Epoch: 7 [5376/14860 (36%)]\tLoss: 0.025279\n",
      "Train Epoch: 7 [5504/14860 (37%)]\tLoss: 0.021674\n",
      "Train Epoch: 7 [5632/14860 (38%)]\tLoss: 0.026256\n",
      "Train Epoch: 7 [5760/14860 (38%)]\tLoss: 0.023413\n",
      "Train Epoch: 7 [5888/14860 (39%)]\tLoss: 0.023276\n",
      "Train Epoch: 7 [6016/14860 (40%)]\tLoss: 0.023354\n",
      "Train Epoch: 7 [6144/14860 (41%)]\tLoss: 0.024487\n",
      "Train Epoch: 7 [6272/14860 (42%)]\tLoss: 0.021682\n",
      "Train Epoch: 7 [6400/14860 (43%)]\tLoss: 0.016447\n",
      "Train Epoch: 7 [6528/14860 (44%)]\tLoss: 0.025375\n",
      "Train Epoch: 7 [6656/14860 (44%)]\tLoss: 0.022350\n",
      "Train Epoch: 7 [6784/14860 (45%)]\tLoss: 0.023469\n",
      "Train Epoch: 7 [6912/14860 (46%)]\tLoss: 0.025938\n",
      "Train Epoch: 7 [7040/14860 (47%)]\tLoss: 0.024630\n",
      "Train Epoch: 7 [7168/14860 (48%)]\tLoss: 0.023663\n",
      "Train Epoch: 7 [7296/14860 (49%)]\tLoss: 0.027885\n",
      "Train Epoch: 7 [7424/14860 (50%)]\tLoss: 0.019806\n",
      "Train Epoch: 7 [7552/14860 (50%)]\tLoss: 0.027764\n",
      "Train Epoch: 7 [7680/14860 (51%)]\tLoss: 0.017155\n",
      "Train Epoch: 7 [7808/14860 (52%)]\tLoss: 0.022596\n",
      "Train Epoch: 7 [7936/14860 (53%)]\tLoss: 0.023688\n",
      "Train Epoch: 7 [8064/14860 (54%)]\tLoss: 0.027737\n",
      "Train Epoch: 7 [8192/14860 (55%)]\tLoss: 0.023410\n",
      "Train Epoch: 7 [8320/14860 (56%)]\tLoss: 0.025931\n",
      "Train Epoch: 7 [8448/14860 (56%)]\tLoss: 0.022102\n",
      "Train Epoch: 7 [8576/14860 (57%)]\tLoss: 0.024353\n",
      "Train Epoch: 7 [8704/14860 (58%)]\tLoss: 0.020683\n",
      "Train Epoch: 7 [8832/14860 (59%)]\tLoss: 0.028682\n",
      "Train Epoch: 7 [8960/14860 (60%)]\tLoss: 0.031268\n",
      "Train Epoch: 7 [9088/14860 (61%)]\tLoss: 0.021621\n",
      "Train Epoch: 7 [9216/14860 (62%)]\tLoss: 0.024887\n",
      "Train Epoch: 7 [9344/14860 (62%)]\tLoss: 0.023811\n",
      "Train Epoch: 7 [9472/14860 (63%)]\tLoss: 0.021664\n",
      "Train Epoch: 7 [9600/14860 (64%)]\tLoss: 0.021729\n",
      "Train Epoch: 7 [9728/14860 (65%)]\tLoss: 0.021603\n",
      "Train Epoch: 7 [9856/14860 (66%)]\tLoss: 0.021969\n",
      "Train Epoch: 7 [9984/14860 (67%)]\tLoss: 0.026283\n",
      "Train Epoch: 7 [10112/14860 (68%)]\tLoss: 0.018227\n",
      "Train Epoch: 7 [10240/14860 (68%)]\tLoss: 0.034861\n",
      "Train Epoch: 7 [10368/14860 (69%)]\tLoss: 0.016147\n",
      "Train Epoch: 7 [10496/14860 (70%)]\tLoss: 0.030247\n",
      "Train Epoch: 7 [10624/14860 (71%)]\tLoss: 0.018260\n",
      "Train Epoch: 7 [10752/14860 (72%)]\tLoss: 0.030226\n",
      "Train Epoch: 7 [10880/14860 (73%)]\tLoss: 0.020186\n",
      "Train Epoch: 7 [11008/14860 (74%)]\tLoss: 0.023770\n",
      "Train Epoch: 7 [11136/14860 (74%)]\tLoss: 0.021983\n",
      "Train Epoch: 7 [11264/14860 (75%)]\tLoss: 0.026764\n",
      "Train Epoch: 7 [11392/14860 (76%)]\tLoss: 0.020539\n",
      "Train Epoch: 7 [11520/14860 (77%)]\tLoss: 0.015059\n",
      "Train Epoch: 7 [11648/14860 (78%)]\tLoss: 0.029451\n",
      "Train Epoch: 7 [11776/14860 (79%)]\tLoss: 0.019609\n",
      "Train Epoch: 7 [11904/14860 (79%)]\tLoss: 0.027041\n",
      "Train Epoch: 7 [12032/14860 (80%)]\tLoss: 0.017206\n",
      "Train Epoch: 7 [12160/14860 (81%)]\tLoss: 0.022237\n",
      "Train Epoch: 7 [12288/14860 (82%)]\tLoss: 0.018094\n",
      "Train Epoch: 7 [12416/14860 (83%)]\tLoss: 0.024889\n",
      "Train Epoch: 7 [12544/14860 (84%)]\tLoss: 0.032499\n",
      "Train Epoch: 7 [12672/14860 (85%)]\tLoss: 0.020749\n",
      "Train Epoch: 7 [12800/14860 (85%)]\tLoss: 0.020131\n",
      "Train Epoch: 7 [12928/14860 (86%)]\tLoss: 0.020095\n",
      "Train Epoch: 7 [13056/14860 (87%)]\tLoss: 0.015313\n",
      "Train Epoch: 7 [13184/14860 (88%)]\tLoss: 0.015621\n",
      "Train Epoch: 7 [13312/14860 (89%)]\tLoss: 0.019181\n",
      "Train Epoch: 7 [13440/14860 (90%)]\tLoss: 0.015142\n",
      "Train Epoch: 7 [13568/14860 (91%)]\tLoss: 0.014222\n",
      "Train Epoch: 7 [13696/14860 (91%)]\tLoss: 0.026495\n",
      "Train Epoch: 7 [13824/14860 (92%)]\tLoss: 0.014367\n",
      "Train Epoch: 7 [13952/14860 (93%)]\tLoss: 0.019292\n",
      "Train Epoch: 7 [14080/14860 (94%)]\tLoss: 0.018374\n",
      "Train Epoch: 7 [14208/14860 (95%)]\tLoss: 0.019448\n",
      "Train Epoch: 7 [14336/14860 (96%)]\tLoss: 0.020058\n",
      "Train Epoch: 7 [14464/14860 (97%)]\tLoss: 0.026915\n",
      "Train Epoch: 7 [14592/14860 (97%)]\tLoss: 0.028287\n",
      "Train Epoch: 7 [14720/14860 (98%)]\tLoss: 0.016375\n",
      "Train Epoch: 7 [1392/14860 (99%)]\tLoss: 0.009808\n",
      "epoch 7 training loss: 0.023531445994591102\n",
      "epoch 7 validation loss: 0.024698215304506315\n",
      "Train Epoch: 8 [0/14860 (0%)]\tLoss: 0.032713\n",
      "Train Epoch: 8 [128/14860 (1%)]\tLoss: 0.025088\n",
      "Train Epoch: 8 [256/14860 (2%)]\tLoss: 0.024397\n",
      "Train Epoch: 8 [384/14860 (3%)]\tLoss: 0.016760\n",
      "Train Epoch: 8 [512/14860 (3%)]\tLoss: 0.016946\n",
      "Train Epoch: 8 [640/14860 (4%)]\tLoss: 0.034631\n",
      "Train Epoch: 8 [768/14860 (5%)]\tLoss: 0.037596\n",
      "Train Epoch: 8 [896/14860 (6%)]\tLoss: 0.028408\n",
      "Train Epoch: 8 [1024/14860 (7%)]\tLoss: 0.020814\n",
      "Train Epoch: 8 [1152/14860 (8%)]\tLoss: 0.020614\n",
      "Train Epoch: 8 [1280/14860 (9%)]\tLoss: 0.022016\n",
      "Train Epoch: 8 [1408/14860 (9%)]\tLoss: 0.014401\n",
      "Train Epoch: 8 [1536/14860 (10%)]\tLoss: 0.025702\n",
      "Train Epoch: 8 [1664/14860 (11%)]\tLoss: 0.023177\n",
      "Train Epoch: 8 [1792/14860 (12%)]\tLoss: 0.020063\n",
      "Train Epoch: 8 [1920/14860 (13%)]\tLoss: 0.022661\n",
      "Train Epoch: 8 [2048/14860 (14%)]\tLoss: 0.026927\n",
      "Train Epoch: 8 [2176/14860 (15%)]\tLoss: 0.029351\n",
      "Train Epoch: 8 [2304/14860 (15%)]\tLoss: 0.020980\n",
      "Train Epoch: 8 [2432/14860 (16%)]\tLoss: 0.013718\n",
      "Train Epoch: 8 [2560/14860 (17%)]\tLoss: 0.032070\n",
      "Train Epoch: 8 [2688/14860 (18%)]\tLoss: 0.025149\n",
      "Train Epoch: 8 [2816/14860 (19%)]\tLoss: 0.016123\n",
      "Train Epoch: 8 [2944/14860 (20%)]\tLoss: 0.029605\n",
      "Train Epoch: 8 [3072/14860 (21%)]\tLoss: 0.018022\n",
      "Train Epoch: 8 [3200/14860 (21%)]\tLoss: 0.036686\n",
      "Train Epoch: 8 [3328/14860 (22%)]\tLoss: 0.021755\n",
      "Train Epoch: 8 [3456/14860 (23%)]\tLoss: 0.028087\n",
      "Train Epoch: 8 [3584/14860 (24%)]\tLoss: 0.020516\n",
      "Train Epoch: 8 [3712/14860 (25%)]\tLoss: 0.024882\n",
      "Train Epoch: 8 [3840/14860 (26%)]\tLoss: 0.024921\n",
      "Train Epoch: 8 [3968/14860 (26%)]\tLoss: 0.016854\n",
      "Train Epoch: 8 [4096/14860 (27%)]\tLoss: 0.022791\n",
      "Train Epoch: 8 [4224/14860 (28%)]\tLoss: 0.014694\n",
      "Train Epoch: 8 [4352/14860 (29%)]\tLoss: 0.025903\n",
      "Train Epoch: 8 [4480/14860 (30%)]\tLoss: 0.020817\n",
      "Train Epoch: 8 [4608/14860 (31%)]\tLoss: 0.023589\n",
      "Train Epoch: 8 [4736/14860 (32%)]\tLoss: 0.021565\n",
      "Train Epoch: 8 [4864/14860 (32%)]\tLoss: 0.022305\n",
      "Train Epoch: 8 [4992/14860 (33%)]\tLoss: 0.024045\n",
      "Train Epoch: 8 [5120/14860 (34%)]\tLoss: 0.022893\n",
      "Train Epoch: 8 [5248/14860 (35%)]\tLoss: 0.018070\n",
      "Train Epoch: 8 [5376/14860 (36%)]\tLoss: 0.023196\n",
      "Train Epoch: 8 [5504/14860 (37%)]\tLoss: 0.022198\n",
      "Train Epoch: 8 [5632/14860 (38%)]\tLoss: 0.019973\n",
      "Train Epoch: 8 [5760/14860 (38%)]\tLoss: 0.018663\n",
      "Train Epoch: 8 [5888/14860 (39%)]\tLoss: 0.020423\n",
      "Train Epoch: 8 [6016/14860 (40%)]\tLoss: 0.016636\n",
      "Train Epoch: 8 [6144/14860 (41%)]\tLoss: 0.024125\n",
      "Train Epoch: 8 [6272/14860 (42%)]\tLoss: 0.027474\n",
      "Train Epoch: 8 [6400/14860 (43%)]\tLoss: 0.017492\n",
      "Train Epoch: 8 [6528/14860 (44%)]\tLoss: 0.023490\n",
      "Train Epoch: 8 [6656/14860 (44%)]\tLoss: 0.022154\n",
      "Train Epoch: 8 [6784/14860 (45%)]\tLoss: 0.019249\n",
      "Train Epoch: 8 [6912/14860 (46%)]\tLoss: 0.025712\n",
      "Train Epoch: 8 [7040/14860 (47%)]\tLoss: 0.022505\n",
      "Train Epoch: 8 [7168/14860 (48%)]\tLoss: 0.022273\n",
      "Train Epoch: 8 [7296/14860 (49%)]\tLoss: 0.020727\n",
      "Train Epoch: 8 [7424/14860 (50%)]\tLoss: 0.020803\n",
      "Train Epoch: 8 [7552/14860 (50%)]\tLoss: 0.023253\n",
      "Train Epoch: 8 [7680/14860 (51%)]\tLoss: 0.026430\n",
      "Train Epoch: 8 [7808/14860 (52%)]\tLoss: 0.021554\n",
      "Train Epoch: 8 [7936/14860 (53%)]\tLoss: 0.012536\n",
      "Train Epoch: 8 [8064/14860 (54%)]\tLoss: 0.027400\n",
      "Train Epoch: 8 [8192/14860 (55%)]\tLoss: 0.024791\n",
      "Train Epoch: 8 [8320/14860 (56%)]\tLoss: 0.030617\n",
      "Train Epoch: 8 [8448/14860 (56%)]\tLoss: 0.021427\n",
      "Train Epoch: 8 [8576/14860 (57%)]\tLoss: 0.037276\n",
      "Train Epoch: 8 [8704/14860 (58%)]\tLoss: 0.028584\n",
      "Train Epoch: 8 [8832/14860 (59%)]\tLoss: 0.049108\n",
      "Train Epoch: 8 [8960/14860 (60%)]\tLoss: 0.043523\n",
      "Train Epoch: 8 [9088/14860 (61%)]\tLoss: 0.030197\n",
      "Train Epoch: 8 [9216/14860 (62%)]\tLoss: 0.034674\n",
      "Train Epoch: 8 [9344/14860 (62%)]\tLoss: 0.032597\n",
      "Train Epoch: 8 [9472/14860 (63%)]\tLoss: 0.044168\n",
      "Train Epoch: 8 [9600/14860 (64%)]\tLoss: 0.039928\n",
      "Train Epoch: 8 [9728/14860 (65%)]\tLoss: 0.060037\n",
      "Train Epoch: 8 [9856/14860 (66%)]\tLoss: 0.027654\n",
      "Train Epoch: 8 [9984/14860 (67%)]\tLoss: 0.061500\n",
      "Train Epoch: 8 [10112/14860 (68%)]\tLoss: 0.028332\n",
      "Train Epoch: 8 [10240/14860 (68%)]\tLoss: 0.047913\n",
      "Train Epoch: 8 [10368/14860 (69%)]\tLoss: 0.027063\n",
      "Train Epoch: 8 [10496/14860 (70%)]\tLoss: 0.033268\n",
      "Train Epoch: 8 [10624/14860 (71%)]\tLoss: 0.038677\n",
      "Train Epoch: 8 [10752/14860 (72%)]\tLoss: 0.027992\n",
      "Train Epoch: 8 [10880/14860 (73%)]\tLoss: 0.022094\n",
      "Train Epoch: 8 [11008/14860 (74%)]\tLoss: 0.021736\n",
      "Train Epoch: 8 [11136/14860 (74%)]\tLoss: 0.036088\n",
      "Train Epoch: 8 [11264/14860 (75%)]\tLoss: 0.022546\n",
      "Train Epoch: 8 [11392/14860 (76%)]\tLoss: 0.024802\n",
      "Train Epoch: 8 [11520/14860 (77%)]\tLoss: 0.026343\n",
      "Train Epoch: 8 [11648/14860 (78%)]\tLoss: 0.021753\n",
      "Train Epoch: 8 [11776/14860 (79%)]\tLoss: 0.021002\n",
      "Train Epoch: 8 [11904/14860 (79%)]\tLoss: 0.023922\n",
      "Train Epoch: 8 [12032/14860 (80%)]\tLoss: 0.024261\n",
      "Train Epoch: 8 [12160/14860 (81%)]\tLoss: 0.020741\n",
      "Train Epoch: 8 [12288/14860 (82%)]\tLoss: 0.023794\n",
      "Train Epoch: 8 [12416/14860 (83%)]\tLoss: 0.021684\n",
      "Train Epoch: 8 [12544/14860 (84%)]\tLoss: 0.023121\n",
      "Train Epoch: 8 [12672/14860 (85%)]\tLoss: 0.020992\n",
      "Train Epoch: 8 [12800/14860 (85%)]\tLoss: 0.019475\n",
      "Train Epoch: 8 [12928/14860 (86%)]\tLoss: 0.025049\n",
      "Train Epoch: 8 [13056/14860 (87%)]\tLoss: 0.021752\n",
      "Train Epoch: 8 [13184/14860 (88%)]\tLoss: 0.021263\n",
      "Train Epoch: 8 [13312/14860 (89%)]\tLoss: 0.018554\n",
      "Train Epoch: 8 [13440/14860 (90%)]\tLoss: 0.012579\n",
      "Train Epoch: 8 [13568/14860 (91%)]\tLoss: 0.020787\n",
      "Train Epoch: 8 [13696/14860 (91%)]\tLoss: 0.020354\n",
      "Train Epoch: 8 [13824/14860 (92%)]\tLoss: 0.030298\n",
      "Train Epoch: 8 [13952/14860 (93%)]\tLoss: 0.025555\n",
      "Train Epoch: 8 [14080/14860 (94%)]\tLoss: 0.020092\n",
      "Train Epoch: 8 [14208/14860 (95%)]\tLoss: 0.021215\n",
      "Train Epoch: 8 [14336/14860 (96%)]\tLoss: 0.035255\n",
      "Train Epoch: 8 [14464/14860 (97%)]\tLoss: 0.033198\n",
      "Train Epoch: 8 [14592/14860 (97%)]\tLoss: 0.027151\n",
      "Train Epoch: 8 [14720/14860 (98%)]\tLoss: 0.024479\n",
      "Train Epoch: 8 [1392/14860 (99%)]\tLoss: 0.050364\n",
      "epoch 8 training loss: 0.025796545534116082\n",
      "epoch 8 validation loss: 0.025072574182514993\n",
      "Train Epoch: 9 [0/14860 (0%)]\tLoss: 0.021631\n",
      "Train Epoch: 9 [128/14860 (1%)]\tLoss: 0.033455\n",
      "Train Epoch: 9 [256/14860 (2%)]\tLoss: 0.023344\n",
      "Train Epoch: 9 [384/14860 (3%)]\tLoss: 0.035374\n",
      "Train Epoch: 9 [512/14860 (3%)]\tLoss: 0.019374\n",
      "Train Epoch: 9 [640/14860 (4%)]\tLoss: 0.032759\n",
      "Train Epoch: 9 [768/14860 (5%)]\tLoss: 0.027721\n",
      "Train Epoch: 9 [896/14860 (6%)]\tLoss: 0.020276\n",
      "Train Epoch: 9 [1024/14860 (7%)]\tLoss: 0.032409\n",
      "Train Epoch: 9 [1152/14860 (8%)]\tLoss: 0.026459\n",
      "Train Epoch: 9 [1280/14860 (9%)]\tLoss: 0.025797\n",
      "Train Epoch: 9 [1408/14860 (9%)]\tLoss: 0.031111\n",
      "Train Epoch: 9 [1536/14860 (10%)]\tLoss: 0.028638\n",
      "Train Epoch: 9 [1664/14860 (11%)]\tLoss: 0.018570\n",
      "Train Epoch: 9 [1792/14860 (12%)]\tLoss: 0.024342\n",
      "Train Epoch: 9 [1920/14860 (13%)]\tLoss: 0.019187\n",
      "Train Epoch: 9 [2048/14860 (14%)]\tLoss: 0.022821\n",
      "Train Epoch: 9 [2176/14860 (15%)]\tLoss: 0.015524\n",
      "Train Epoch: 9 [2304/14860 (15%)]\tLoss: 0.022378\n",
      "Train Epoch: 9 [2432/14860 (16%)]\tLoss: 0.021344\n",
      "Train Epoch: 9 [2560/14860 (17%)]\tLoss: 0.024616\n",
      "Train Epoch: 9 [2688/14860 (18%)]\tLoss: 0.014523\n",
      "Train Epoch: 9 [2816/14860 (19%)]\tLoss: 0.021950\n",
      "Train Epoch: 9 [2944/14860 (20%)]\tLoss: 0.019274\n",
      "Train Epoch: 9 [3072/14860 (21%)]\tLoss: 0.023072\n",
      "Train Epoch: 9 [3200/14860 (21%)]\tLoss: 0.022414\n",
      "Train Epoch: 9 [3328/14860 (22%)]\tLoss: 0.021387\n",
      "Train Epoch: 9 [3456/14860 (23%)]\tLoss: 0.026214\n",
      "Train Epoch: 9 [3584/14860 (24%)]\tLoss: 0.026029\n",
      "Train Epoch: 9 [3712/14860 (25%)]\tLoss: 0.022943\n",
      "Train Epoch: 9 [3840/14860 (26%)]\tLoss: 0.019056\n",
      "Train Epoch: 9 [3968/14860 (26%)]\tLoss: 0.019142\n",
      "Train Epoch: 9 [4096/14860 (27%)]\tLoss: 0.016109\n",
      "Train Epoch: 9 [4224/14860 (28%)]\tLoss: 0.025824\n",
      "Train Epoch: 9 [4352/14860 (29%)]\tLoss: 0.018840\n",
      "Train Epoch: 9 [4480/14860 (30%)]\tLoss: 0.019039\n",
      "Train Epoch: 9 [4608/14860 (31%)]\tLoss: 0.014327\n",
      "Train Epoch: 9 [4736/14860 (32%)]\tLoss: 0.025516\n",
      "Train Epoch: 9 [4864/14860 (32%)]\tLoss: 0.020404\n",
      "Train Epoch: 9 [4992/14860 (33%)]\tLoss: 0.021721\n",
      "Train Epoch: 9 [5120/14860 (34%)]\tLoss: 0.029464\n",
      "Train Epoch: 9 [5248/14860 (35%)]\tLoss: 0.021289\n",
      "Train Epoch: 9 [5376/14860 (36%)]\tLoss: 0.014684\n",
      "Train Epoch: 9 [5504/14860 (37%)]\tLoss: 0.015810\n",
      "Train Epoch: 9 [5632/14860 (38%)]\tLoss: 0.017599\n",
      "Train Epoch: 9 [5760/14860 (38%)]\tLoss: 0.022117\n",
      "Train Epoch: 9 [5888/14860 (39%)]\tLoss: 0.030874\n",
      "Train Epoch: 9 [6016/14860 (40%)]\tLoss: 0.022592\n",
      "Train Epoch: 9 [6144/14860 (41%)]\tLoss: 0.021915\n",
      "Train Epoch: 9 [6272/14860 (42%)]\tLoss: 0.019392\n",
      "Train Epoch: 9 [6400/14860 (43%)]\tLoss: 0.022380\n",
      "Train Epoch: 9 [6528/14860 (44%)]\tLoss: 0.016848\n",
      "Train Epoch: 9 [6656/14860 (44%)]\tLoss: 0.018019\n",
      "Train Epoch: 9 [6784/14860 (45%)]\tLoss: 0.036380\n",
      "Train Epoch: 9 [6912/14860 (46%)]\tLoss: 0.028455\n",
      "Train Epoch: 9 [7040/14860 (47%)]\tLoss: 0.028658\n",
      "Train Epoch: 9 [7168/14860 (48%)]\tLoss: 0.028380\n",
      "Train Epoch: 9 [7296/14860 (49%)]\tLoss: 0.030953\n",
      "Train Epoch: 9 [7424/14860 (50%)]\tLoss: 0.034204\n",
      "Train Epoch: 9 [7552/14860 (50%)]\tLoss: 0.024475\n",
      "Train Epoch: 9 [7680/14860 (51%)]\tLoss: 0.024405\n",
      "Train Epoch: 9 [7808/14860 (52%)]\tLoss: 0.027030\n",
      "Train Epoch: 9 [7936/14860 (53%)]\tLoss: 0.027904\n",
      "Train Epoch: 9 [8064/14860 (54%)]\tLoss: 0.030033\n",
      "Train Epoch: 9 [8192/14860 (55%)]\tLoss: 0.018099\n",
      "Train Epoch: 9 [8320/14860 (56%)]\tLoss: 0.026938\n",
      "Train Epoch: 9 [8448/14860 (56%)]\tLoss: 0.018306\n",
      "Train Epoch: 9 [8576/14860 (57%)]\tLoss: 0.032771\n",
      "Train Epoch: 9 [8704/14860 (58%)]\tLoss: 0.023472\n",
      "Train Epoch: 9 [8832/14860 (59%)]\tLoss: 0.031222\n",
      "Train Epoch: 9 [8960/14860 (60%)]\tLoss: 0.018853\n",
      "Train Epoch: 9 [9088/14860 (61%)]\tLoss: 0.024829\n",
      "Train Epoch: 9 [9216/14860 (62%)]\tLoss: 0.025658\n",
      "Train Epoch: 9 [9344/14860 (62%)]\tLoss: 0.023815\n",
      "Train Epoch: 9 [9472/14860 (63%)]\tLoss: 0.021920\n",
      "Train Epoch: 9 [9600/14860 (64%)]\tLoss: 0.023880\n",
      "Train Epoch: 9 [9728/14860 (65%)]\tLoss: 0.019335\n",
      "Train Epoch: 9 [9856/14860 (66%)]\tLoss: 0.025254\n",
      "Train Epoch: 9 [9984/14860 (67%)]\tLoss: 0.024332\n",
      "Train Epoch: 9 [10112/14860 (68%)]\tLoss: 0.033929\n",
      "Train Epoch: 9 [10240/14860 (68%)]\tLoss: 0.024830\n",
      "Train Epoch: 9 [10368/14860 (69%)]\tLoss: 0.024670\n",
      "Train Epoch: 9 [10496/14860 (70%)]\tLoss: 0.017884\n",
      "Train Epoch: 9 [10624/14860 (71%)]\tLoss: 0.019508\n",
      "Train Epoch: 9 [10752/14860 (72%)]\tLoss: 0.021956\n",
      "Train Epoch: 9 [10880/14860 (73%)]\tLoss: 0.024621\n",
      "Train Epoch: 9 [11008/14860 (74%)]\tLoss: 0.022506\n",
      "Train Epoch: 9 [11136/14860 (74%)]\tLoss: 0.016228\n",
      "Train Epoch: 9 [11264/14860 (75%)]\tLoss: 0.019350\n",
      "Train Epoch: 9 [11392/14860 (76%)]\tLoss: 0.013677\n",
      "Train Epoch: 9 [11520/14860 (77%)]\tLoss: 0.023055\n",
      "Train Epoch: 9 [11648/14860 (78%)]\tLoss: 0.019599\n",
      "Train Epoch: 9 [11776/14860 (79%)]\tLoss: 0.031539\n",
      "Train Epoch: 9 [11904/14860 (79%)]\tLoss: 0.023520\n",
      "Train Epoch: 9 [12032/14860 (80%)]\tLoss: 0.018709\n",
      "Train Epoch: 9 [12160/14860 (81%)]\tLoss: 0.018660\n",
      "Train Epoch: 9 [12288/14860 (82%)]\tLoss: 0.025088\n",
      "Train Epoch: 9 [12416/14860 (83%)]\tLoss: 0.020259\n",
      "Train Epoch: 9 [12544/14860 (84%)]\tLoss: 0.021493\n",
      "Train Epoch: 9 [12672/14860 (85%)]\tLoss: 0.025492\n",
      "Train Epoch: 9 [12800/14860 (85%)]\tLoss: 0.021570\n",
      "Train Epoch: 9 [12928/14860 (86%)]\tLoss: 0.023715\n",
      "Train Epoch: 9 [13056/14860 (87%)]\tLoss: 0.016631\n",
      "Train Epoch: 9 [13184/14860 (88%)]\tLoss: 0.024748\n",
      "Train Epoch: 9 [13312/14860 (89%)]\tLoss: 0.023857\n",
      "Train Epoch: 9 [13440/14860 (90%)]\tLoss: 0.024566\n",
      "Train Epoch: 9 [13568/14860 (91%)]\tLoss: 0.019732\n",
      "Train Epoch: 9 [13696/14860 (91%)]\tLoss: 0.018716\n",
      "Train Epoch: 9 [13824/14860 (92%)]\tLoss: 0.016443\n",
      "Train Epoch: 9 [13952/14860 (93%)]\tLoss: 0.017553\n",
      "Train Epoch: 9 [14080/14860 (94%)]\tLoss: 0.026753\n",
      "Train Epoch: 9 [14208/14860 (95%)]\tLoss: 0.019900\n",
      "Train Epoch: 9 [14336/14860 (96%)]\tLoss: 0.014749\n",
      "Train Epoch: 9 [14464/14860 (97%)]\tLoss: 0.020803\n",
      "Train Epoch: 9 [14592/14860 (97%)]\tLoss: 0.025296\n",
      "Train Epoch: 9 [14720/14860 (98%)]\tLoss: 0.025736\n",
      "Train Epoch: 9 [1392/14860 (99%)]\tLoss: 0.009283\n",
      "epoch 9 training loss: 0.023026321266387772\n",
      "epoch 9 validation loss: 0.03056112545165831\n",
      "Train Epoch: 10 [0/14860 (0%)]\tLoss: 0.019321\n",
      "Train Epoch: 10 [128/14860 (1%)]\tLoss: 0.026154\n",
      "Train Epoch: 10 [256/14860 (2%)]\tLoss: 0.027116\n",
      "Train Epoch: 10 [384/14860 (3%)]\tLoss: 0.026183\n",
      "Train Epoch: 10 [512/14860 (3%)]\tLoss: 0.027399\n",
      "Train Epoch: 10 [640/14860 (4%)]\tLoss: 0.020766\n",
      "Train Epoch: 10 [768/14860 (5%)]\tLoss: 0.015795\n",
      "Train Epoch: 10 [896/14860 (6%)]\tLoss: 0.015739\n",
      "Train Epoch: 10 [1024/14860 (7%)]\tLoss: 0.022773\n",
      "Train Epoch: 10 [1152/14860 (8%)]\tLoss: 0.022566\n",
      "Train Epoch: 10 [1280/14860 (9%)]\tLoss: 0.018600\n",
      "Train Epoch: 10 [1408/14860 (9%)]\tLoss: 0.020848\n",
      "Train Epoch: 10 [1536/14860 (10%)]\tLoss: 0.020650\n",
      "Train Epoch: 10 [1664/14860 (11%)]\tLoss: 0.020580\n",
      "Train Epoch: 10 [1792/14860 (12%)]\tLoss: 0.022978\n",
      "Train Epoch: 10 [1920/14860 (13%)]\tLoss: 0.026581\n",
      "Train Epoch: 10 [2048/14860 (14%)]\tLoss: 0.022703\n",
      "Train Epoch: 10 [2176/14860 (15%)]\tLoss: 0.020237\n",
      "Train Epoch: 10 [2304/14860 (15%)]\tLoss: 0.022850\n",
      "Train Epoch: 10 [2432/14860 (16%)]\tLoss: 0.022378\n",
      "Train Epoch: 10 [2560/14860 (17%)]\tLoss: 0.030719\n",
      "Train Epoch: 10 [2688/14860 (18%)]\tLoss: 0.020304\n",
      "Train Epoch: 10 [2816/14860 (19%)]\tLoss: 0.021512\n",
      "Train Epoch: 10 [2944/14860 (20%)]\tLoss: 0.028074\n",
      "Train Epoch: 10 [3072/14860 (21%)]\tLoss: 0.035790\n",
      "Train Epoch: 10 [3200/14860 (21%)]\tLoss: 0.020775\n",
      "Train Epoch: 10 [3328/14860 (22%)]\tLoss: 0.023085\n",
      "Train Epoch: 10 [3456/14860 (23%)]\tLoss: 0.022101\n",
      "Train Epoch: 10 [3584/14860 (24%)]\tLoss: 0.029905\n",
      "Train Epoch: 10 [3712/14860 (25%)]\tLoss: 0.023881\n",
      "Train Epoch: 10 [3840/14860 (26%)]\tLoss: 0.028133\n",
      "Train Epoch: 10 [3968/14860 (26%)]\tLoss: 0.027936\n",
      "Train Epoch: 10 [4096/14860 (27%)]\tLoss: 0.032834\n",
      "Train Epoch: 10 [4224/14860 (28%)]\tLoss: 0.033320\n",
      "Train Epoch: 10 [4352/14860 (29%)]\tLoss: 0.024667\n",
      "Train Epoch: 10 [4480/14860 (30%)]\tLoss: 0.019372\n",
      "Train Epoch: 10 [4608/14860 (31%)]\tLoss: 0.019212\n",
      "Train Epoch: 10 [4736/14860 (32%)]\tLoss: 0.022449\n",
      "Train Epoch: 10 [4864/14860 (32%)]\tLoss: 0.017789\n",
      "Train Epoch: 10 [4992/14860 (33%)]\tLoss: 0.034685\n",
      "Train Epoch: 10 [5120/14860 (34%)]\tLoss: 0.026944\n",
      "Train Epoch: 10 [5248/14860 (35%)]\tLoss: 0.029999\n",
      "Train Epoch: 10 [5376/14860 (36%)]\tLoss: 0.020948\n",
      "Train Epoch: 10 [5504/14860 (37%)]\tLoss: 0.025560\n",
      "Train Epoch: 10 [5632/14860 (38%)]\tLoss: 0.022937\n",
      "Train Epoch: 10 [5760/14860 (38%)]\tLoss: 0.032250\n",
      "Train Epoch: 10 [5888/14860 (39%)]\tLoss: 0.027565\n",
      "Train Epoch: 10 [6016/14860 (40%)]\tLoss: 0.027859\n",
      "Train Epoch: 10 [6144/14860 (41%)]\tLoss: 0.030123\n",
      "Train Epoch: 10 [6272/14860 (42%)]\tLoss: 0.021413\n",
      "Train Epoch: 10 [6400/14860 (43%)]\tLoss: 0.050621\n",
      "Train Epoch: 10 [6528/14860 (44%)]\tLoss: 0.028459\n",
      "Train Epoch: 10 [6656/14860 (44%)]\tLoss: 0.033468\n",
      "Train Epoch: 10 [6784/14860 (45%)]\tLoss: 0.021252\n",
      "Train Epoch: 10 [6912/14860 (46%)]\tLoss: 0.031937\n",
      "Train Epoch: 10 [7040/14860 (47%)]\tLoss: 0.029672\n",
      "Train Epoch: 10 [7168/14860 (48%)]\tLoss: 0.023425\n",
      "Train Epoch: 10 [7296/14860 (49%)]\tLoss: 0.028505\n",
      "Train Epoch: 10 [7424/14860 (50%)]\tLoss: 0.019297\n",
      "Train Epoch: 10 [7552/14860 (50%)]\tLoss: 0.022957\n",
      "Train Epoch: 10 [7680/14860 (51%)]\tLoss: 0.027966\n",
      "Train Epoch: 10 [7808/14860 (52%)]\tLoss: 0.025190\n",
      "Train Epoch: 10 [7936/14860 (53%)]\tLoss: 0.016750\n",
      "Train Epoch: 10 [8064/14860 (54%)]\tLoss: 0.014346\n",
      "Train Epoch: 10 [8192/14860 (55%)]\tLoss: 0.023160\n",
      "Train Epoch: 10 [8320/14860 (56%)]\tLoss: 0.019095\n",
      "Train Epoch: 10 [8448/14860 (56%)]\tLoss: 0.016598\n",
      "Train Epoch: 10 [8576/14860 (57%)]\tLoss: 0.022774\n",
      "Train Epoch: 10 [8704/14860 (58%)]\tLoss: 0.016327\n",
      "Train Epoch: 10 [8832/14860 (59%)]\tLoss: 0.027368\n",
      "Train Epoch: 10 [8960/14860 (60%)]\tLoss: 0.016428\n",
      "Train Epoch: 10 [9088/14860 (61%)]\tLoss: 0.014513\n",
      "Train Epoch: 10 [9216/14860 (62%)]\tLoss: 0.015310\n",
      "Train Epoch: 10 [9344/14860 (62%)]\tLoss: 0.021558\n",
      "Train Epoch: 10 [9472/14860 (63%)]\tLoss: 0.019630\n",
      "Train Epoch: 10 [9600/14860 (64%)]\tLoss: 0.017308\n",
      "Train Epoch: 10 [9728/14860 (65%)]\tLoss: 0.020165\n",
      "Train Epoch: 10 [9856/14860 (66%)]\tLoss: 0.023028\n",
      "Train Epoch: 10 [9984/14860 (67%)]\tLoss: 0.015631\n",
      "Train Epoch: 10 [10112/14860 (68%)]\tLoss: 0.014710\n",
      "Train Epoch: 10 [10240/14860 (68%)]\tLoss: 0.035495\n",
      "Train Epoch: 10 [10368/14860 (69%)]\tLoss: 0.023982\n",
      "Train Epoch: 10 [10496/14860 (70%)]\tLoss: 0.032087\n",
      "Train Epoch: 10 [10624/14860 (71%)]\tLoss: 0.019687\n",
      "Train Epoch: 10 [10752/14860 (72%)]\tLoss: 0.032379\n",
      "Train Epoch: 10 [10880/14860 (73%)]\tLoss: 0.030296\n",
      "Train Epoch: 10 [11008/14860 (74%)]\tLoss: 0.041462\n",
      "Train Epoch: 10 [11136/14860 (74%)]\tLoss: 0.014803\n",
      "Train Epoch: 10 [11264/14860 (75%)]\tLoss: 0.038059\n",
      "Train Epoch: 10 [11392/14860 (76%)]\tLoss: 0.015918\n",
      "Train Epoch: 10 [11520/14860 (77%)]\tLoss: 0.022505\n",
      "Train Epoch: 10 [11648/14860 (78%)]\tLoss: 0.027151\n",
      "Train Epoch: 10 [11776/14860 (79%)]\tLoss: 0.023492\n",
      "Train Epoch: 10 [11904/14860 (79%)]\tLoss: 0.022669\n",
      "Train Epoch: 10 [12032/14860 (80%)]\tLoss: 0.021717\n",
      "Train Epoch: 10 [12160/14860 (81%)]\tLoss: 0.029454\n",
      "Train Epoch: 10 [12288/14860 (82%)]\tLoss: 0.017129\n",
      "Train Epoch: 10 [12416/14860 (83%)]\tLoss: 0.022422\n",
      "Train Epoch: 10 [12544/14860 (84%)]\tLoss: 0.027688\n",
      "Train Epoch: 10 [12672/14860 (85%)]\tLoss: 0.032076\n",
      "Train Epoch: 10 [12800/14860 (85%)]\tLoss: 0.042574\n",
      "Train Epoch: 10 [12928/14860 (86%)]\tLoss: 0.022303\n",
      "Train Epoch: 10 [13056/14860 (87%)]\tLoss: 0.037381\n",
      "Train Epoch: 10 [13184/14860 (88%)]\tLoss: 0.024718\n",
      "Train Epoch: 10 [13312/14860 (89%)]\tLoss: 0.031753\n",
      "Train Epoch: 10 [13440/14860 (90%)]\tLoss: 0.021551\n",
      "Train Epoch: 10 [13568/14860 (91%)]\tLoss: 0.027977\n",
      "Train Epoch: 10 [13696/14860 (91%)]\tLoss: 0.020410\n",
      "Train Epoch: 10 [13824/14860 (92%)]\tLoss: 0.024364\n",
      "Train Epoch: 10 [13952/14860 (93%)]\tLoss: 0.022912\n",
      "Train Epoch: 10 [14080/14860 (94%)]\tLoss: 0.020925\n",
      "Train Epoch: 10 [14208/14860 (95%)]\tLoss: 0.022197\n",
      "Train Epoch: 10 [14336/14860 (96%)]\tLoss: 0.024217\n",
      "Train Epoch: 10 [14464/14860 (97%)]\tLoss: 0.027468\n",
      "Train Epoch: 10 [14592/14860 (97%)]\tLoss: 0.023402\n",
      "Train Epoch: 10 [14720/14860 (98%)]\tLoss: 0.023058\n",
      "Train Epoch: 10 [1392/14860 (99%)]\tLoss: 0.023747\n",
      "epoch 10 training loss: 0.024557601310249068\n",
      "epoch 10 validation loss: 0.02238300854010963\n",
      "Train Epoch: 11 [0/14860 (0%)]\tLoss: 0.030523\n",
      "Train Epoch: 11 [128/14860 (1%)]\tLoss: 0.038623\n",
      "Train Epoch: 11 [256/14860 (2%)]\tLoss: 0.021129\n",
      "Train Epoch: 11 [384/14860 (3%)]\tLoss: 0.021647\n",
      "Train Epoch: 11 [512/14860 (3%)]\tLoss: 0.034630\n",
      "Train Epoch: 11 [640/14860 (4%)]\tLoss: 0.023921\n",
      "Train Epoch: 11 [768/14860 (5%)]\tLoss: 0.037795\n",
      "Train Epoch: 11 [896/14860 (6%)]\tLoss: 0.017398\n",
      "Train Epoch: 11 [1024/14860 (7%)]\tLoss: 0.028044\n",
      "Train Epoch: 11 [1152/14860 (8%)]\tLoss: 0.050727\n",
      "Train Epoch: 11 [1280/14860 (9%)]\tLoss: 0.021244\n",
      "Train Epoch: 11 [1408/14860 (9%)]\tLoss: 0.036722\n",
      "Train Epoch: 11 [1536/14860 (10%)]\tLoss: 0.023495\n",
      "Train Epoch: 11 [1664/14860 (11%)]\tLoss: 0.018724\n",
      "Train Epoch: 11 [1792/14860 (12%)]\tLoss: 0.046595\n",
      "Train Epoch: 11 [1920/14860 (13%)]\tLoss: 0.015146\n",
      "Train Epoch: 11 [2048/14860 (14%)]\tLoss: 0.026555\n",
      "Train Epoch: 11 [2176/14860 (15%)]\tLoss: 0.030253\n",
      "Train Epoch: 11 [2304/14860 (15%)]\tLoss: 0.025545\n",
      "Train Epoch: 11 [2432/14860 (16%)]\tLoss: 0.029878\n",
      "Train Epoch: 11 [2560/14860 (17%)]\tLoss: 0.016812\n",
      "Train Epoch: 11 [2688/14860 (18%)]\tLoss: 0.023421\n",
      "Train Epoch: 11 [2816/14860 (19%)]\tLoss: 0.018633\n",
      "Train Epoch: 11 [2944/14860 (20%)]\tLoss: 0.025523\n",
      "Train Epoch: 11 [3072/14860 (21%)]\tLoss: 0.022011\n",
      "Train Epoch: 11 [3200/14860 (21%)]\tLoss: 0.019572\n",
      "Train Epoch: 11 [3328/14860 (22%)]\tLoss: 0.021382\n",
      "Train Epoch: 11 [3456/14860 (23%)]\tLoss: 0.023088\n",
      "Train Epoch: 11 [3584/14860 (24%)]\tLoss: 0.023330\n",
      "Train Epoch: 11 [3712/14860 (25%)]\tLoss: 0.015437\n",
      "Train Epoch: 11 [3840/14860 (26%)]\tLoss: 0.023008\n",
      "Train Epoch: 11 [3968/14860 (26%)]\tLoss: 0.020606\n",
      "Train Epoch: 11 [4096/14860 (27%)]\tLoss: 0.019895\n",
      "Train Epoch: 11 [4224/14860 (28%)]\tLoss: 0.022180\n",
      "Train Epoch: 11 [4352/14860 (29%)]\tLoss: 0.024422\n",
      "Train Epoch: 11 [4480/14860 (30%)]\tLoss: 0.022822\n",
      "Train Epoch: 11 [4608/14860 (31%)]\tLoss: 0.021325\n",
      "Train Epoch: 11 [4736/14860 (32%)]\tLoss: 0.023806\n",
      "Train Epoch: 11 [4864/14860 (32%)]\tLoss: 0.017530\n",
      "Train Epoch: 11 [4992/14860 (33%)]\tLoss: 0.023510\n",
      "Train Epoch: 11 [5120/14860 (34%)]\tLoss: 0.020126\n",
      "Train Epoch: 11 [5248/14860 (35%)]\tLoss: 0.021779\n",
      "Train Epoch: 11 [5376/14860 (36%)]\tLoss: 0.021124\n",
      "Train Epoch: 11 [5504/14860 (37%)]\tLoss: 0.017500\n",
      "Train Epoch: 11 [5632/14860 (38%)]\tLoss: 0.015687\n",
      "Train Epoch: 11 [5760/14860 (38%)]\tLoss: 0.023227\n",
      "Train Epoch: 11 [5888/14860 (39%)]\tLoss: 0.019392\n",
      "Train Epoch: 11 [6016/14860 (40%)]\tLoss: 0.021158\n",
      "Train Epoch: 11 [6144/14860 (41%)]\tLoss: 0.018653\n",
      "Train Epoch: 11 [6272/14860 (42%)]\tLoss: 0.016235\n",
      "Train Epoch: 11 [6400/14860 (43%)]\tLoss: 0.024027\n",
      "Train Epoch: 11 [6528/14860 (44%)]\tLoss: 0.025675\n",
      "Train Epoch: 11 [6656/14860 (44%)]\tLoss: 0.023540\n",
      "Train Epoch: 11 [6784/14860 (45%)]\tLoss: 0.021838\n",
      "Train Epoch: 11 [6912/14860 (46%)]\tLoss: 0.021745\n",
      "Train Epoch: 11 [7040/14860 (47%)]\tLoss: 0.027173\n",
      "Train Epoch: 11 [7168/14860 (48%)]\tLoss: 0.013099\n",
      "Train Epoch: 11 [7296/14860 (49%)]\tLoss: 0.030503\n",
      "Train Epoch: 11 [7424/14860 (50%)]\tLoss: 0.017858\n",
      "Train Epoch: 11 [7552/14860 (50%)]\tLoss: 0.018521\n",
      "Train Epoch: 11 [7680/14860 (51%)]\tLoss: 0.016107\n",
      "Train Epoch: 11 [7808/14860 (52%)]\tLoss: 0.018778\n",
      "Train Epoch: 11 [7936/14860 (53%)]\tLoss: 0.024825\n",
      "Train Epoch: 11 [8064/14860 (54%)]\tLoss: 0.030586\n",
      "Train Epoch: 11 [8192/14860 (55%)]\tLoss: 0.020615\n",
      "Train Epoch: 11 [8320/14860 (56%)]\tLoss: 0.031082\n",
      "Train Epoch: 11 [8448/14860 (56%)]\tLoss: 0.014625\n",
      "Train Epoch: 11 [8576/14860 (57%)]\tLoss: 0.021042\n",
      "Train Epoch: 11 [8704/14860 (58%)]\tLoss: 0.020065\n",
      "Train Epoch: 11 [8832/14860 (59%)]\tLoss: 0.029581\n",
      "Train Epoch: 11 [8960/14860 (60%)]\tLoss: 0.027947\n",
      "Train Epoch: 11 [9088/14860 (61%)]\tLoss: 0.023021\n",
      "Train Epoch: 11 [9216/14860 (62%)]\tLoss: 0.020989\n",
      "Train Epoch: 11 [9344/14860 (62%)]\tLoss: 0.023453\n",
      "Train Epoch: 11 [9472/14860 (63%)]\tLoss: 0.016503\n",
      "Train Epoch: 11 [9600/14860 (64%)]\tLoss: 0.017716\n",
      "Train Epoch: 11 [9728/14860 (65%)]\tLoss: 0.016742\n",
      "Train Epoch: 11 [9856/14860 (66%)]\tLoss: 0.016748\n",
      "Train Epoch: 11 [9984/14860 (67%)]\tLoss: 0.025485\n",
      "Train Epoch: 11 [10112/14860 (68%)]\tLoss: 0.013064\n",
      "Train Epoch: 11 [10240/14860 (68%)]\tLoss: 0.026249\n",
      "Train Epoch: 11 [10368/14860 (69%)]\tLoss: 0.027036\n",
      "Train Epoch: 11 [10496/14860 (70%)]\tLoss: 0.023556\n",
      "Train Epoch: 11 [10624/14860 (71%)]\tLoss: 0.033959\n",
      "Train Epoch: 11 [10752/14860 (72%)]\tLoss: 0.020789\n",
      "Train Epoch: 11 [10880/14860 (73%)]\tLoss: 0.035527\n",
      "Train Epoch: 11 [11008/14860 (74%)]\tLoss: 0.017285\n",
      "Train Epoch: 11 [11136/14860 (74%)]\tLoss: 0.035550\n",
      "Train Epoch: 11 [11264/14860 (75%)]\tLoss: 0.031977\n",
      "Train Epoch: 11 [11392/14860 (76%)]\tLoss: 0.031571\n",
      "Train Epoch: 11 [11520/14860 (77%)]\tLoss: 0.030605\n",
      "Train Epoch: 11 [11648/14860 (78%)]\tLoss: 0.023171\n",
      "Train Epoch: 11 [11776/14860 (79%)]\tLoss: 0.038730\n",
      "Train Epoch: 11 [11904/14860 (79%)]\tLoss: 0.014850\n",
      "Train Epoch: 11 [12032/14860 (80%)]\tLoss: 0.035052\n",
      "Train Epoch: 11 [12160/14860 (81%)]\tLoss: 0.025867\n",
      "Train Epoch: 11 [12288/14860 (82%)]\tLoss: 0.030870\n",
      "Train Epoch: 11 [12416/14860 (83%)]\tLoss: 0.015193\n",
      "Train Epoch: 11 [12544/14860 (84%)]\tLoss: 0.021877\n",
      "Train Epoch: 11 [12672/14860 (85%)]\tLoss: 0.018754\n",
      "Train Epoch: 11 [12800/14860 (85%)]\tLoss: 0.026652\n",
      "Train Epoch: 11 [12928/14860 (86%)]\tLoss: 0.025074\n",
      "Train Epoch: 11 [13056/14860 (87%)]\tLoss: 0.024946\n",
      "Train Epoch: 11 [13184/14860 (88%)]\tLoss: 0.018894\n",
      "Train Epoch: 11 [13312/14860 (89%)]\tLoss: 0.031418\n",
      "Train Epoch: 11 [13440/14860 (90%)]\tLoss: 0.018856\n",
      "Train Epoch: 11 [13568/14860 (91%)]\tLoss: 0.022031\n",
      "Train Epoch: 11 [13696/14860 (91%)]\tLoss: 0.025204\n",
      "Train Epoch: 11 [13824/14860 (92%)]\tLoss: 0.018515\n",
      "Train Epoch: 11 [13952/14860 (93%)]\tLoss: 0.030702\n",
      "Train Epoch: 11 [14080/14860 (94%)]\tLoss: 0.018214\n",
      "Train Epoch: 11 [14208/14860 (95%)]\tLoss: 0.023665\n",
      "Train Epoch: 11 [14336/14860 (96%)]\tLoss: 0.019424\n",
      "Train Epoch: 11 [14464/14860 (97%)]\tLoss: 0.022662\n",
      "Train Epoch: 11 [14592/14860 (97%)]\tLoss: 0.016574\n",
      "Train Epoch: 11 [14720/14860 (98%)]\tLoss: 0.022500\n",
      "Train Epoch: 11 [1392/14860 (99%)]\tLoss: 0.020516\n",
      "epoch 11 training loss: 0.02375259228910391\n",
      "epoch 11 validation loss: 0.023255350659026362\n",
      "Train Epoch: 12 [0/14860 (0%)]\tLoss: 0.017935\n",
      "Train Epoch: 12 [128/14860 (1%)]\tLoss: 0.025728\n",
      "Train Epoch: 12 [256/14860 (2%)]\tLoss: 0.024219\n",
      "Train Epoch: 12 [384/14860 (3%)]\tLoss: 0.025513\n",
      "Train Epoch: 12 [512/14860 (3%)]\tLoss: 0.029751\n",
      "Train Epoch: 12 [640/14860 (4%)]\tLoss: 0.015717\n",
      "Train Epoch: 12 [768/14860 (5%)]\tLoss: 0.017812\n",
      "Train Epoch: 12 [896/14860 (6%)]\tLoss: 0.029776\n",
      "Train Epoch: 12 [1024/14860 (7%)]\tLoss: 0.022977\n",
      "Train Epoch: 12 [1152/14860 (8%)]\tLoss: 0.023738\n",
      "Train Epoch: 12 [1280/14860 (9%)]\tLoss: 0.023790\n",
      "Train Epoch: 12 [1408/14860 (9%)]\tLoss: 0.020964\n",
      "Train Epoch: 12 [1536/14860 (10%)]\tLoss: 0.021848\n",
      "Train Epoch: 12 [1664/14860 (11%)]\tLoss: 0.019606\n",
      "Train Epoch: 12 [1792/14860 (12%)]\tLoss: 0.020402\n",
      "Train Epoch: 12 [1920/14860 (13%)]\tLoss: 0.022700\n",
      "Train Epoch: 12 [2048/14860 (14%)]\tLoss: 0.017228\n",
      "Train Epoch: 12 [2176/14860 (15%)]\tLoss: 0.023329\n",
      "Train Epoch: 12 [2304/14860 (15%)]\tLoss: 0.015289\n",
      "Train Epoch: 12 [2432/14860 (16%)]\tLoss: 0.022534\n",
      "Train Epoch: 12 [2560/14860 (17%)]\tLoss: 0.019031\n",
      "Train Epoch: 12 [2688/14860 (18%)]\tLoss: 0.021162\n",
      "Train Epoch: 12 [2816/14860 (19%)]\tLoss: 0.022086\n",
      "Train Epoch: 12 [2944/14860 (20%)]\tLoss: 0.037125\n",
      "Train Epoch: 12 [3072/14860 (21%)]\tLoss: 0.020140\n",
      "Train Epoch: 12 [3200/14860 (21%)]\tLoss: 0.024072\n",
      "Train Epoch: 12 [3328/14860 (22%)]\tLoss: 0.020154\n",
      "Train Epoch: 12 [3456/14860 (23%)]\tLoss: 0.016162\n",
      "Train Epoch: 12 [3584/14860 (24%)]\tLoss: 0.025652\n",
      "Train Epoch: 12 [3712/14860 (25%)]\tLoss: 0.021246\n",
      "Train Epoch: 12 [3840/14860 (26%)]\tLoss: 0.018329\n",
      "Train Epoch: 12 [3968/14860 (26%)]\tLoss: 0.017358\n",
      "Train Epoch: 12 [4096/14860 (27%)]\tLoss: 0.027947\n",
      "Train Epoch: 12 [4224/14860 (28%)]\tLoss: 0.026060\n",
      "Train Epoch: 12 [4352/14860 (29%)]\tLoss: 0.022068\n",
      "Train Epoch: 12 [4480/14860 (30%)]\tLoss: 0.024466\n",
      "Train Epoch: 12 [4608/14860 (31%)]\tLoss: 0.019965\n",
      "Train Epoch: 12 [4736/14860 (32%)]\tLoss: 0.021883\n",
      "Train Epoch: 12 [4864/14860 (32%)]\tLoss: 0.024765\n",
      "Train Epoch: 12 [4992/14860 (33%)]\tLoss: 0.017298\n",
      "Train Epoch: 12 [5120/14860 (34%)]\tLoss: 0.022377\n",
      "Train Epoch: 12 [5248/14860 (35%)]\tLoss: 0.019832\n",
      "Train Epoch: 12 [5376/14860 (36%)]\tLoss: 0.024537\n",
      "Train Epoch: 12 [5504/14860 (37%)]\tLoss: 0.024829\n",
      "Train Epoch: 12 [5632/14860 (38%)]\tLoss: 0.020918\n",
      "Train Epoch: 12 [5760/14860 (38%)]\tLoss: 0.019959\n",
      "Train Epoch: 12 [5888/14860 (39%)]\tLoss: 0.021431\n",
      "Train Epoch: 12 [6016/14860 (40%)]\tLoss: 0.025361\n",
      "Train Epoch: 12 [6144/14860 (41%)]\tLoss: 0.027183\n",
      "Train Epoch: 12 [6272/14860 (42%)]\tLoss: 0.024811\n",
      "Train Epoch: 12 [6400/14860 (43%)]\tLoss: 0.020608\n",
      "Train Epoch: 12 [6528/14860 (44%)]\tLoss: 0.020544\n",
      "Train Epoch: 12 [6656/14860 (44%)]\tLoss: 0.024706\n",
      "Train Epoch: 12 [6784/14860 (45%)]\tLoss: 0.019515\n",
      "Train Epoch: 12 [6912/14860 (46%)]\tLoss: 0.017507\n",
      "Train Epoch: 12 [7040/14860 (47%)]\tLoss: 0.028997\n",
      "Train Epoch: 12 [7168/14860 (48%)]\tLoss: 0.021061\n",
      "Train Epoch: 12 [7296/14860 (49%)]\tLoss: 0.023529\n",
      "Train Epoch: 12 [7424/14860 (50%)]\tLoss: 0.017074\n",
      "Train Epoch: 12 [7552/14860 (50%)]\tLoss: 0.028650\n",
      "Train Epoch: 12 [7680/14860 (51%)]\tLoss: 0.024929\n",
      "Train Epoch: 12 [7808/14860 (52%)]\tLoss: 0.024572\n",
      "Train Epoch: 12 [7936/14860 (53%)]\tLoss: 0.017071\n",
      "Train Epoch: 12 [8064/14860 (54%)]\tLoss: 0.019732\n",
      "Train Epoch: 12 [8192/14860 (55%)]\tLoss: 0.020355\n",
      "Train Epoch: 12 [8320/14860 (56%)]\tLoss: 0.016277\n",
      "Train Epoch: 12 [8448/14860 (56%)]\tLoss: 0.026682\n",
      "Train Epoch: 12 [8576/14860 (57%)]\tLoss: 0.014877\n",
      "Train Epoch: 12 [8704/14860 (58%)]\tLoss: 0.023849\n",
      "Train Epoch: 12 [8832/14860 (59%)]\tLoss: 0.020259\n",
      "Train Epoch: 12 [8960/14860 (60%)]\tLoss: 0.030838\n",
      "Train Epoch: 12 [9088/14860 (61%)]\tLoss: 0.022773\n",
      "Train Epoch: 12 [9216/14860 (62%)]\tLoss: 0.017287\n",
      "Train Epoch: 12 [9344/14860 (62%)]\tLoss: 0.030773\n",
      "Train Epoch: 12 [9472/14860 (63%)]\tLoss: 0.021236\n",
      "Train Epoch: 12 [9600/14860 (64%)]\tLoss: 0.017307\n",
      "Train Epoch: 12 [9728/14860 (65%)]\tLoss: 0.019969\n",
      "Train Epoch: 12 [9856/14860 (66%)]\tLoss: 0.015909\n",
      "Train Epoch: 12 [9984/14860 (67%)]\tLoss: 0.022607\n",
      "Train Epoch: 12 [10112/14860 (68%)]\tLoss: 0.014671\n",
      "Train Epoch: 12 [10240/14860 (68%)]\tLoss: 0.020046\n",
      "Train Epoch: 12 [10368/14860 (69%)]\tLoss: 0.014604\n",
      "Train Epoch: 12 [10496/14860 (70%)]\tLoss: 0.019368\n",
      "Train Epoch: 12 [10624/14860 (71%)]\tLoss: 0.022320\n",
      "Train Epoch: 12 [10752/14860 (72%)]\tLoss: 0.017483\n",
      "Train Epoch: 12 [10880/14860 (73%)]\tLoss: 0.023468\n",
      "Train Epoch: 12 [11008/14860 (74%)]\tLoss: 0.015330\n",
      "Train Epoch: 12 [11136/14860 (74%)]\tLoss: 0.026679\n",
      "Train Epoch: 12 [11264/14860 (75%)]\tLoss: 0.027410\n",
      "Train Epoch: 12 [11392/14860 (76%)]\tLoss: 0.026084\n",
      "Train Epoch: 12 [11520/14860 (77%)]\tLoss: 0.012367\n",
      "Train Epoch: 12 [11648/14860 (78%)]\tLoss: 0.027925\n",
      "Train Epoch: 12 [11776/14860 (79%)]\tLoss: 0.022091\n",
      "Train Epoch: 12 [11904/14860 (79%)]\tLoss: 0.029558\n",
      "Train Epoch: 12 [12032/14860 (80%)]\tLoss: 0.020942\n",
      "Train Epoch: 12 [12160/14860 (81%)]\tLoss: 0.026811\n",
      "Train Epoch: 12 [12288/14860 (82%)]\tLoss: 0.036731\n",
      "Train Epoch: 12 [12416/14860 (83%)]\tLoss: 0.040081\n",
      "Train Epoch: 12 [12544/14860 (84%)]\tLoss: 0.027701\n",
      "Train Epoch: 12 [12672/14860 (85%)]\tLoss: 0.036975\n",
      "Train Epoch: 12 [12800/14860 (85%)]\tLoss: 0.028123\n",
      "Train Epoch: 12 [12928/14860 (86%)]\tLoss: 0.029173\n",
      "Train Epoch: 12 [13056/14860 (87%)]\tLoss: 0.021311\n",
      "Train Epoch: 12 [13184/14860 (88%)]\tLoss: 0.020926\n",
      "Train Epoch: 12 [13312/14860 (89%)]\tLoss: 0.035839\n",
      "Train Epoch: 12 [13440/14860 (90%)]\tLoss: 0.020201\n",
      "Train Epoch: 12 [13568/14860 (91%)]\tLoss: 0.039397\n",
      "Train Epoch: 12 [13696/14860 (91%)]\tLoss: 0.023999\n",
      "Train Epoch: 12 [13824/14860 (92%)]\tLoss: 0.043140\n",
      "Train Epoch: 12 [13952/14860 (93%)]\tLoss: 0.019386\n",
      "Train Epoch: 12 [14080/14860 (94%)]\tLoss: 0.029288\n",
      "Train Epoch: 12 [14208/14860 (95%)]\tLoss: 0.023538\n",
      "Train Epoch: 12 [14336/14860 (96%)]\tLoss: 0.023871\n",
      "Train Epoch: 12 [14464/14860 (97%)]\tLoss: 0.012893\n",
      "Train Epoch: 12 [14592/14860 (97%)]\tLoss: 0.021589\n",
      "Train Epoch: 12 [14720/14860 (98%)]\tLoss: 0.023390\n",
      "Train Epoch: 12 [1392/14860 (99%)]\tLoss: 0.010250\n",
      "epoch 12 training loss: 0.022936014824698113\n",
      "epoch 12 validation loss: 0.025735780199849866\n",
      "Train Epoch: 13 [0/14860 (0%)]\tLoss: 0.032226\n",
      "Train Epoch: 13 [128/14860 (1%)]\tLoss: 0.022006\n",
      "Train Epoch: 13 [256/14860 (2%)]\tLoss: 0.020249\n",
      "Train Epoch: 13 [384/14860 (3%)]\tLoss: 0.019725\n",
      "Train Epoch: 13 [512/14860 (3%)]\tLoss: 0.014780\n",
      "Train Epoch: 13 [640/14860 (4%)]\tLoss: 0.016356\n",
      "Train Epoch: 13 [768/14860 (5%)]\tLoss: 0.018876\n",
      "Train Epoch: 13 [896/14860 (6%)]\tLoss: 0.023123\n",
      "Train Epoch: 13 [1024/14860 (7%)]\tLoss: 0.024386\n",
      "Train Epoch: 13 [1152/14860 (8%)]\tLoss: 0.025124\n",
      "Train Epoch: 13 [1280/14860 (9%)]\tLoss: 0.021858\n",
      "Train Epoch: 13 [1408/14860 (9%)]\tLoss: 0.024514\n",
      "Train Epoch: 13 [1536/14860 (10%)]\tLoss: 0.021272\n",
      "Train Epoch: 13 [1664/14860 (11%)]\tLoss: 0.019735\n",
      "Train Epoch: 13 [1792/14860 (12%)]\tLoss: 0.024954\n",
      "Train Epoch: 13 [1920/14860 (13%)]\tLoss: 0.012481\n",
      "Train Epoch: 13 [2048/14860 (14%)]\tLoss: 0.018892\n",
      "Train Epoch: 13 [2176/14860 (15%)]\tLoss: 0.023923\n",
      "Train Epoch: 13 [2304/14860 (15%)]\tLoss: 0.017089\n",
      "Train Epoch: 13 [2432/14860 (16%)]\tLoss: 0.024163\n",
      "Train Epoch: 13 [2560/14860 (17%)]\tLoss: 0.018672\n",
      "Train Epoch: 13 [2688/14860 (18%)]\tLoss: 0.023823\n",
      "Train Epoch: 13 [2816/14860 (19%)]\tLoss: 0.018295\n",
      "Train Epoch: 13 [2944/14860 (20%)]\tLoss: 0.016916\n",
      "Train Epoch: 13 [3072/14860 (21%)]\tLoss: 0.021873\n",
      "Train Epoch: 13 [3200/14860 (21%)]\tLoss: 0.022500\n",
      "Train Epoch: 13 [3328/14860 (22%)]\tLoss: 0.027780\n",
      "Train Epoch: 13 [3456/14860 (23%)]\tLoss: 0.016317\n",
      "Train Epoch: 13 [3584/14860 (24%)]\tLoss: 0.019976\n",
      "Train Epoch: 13 [3712/14860 (25%)]\tLoss: 0.026361\n",
      "Train Epoch: 13 [3840/14860 (26%)]\tLoss: 0.011159\n",
      "Train Epoch: 13 [3968/14860 (26%)]\tLoss: 0.030054\n",
      "Train Epoch: 13 [4096/14860 (27%)]\tLoss: 0.027485\n",
      "Train Epoch: 13 [4224/14860 (28%)]\tLoss: 0.026320\n",
      "Train Epoch: 13 [4352/14860 (29%)]\tLoss: 0.025188\n",
      "Train Epoch: 13 [4480/14860 (30%)]\tLoss: 0.017665\n",
      "Train Epoch: 13 [4608/14860 (31%)]\tLoss: 0.017686\n",
      "Train Epoch: 13 [4736/14860 (32%)]\tLoss: 0.023282\n",
      "Train Epoch: 13 [4864/14860 (32%)]\tLoss: 0.022333\n",
      "Train Epoch: 13 [4992/14860 (33%)]\tLoss: 0.018719\n",
      "Train Epoch: 13 [5120/14860 (34%)]\tLoss: 0.020221\n",
      "Train Epoch: 13 [5248/14860 (35%)]\tLoss: 0.014517\n",
      "Train Epoch: 13 [5376/14860 (36%)]\tLoss: 0.020632\n",
      "Train Epoch: 13 [5504/14860 (37%)]\tLoss: 0.022230\n",
      "Train Epoch: 13 [5632/14860 (38%)]\tLoss: 0.028459\n",
      "Train Epoch: 13 [5760/14860 (38%)]\tLoss: 0.025774\n",
      "Train Epoch: 13 [5888/14860 (39%)]\tLoss: 0.033179\n",
      "Train Epoch: 13 [6016/14860 (40%)]\tLoss: 0.031494\n",
      "Train Epoch: 13 [6144/14860 (41%)]\tLoss: 0.023602\n",
      "Train Epoch: 13 [6272/14860 (42%)]\tLoss: 0.018097\n",
      "Train Epoch: 13 [6400/14860 (43%)]\tLoss: 0.020760\n",
      "Train Epoch: 13 [6528/14860 (44%)]\tLoss: 0.024914\n",
      "Train Epoch: 13 [6656/14860 (44%)]\tLoss: 0.023456\n",
      "Train Epoch: 13 [6784/14860 (45%)]\tLoss: 0.024742\n",
      "Train Epoch: 13 [6912/14860 (46%)]\tLoss: 0.017995\n",
      "Train Epoch: 13 [7040/14860 (47%)]\tLoss: 0.023752\n",
      "Train Epoch: 13 [7168/14860 (48%)]\tLoss: 0.018278\n",
      "Train Epoch: 13 [7296/14860 (49%)]\tLoss: 0.020661\n",
      "Train Epoch: 13 [7424/14860 (50%)]\tLoss: 0.019937\n",
      "Train Epoch: 13 [7552/14860 (50%)]\tLoss: 0.024461\n",
      "Train Epoch: 13 [7680/14860 (51%)]\tLoss: 0.018940\n",
      "Train Epoch: 13 [7808/14860 (52%)]\tLoss: 0.023329\n",
      "Train Epoch: 13 [7936/14860 (53%)]\tLoss: 0.017301\n",
      "Train Epoch: 13 [8064/14860 (54%)]\tLoss: 0.039228\n",
      "Train Epoch: 13 [8192/14860 (55%)]\tLoss: 0.022085\n",
      "Train Epoch: 13 [8320/14860 (56%)]\tLoss: 0.025856\n",
      "Train Epoch: 13 [8448/14860 (56%)]\tLoss: 0.016759\n",
      "Train Epoch: 13 [8576/14860 (57%)]\tLoss: 0.025109\n",
      "Train Epoch: 13 [8704/14860 (58%)]\tLoss: 0.017611\n",
      "Train Epoch: 13 [8832/14860 (59%)]\tLoss: 0.020266\n",
      "Train Epoch: 13 [8960/14860 (60%)]\tLoss: 0.022437\n",
      "Train Epoch: 13 [9088/14860 (61%)]\tLoss: 0.023799\n",
      "Train Epoch: 13 [9216/14860 (62%)]\tLoss: 0.019613\n",
      "Train Epoch: 13 [9344/14860 (62%)]\tLoss: 0.015301\n",
      "Train Epoch: 13 [9472/14860 (63%)]\tLoss: 0.020093\n",
      "Train Epoch: 13 [9600/14860 (64%)]\tLoss: 0.016758\n",
      "Train Epoch: 13 [9728/14860 (65%)]\tLoss: 0.023946\n",
      "Train Epoch: 13 [9856/14860 (66%)]\tLoss: 0.020109\n",
      "Train Epoch: 13 [9984/14860 (67%)]\tLoss: 0.016885\n",
      "Train Epoch: 13 [10112/14860 (68%)]\tLoss: 0.037405\n",
      "Train Epoch: 13 [10240/14860 (68%)]\tLoss: 0.023886\n",
      "Train Epoch: 13 [10368/14860 (69%)]\tLoss: 0.023934\n",
      "Train Epoch: 13 [10496/14860 (70%)]\tLoss: 0.026186\n",
      "Train Epoch: 13 [10624/14860 (71%)]\tLoss: 0.020713\n",
      "Train Epoch: 13 [10752/14860 (72%)]\tLoss: 0.015811\n",
      "Train Epoch: 13 [10880/14860 (73%)]\tLoss: 0.014781\n",
      "Train Epoch: 13 [11008/14860 (74%)]\tLoss: 0.023057\n",
      "Train Epoch: 13 [11136/14860 (74%)]\tLoss: 0.018619\n",
      "Train Epoch: 13 [11264/14860 (75%)]\tLoss: 0.023176\n",
      "Train Epoch: 13 [11392/14860 (76%)]\tLoss: 0.018374\n",
      "Train Epoch: 13 [11520/14860 (77%)]\tLoss: 0.018587\n",
      "Train Epoch: 13 [11648/14860 (78%)]\tLoss: 0.024976\n",
      "Train Epoch: 13 [11776/14860 (79%)]\tLoss: 0.020349\n",
      "Train Epoch: 13 [11904/14860 (79%)]\tLoss: 0.014361\n",
      "Train Epoch: 13 [12032/14860 (80%)]\tLoss: 0.024481\n",
      "Train Epoch: 13 [12160/14860 (81%)]\tLoss: 0.020447\n",
      "Train Epoch: 13 [12288/14860 (82%)]\tLoss: 0.018173\n",
      "Train Epoch: 13 [12416/14860 (83%)]\tLoss: 0.026956\n",
      "Train Epoch: 13 [12544/14860 (84%)]\tLoss: 0.022031\n",
      "Train Epoch: 13 [12672/14860 (85%)]\tLoss: 0.026476\n",
      "Train Epoch: 13 [12800/14860 (85%)]\tLoss: 0.027912\n",
      "Train Epoch: 13 [12928/14860 (86%)]\tLoss: 0.022306\n",
      "Train Epoch: 13 [13056/14860 (87%)]\tLoss: 0.025587\n",
      "Train Epoch: 13 [13184/14860 (88%)]\tLoss: 0.019027\n",
      "Train Epoch: 13 [13312/14860 (89%)]\tLoss: 0.027598\n",
      "Train Epoch: 13 [13440/14860 (90%)]\tLoss: 0.020264\n",
      "Train Epoch: 13 [13568/14860 (91%)]\tLoss: 0.020462\n",
      "Train Epoch: 13 [13696/14860 (91%)]\tLoss: 0.021026\n",
      "Train Epoch: 13 [13824/14860 (92%)]\tLoss: 0.022941\n",
      "Train Epoch: 13 [13952/14860 (93%)]\tLoss: 0.022990\n",
      "Train Epoch: 13 [14080/14860 (94%)]\tLoss: 0.017473\n",
      "Train Epoch: 13 [14208/14860 (95%)]\tLoss: 0.016789\n",
      "Train Epoch: 13 [14336/14860 (96%)]\tLoss: 0.019801\n",
      "Train Epoch: 13 [14464/14860 (97%)]\tLoss: 0.024960\n",
      "Train Epoch: 13 [14592/14860 (97%)]\tLoss: 0.024664\n",
      "Train Epoch: 13 [14720/14860 (98%)]\tLoss: 0.017886\n",
      "Train Epoch: 13 [1392/14860 (99%)]\tLoss: 0.019798\n",
      "epoch 13 training loss: 0.02183748821481171\n",
      "epoch 13 validation loss: 0.022350517225611873\n",
      "Train Epoch: 14 [0/14860 (0%)]\tLoss: 0.025518\n",
      "Train Epoch: 14 [128/14860 (1%)]\tLoss: 0.019042\n",
      "Train Epoch: 14 [256/14860 (2%)]\tLoss: 0.016205\n",
      "Train Epoch: 14 [384/14860 (3%)]\tLoss: 0.020708\n",
      "Train Epoch: 14 [512/14860 (3%)]\tLoss: 0.022377\n",
      "Train Epoch: 14 [640/14860 (4%)]\tLoss: 0.018037\n",
      "Train Epoch: 14 [768/14860 (5%)]\tLoss: 0.026556\n",
      "Train Epoch: 14 [896/14860 (6%)]\tLoss: 0.023786\n",
      "Train Epoch: 14 [1024/14860 (7%)]\tLoss: 0.026113\n",
      "Train Epoch: 14 [1152/14860 (8%)]\tLoss: 0.021376\n",
      "Train Epoch: 14 [1280/14860 (9%)]\tLoss: 0.021452\n",
      "Train Epoch: 14 [1408/14860 (9%)]\tLoss: 0.027499\n",
      "Train Epoch: 14 [1536/14860 (10%)]\tLoss: 0.020878\n",
      "Train Epoch: 14 [1664/14860 (11%)]\tLoss: 0.023870\n",
      "Train Epoch: 14 [1792/14860 (12%)]\tLoss: 0.023631\n",
      "Train Epoch: 14 [1920/14860 (13%)]\tLoss: 0.020220\n",
      "Train Epoch: 14 [2048/14860 (14%)]\tLoss: 0.019066\n",
      "Train Epoch: 14 [2176/14860 (15%)]\tLoss: 0.015411\n",
      "Train Epoch: 14 [2304/14860 (15%)]\tLoss: 0.023839\n",
      "Train Epoch: 14 [2432/14860 (16%)]\tLoss: 0.026120\n",
      "Train Epoch: 14 [2560/14860 (17%)]\tLoss: 0.018292\n",
      "Train Epoch: 14 [2688/14860 (18%)]\tLoss: 0.018311\n",
      "Train Epoch: 14 [2816/14860 (19%)]\tLoss: 0.023282\n",
      "Train Epoch: 14 [2944/14860 (20%)]\tLoss: 0.019411\n",
      "Train Epoch: 14 [3072/14860 (21%)]\tLoss: 0.016720\n",
      "Train Epoch: 14 [3200/14860 (21%)]\tLoss: 0.030056\n",
      "Train Epoch: 14 [3328/14860 (22%)]\tLoss: 0.023771\n",
      "Train Epoch: 14 [3456/14860 (23%)]\tLoss: 0.017561\n",
      "Train Epoch: 14 [3584/14860 (24%)]\tLoss: 0.020573\n",
      "Train Epoch: 14 [3712/14860 (25%)]\tLoss: 0.021030\n",
      "Train Epoch: 14 [3840/14860 (26%)]\tLoss: 0.026444\n",
      "Train Epoch: 14 [3968/14860 (26%)]\tLoss: 0.016360\n",
      "Train Epoch: 14 [4096/14860 (27%)]\tLoss: 0.024398\n",
      "Train Epoch: 14 [4224/14860 (28%)]\tLoss: 0.021559\n",
      "Train Epoch: 14 [4352/14860 (29%)]\tLoss: 0.019982\n",
      "Train Epoch: 14 [4480/14860 (30%)]\tLoss: 0.021882\n",
      "Train Epoch: 14 [4608/14860 (31%)]\tLoss: 0.017174\n",
      "Train Epoch: 14 [4736/14860 (32%)]\tLoss: 0.025717\n",
      "Train Epoch: 14 [4864/14860 (32%)]\tLoss: 0.022861\n",
      "Train Epoch: 14 [4992/14860 (33%)]\tLoss: 0.021445\n",
      "Train Epoch: 14 [5120/14860 (34%)]\tLoss: 0.026415\n",
      "Train Epoch: 14 [5248/14860 (35%)]\tLoss: 0.019136\n",
      "Train Epoch: 14 [5376/14860 (36%)]\tLoss: 0.019942\n",
      "Train Epoch: 14 [5504/14860 (37%)]\tLoss: 0.017267\n",
      "Train Epoch: 14 [5632/14860 (38%)]\tLoss: 0.027423\n",
      "Train Epoch: 14 [5760/14860 (38%)]\tLoss: 0.022844\n",
      "Train Epoch: 14 [5888/14860 (39%)]\tLoss: 0.023771\n",
      "Train Epoch: 14 [6016/14860 (40%)]\tLoss: 0.027709\n",
      "Train Epoch: 14 [6144/14860 (41%)]\tLoss: 0.022153\n",
      "Train Epoch: 14 [6272/14860 (42%)]\tLoss: 0.025031\n",
      "Train Epoch: 14 [6400/14860 (43%)]\tLoss: 0.021223\n",
      "Train Epoch: 14 [6528/14860 (44%)]\tLoss: 0.025168\n",
      "Train Epoch: 14 [6656/14860 (44%)]\tLoss: 0.023506\n",
      "Train Epoch: 14 [6784/14860 (45%)]\tLoss: 0.031184\n",
      "Train Epoch: 14 [6912/14860 (46%)]\tLoss: 0.022248\n",
      "Train Epoch: 14 [7040/14860 (47%)]\tLoss: 0.023070\n",
      "Train Epoch: 14 [7168/14860 (48%)]\tLoss: 0.016496\n",
      "Train Epoch: 14 [7296/14860 (49%)]\tLoss: 0.019426\n",
      "Train Epoch: 14 [7424/14860 (50%)]\tLoss: 0.018913\n",
      "Train Epoch: 14 [7552/14860 (50%)]\tLoss: 0.017317\n",
      "Train Epoch: 14 [7680/14860 (51%)]\tLoss: 0.018752\n",
      "Train Epoch: 14 [7808/14860 (52%)]\tLoss: 0.023558\n",
      "Train Epoch: 14 [7936/14860 (53%)]\tLoss: 0.019655\n",
      "Train Epoch: 14 [8064/14860 (54%)]\tLoss: 0.024593\n",
      "Train Epoch: 14 [8192/14860 (55%)]\tLoss: 0.022946\n",
      "Train Epoch: 14 [8320/14860 (56%)]\tLoss: 0.025430\n",
      "Train Epoch: 14 [8448/14860 (56%)]\tLoss: 0.020532\n",
      "Train Epoch: 14 [8576/14860 (57%)]\tLoss: 0.023701\n",
      "Train Epoch: 14 [8704/14860 (58%)]\tLoss: 0.019712\n",
      "Train Epoch: 14 [8832/14860 (59%)]\tLoss: 0.019017\n",
      "Train Epoch: 14 [8960/14860 (60%)]\tLoss: 0.018942\n",
      "Train Epoch: 14 [9088/14860 (61%)]\tLoss: 0.019451\n",
      "Train Epoch: 14 [9216/14860 (62%)]\tLoss: 0.018907\n",
      "Train Epoch: 14 [9344/14860 (62%)]\tLoss: 0.019782\n",
      "Train Epoch: 14 [9472/14860 (63%)]\tLoss: 0.024682\n",
      "Train Epoch: 14 [9600/14860 (64%)]\tLoss: 0.021968\n",
      "Train Epoch: 14 [9728/14860 (65%)]\tLoss: 0.036106\n",
      "Train Epoch: 14 [9856/14860 (66%)]\tLoss: 0.021531\n",
      "Train Epoch: 14 [9984/14860 (67%)]\tLoss: 0.019651\n",
      "Train Epoch: 14 [10112/14860 (68%)]\tLoss: 0.024859\n",
      "Train Epoch: 14 [10240/14860 (68%)]\tLoss: 0.021820\n",
      "Train Epoch: 14 [10368/14860 (69%)]\tLoss: 0.021816\n",
      "Train Epoch: 14 [10496/14860 (70%)]\tLoss: 0.027994\n",
      "Train Epoch: 14 [10624/14860 (71%)]\tLoss: 0.022207\n",
      "Train Epoch: 14 [10752/14860 (72%)]\tLoss: 0.022517\n",
      "Train Epoch: 14 [10880/14860 (73%)]\tLoss: 0.025858\n",
      "Train Epoch: 14 [11008/14860 (74%)]\tLoss: 0.021277\n",
      "Train Epoch: 14 [11136/14860 (74%)]\tLoss: 0.020973\n",
      "Train Epoch: 14 [11264/14860 (75%)]\tLoss: 0.017387\n",
      "Train Epoch: 14 [11392/14860 (76%)]\tLoss: 0.034959\n",
      "Train Epoch: 14 [11520/14860 (77%)]\tLoss: 0.025322\n",
      "Train Epoch: 14 [11648/14860 (78%)]\tLoss: 0.027215\n",
      "Train Epoch: 14 [11776/14860 (79%)]\tLoss: 0.022654\n",
      "Train Epoch: 14 [11904/14860 (79%)]\tLoss: 0.018436\n",
      "Train Epoch: 14 [12032/14860 (80%)]\tLoss: 0.022831\n",
      "Train Epoch: 14 [12160/14860 (81%)]\tLoss: 0.015594\n",
      "Train Epoch: 14 [12288/14860 (82%)]\tLoss: 0.015849\n",
      "Train Epoch: 14 [12416/14860 (83%)]\tLoss: 0.022668\n",
      "Train Epoch: 14 [12544/14860 (84%)]\tLoss: 0.024769\n",
      "Train Epoch: 14 [12672/14860 (85%)]\tLoss: 0.023695\n",
      "Train Epoch: 14 [12800/14860 (85%)]\tLoss: 0.017212\n",
      "Train Epoch: 14 [12928/14860 (86%)]\tLoss: 0.024906\n",
      "Train Epoch: 14 [13056/14860 (87%)]\tLoss: 0.023412\n",
      "Train Epoch: 14 [13184/14860 (88%)]\tLoss: 0.020446\n",
      "Train Epoch: 14 [13312/14860 (89%)]\tLoss: 0.017251\n",
      "Train Epoch: 14 [13440/14860 (90%)]\tLoss: 0.024540\n",
      "Train Epoch: 14 [13568/14860 (91%)]\tLoss: 0.019167\n",
      "Train Epoch: 14 [13696/14860 (91%)]\tLoss: 0.019583\n",
      "Train Epoch: 14 [13824/14860 (92%)]\tLoss: 0.025031\n",
      "Train Epoch: 14 [13952/14860 (93%)]\tLoss: 0.016851\n",
      "Train Epoch: 14 [14080/14860 (94%)]\tLoss: 0.023966\n",
      "Train Epoch: 14 [14208/14860 (95%)]\tLoss: 0.022458\n",
      "Train Epoch: 14 [14336/14860 (96%)]\tLoss: 0.014216\n",
      "Train Epoch: 14 [14464/14860 (97%)]\tLoss: 0.017225\n",
      "Train Epoch: 14 [14592/14860 (97%)]\tLoss: 0.016877\n",
      "Train Epoch: 14 [14720/14860 (98%)]\tLoss: 0.030094\n",
      "Train Epoch: 14 [1392/14860 (99%)]\tLoss: 0.011866\n",
      "epoch 14 training loss: 0.02191016923349637\n",
      "epoch 14 validation loss: 0.032911170770123274\n",
      "Train Epoch: 15 [0/14860 (0%)]\tLoss: 0.026039\n",
      "Train Epoch: 15 [128/14860 (1%)]\tLoss: 0.035256\n",
      "Train Epoch: 15 [256/14860 (2%)]\tLoss: 0.019904\n",
      "Train Epoch: 15 [384/14860 (3%)]\tLoss: 0.026630\n",
      "Train Epoch: 15 [512/14860 (3%)]\tLoss: 0.022373\n",
      "Train Epoch: 15 [640/14860 (4%)]\tLoss: 0.023919\n",
      "Train Epoch: 15 [768/14860 (5%)]\tLoss: 0.020285\n",
      "Train Epoch: 15 [896/14860 (6%)]\tLoss: 0.020834\n",
      "Train Epoch: 15 [1024/14860 (7%)]\tLoss: 0.021397\n",
      "Train Epoch: 15 [1152/14860 (8%)]\tLoss: 0.018758\n",
      "Train Epoch: 15 [1280/14860 (9%)]\tLoss: 0.024174\n",
      "Train Epoch: 15 [1408/14860 (9%)]\tLoss: 0.014998\n",
      "Train Epoch: 15 [1536/14860 (10%)]\tLoss: 0.018075\n",
      "Train Epoch: 15 [1664/14860 (11%)]\tLoss: 0.017975\n",
      "Train Epoch: 15 [1792/14860 (12%)]\tLoss: 0.015800\n",
      "Train Epoch: 15 [1920/14860 (13%)]\tLoss: 0.024203\n",
      "Train Epoch: 15 [2048/14860 (14%)]\tLoss: 0.024083\n",
      "Train Epoch: 15 [2176/14860 (15%)]\tLoss: 0.019982\n",
      "Train Epoch: 15 [2304/14860 (15%)]\tLoss: 0.021170\n",
      "Train Epoch: 15 [2432/14860 (16%)]\tLoss: 0.022617\n",
      "Train Epoch: 15 [2560/14860 (17%)]\tLoss: 0.017806\n",
      "Train Epoch: 15 [2688/14860 (18%)]\tLoss: 0.017298\n",
      "Train Epoch: 15 [2816/14860 (19%)]\tLoss: 0.013631\n",
      "Train Epoch: 15 [2944/14860 (20%)]\tLoss: 0.033142\n",
      "Train Epoch: 15 [3072/14860 (21%)]\tLoss: 0.030022\n",
      "Train Epoch: 15 [3200/14860 (21%)]\tLoss: 0.019966\n",
      "Train Epoch: 15 [3328/14860 (22%)]\tLoss: 0.026782\n",
      "Train Epoch: 15 [3456/14860 (23%)]\tLoss: 0.017115\n",
      "Train Epoch: 15 [3584/14860 (24%)]\tLoss: 0.026864\n",
      "Train Epoch: 15 [3712/14860 (25%)]\tLoss: 0.022187\n",
      "Train Epoch: 15 [3840/14860 (26%)]\tLoss: 0.029904\n",
      "Train Epoch: 15 [3968/14860 (26%)]\tLoss: 0.015274\n",
      "Train Epoch: 15 [4096/14860 (27%)]\tLoss: 0.025859\n",
      "Train Epoch: 15 [4224/14860 (28%)]\tLoss: 0.017518\n",
      "Train Epoch: 15 [4352/14860 (29%)]\tLoss: 0.035286\n",
      "Train Epoch: 15 [4480/14860 (30%)]\tLoss: 0.017761\n",
      "Train Epoch: 15 [4608/14860 (31%)]\tLoss: 0.017826\n",
      "Train Epoch: 15 [4736/14860 (32%)]\tLoss: 0.030096\n",
      "Train Epoch: 15 [4864/14860 (32%)]\tLoss: 0.018287\n",
      "Train Epoch: 15 [4992/14860 (33%)]\tLoss: 0.023230\n",
      "Train Epoch: 15 [5120/14860 (34%)]\tLoss: 0.025253\n",
      "Train Epoch: 15 [5248/14860 (35%)]\tLoss: 0.025549\n",
      "Train Epoch: 15 [5376/14860 (36%)]\tLoss: 0.027304\n",
      "Train Epoch: 15 [5504/14860 (37%)]\tLoss: 0.023697\n",
      "Train Epoch: 15 [5632/14860 (38%)]\tLoss: 0.020988\n",
      "Train Epoch: 15 [5760/14860 (38%)]\tLoss: 0.026431\n",
      "Train Epoch: 15 [5888/14860 (39%)]\tLoss: 0.020978\n",
      "Train Epoch: 15 [6016/14860 (40%)]\tLoss: 0.026628\n",
      "Train Epoch: 15 [6144/14860 (41%)]\tLoss: 0.016703\n",
      "Train Epoch: 15 [6272/14860 (42%)]\tLoss: 0.024127\n",
      "Train Epoch: 15 [6400/14860 (43%)]\tLoss: 0.020553\n",
      "Train Epoch: 15 [6528/14860 (44%)]\tLoss: 0.023613\n",
      "Train Epoch: 15 [6656/14860 (44%)]\tLoss: 0.031057\n",
      "Train Epoch: 15 [6784/14860 (45%)]\tLoss: 0.022822\n",
      "Train Epoch: 15 [6912/14860 (46%)]\tLoss: 0.031370\n",
      "Train Epoch: 15 [7040/14860 (47%)]\tLoss: 0.016538\n",
      "Train Epoch: 15 [7168/14860 (48%)]\tLoss: 0.027616\n",
      "Train Epoch: 15 [7296/14860 (49%)]\tLoss: 0.018900\n",
      "Train Epoch: 15 [7424/14860 (50%)]\tLoss: 0.025136\n",
      "Train Epoch: 15 [7552/14860 (50%)]\tLoss: 0.023984\n",
      "Train Epoch: 15 [7680/14860 (51%)]\tLoss: 0.033194\n",
      "Train Epoch: 15 [7808/14860 (52%)]\tLoss: 0.029888\n",
      "Train Epoch: 15 [7936/14860 (53%)]\tLoss: 0.033005\n",
      "Train Epoch: 15 [8064/14860 (54%)]\tLoss: 0.047117\n",
      "Train Epoch: 15 [8192/14860 (55%)]\tLoss: 0.024890\n",
      "Train Epoch: 15 [8320/14860 (56%)]\tLoss: 0.039216\n",
      "Train Epoch: 15 [8448/14860 (56%)]\tLoss: 0.029229\n",
      "Train Epoch: 15 [8576/14860 (57%)]\tLoss: 0.040062\n",
      "Train Epoch: 15 [8704/14860 (58%)]\tLoss: 0.018394\n",
      "Train Epoch: 15 [8832/14860 (59%)]\tLoss: 0.027559\n",
      "Train Epoch: 15 [8960/14860 (60%)]\tLoss: 0.020243\n",
      "Train Epoch: 15 [9088/14860 (61%)]\tLoss: 0.025891\n",
      "Train Epoch: 15 [9216/14860 (62%)]\tLoss: 0.030987\n",
      "Train Epoch: 15 [9344/14860 (62%)]\tLoss: 0.019233\n",
      "Train Epoch: 15 [9472/14860 (63%)]\tLoss: 0.016537\n",
      "Train Epoch: 15 [9600/14860 (64%)]\tLoss: 0.018211\n",
      "Train Epoch: 15 [9728/14860 (65%)]\tLoss: 0.022634\n",
      "Train Epoch: 15 [9856/14860 (66%)]\tLoss: 0.023338\n",
      "Train Epoch: 15 [9984/14860 (67%)]\tLoss: 0.016662\n",
      "Train Epoch: 15 [10112/14860 (68%)]\tLoss: 0.017145\n",
      "Train Epoch: 15 [10240/14860 (68%)]\tLoss: 0.020554\n",
      "Train Epoch: 15 [10368/14860 (69%)]\tLoss: 0.025080\n",
      "Train Epoch: 15 [10496/14860 (70%)]\tLoss: 0.032519\n",
      "Train Epoch: 15 [10624/14860 (71%)]\tLoss: 0.020545\n",
      "Train Epoch: 15 [10752/14860 (72%)]\tLoss: 0.024738\n",
      "Train Epoch: 15 [10880/14860 (73%)]\tLoss: 0.021608\n",
      "Train Epoch: 15 [11008/14860 (74%)]\tLoss: 0.024136\n",
      "Train Epoch: 15 [11136/14860 (74%)]\tLoss: 0.024634\n",
      "Train Epoch: 15 [11264/14860 (75%)]\tLoss: 0.016068\n",
      "Train Epoch: 15 [11392/14860 (76%)]\tLoss: 0.026769\n",
      "Train Epoch: 15 [11520/14860 (77%)]\tLoss: 0.020615\n",
      "Train Epoch: 15 [11648/14860 (78%)]\tLoss: 0.022039\n",
      "Train Epoch: 15 [11776/14860 (79%)]\tLoss: 0.014663\n",
      "Train Epoch: 15 [11904/14860 (79%)]\tLoss: 0.025690\n",
      "Train Epoch: 15 [12032/14860 (80%)]\tLoss: 0.015930\n",
      "Train Epoch: 15 [12160/14860 (81%)]\tLoss: 0.015436\n",
      "Train Epoch: 15 [12288/14860 (82%)]\tLoss: 0.014784\n",
      "Train Epoch: 15 [12416/14860 (83%)]\tLoss: 0.028086\n",
      "Train Epoch: 15 [12544/14860 (84%)]\tLoss: 0.029980\n",
      "Train Epoch: 15 [12672/14860 (85%)]\tLoss: 0.023542\n",
      "Train Epoch: 15 [12800/14860 (85%)]\tLoss: 0.030351\n",
      "Train Epoch: 15 [12928/14860 (86%)]\tLoss: 0.019262\n",
      "Train Epoch: 15 [13056/14860 (87%)]\tLoss: 0.022400\n",
      "Train Epoch: 15 [13184/14860 (88%)]\tLoss: 0.024517\n",
      "Train Epoch: 15 [13312/14860 (89%)]\tLoss: 0.024188\n",
      "Train Epoch: 15 [13440/14860 (90%)]\tLoss: 0.026866\n",
      "Train Epoch: 15 [13568/14860 (91%)]\tLoss: 0.017265\n",
      "Train Epoch: 15 [13696/14860 (91%)]\tLoss: 0.018907\n",
      "Train Epoch: 15 [13824/14860 (92%)]\tLoss: 0.024999\n",
      "Train Epoch: 15 [13952/14860 (93%)]\tLoss: 0.015338\n",
      "Train Epoch: 15 [14080/14860 (94%)]\tLoss: 0.017806\n",
      "Train Epoch: 15 [14208/14860 (95%)]\tLoss: 0.024886\n",
      "Train Epoch: 15 [14336/14860 (96%)]\tLoss: 0.019523\n",
      "Train Epoch: 15 [14464/14860 (97%)]\tLoss: 0.017250\n",
      "Train Epoch: 15 [14592/14860 (97%)]\tLoss: 0.022973\n",
      "Train Epoch: 15 [14720/14860 (98%)]\tLoss: 0.016559\n",
      "Train Epoch: 15 [1392/14860 (99%)]\tLoss: 0.038902\n",
      "epoch 15 training loss: 0.02338818551447147\n",
      "epoch 15 validation loss: 0.022964223678117804\n",
      "Train Epoch: 16 [0/14860 (0%)]\tLoss: 0.020556\n",
      "Train Epoch: 16 [128/14860 (1%)]\tLoss: 0.025100\n",
      "Train Epoch: 16 [256/14860 (2%)]\tLoss: 0.026702\n",
      "Train Epoch: 16 [384/14860 (3%)]\tLoss: 0.025710\n",
      "Train Epoch: 16 [512/14860 (3%)]\tLoss: 0.019388\n",
      "Train Epoch: 16 [640/14860 (4%)]\tLoss: 0.019155\n",
      "Train Epoch: 16 [768/14860 (5%)]\tLoss: 0.034104\n",
      "Train Epoch: 16 [896/14860 (6%)]\tLoss: 0.040493\n",
      "Train Epoch: 16 [1024/14860 (7%)]\tLoss: 0.023858\n",
      "Train Epoch: 16 [1152/14860 (8%)]\tLoss: 0.034532\n",
      "Train Epoch: 16 [1280/14860 (9%)]\tLoss: 0.023882\n",
      "Train Epoch: 16 [1408/14860 (9%)]\tLoss: 0.020936\n",
      "Train Epoch: 16 [1536/14860 (10%)]\tLoss: 0.025474\n",
      "Train Epoch: 16 [1664/14860 (11%)]\tLoss: 0.019726\n",
      "Train Epoch: 16 [1792/14860 (12%)]\tLoss: 0.024344\n",
      "Train Epoch: 16 [1920/14860 (13%)]\tLoss: 0.012592\n",
      "Train Epoch: 16 [2048/14860 (14%)]\tLoss: 0.025107\n",
      "Train Epoch: 16 [2176/14860 (15%)]\tLoss: 0.018893\n",
      "Train Epoch: 16 [2304/14860 (15%)]\tLoss: 0.021713\n",
      "Train Epoch: 16 [2432/14860 (16%)]\tLoss: 0.021420\n",
      "Train Epoch: 16 [2560/14860 (17%)]\tLoss: 0.019782\n",
      "Train Epoch: 16 [2688/14860 (18%)]\tLoss: 0.019580\n",
      "Train Epoch: 16 [2816/14860 (19%)]\tLoss: 0.017178\n",
      "Train Epoch: 16 [2944/14860 (20%)]\tLoss: 0.022731\n",
      "Train Epoch: 16 [3072/14860 (21%)]\tLoss: 0.018934\n",
      "Train Epoch: 16 [3200/14860 (21%)]\tLoss: 0.024024\n",
      "Train Epoch: 16 [3328/14860 (22%)]\tLoss: 0.025910\n",
      "Train Epoch: 16 [3456/14860 (23%)]\tLoss: 0.023704\n",
      "Train Epoch: 16 [3584/14860 (24%)]\tLoss: 0.024111\n",
      "Train Epoch: 16 [3712/14860 (25%)]\tLoss: 0.015572\n",
      "Train Epoch: 16 [3840/14860 (26%)]\tLoss: 0.019643\n",
      "Train Epoch: 16 [3968/14860 (26%)]\tLoss: 0.018444\n",
      "Train Epoch: 16 [4096/14860 (27%)]\tLoss: 0.021415\n",
      "Train Epoch: 16 [4224/14860 (28%)]\tLoss: 0.027031\n",
      "Train Epoch: 16 [4352/14860 (29%)]\tLoss: 0.021407\n",
      "Train Epoch: 16 [4480/14860 (30%)]\tLoss: 0.018085\n",
      "Train Epoch: 16 [4608/14860 (31%)]\tLoss: 0.016255\n",
      "Train Epoch: 16 [4736/14860 (32%)]\tLoss: 0.022219\n",
      "Train Epoch: 16 [4864/14860 (32%)]\tLoss: 0.024420\n",
      "Train Epoch: 16 [4992/14860 (33%)]\tLoss: 0.019096\n",
      "Train Epoch: 16 [5120/14860 (34%)]\tLoss: 0.024878\n",
      "Train Epoch: 16 [5248/14860 (35%)]\tLoss: 0.016854\n",
      "Train Epoch: 16 [5376/14860 (36%)]\tLoss: 0.010411\n",
      "Train Epoch: 16 [5504/14860 (37%)]\tLoss: 0.019502\n",
      "Train Epoch: 16 [5632/14860 (38%)]\tLoss: 0.020289\n",
      "Train Epoch: 16 [5760/14860 (38%)]\tLoss: 0.017279\n",
      "Train Epoch: 16 [5888/14860 (39%)]\tLoss: 0.024327\n",
      "Train Epoch: 16 [6016/14860 (40%)]\tLoss: 0.018233\n",
      "Train Epoch: 16 [6144/14860 (41%)]\tLoss: 0.028574\n",
      "Train Epoch: 16 [6272/14860 (42%)]\tLoss: 0.022068\n",
      "Train Epoch: 16 [6400/14860 (43%)]\tLoss: 0.018892\n",
      "Train Epoch: 16 [6528/14860 (44%)]\tLoss: 0.017232\n",
      "Train Epoch: 16 [6656/14860 (44%)]\tLoss: 0.020231\n",
      "Train Epoch: 16 [6784/14860 (45%)]\tLoss: 0.026131\n",
      "Train Epoch: 16 [6912/14860 (46%)]\tLoss: 0.015800\n",
      "Train Epoch: 16 [7040/14860 (47%)]\tLoss: 0.023118\n",
      "Train Epoch: 16 [7168/14860 (48%)]\tLoss: 0.020813\n",
      "Train Epoch: 16 [7296/14860 (49%)]\tLoss: 0.018113\n",
      "Train Epoch: 16 [7424/14860 (50%)]\tLoss: 0.019607\n",
      "Train Epoch: 16 [7552/14860 (50%)]\tLoss: 0.025379\n",
      "Train Epoch: 16 [7680/14860 (51%)]\tLoss: 0.018151\n",
      "Train Epoch: 16 [7808/14860 (52%)]\tLoss: 0.026410\n",
      "Train Epoch: 16 [7936/14860 (53%)]\tLoss: 0.021024\n",
      "Train Epoch: 16 [8064/14860 (54%)]\tLoss: 0.021372\n",
      "Train Epoch: 16 [8192/14860 (55%)]\tLoss: 0.028412\n",
      "Train Epoch: 16 [8320/14860 (56%)]\tLoss: 0.017635\n",
      "Train Epoch: 16 [8448/14860 (56%)]\tLoss: 0.022205\n",
      "Train Epoch: 16 [8576/14860 (57%)]\tLoss: 0.024707\n",
      "Train Epoch: 16 [8704/14860 (58%)]\tLoss: 0.022128\n",
      "Train Epoch: 16 [8832/14860 (59%)]\tLoss: 0.018854\n",
      "Train Epoch: 16 [8960/14860 (60%)]\tLoss: 0.019620\n",
      "Train Epoch: 16 [9088/14860 (61%)]\tLoss: 0.034394\n",
      "Train Epoch: 16 [9216/14860 (62%)]\tLoss: 0.022141\n",
      "Train Epoch: 16 [9344/14860 (62%)]\tLoss: 0.019514\n",
      "Train Epoch: 16 [9472/14860 (63%)]\tLoss: 0.029617\n",
      "Train Epoch: 16 [9600/14860 (64%)]\tLoss: 0.025031\n",
      "Train Epoch: 16 [9728/14860 (65%)]\tLoss: 0.021653\n",
      "Train Epoch: 16 [9856/14860 (66%)]\tLoss: 0.019143\n",
      "Train Epoch: 16 [9984/14860 (67%)]\tLoss: 0.017720\n",
      "Train Epoch: 16 [10112/14860 (68%)]\tLoss: 0.020322\n",
      "Train Epoch: 16 [10240/14860 (68%)]\tLoss: 0.017148\n",
      "Train Epoch: 16 [10368/14860 (69%)]\tLoss: 0.023274\n",
      "Train Epoch: 16 [10496/14860 (70%)]\tLoss: 0.023681\n",
      "Train Epoch: 16 [10624/14860 (71%)]\tLoss: 0.033884\n",
      "Train Epoch: 16 [10752/14860 (72%)]\tLoss: 0.013896\n",
      "Train Epoch: 16 [10880/14860 (73%)]\tLoss: 0.019630\n",
      "Train Epoch: 16 [11008/14860 (74%)]\tLoss: 0.023361\n",
      "Train Epoch: 16 [11136/14860 (74%)]\tLoss: 0.023272\n",
      "Train Epoch: 16 [11264/14860 (75%)]\tLoss: 0.024878\n",
      "Train Epoch: 16 [11392/14860 (76%)]\tLoss: 0.021653\n",
      "Train Epoch: 16 [11520/14860 (77%)]\tLoss: 0.020834\n",
      "Train Epoch: 16 [11648/14860 (78%)]\tLoss: 0.015239\n",
      "Train Epoch: 16 [11776/14860 (79%)]\tLoss: 0.027842\n",
      "Train Epoch: 16 [11904/14860 (79%)]\tLoss: 0.022492\n",
      "Train Epoch: 16 [12032/14860 (80%)]\tLoss: 0.026241\n",
      "Train Epoch: 16 [12160/14860 (81%)]\tLoss: 0.020436\n",
      "Train Epoch: 16 [12288/14860 (82%)]\tLoss: 0.034717\n",
      "Train Epoch: 16 [12416/14860 (83%)]\tLoss: 0.023877\n",
      "Train Epoch: 16 [12544/14860 (84%)]\tLoss: 0.029975\n",
      "Train Epoch: 16 [12672/14860 (85%)]\tLoss: 0.033718\n",
      "Train Epoch: 16 [12800/14860 (85%)]\tLoss: 0.011793\n",
      "Train Epoch: 16 [12928/14860 (86%)]\tLoss: 0.026434\n",
      "Train Epoch: 16 [13056/14860 (87%)]\tLoss: 0.024789\n",
      "Train Epoch: 16 [13184/14860 (88%)]\tLoss: 0.016159\n",
      "Train Epoch: 16 [13312/14860 (89%)]\tLoss: 0.020787\n",
      "Train Epoch: 16 [13440/14860 (90%)]\tLoss: 0.024945\n",
      "Train Epoch: 16 [13568/14860 (91%)]\tLoss: 0.018818\n",
      "Train Epoch: 16 [13696/14860 (91%)]\tLoss: 0.018128\n",
      "Train Epoch: 16 [13824/14860 (92%)]\tLoss: 0.028008\n",
      "Train Epoch: 16 [13952/14860 (93%)]\tLoss: 0.016524\n",
      "Train Epoch: 16 [14080/14860 (94%)]\tLoss: 0.017871\n",
      "Train Epoch: 16 [14208/14860 (95%)]\tLoss: 0.023367\n",
      "Train Epoch: 16 [14336/14860 (96%)]\tLoss: 0.021850\n",
      "Train Epoch: 16 [14464/14860 (97%)]\tLoss: 0.023407\n",
      "Train Epoch: 16 [14592/14860 (97%)]\tLoss: 0.031527\n",
      "Train Epoch: 16 [14720/14860 (98%)]\tLoss: 0.023716\n",
      "Train Epoch: 16 [1392/14860 (99%)]\tLoss: 0.023602\n",
      "epoch 16 training loss: 0.022331441370531533\n",
      "epoch 16 validation loss: 0.02858252805312667\n",
      "Train Epoch: 17 [0/14860 (0%)]\tLoss: 0.025882\n",
      "Train Epoch: 17 [128/14860 (1%)]\tLoss: 0.028420\n",
      "Train Epoch: 17 [256/14860 (2%)]\tLoss: 0.042567\n",
      "Train Epoch: 17 [384/14860 (3%)]\tLoss: 0.036311\n",
      "Train Epoch: 17 [512/14860 (3%)]\tLoss: 0.020100\n",
      "Train Epoch: 17 [640/14860 (4%)]\tLoss: 0.049454\n",
      "Train Epoch: 17 [768/14860 (5%)]\tLoss: 0.023930\n",
      "Train Epoch: 17 [896/14860 (6%)]\tLoss: 0.026119\n",
      "Train Epoch: 17 [1024/14860 (7%)]\tLoss: 0.032356\n",
      "Train Epoch: 17 [1152/14860 (8%)]\tLoss: 0.029245\n",
      "Train Epoch: 17 [1280/14860 (9%)]\tLoss: 0.027171\n",
      "Train Epoch: 17 [1408/14860 (9%)]\tLoss: 0.027263\n",
      "Train Epoch: 17 [1536/14860 (10%)]\tLoss: 0.032012\n",
      "Train Epoch: 17 [1664/14860 (11%)]\tLoss: 0.021711\n",
      "Train Epoch: 17 [1792/14860 (12%)]\tLoss: 0.024560\n",
      "Train Epoch: 17 [1920/14860 (13%)]\tLoss: 0.033532\n",
      "Train Epoch: 17 [2048/14860 (14%)]\tLoss: 0.019243\n",
      "Train Epoch: 17 [2176/14860 (15%)]\tLoss: 0.042536\n",
      "Train Epoch: 17 [2304/14860 (15%)]\tLoss: 0.016363\n",
      "Train Epoch: 17 [2432/14860 (16%)]\tLoss: 0.045310\n",
      "Train Epoch: 17 [2560/14860 (17%)]\tLoss: 0.025448\n",
      "Train Epoch: 17 [2688/14860 (18%)]\tLoss: 0.033125\n",
      "Train Epoch: 17 [2816/14860 (19%)]\tLoss: 0.015567\n",
      "Train Epoch: 17 [2944/14860 (20%)]\tLoss: 0.031413\n",
      "Train Epoch: 17 [3072/14860 (21%)]\tLoss: 0.026085\n",
      "Train Epoch: 17 [3200/14860 (21%)]\tLoss: 0.037717\n",
      "Train Epoch: 17 [3328/14860 (22%)]\tLoss: 0.022214\n",
      "Train Epoch: 17 [3456/14860 (23%)]\tLoss: 0.030244\n",
      "Train Epoch: 17 [3584/14860 (24%)]\tLoss: 0.024514\n",
      "Train Epoch: 17 [3712/14860 (25%)]\tLoss: 0.025605\n",
      "Train Epoch: 17 [3840/14860 (26%)]\tLoss: 0.024951\n",
      "Train Epoch: 17 [3968/14860 (26%)]\tLoss: 0.016557\n",
      "Train Epoch: 17 [4096/14860 (27%)]\tLoss: 0.019289\n",
      "Train Epoch: 17 [4224/14860 (28%)]\tLoss: 0.022232\n",
      "Train Epoch: 17 [4352/14860 (29%)]\tLoss: 0.017125\n",
      "Train Epoch: 17 [4480/14860 (30%)]\tLoss: 0.019488\n",
      "Train Epoch: 17 [4608/14860 (31%)]\tLoss: 0.019992\n",
      "Train Epoch: 17 [4736/14860 (32%)]\tLoss: 0.017110\n",
      "Train Epoch: 17 [4864/14860 (32%)]\tLoss: 0.020055\n",
      "Train Epoch: 17 [4992/14860 (33%)]\tLoss: 0.022953\n",
      "Train Epoch: 17 [5120/14860 (34%)]\tLoss: 0.021115\n",
      "Train Epoch: 17 [5248/14860 (35%)]\tLoss: 0.027212\n",
      "Train Epoch: 17 [5376/14860 (36%)]\tLoss: 0.023440\n",
      "Train Epoch: 17 [5504/14860 (37%)]\tLoss: 0.021929\n",
      "Train Epoch: 17 [5632/14860 (38%)]\tLoss: 0.023488\n",
      "Train Epoch: 17 [5760/14860 (38%)]\tLoss: 0.019625\n",
      "Train Epoch: 17 [5888/14860 (39%)]\tLoss: 0.013109\n",
      "Train Epoch: 17 [6016/14860 (40%)]\tLoss: 0.019760\n",
      "Train Epoch: 17 [6144/14860 (41%)]\tLoss: 0.024840\n",
      "Train Epoch: 17 [6272/14860 (42%)]\tLoss: 0.025130\n",
      "Train Epoch: 17 [6400/14860 (43%)]\tLoss: 0.019235\n",
      "Train Epoch: 17 [6528/14860 (44%)]\tLoss: 0.036000\n",
      "Train Epoch: 17 [6656/14860 (44%)]\tLoss: 0.021808\n",
      "Train Epoch: 17 [6784/14860 (45%)]\tLoss: 0.025187\n",
      "Train Epoch: 17 [6912/14860 (46%)]\tLoss: 0.017450\n",
      "Train Epoch: 17 [7040/14860 (47%)]\tLoss: 0.033400\n",
      "Train Epoch: 17 [7168/14860 (48%)]\tLoss: 0.016878\n",
      "Train Epoch: 17 [7296/14860 (49%)]\tLoss: 0.035948\n",
      "Train Epoch: 17 [7424/14860 (50%)]\tLoss: 0.026050\n",
      "Train Epoch: 17 [7552/14860 (50%)]\tLoss: 0.023130\n",
      "Train Epoch: 17 [7680/14860 (51%)]\tLoss: 0.016340\n",
      "Train Epoch: 17 [7808/14860 (52%)]\tLoss: 0.025807\n",
      "Train Epoch: 17 [7936/14860 (53%)]\tLoss: 0.021884\n",
      "Train Epoch: 17 [8064/14860 (54%)]\tLoss: 0.021565\n",
      "Train Epoch: 17 [8192/14860 (55%)]\tLoss: 0.020867\n",
      "Train Epoch: 17 [8320/14860 (56%)]\tLoss: 0.025347\n",
      "Train Epoch: 17 [8448/14860 (56%)]\tLoss: 0.018128\n",
      "Train Epoch: 17 [8576/14860 (57%)]\tLoss: 0.020799\n",
      "Train Epoch: 17 [8704/14860 (58%)]\tLoss: 0.014712\n",
      "Train Epoch: 17 [8832/14860 (59%)]\tLoss: 0.020271\n",
      "Train Epoch: 17 [8960/14860 (60%)]\tLoss: 0.023740\n",
      "Train Epoch: 17 [9088/14860 (61%)]\tLoss: 0.022015\n",
      "Train Epoch: 17 [9216/14860 (62%)]\tLoss: 0.031893\n",
      "Train Epoch: 17 [9344/14860 (62%)]\tLoss: 0.030094\n",
      "Train Epoch: 17 [9472/14860 (63%)]\tLoss: 0.018321\n",
      "Train Epoch: 17 [9600/14860 (64%)]\tLoss: 0.027734\n",
      "Train Epoch: 17 [9728/14860 (65%)]\tLoss: 0.012213\n",
      "Train Epoch: 17 [9856/14860 (66%)]\tLoss: 0.021347\n",
      "Train Epoch: 17 [9984/14860 (67%)]\tLoss: 0.021468\n",
      "Train Epoch: 17 [10112/14860 (68%)]\tLoss: 0.022216\n",
      "Train Epoch: 17 [10240/14860 (68%)]\tLoss: 0.027084\n",
      "Train Epoch: 17 [10368/14860 (69%)]\tLoss: 0.017280\n",
      "Train Epoch: 17 [10496/14860 (70%)]\tLoss: 0.017737\n",
      "Train Epoch: 17 [10624/14860 (71%)]\tLoss: 0.018077\n",
      "Train Epoch: 17 [10752/14860 (72%)]\tLoss: 0.022826\n",
      "Train Epoch: 17 [10880/14860 (73%)]\tLoss: 0.020993\n",
      "Train Epoch: 17 [11008/14860 (74%)]\tLoss: 0.022988\n",
      "Train Epoch: 17 [11136/14860 (74%)]\tLoss: 0.015003\n",
      "Train Epoch: 17 [11264/14860 (75%)]\tLoss: 0.036435\n",
      "Train Epoch: 17 [11392/14860 (76%)]\tLoss: 0.019183\n",
      "Train Epoch: 17 [11520/14860 (77%)]\tLoss: 0.028478\n",
      "Train Epoch: 17 [11648/14860 (78%)]\tLoss: 0.028152\n",
      "Train Epoch: 17 [11776/14860 (79%)]\tLoss: 0.033857\n",
      "Train Epoch: 17 [11904/14860 (79%)]\tLoss: 0.028058\n",
      "Train Epoch: 17 [12032/14860 (80%)]\tLoss: 0.024977\n",
      "Train Epoch: 17 [12160/14860 (81%)]\tLoss: 0.025075\n",
      "Train Epoch: 17 [12288/14860 (82%)]\tLoss: 0.030220\n",
      "Train Epoch: 17 [12416/14860 (83%)]\tLoss: 0.019899\n",
      "Train Epoch: 17 [12544/14860 (84%)]\tLoss: 0.026290\n",
      "Train Epoch: 17 [12672/14860 (85%)]\tLoss: 0.028965\n",
      "Train Epoch: 17 [12800/14860 (85%)]\tLoss: 0.026795\n",
      "Train Epoch: 17 [12928/14860 (86%)]\tLoss: 0.020213\n",
      "Train Epoch: 17 [13056/14860 (87%)]\tLoss: 0.023926\n",
      "Train Epoch: 17 [13184/14860 (88%)]\tLoss: 0.020430\n",
      "Train Epoch: 17 [13312/14860 (89%)]\tLoss: 0.012837\n",
      "Train Epoch: 17 [13440/14860 (90%)]\tLoss: 0.015943\n",
      "Train Epoch: 17 [13568/14860 (91%)]\tLoss: 0.024703\n",
      "Train Epoch: 17 [13696/14860 (91%)]\tLoss: 0.028067\n",
      "Train Epoch: 17 [13824/14860 (92%)]\tLoss: 0.018369\n",
      "Train Epoch: 17 [13952/14860 (93%)]\tLoss: 0.023546\n",
      "Train Epoch: 17 [14080/14860 (94%)]\tLoss: 0.020178\n",
      "Train Epoch: 17 [14208/14860 (95%)]\tLoss: 0.014189\n",
      "Train Epoch: 17 [14336/14860 (96%)]\tLoss: 0.018933\n",
      "Train Epoch: 17 [14464/14860 (97%)]\tLoss: 0.021409\n",
      "Train Epoch: 17 [14592/14860 (97%)]\tLoss: 0.025325\n",
      "Train Epoch: 17 [14720/14860 (98%)]\tLoss: 0.018984\n",
      "Train Epoch: 17 [1392/14860 (99%)]\tLoss: 0.023083\n",
      "epoch 17 training loss: 0.024237339050532915\n",
      "epoch 17 validation loss: 0.022842411123234194\n",
      "Train Epoch: 18 [0/14860 (0%)]\tLoss: 0.016133\n",
      "Train Epoch: 18 [128/14860 (1%)]\tLoss: 0.022607\n",
      "Train Epoch: 18 [256/14860 (2%)]\tLoss: 0.015215\n",
      "Train Epoch: 18 [384/14860 (3%)]\tLoss: 0.050269\n",
      "Train Epoch: 18 [512/14860 (3%)]\tLoss: 0.038385\n",
      "Train Epoch: 18 [640/14860 (4%)]\tLoss: 0.034290\n",
      "Train Epoch: 18 [768/14860 (5%)]\tLoss: 0.048191\n",
      "Train Epoch: 18 [896/14860 (6%)]\tLoss: 0.042981\n",
      "Train Epoch: 18 [1024/14860 (7%)]\tLoss: 0.031122\n",
      "Train Epoch: 18 [1152/14860 (8%)]\tLoss: 0.030276\n",
      "Train Epoch: 18 [1280/14860 (9%)]\tLoss: 0.026308\n",
      "Train Epoch: 18 [1408/14860 (9%)]\tLoss: 0.036441\n",
      "Train Epoch: 18 [1536/14860 (10%)]\tLoss: 0.021318\n",
      "Train Epoch: 18 [1664/14860 (11%)]\tLoss: 0.028677\n",
      "Train Epoch: 18 [1792/14860 (12%)]\tLoss: 0.014924\n",
      "Train Epoch: 18 [1920/14860 (13%)]\tLoss: 0.025575\n",
      "Train Epoch: 18 [2048/14860 (14%)]\tLoss: 0.026812\n",
      "Train Epoch: 18 [2176/14860 (15%)]\tLoss: 0.028581\n",
      "Train Epoch: 18 [2304/14860 (15%)]\tLoss: 0.029324\n",
      "Train Epoch: 18 [2432/14860 (16%)]\tLoss: 0.018877\n",
      "Train Epoch: 18 [2560/14860 (17%)]\tLoss: 0.023472\n",
      "Train Epoch: 18 [2688/14860 (18%)]\tLoss: 0.023041\n",
      "Train Epoch: 18 [2816/14860 (19%)]\tLoss: 0.018349\n",
      "Train Epoch: 18 [2944/14860 (20%)]\tLoss: 0.024826\n",
      "Train Epoch: 18 [3072/14860 (21%)]\tLoss: 0.016379\n",
      "Train Epoch: 18 [3200/14860 (21%)]\tLoss: 0.022707\n",
      "Train Epoch: 18 [3328/14860 (22%)]\tLoss: 0.019672\n",
      "Train Epoch: 18 [3456/14860 (23%)]\tLoss: 0.021086\n",
      "Train Epoch: 18 [3584/14860 (24%)]\tLoss: 0.026708\n",
      "Train Epoch: 18 [3712/14860 (25%)]\tLoss: 0.022852\n",
      "Train Epoch: 18 [3840/14860 (26%)]\tLoss: 0.026360\n",
      "Train Epoch: 18 [3968/14860 (26%)]\tLoss: 0.019170\n",
      "Train Epoch: 18 [4096/14860 (27%)]\tLoss: 0.014360\n",
      "Train Epoch: 18 [4224/14860 (28%)]\tLoss: 0.024947\n",
      "Train Epoch: 18 [4352/14860 (29%)]\tLoss: 0.015132\n",
      "Train Epoch: 18 [4480/14860 (30%)]\tLoss: 0.023505\n",
      "Train Epoch: 18 [4608/14860 (31%)]\tLoss: 0.028406\n",
      "Train Epoch: 18 [4736/14860 (32%)]\tLoss: 0.015437\n",
      "Train Epoch: 18 [4864/14860 (32%)]\tLoss: 0.020591\n",
      "Train Epoch: 18 [4992/14860 (33%)]\tLoss: 0.027876\n",
      "Train Epoch: 18 [5120/14860 (34%)]\tLoss: 0.017633\n",
      "Train Epoch: 18 [5248/14860 (35%)]\tLoss: 0.022011\n",
      "Train Epoch: 18 [5376/14860 (36%)]\tLoss: 0.030653\n",
      "Train Epoch: 18 [5504/14860 (37%)]\tLoss: 0.022349\n",
      "Train Epoch: 18 [5632/14860 (38%)]\tLoss: 0.025042\n",
      "Train Epoch: 18 [5760/14860 (38%)]\tLoss: 0.021215\n",
      "Train Epoch: 18 [5888/14860 (39%)]\tLoss: 0.021236\n",
      "Train Epoch: 18 [6016/14860 (40%)]\tLoss: 0.026153\n",
      "Train Epoch: 18 [6144/14860 (41%)]\tLoss: 0.022016\n",
      "Train Epoch: 18 [6272/14860 (42%)]\tLoss: 0.026742\n",
      "Train Epoch: 18 [6400/14860 (43%)]\tLoss: 0.027430\n",
      "Train Epoch: 18 [6528/14860 (44%)]\tLoss: 0.020160\n",
      "Train Epoch: 18 [6656/14860 (44%)]\tLoss: 0.017634\n",
      "Train Epoch: 18 [6784/14860 (45%)]\tLoss: 0.021705\n",
      "Train Epoch: 18 [6912/14860 (46%)]\tLoss: 0.015090\n",
      "Train Epoch: 18 [7040/14860 (47%)]\tLoss: 0.012872\n",
      "Train Epoch: 18 [7168/14860 (48%)]\tLoss: 0.019237\n",
      "Train Epoch: 18 [7296/14860 (49%)]\tLoss: 0.015971\n",
      "Train Epoch: 18 [7424/14860 (50%)]\tLoss: 0.018764\n",
      "Train Epoch: 18 [7552/14860 (50%)]\tLoss: 0.026900\n",
      "Train Epoch: 18 [7680/14860 (51%)]\tLoss: 0.021144\n",
      "Train Epoch: 18 [7808/14860 (52%)]\tLoss: 0.033734\n",
      "Train Epoch: 18 [7936/14860 (53%)]\tLoss: 0.015671\n",
      "Train Epoch: 18 [8064/14860 (54%)]\tLoss: 0.026956\n",
      "Train Epoch: 18 [8192/14860 (55%)]\tLoss: 0.019752\n",
      "Train Epoch: 18 [8320/14860 (56%)]\tLoss: 0.026643\n",
      "Train Epoch: 18 [8448/14860 (56%)]\tLoss: 0.015394\n",
      "Train Epoch: 18 [8576/14860 (57%)]\tLoss: 0.023212\n",
      "Train Epoch: 18 [8704/14860 (58%)]\tLoss: 0.021065\n",
      "Train Epoch: 18 [8832/14860 (59%)]\tLoss: 0.025027\n",
      "Train Epoch: 18 [8960/14860 (60%)]\tLoss: 0.019878\n",
      "Train Epoch: 18 [9088/14860 (61%)]\tLoss: 0.026030\n",
      "Train Epoch: 18 [9216/14860 (62%)]\tLoss: 0.016350\n",
      "Train Epoch: 18 [9344/14860 (62%)]\tLoss: 0.019608\n",
      "Train Epoch: 18 [9472/14860 (63%)]\tLoss: 0.020820\n",
      "Train Epoch: 18 [9600/14860 (64%)]\tLoss: 0.018004\n",
      "Train Epoch: 18 [9728/14860 (65%)]\tLoss: 0.025585\n",
      "Train Epoch: 18 [9856/14860 (66%)]\tLoss: 0.020611\n",
      "Train Epoch: 18 [9984/14860 (67%)]\tLoss: 0.015262\n",
      "Train Epoch: 18 [10112/14860 (68%)]\tLoss: 0.023417\n",
      "Train Epoch: 18 [10240/14860 (68%)]\tLoss: 0.024032\n",
      "Train Epoch: 18 [10368/14860 (69%)]\tLoss: 0.022232\n",
      "Train Epoch: 18 [10496/14860 (70%)]\tLoss: 0.013513\n",
      "Train Epoch: 18 [10624/14860 (71%)]\tLoss: 0.034850\n",
      "Train Epoch: 18 [10752/14860 (72%)]\tLoss: 0.017673\n",
      "Train Epoch: 18 [10880/14860 (73%)]\tLoss: 0.036936\n",
      "Train Epoch: 18 [11008/14860 (74%)]\tLoss: 0.021679\n",
      "Train Epoch: 18 [11136/14860 (74%)]\tLoss: 0.021383\n",
      "Train Epoch: 18 [11264/14860 (75%)]\tLoss: 0.024982\n",
      "Train Epoch: 18 [11392/14860 (76%)]\tLoss: 0.021047\n",
      "Train Epoch: 18 [11520/14860 (77%)]\tLoss: 0.023099\n",
      "Train Epoch: 18 [11648/14860 (78%)]\tLoss: 0.020051\n",
      "Train Epoch: 18 [11776/14860 (79%)]\tLoss: 0.022428\n",
      "Train Epoch: 18 [11904/14860 (79%)]\tLoss: 0.013445\n",
      "Train Epoch: 18 [12032/14860 (80%)]\tLoss: 0.025497\n",
      "Train Epoch: 18 [12160/14860 (81%)]\tLoss: 0.023728\n",
      "Train Epoch: 18 [12288/14860 (82%)]\tLoss: 0.023281\n",
      "Train Epoch: 18 [12416/14860 (83%)]\tLoss: 0.017149\n",
      "Train Epoch: 18 [12544/14860 (84%)]\tLoss: 0.014901\n",
      "Train Epoch: 18 [12672/14860 (85%)]\tLoss: 0.024212\n",
      "Train Epoch: 18 [12800/14860 (85%)]\tLoss: 0.025588\n",
      "Train Epoch: 18 [12928/14860 (86%)]\tLoss: 0.020730\n",
      "Train Epoch: 18 [13056/14860 (87%)]\tLoss: 0.026469\n",
      "Train Epoch: 18 [13184/14860 (88%)]\tLoss: 0.016111\n",
      "Train Epoch: 18 [13312/14860 (89%)]\tLoss: 0.025134\n",
      "Train Epoch: 18 [13440/14860 (90%)]\tLoss: 0.014976\n",
      "Train Epoch: 18 [13568/14860 (91%)]\tLoss: 0.019280\n",
      "Train Epoch: 18 [13696/14860 (91%)]\tLoss: 0.018981\n",
      "Train Epoch: 18 [13824/14860 (92%)]\tLoss: 0.026622\n",
      "Train Epoch: 18 [13952/14860 (93%)]\tLoss: 0.024957\n",
      "Train Epoch: 18 [14080/14860 (94%)]\tLoss: 0.020567\n",
      "Train Epoch: 18 [14208/14860 (95%)]\tLoss: 0.023847\n",
      "Train Epoch: 18 [14336/14860 (96%)]\tLoss: 0.017249\n",
      "Train Epoch: 18 [14464/14860 (97%)]\tLoss: 0.026656\n",
      "Train Epoch: 18 [14592/14860 (97%)]\tLoss: 0.022387\n",
      "Train Epoch: 18 [14720/14860 (98%)]\tLoss: 0.031006\n",
      "Train Epoch: 18 [1392/14860 (99%)]\tLoss: 0.015934\n",
      "epoch 18 training loss: 0.02315181715047767\n",
      "epoch 18 validation loss: 0.03855764981332183\n",
      "Train Epoch: 19 [0/14860 (0%)]\tLoss: 0.030004\n",
      "Train Epoch: 19 [128/14860 (1%)]\tLoss: 0.028859\n",
      "Train Epoch: 19 [256/14860 (2%)]\tLoss: 0.048242\n",
      "Train Epoch: 19 [384/14860 (3%)]\tLoss: 0.017901\n",
      "Train Epoch: 19 [512/14860 (3%)]\tLoss: 0.022583\n",
      "Train Epoch: 19 [640/14860 (4%)]\tLoss: 0.029831\n",
      "Train Epoch: 19 [768/14860 (5%)]\tLoss: 0.032324\n",
      "Train Epoch: 19 [896/14860 (6%)]\tLoss: 0.019936\n",
      "Train Epoch: 19 [1024/14860 (7%)]\tLoss: 0.015850\n",
      "Train Epoch: 19 [1152/14860 (8%)]\tLoss: 0.023773\n",
      "Train Epoch: 19 [1280/14860 (9%)]\tLoss: 0.024061\n",
      "Train Epoch: 19 [1408/14860 (9%)]\tLoss: 0.035697\n",
      "Train Epoch: 19 [1536/14860 (10%)]\tLoss: 0.022459\n",
      "Train Epoch: 19 [1664/14860 (11%)]\tLoss: 0.030510\n",
      "Train Epoch: 19 [1792/14860 (12%)]\tLoss: 0.017679\n",
      "Train Epoch: 19 [1920/14860 (13%)]\tLoss: 0.022059\n",
      "Train Epoch: 19 [2048/14860 (14%)]\tLoss: 0.021408\n",
      "Train Epoch: 19 [2176/14860 (15%)]\tLoss: 0.021411\n",
      "Train Epoch: 19 [2304/14860 (15%)]\tLoss: 0.020320\n",
      "Train Epoch: 19 [2432/14860 (16%)]\tLoss: 0.020054\n",
      "Train Epoch: 19 [2560/14860 (17%)]\tLoss: 0.025858\n",
      "Train Epoch: 19 [2688/14860 (18%)]\tLoss: 0.019145\n",
      "Train Epoch: 19 [2816/14860 (19%)]\tLoss: 0.029206\n",
      "Train Epoch: 19 [2944/14860 (20%)]\tLoss: 0.011851\n",
      "Train Epoch: 19 [3072/14860 (21%)]\tLoss: 0.026320\n",
      "Train Epoch: 19 [3200/14860 (21%)]\tLoss: 0.019176\n",
      "Train Epoch: 19 [3328/14860 (22%)]\tLoss: 0.022186\n",
      "Train Epoch: 19 [3456/14860 (23%)]\tLoss: 0.015485\n",
      "Train Epoch: 19 [3584/14860 (24%)]\tLoss: 0.026798\n",
      "Train Epoch: 19 [3712/14860 (25%)]\tLoss: 0.024697\n",
      "Train Epoch: 19 [3840/14860 (26%)]\tLoss: 0.015213\n",
      "Train Epoch: 19 [3968/14860 (26%)]\tLoss: 0.025343\n",
      "Train Epoch: 19 [4096/14860 (27%)]\tLoss: 0.022153\n",
      "Train Epoch: 19 [4224/14860 (28%)]\tLoss: 0.028238\n",
      "Train Epoch: 19 [4352/14860 (29%)]\tLoss: 0.020202\n",
      "Train Epoch: 19 [4480/14860 (30%)]\tLoss: 0.016297\n",
      "Train Epoch: 19 [4608/14860 (31%)]\tLoss: 0.019391\n",
      "Train Epoch: 19 [4736/14860 (32%)]\tLoss: 0.028539\n",
      "Train Epoch: 19 [4864/14860 (32%)]\tLoss: 0.023175\n",
      "Train Epoch: 19 [4992/14860 (33%)]\tLoss: 0.013480\n",
      "Train Epoch: 19 [5120/14860 (34%)]\tLoss: 0.018895\n",
      "Train Epoch: 19 [5248/14860 (35%)]\tLoss: 0.020884\n",
      "Train Epoch: 19 [5376/14860 (36%)]\tLoss: 0.020710\n",
      "Train Epoch: 19 [5504/14860 (37%)]\tLoss: 0.015742\n",
      "Train Epoch: 19 [5632/14860 (38%)]\tLoss: 0.022327\n",
      "Train Epoch: 19 [5760/14860 (38%)]\tLoss: 0.017723\n",
      "Train Epoch: 19 [5888/14860 (39%)]\tLoss: 0.026383\n",
      "Train Epoch: 19 [6016/14860 (40%)]\tLoss: 0.016546\n",
      "Train Epoch: 19 [6144/14860 (41%)]\tLoss: 0.016339\n",
      "Train Epoch: 19 [6272/14860 (42%)]\tLoss: 0.023328\n",
      "Train Epoch: 19 [6400/14860 (43%)]\tLoss: 0.022119\n",
      "Train Epoch: 19 [6528/14860 (44%)]\tLoss: 0.018523\n",
      "Train Epoch: 19 [6656/14860 (44%)]\tLoss: 0.028699\n",
      "Train Epoch: 19 [6784/14860 (45%)]\tLoss: 0.019062\n",
      "Train Epoch: 19 [6912/14860 (46%)]\tLoss: 0.024540\n",
      "Train Epoch: 19 [7040/14860 (47%)]\tLoss: 0.021378\n",
      "Train Epoch: 19 [7168/14860 (48%)]\tLoss: 0.022039\n",
      "Train Epoch: 19 [7296/14860 (49%)]\tLoss: 0.017591\n",
      "Train Epoch: 19 [7424/14860 (50%)]\tLoss: 0.016190\n",
      "Train Epoch: 19 [7552/14860 (50%)]\tLoss: 0.026463\n",
      "Train Epoch: 19 [7680/14860 (51%)]\tLoss: 0.020510\n",
      "Train Epoch: 19 [7808/14860 (52%)]\tLoss: 0.019581\n",
      "Train Epoch: 19 [7936/14860 (53%)]\tLoss: 0.018024\n",
      "Train Epoch: 19 [8064/14860 (54%)]\tLoss: 0.030028\n",
      "Train Epoch: 19 [8192/14860 (55%)]\tLoss: 0.017415\n",
      "Train Epoch: 19 [8320/14860 (56%)]\tLoss: 0.028142\n",
      "Train Epoch: 19 [8448/14860 (56%)]\tLoss: 0.024204\n",
      "Train Epoch: 19 [8576/14860 (57%)]\tLoss: 0.024842\n",
      "Train Epoch: 19 [8704/14860 (58%)]\tLoss: 0.016443\n",
      "Train Epoch: 19 [8832/14860 (59%)]\tLoss: 0.028132\n",
      "Train Epoch: 19 [8960/14860 (60%)]\tLoss: 0.024599\n",
      "Train Epoch: 19 [9088/14860 (61%)]\tLoss: 0.019124\n",
      "Train Epoch: 19 [9216/14860 (62%)]\tLoss: 0.014636\n",
      "Train Epoch: 19 [9344/14860 (62%)]\tLoss: 0.025579\n",
      "Train Epoch: 19 [9472/14860 (63%)]\tLoss: 0.020906\n",
      "Train Epoch: 19 [9600/14860 (64%)]\tLoss: 0.024418\n",
      "Train Epoch: 19 [9728/14860 (65%)]\tLoss: 0.029500\n",
      "Train Epoch: 19 [9856/14860 (66%)]\tLoss: 0.022172\n",
      "Train Epoch: 19 [9984/14860 (67%)]\tLoss: 0.027618\n",
      "Train Epoch: 19 [10112/14860 (68%)]\tLoss: 0.024061\n",
      "Train Epoch: 19 [10240/14860 (68%)]\tLoss: 0.032283\n",
      "Train Epoch: 19 [10368/14860 (69%)]\tLoss: 0.026495\n",
      "Train Epoch: 19 [10496/14860 (70%)]\tLoss: 0.028144\n",
      "Train Epoch: 19 [10624/14860 (71%)]\tLoss: 0.019650\n",
      "Train Epoch: 19 [10752/14860 (72%)]\tLoss: 0.023299\n",
      "Train Epoch: 19 [10880/14860 (73%)]\tLoss: 0.019389\n",
      "Train Epoch: 19 [11008/14860 (74%)]\tLoss: 0.025807\n",
      "Train Epoch: 19 [11136/14860 (74%)]\tLoss: 0.019421\n",
      "Train Epoch: 19 [11264/14860 (75%)]\tLoss: 0.036651\n",
      "Train Epoch: 19 [11392/14860 (76%)]\tLoss: 0.031376\n",
      "Train Epoch: 19 [11520/14860 (77%)]\tLoss: 0.024105\n",
      "Train Epoch: 19 [11648/14860 (78%)]\tLoss: 0.022891\n",
      "Train Epoch: 19 [11776/14860 (79%)]\tLoss: 0.025118\n",
      "Train Epoch: 19 [11904/14860 (79%)]\tLoss: 0.022115\n",
      "Train Epoch: 19 [12032/14860 (80%)]\tLoss: 0.021916\n",
      "Train Epoch: 19 [12160/14860 (81%)]\tLoss: 0.016748\n",
      "Train Epoch: 19 [12288/14860 (82%)]\tLoss: 0.015706\n",
      "Train Epoch: 19 [12416/14860 (83%)]\tLoss: 0.019860\n",
      "Train Epoch: 19 [12544/14860 (84%)]\tLoss: 0.025219\n",
      "Train Epoch: 19 [12672/14860 (85%)]\tLoss: 0.019851\n",
      "Train Epoch: 19 [12800/14860 (85%)]\tLoss: 0.019374\n",
      "Train Epoch: 19 [12928/14860 (86%)]\tLoss: 0.014882\n",
      "Train Epoch: 19 [13056/14860 (87%)]\tLoss: 0.016207\n",
      "Train Epoch: 19 [13184/14860 (88%)]\tLoss: 0.023593\n",
      "Train Epoch: 19 [13312/14860 (89%)]\tLoss: 0.020668\n",
      "Train Epoch: 19 [13440/14860 (90%)]\tLoss: 0.019828\n",
      "Train Epoch: 19 [13568/14860 (91%)]\tLoss: 0.017818\n",
      "Train Epoch: 19 [13696/14860 (91%)]\tLoss: 0.023012\n",
      "Train Epoch: 19 [13824/14860 (92%)]\tLoss: 0.021662\n",
      "Train Epoch: 19 [13952/14860 (93%)]\tLoss: 0.020699\n",
      "Train Epoch: 19 [14080/14860 (94%)]\tLoss: 0.026802\n",
      "Train Epoch: 19 [14208/14860 (95%)]\tLoss: 0.022326\n",
      "Train Epoch: 19 [14336/14860 (96%)]\tLoss: 0.022011\n",
      "Train Epoch: 19 [14464/14860 (97%)]\tLoss: 0.024177\n",
      "Train Epoch: 19 [14592/14860 (97%)]\tLoss: 0.020700\n",
      "Train Epoch: 19 [14720/14860 (98%)]\tLoss: 0.017218\n",
      "Train Epoch: 19 [1392/14860 (99%)]\tLoss: 0.017374\n",
      "epoch 19 training loss: 0.022542909695169866\n",
      "epoch 19 validation loss: 0.02460284974904095\n",
      "Train Epoch: 20 [0/14860 (0%)]\tLoss: 0.032956\n",
      "Train Epoch: 20 [128/14860 (1%)]\tLoss: 0.023659\n",
      "Train Epoch: 20 [256/14860 (2%)]\tLoss: 0.023169\n",
      "Train Epoch: 20 [384/14860 (3%)]\tLoss: 0.020769\n",
      "Train Epoch: 20 [512/14860 (3%)]\tLoss: 0.028817\n",
      "Train Epoch: 20 [640/14860 (4%)]\tLoss: 0.028389\n",
      "Train Epoch: 20 [768/14860 (5%)]\tLoss: 0.020503\n",
      "Train Epoch: 20 [896/14860 (6%)]\tLoss: 0.021844\n",
      "Train Epoch: 20 [1024/14860 (7%)]\tLoss: 0.019099\n",
      "Train Epoch: 20 [1152/14860 (8%)]\tLoss: 0.015415\n",
      "Train Epoch: 20 [1280/14860 (9%)]\tLoss: 0.019911\n",
      "Train Epoch: 20 [1408/14860 (9%)]\tLoss: 0.021936\n",
      "Train Epoch: 20 [1536/14860 (10%)]\tLoss: 0.028452\n",
      "Train Epoch: 20 [1664/14860 (11%)]\tLoss: 0.013927\n",
      "Train Epoch: 20 [1792/14860 (12%)]\tLoss: 0.015879\n",
      "Train Epoch: 20 [1920/14860 (13%)]\tLoss: 0.018912\n",
      "Train Epoch: 20 [2048/14860 (14%)]\tLoss: 0.025613\n",
      "Train Epoch: 20 [2176/14860 (15%)]\tLoss: 0.016614\n",
      "Train Epoch: 20 [2304/14860 (15%)]\tLoss: 0.026543\n",
      "Train Epoch: 20 [2432/14860 (16%)]\tLoss: 0.019798\n",
      "Train Epoch: 20 [2560/14860 (17%)]\tLoss: 0.019990\n",
      "Train Epoch: 20 [2688/14860 (18%)]\tLoss: 0.015140\n",
      "Train Epoch: 20 [2816/14860 (19%)]\tLoss: 0.022343\n",
      "Train Epoch: 20 [2944/14860 (20%)]\tLoss: 0.017691\n",
      "Train Epoch: 20 [3072/14860 (21%)]\tLoss: 0.012881\n",
      "Train Epoch: 20 [3200/14860 (21%)]\tLoss: 0.011695\n",
      "Train Epoch: 20 [3328/14860 (22%)]\tLoss: 0.015285\n",
      "Train Epoch: 20 [3456/14860 (23%)]\tLoss: 0.022212\n",
      "Train Epoch: 20 [3584/14860 (24%)]\tLoss: 0.023938\n",
      "Train Epoch: 20 [3712/14860 (25%)]\tLoss: 0.025443\n",
      "Train Epoch: 20 [3840/14860 (26%)]\tLoss: 0.015529\n",
      "Train Epoch: 20 [3968/14860 (26%)]\tLoss: 0.016756\n",
      "Train Epoch: 20 [4096/14860 (27%)]\tLoss: 0.023437\n",
      "Train Epoch: 20 [4224/14860 (28%)]\tLoss: 0.023075\n",
      "Train Epoch: 20 [4352/14860 (29%)]\tLoss: 0.021082\n",
      "Train Epoch: 20 [4480/14860 (30%)]\tLoss: 0.020934\n",
      "Train Epoch: 20 [4608/14860 (31%)]\tLoss: 0.019533\n",
      "Train Epoch: 20 [4736/14860 (32%)]\tLoss: 0.024990\n",
      "Train Epoch: 20 [4864/14860 (32%)]\tLoss: 0.022547\n",
      "Train Epoch: 20 [4992/14860 (33%)]\tLoss: 0.021717\n",
      "Train Epoch: 20 [5120/14860 (34%)]\tLoss: 0.018427\n",
      "Train Epoch: 20 [5248/14860 (35%)]\tLoss: 0.021602\n",
      "Train Epoch: 20 [5376/14860 (36%)]\tLoss: 0.021607\n",
      "Train Epoch: 20 [5504/14860 (37%)]\tLoss: 0.019741\n",
      "Train Epoch: 20 [5632/14860 (38%)]\tLoss: 0.023317\n",
      "Train Epoch: 20 [5760/14860 (38%)]\tLoss: 0.022826\n",
      "Train Epoch: 20 [5888/14860 (39%)]\tLoss: 0.017530\n",
      "Train Epoch: 20 [6016/14860 (40%)]\tLoss: 0.017770\n",
      "Train Epoch: 20 [6144/14860 (41%)]\tLoss: 0.014978\n",
      "Train Epoch: 20 [6272/14860 (42%)]\tLoss: 0.019962\n",
      "Train Epoch: 20 [6400/14860 (43%)]\tLoss: 0.020045\n",
      "Train Epoch: 20 [6528/14860 (44%)]\tLoss: 0.024840\n",
      "Train Epoch: 20 [6656/14860 (44%)]\tLoss: 0.011662\n",
      "Train Epoch: 20 [6784/14860 (45%)]\tLoss: 0.024332\n",
      "Train Epoch: 20 [6912/14860 (46%)]\tLoss: 0.014936\n",
      "Train Epoch: 20 [7040/14860 (47%)]\tLoss: 0.032190\n",
      "Train Epoch: 20 [7168/14860 (48%)]\tLoss: 0.017300\n",
      "Train Epoch: 20 [7296/14860 (49%)]\tLoss: 0.025671\n",
      "Train Epoch: 20 [7424/14860 (50%)]\tLoss: 0.021642\n",
      "Train Epoch: 20 [7552/14860 (50%)]\tLoss: 0.026358\n",
      "Train Epoch: 20 [7680/14860 (51%)]\tLoss: 0.025299\n",
      "Train Epoch: 20 [7808/14860 (52%)]\tLoss: 0.012803\n",
      "Train Epoch: 20 [7936/14860 (53%)]\tLoss: 0.019907\n",
      "Train Epoch: 20 [8064/14860 (54%)]\tLoss: 0.027008\n",
      "Train Epoch: 20 [8192/14860 (55%)]\tLoss: 0.026402\n",
      "Train Epoch: 20 [8320/14860 (56%)]\tLoss: 0.025910\n",
      "Train Epoch: 20 [8448/14860 (56%)]\tLoss: 0.028327\n",
      "Train Epoch: 20 [8576/14860 (57%)]\tLoss: 0.025998\n",
      "Train Epoch: 20 [8704/14860 (58%)]\tLoss: 0.026941\n",
      "Train Epoch: 20 [8832/14860 (59%)]\tLoss: 0.024374\n",
      "Train Epoch: 20 [8960/14860 (60%)]\tLoss: 0.037505\n",
      "Train Epoch: 20 [9088/14860 (61%)]\tLoss: 0.026343\n",
      "Train Epoch: 20 [9216/14860 (62%)]\tLoss: 0.037982\n",
      "Train Epoch: 20 [9344/14860 (62%)]\tLoss: 0.025786\n",
      "Train Epoch: 20 [9472/14860 (63%)]\tLoss: 0.047680\n",
      "Train Epoch: 20 [9600/14860 (64%)]\tLoss: 0.022996\n",
      "Train Epoch: 20 [9728/14860 (65%)]\tLoss: 0.033733\n",
      "Train Epoch: 20 [9856/14860 (66%)]\tLoss: 0.018870\n",
      "Train Epoch: 20 [9984/14860 (67%)]\tLoss: 0.035755\n",
      "Train Epoch: 20 [10112/14860 (68%)]\tLoss: 0.020733\n",
      "Train Epoch: 20 [10240/14860 (68%)]\tLoss: 0.023761\n",
      "Train Epoch: 20 [10368/14860 (69%)]\tLoss: 0.017069\n",
      "Train Epoch: 20 [10496/14860 (70%)]\tLoss: 0.033458\n",
      "Train Epoch: 20 [10624/14860 (71%)]\tLoss: 0.023030\n",
      "Train Epoch: 20 [10752/14860 (72%)]\tLoss: 0.032675\n",
      "Train Epoch: 20 [10880/14860 (73%)]\tLoss: 0.024147\n",
      "Train Epoch: 20 [11008/14860 (74%)]\tLoss: 0.020827\n",
      "Train Epoch: 20 [11136/14860 (74%)]\tLoss: 0.034504\n",
      "Train Epoch: 20 [11264/14860 (75%)]\tLoss: 0.023705\n",
      "Train Epoch: 20 [11392/14860 (76%)]\tLoss: 0.038363\n",
      "Train Epoch: 20 [11520/14860 (77%)]\tLoss: 0.027013\n",
      "Train Epoch: 20 [11648/14860 (78%)]\tLoss: 0.033764\n",
      "Train Epoch: 20 [11776/14860 (79%)]\tLoss: 0.019499\n",
      "Train Epoch: 20 [11904/14860 (79%)]\tLoss: 0.019093\n",
      "Train Epoch: 20 [12032/14860 (80%)]\tLoss: 0.021135\n",
      "Train Epoch: 20 [12160/14860 (81%)]\tLoss: 0.024811\n",
      "Train Epoch: 20 [12288/14860 (82%)]\tLoss: 0.017120\n",
      "Train Epoch: 20 [12416/14860 (83%)]\tLoss: 0.027613\n",
      "Train Epoch: 20 [12544/14860 (84%)]\tLoss: 0.027944\n",
      "Train Epoch: 20 [12672/14860 (85%)]\tLoss: 0.020445\n",
      "Train Epoch: 20 [12800/14860 (85%)]\tLoss: 0.016117\n",
      "Train Epoch: 20 [12928/14860 (86%)]\tLoss: 0.026210\n",
      "Train Epoch: 20 [13056/14860 (87%)]\tLoss: 0.020867\n",
      "Train Epoch: 20 [13184/14860 (88%)]\tLoss: 0.025371\n",
      "Train Epoch: 20 [13312/14860 (89%)]\tLoss: 0.018937\n",
      "Train Epoch: 20 [13440/14860 (90%)]\tLoss: 0.013548\n",
      "Train Epoch: 20 [13568/14860 (91%)]\tLoss: 0.020968\n",
      "Train Epoch: 20 [13696/14860 (91%)]\tLoss: 0.023174\n",
      "Train Epoch: 20 [13824/14860 (92%)]\tLoss: 0.029903\n",
      "Train Epoch: 20 [13952/14860 (93%)]\tLoss: 0.030161\n",
      "Train Epoch: 20 [14080/14860 (94%)]\tLoss: 0.022076\n",
      "Train Epoch: 20 [14208/14860 (95%)]\tLoss: 0.036596\n",
      "Train Epoch: 20 [14336/14860 (96%)]\tLoss: 0.021743\n",
      "Train Epoch: 20 [14464/14860 (97%)]\tLoss: 0.030173\n",
      "Train Epoch: 20 [14592/14860 (97%)]\tLoss: 0.018219\n",
      "Train Epoch: 20 [14720/14860 (98%)]\tLoss: 0.023061\n",
      "Train Epoch: 20 [1392/14860 (99%)]\tLoss: 0.030404\n",
      "epoch 20 training loss: 0.02327364956976002\n",
      "epoch 20 validation loss: 0.031657083704165624\n",
      "Train Epoch: 21 [0/14860 (0%)]\tLoss: 0.021480\n",
      "Train Epoch: 21 [128/14860 (1%)]\tLoss: 0.031388\n",
      "Train Epoch: 21 [256/14860 (2%)]\tLoss: 0.018550\n",
      "Train Epoch: 21 [384/14860 (3%)]\tLoss: 0.028626\n",
      "Train Epoch: 21 [512/14860 (3%)]\tLoss: 0.016095\n",
      "Train Epoch: 21 [640/14860 (4%)]\tLoss: 0.026142\n",
      "Train Epoch: 21 [768/14860 (5%)]\tLoss: 0.026753\n",
      "Train Epoch: 21 [896/14860 (6%)]\tLoss: 0.031772\n",
      "Train Epoch: 21 [1024/14860 (7%)]\tLoss: 0.034435\n",
      "Train Epoch: 21 [1152/14860 (8%)]\tLoss: 0.021954\n",
      "Train Epoch: 21 [1280/14860 (9%)]\tLoss: 0.044522\n",
      "Train Epoch: 21 [1408/14860 (9%)]\tLoss: 0.021372\n",
      "Train Epoch: 21 [1536/14860 (10%)]\tLoss: 0.040950\n",
      "Train Epoch: 21 [1664/14860 (11%)]\tLoss: 0.017470\n",
      "Train Epoch: 21 [1792/14860 (12%)]\tLoss: 0.020988\n",
      "Train Epoch: 21 [1920/14860 (13%)]\tLoss: 0.027129\n",
      "Train Epoch: 21 [2048/14860 (14%)]\tLoss: 0.019886\n",
      "Train Epoch: 21 [2176/14860 (15%)]\tLoss: 0.017314\n",
      "Train Epoch: 21 [2304/14860 (15%)]\tLoss: 0.017965\n",
      "Train Epoch: 21 [2432/14860 (16%)]\tLoss: 0.019929\n",
      "Train Epoch: 21 [2560/14860 (17%)]\tLoss: 0.023426\n",
      "Train Epoch: 21 [2688/14860 (18%)]\tLoss: 0.022626\n",
      "Train Epoch: 21 [2816/14860 (19%)]\tLoss: 0.026857\n",
      "Train Epoch: 21 [2944/14860 (20%)]\tLoss: 0.017309\n",
      "Train Epoch: 21 [3072/14860 (21%)]\tLoss: 0.021322\n",
      "Train Epoch: 21 [3200/14860 (21%)]\tLoss: 0.022448\n",
      "Train Epoch: 21 [3328/14860 (22%)]\tLoss: 0.017513\n",
      "Train Epoch: 21 [3456/14860 (23%)]\tLoss: 0.022453\n",
      "Train Epoch: 21 [3584/14860 (24%)]\tLoss: 0.022143\n",
      "Train Epoch: 21 [3712/14860 (25%)]\tLoss: 0.020389\n",
      "Train Epoch: 21 [3840/14860 (26%)]\tLoss: 0.026681\n",
      "Train Epoch: 21 [3968/14860 (26%)]\tLoss: 0.022204\n",
      "Train Epoch: 21 [4096/14860 (27%)]\tLoss: 0.024265\n",
      "Train Epoch: 21 [4224/14860 (28%)]\tLoss: 0.016188\n",
      "Train Epoch: 21 [4352/14860 (29%)]\tLoss: 0.018142\n",
      "Train Epoch: 21 [4480/14860 (30%)]\tLoss: 0.023824\n",
      "Train Epoch: 21 [4608/14860 (31%)]\tLoss: 0.020082\n",
      "Train Epoch: 21 [4736/14860 (32%)]\tLoss: 0.024003\n",
      "Train Epoch: 21 [4864/14860 (32%)]\tLoss: 0.014050\n",
      "Train Epoch: 21 [4992/14860 (33%)]\tLoss: 0.023715\n",
      "Train Epoch: 21 [5120/14860 (34%)]\tLoss: 0.017905\n",
      "Train Epoch: 21 [5248/14860 (35%)]\tLoss: 0.015295\n",
      "Train Epoch: 21 [5376/14860 (36%)]\tLoss: 0.019719\n",
      "Train Epoch: 21 [5504/14860 (37%)]\tLoss: 0.020635\n",
      "Train Epoch: 21 [5632/14860 (38%)]\tLoss: 0.018594\n",
      "Train Epoch: 21 [5760/14860 (38%)]\tLoss: 0.018721\n",
      "Train Epoch: 21 [5888/14860 (39%)]\tLoss: 0.016902\n",
      "Train Epoch: 21 [6016/14860 (40%)]\tLoss: 0.019211\n",
      "Train Epoch: 21 [6144/14860 (41%)]\tLoss: 0.018607\n",
      "Train Epoch: 21 [6272/14860 (42%)]\tLoss: 0.020753\n",
      "Train Epoch: 21 [6400/14860 (43%)]\tLoss: 0.023612\n",
      "Train Epoch: 21 [6528/14860 (44%)]\tLoss: 0.019353\n",
      "Train Epoch: 21 [6656/14860 (44%)]\tLoss: 0.016607\n",
      "Train Epoch: 21 [6784/14860 (45%)]\tLoss: 0.020628\n",
      "Train Epoch: 21 [6912/14860 (46%)]\tLoss: 0.031677\n",
      "Train Epoch: 21 [7040/14860 (47%)]\tLoss: 0.024012\n",
      "Train Epoch: 21 [7168/14860 (48%)]\tLoss: 0.027929\n",
      "Train Epoch: 21 [7296/14860 (49%)]\tLoss: 0.020910\n",
      "Train Epoch: 21 [7424/14860 (50%)]\tLoss: 0.022208\n",
      "Train Epoch: 21 [7552/14860 (50%)]\tLoss: 0.022531\n",
      "Train Epoch: 21 [7680/14860 (51%)]\tLoss: 0.030383\n",
      "Train Epoch: 21 [7808/14860 (52%)]\tLoss: 0.017033\n",
      "Train Epoch: 21 [7936/14860 (53%)]\tLoss: 0.022252\n",
      "Train Epoch: 21 [8064/14860 (54%)]\tLoss: 0.012768\n",
      "Train Epoch: 21 [8192/14860 (55%)]\tLoss: 0.014786\n",
      "Train Epoch: 21 [8320/14860 (56%)]\tLoss: 0.024496\n",
      "Train Epoch: 21 [8448/14860 (56%)]\tLoss: 0.018587\n",
      "Train Epoch: 21 [8576/14860 (57%)]\tLoss: 0.019397\n",
      "Train Epoch: 21 [8704/14860 (58%)]\tLoss: 0.023879\n",
      "Train Epoch: 21 [8832/14860 (59%)]\tLoss: 0.028417\n",
      "Train Epoch: 21 [8960/14860 (60%)]\tLoss: 0.024159\n",
      "Train Epoch: 21 [9088/14860 (61%)]\tLoss: 0.022374\n",
      "Train Epoch: 21 [9216/14860 (62%)]\tLoss: 0.019867\n",
      "Train Epoch: 21 [9344/14860 (62%)]\tLoss: 0.024842\n",
      "Train Epoch: 21 [9472/14860 (63%)]\tLoss: 0.015653\n",
      "Train Epoch: 21 [9600/14860 (64%)]\tLoss: 0.022611\n",
      "Train Epoch: 21 [9728/14860 (65%)]\tLoss: 0.037701\n",
      "Train Epoch: 21 [9856/14860 (66%)]\tLoss: 0.039278\n",
      "Train Epoch: 21 [9984/14860 (67%)]\tLoss: 0.031714\n",
      "Train Epoch: 21 [10112/14860 (68%)]\tLoss: 0.029138\n",
      "Train Epoch: 21 [10240/14860 (68%)]\tLoss: 0.017204\n",
      "Train Epoch: 21 [10368/14860 (69%)]\tLoss: 0.015955\n",
      "Train Epoch: 21 [10496/14860 (70%)]\tLoss: 0.022455\n",
      "Train Epoch: 21 [10624/14860 (71%)]\tLoss: 0.024930\n",
      "Train Epoch: 21 [10752/14860 (72%)]\tLoss: 0.028860\n",
      "Train Epoch: 21 [10880/14860 (73%)]\tLoss: 0.018156\n",
      "Train Epoch: 21 [11008/14860 (74%)]\tLoss: 0.021140\n",
      "Train Epoch: 21 [11136/14860 (74%)]\tLoss: 0.017153\n",
      "Train Epoch: 21 [11264/14860 (75%)]\tLoss: 0.023124\n",
      "Train Epoch: 21 [11392/14860 (76%)]\tLoss: 0.026578\n",
      "Train Epoch: 21 [11520/14860 (77%)]\tLoss: 0.031072\n",
      "Train Epoch: 21 [11648/14860 (78%)]\tLoss: 0.023167\n",
      "Train Epoch: 21 [11776/14860 (79%)]\tLoss: 0.023657\n",
      "Train Epoch: 21 [11904/14860 (79%)]\tLoss: 0.022471\n",
      "Train Epoch: 21 [12032/14860 (80%)]\tLoss: 0.025506\n",
      "Train Epoch: 21 [12160/14860 (81%)]\tLoss: 0.021271\n",
      "Train Epoch: 21 [12288/14860 (82%)]\tLoss: 0.025476\n",
      "Train Epoch: 21 [12416/14860 (83%)]\tLoss: 0.024763\n",
      "Train Epoch: 21 [12544/14860 (84%)]\tLoss: 0.022408\n",
      "Train Epoch: 21 [12672/14860 (85%)]\tLoss: 0.033249\n",
      "Train Epoch: 21 [12800/14860 (85%)]\tLoss: 0.017482\n",
      "Train Epoch: 21 [12928/14860 (86%)]\tLoss: 0.033522\n",
      "Train Epoch: 21 [13056/14860 (87%)]\tLoss: 0.015777\n",
      "Train Epoch: 21 [13184/14860 (88%)]\tLoss: 0.034670\n",
      "Train Epoch: 21 [13312/14860 (89%)]\tLoss: 0.026580\n",
      "Train Epoch: 21 [13440/14860 (90%)]\tLoss: 0.028869\n",
      "Train Epoch: 21 [13568/14860 (91%)]\tLoss: 0.023729\n",
      "Train Epoch: 21 [13696/14860 (91%)]\tLoss: 0.022402\n",
      "Train Epoch: 21 [13824/14860 (92%)]\tLoss: 0.024351\n",
      "Train Epoch: 21 [13952/14860 (93%)]\tLoss: 0.021931\n",
      "Train Epoch: 21 [14080/14860 (94%)]\tLoss: 0.029770\n",
      "Train Epoch: 21 [14208/14860 (95%)]\tLoss: 0.022671\n",
      "Train Epoch: 21 [14336/14860 (96%)]\tLoss: 0.029126\n",
      "Train Epoch: 21 [14464/14860 (97%)]\tLoss: 0.024017\n",
      "Train Epoch: 21 [14592/14860 (97%)]\tLoss: 0.020115\n",
      "Train Epoch: 21 [14720/14860 (98%)]\tLoss: 0.026229\n",
      "Train Epoch: 21 [1392/14860 (99%)]\tLoss: 0.009829\n",
      "epoch 21 training loss: 0.023155289248396188\n",
      "epoch 21 validation loss: 0.025564358540366407\n",
      "Train Epoch: 22 [0/14860 (0%)]\tLoss: 0.025560\n",
      "Train Epoch: 22 [128/14860 (1%)]\tLoss: 0.022509\n",
      "Train Epoch: 22 [256/14860 (2%)]\tLoss: 0.024940\n",
      "Train Epoch: 22 [384/14860 (3%)]\tLoss: 0.014935\n",
      "Train Epoch: 22 [512/14860 (3%)]\tLoss: 0.013614\n",
      "Train Epoch: 22 [640/14860 (4%)]\tLoss: 0.016332\n",
      "Train Epoch: 22 [768/14860 (5%)]\tLoss: 0.025474\n",
      "Train Epoch: 22 [896/14860 (6%)]\tLoss: 0.018105\n",
      "Train Epoch: 22 [1024/14860 (7%)]\tLoss: 0.024428\n",
      "Train Epoch: 22 [1152/14860 (8%)]\tLoss: 0.021079\n",
      "Train Epoch: 22 [1280/14860 (9%)]\tLoss: 0.019028\n",
      "Train Epoch: 22 [1408/14860 (9%)]\tLoss: 0.021871\n",
      "Train Epoch: 22 [1536/14860 (10%)]\tLoss: 0.029068\n",
      "Train Epoch: 22 [1664/14860 (11%)]\tLoss: 0.020498\n",
      "Train Epoch: 22 [1792/14860 (12%)]\tLoss: 0.023559\n",
      "Train Epoch: 22 [1920/14860 (13%)]\tLoss: 0.012707\n",
      "Train Epoch: 22 [2048/14860 (14%)]\tLoss: 0.023582\n",
      "Train Epoch: 22 [2176/14860 (15%)]\tLoss: 0.011540\n",
      "Train Epoch: 22 [2304/14860 (15%)]\tLoss: 0.018186\n",
      "Train Epoch: 22 [2432/14860 (16%)]\tLoss: 0.022861\n",
      "Train Epoch: 22 [2560/14860 (17%)]\tLoss: 0.016542\n",
      "Train Epoch: 22 [2688/14860 (18%)]\tLoss: 0.017312\n",
      "Train Epoch: 22 [2816/14860 (19%)]\tLoss: 0.020671\n",
      "Train Epoch: 22 [2944/14860 (20%)]\tLoss: 0.019378\n",
      "Train Epoch: 22 [3072/14860 (21%)]\tLoss: 0.025507\n",
      "Train Epoch: 22 [3200/14860 (21%)]\tLoss: 0.015989\n",
      "Train Epoch: 22 [3328/14860 (22%)]\tLoss: 0.026616\n",
      "Train Epoch: 22 [3456/14860 (23%)]\tLoss: 0.017597\n",
      "Train Epoch: 22 [3584/14860 (24%)]\tLoss: 0.020542\n",
      "Train Epoch: 22 [3712/14860 (25%)]\tLoss: 0.022887\n",
      "Train Epoch: 22 [3840/14860 (26%)]\tLoss: 0.022543\n",
      "Train Epoch: 22 [3968/14860 (26%)]\tLoss: 0.024557\n",
      "Train Epoch: 22 [4096/14860 (27%)]\tLoss: 0.019831\n",
      "Train Epoch: 22 [4224/14860 (28%)]\tLoss: 0.018578\n",
      "Train Epoch: 22 [4352/14860 (29%)]\tLoss: 0.026363\n",
      "Train Epoch: 22 [4480/14860 (30%)]\tLoss: 0.021289\n",
      "Train Epoch: 22 [4608/14860 (31%)]\tLoss: 0.018067\n",
      "Train Epoch: 22 [4736/14860 (32%)]\tLoss: 0.022847\n",
      "Train Epoch: 22 [4864/14860 (32%)]\tLoss: 0.016437\n",
      "Train Epoch: 22 [4992/14860 (33%)]\tLoss: 0.017906\n",
      "Train Epoch: 22 [5120/14860 (34%)]\tLoss: 0.018362\n",
      "Train Epoch: 22 [5248/14860 (35%)]\tLoss: 0.021067\n",
      "Train Epoch: 22 [5376/14860 (36%)]\tLoss: 0.015422\n",
      "Train Epoch: 22 [5504/14860 (37%)]\tLoss: 0.020017\n",
      "Train Epoch: 22 [5632/14860 (38%)]\tLoss: 0.014237\n",
      "Train Epoch: 22 [5760/14860 (38%)]\tLoss: 0.020193\n",
      "Train Epoch: 22 [5888/14860 (39%)]\tLoss: 0.019041\n",
      "Train Epoch: 22 [6016/14860 (40%)]\tLoss: 0.025411\n",
      "Train Epoch: 22 [6144/14860 (41%)]\tLoss: 0.024829\n",
      "Train Epoch: 22 [6272/14860 (42%)]\tLoss: 0.018641\n",
      "Train Epoch: 22 [6400/14860 (43%)]\tLoss: 0.023864\n",
      "Train Epoch: 22 [6528/14860 (44%)]\tLoss: 0.015496\n",
      "Train Epoch: 22 [6656/14860 (44%)]\tLoss: 0.028418\n",
      "Train Epoch: 22 [6784/14860 (45%)]\tLoss: 0.017921\n",
      "Train Epoch: 22 [6912/14860 (46%)]\tLoss: 0.020162\n",
      "Train Epoch: 22 [7040/14860 (47%)]\tLoss: 0.026474\n",
      "Train Epoch: 22 [7168/14860 (48%)]\tLoss: 0.031300\n",
      "Train Epoch: 22 [7296/14860 (49%)]\tLoss: 0.014888\n",
      "Train Epoch: 22 [7424/14860 (50%)]\tLoss: 0.022422\n",
      "Train Epoch: 22 [7552/14860 (50%)]\tLoss: 0.020378\n",
      "Train Epoch: 22 [7680/14860 (51%)]\tLoss: 0.021529\n",
      "Train Epoch: 22 [7808/14860 (52%)]\tLoss: 0.030730\n",
      "Train Epoch: 22 [7936/14860 (53%)]\tLoss: 0.017340\n",
      "Train Epoch: 22 [8064/14860 (54%)]\tLoss: 0.029979\n",
      "Train Epoch: 22 [8192/14860 (55%)]\tLoss: 0.018620\n",
      "Train Epoch: 22 [8320/14860 (56%)]\tLoss: 0.039598\n",
      "Train Epoch: 22 [8448/14860 (56%)]\tLoss: 0.026301\n",
      "Train Epoch: 22 [8576/14860 (57%)]\tLoss: 0.044747\n",
      "Train Epoch: 22 [8704/14860 (58%)]\tLoss: 0.014024\n",
      "Train Epoch: 22 [8832/14860 (59%)]\tLoss: 0.025721\n",
      "Train Epoch: 22 [8960/14860 (60%)]\tLoss: 0.018323\n",
      "Train Epoch: 22 [9088/14860 (61%)]\tLoss: 0.026710\n",
      "Train Epoch: 22 [9216/14860 (62%)]\tLoss: 0.022540\n",
      "Train Epoch: 22 [9344/14860 (62%)]\tLoss: 0.028922\n",
      "Train Epoch: 22 [9472/14860 (63%)]\tLoss: 0.015980\n",
      "Train Epoch: 22 [9600/14860 (64%)]\tLoss: 0.029250\n",
      "Train Epoch: 22 [9728/14860 (65%)]\tLoss: 0.016204\n",
      "Train Epoch: 22 [9856/14860 (66%)]\tLoss: 0.017260\n",
      "Train Epoch: 22 [9984/14860 (67%)]\tLoss: 0.023974\n",
      "Train Epoch: 22 [10112/14860 (68%)]\tLoss: 0.021051\n",
      "Train Epoch: 22 [10240/14860 (68%)]\tLoss: 0.021197\n",
      "Train Epoch: 22 [10368/14860 (69%)]\tLoss: 0.023549\n",
      "Train Epoch: 22 [10496/14860 (70%)]\tLoss: 0.016882\n",
      "Train Epoch: 22 [10624/14860 (71%)]\tLoss: 0.016246\n",
      "Train Epoch: 22 [10752/14860 (72%)]\tLoss: 0.017007\n",
      "Train Epoch: 22 [10880/14860 (73%)]\tLoss: 0.030105\n",
      "Train Epoch: 22 [11008/14860 (74%)]\tLoss: 0.021962\n",
      "Train Epoch: 22 [11136/14860 (74%)]\tLoss: 0.022465\n",
      "Train Epoch: 22 [11264/14860 (75%)]\tLoss: 0.024150\n",
      "Train Epoch: 22 [11392/14860 (76%)]\tLoss: 0.018654\n",
      "Train Epoch: 22 [11520/14860 (77%)]\tLoss: 0.019235\n",
      "Train Epoch: 22 [11648/14860 (78%)]\tLoss: 0.026662\n",
      "Train Epoch: 22 [11776/14860 (79%)]\tLoss: 0.018030\n",
      "Train Epoch: 22 [11904/14860 (79%)]\tLoss: 0.022529\n",
      "Train Epoch: 22 [12032/14860 (80%)]\tLoss: 0.018431\n",
      "Train Epoch: 22 [12160/14860 (81%)]\tLoss: 0.026239\n",
      "Train Epoch: 22 [12288/14860 (82%)]\tLoss: 0.017679\n",
      "Train Epoch: 22 [12416/14860 (83%)]\tLoss: 0.022918\n",
      "Train Epoch: 22 [12544/14860 (84%)]\tLoss: 0.014419\n",
      "Train Epoch: 22 [12672/14860 (85%)]\tLoss: 0.026395\n",
      "Train Epoch: 22 [12800/14860 (85%)]\tLoss: 0.024325\n",
      "Train Epoch: 22 [12928/14860 (86%)]\tLoss: 0.017505\n",
      "Train Epoch: 22 [13056/14860 (87%)]\tLoss: 0.018750\n",
      "Train Epoch: 22 [13184/14860 (88%)]\tLoss: 0.039151\n",
      "Train Epoch: 22 [13312/14860 (89%)]\tLoss: 0.022288\n",
      "Train Epoch: 22 [13440/14860 (90%)]\tLoss: 0.028609\n",
      "Train Epoch: 22 [13568/14860 (91%)]\tLoss: 0.024198\n",
      "Train Epoch: 22 [13696/14860 (91%)]\tLoss: 0.017190\n",
      "Train Epoch: 22 [13824/14860 (92%)]\tLoss: 0.027150\n",
      "Train Epoch: 22 [13952/14860 (93%)]\tLoss: 0.022309\n",
      "Train Epoch: 22 [14080/14860 (94%)]\tLoss: 0.021660\n",
      "Train Epoch: 22 [14208/14860 (95%)]\tLoss: 0.030519\n",
      "Train Epoch: 22 [14336/14860 (96%)]\tLoss: 0.021738\n",
      "Train Epoch: 22 [14464/14860 (97%)]\tLoss: 0.026828\n",
      "Train Epoch: 22 [14592/14860 (97%)]\tLoss: 0.016979\n",
      "Train Epoch: 22 [14720/14860 (98%)]\tLoss: 0.021166\n",
      "Train Epoch: 22 [1392/14860 (99%)]\tLoss: 0.021212\n",
      "epoch 22 training loss: 0.021837606110697627\n",
      "epoch 22 validation loss: 0.03199695790362416\n",
      "Train Epoch: 23 [0/14860 (0%)]\tLoss: 0.027662\n",
      "Train Epoch: 23 [128/14860 (1%)]\tLoss: 0.020811\n",
      "Train Epoch: 23 [256/14860 (2%)]\tLoss: 0.037384\n",
      "Train Epoch: 23 [384/14860 (3%)]\tLoss: 0.016897\n",
      "Train Epoch: 23 [512/14860 (3%)]\tLoss: 0.024225\n",
      "Train Epoch: 23 [640/14860 (4%)]\tLoss: 0.022956\n",
      "Train Epoch: 23 [768/14860 (5%)]\tLoss: 0.029119\n",
      "Train Epoch: 23 [896/14860 (6%)]\tLoss: 0.024580\n",
      "Train Epoch: 23 [1024/14860 (7%)]\tLoss: 0.019198\n",
      "Train Epoch: 23 [1152/14860 (8%)]\tLoss: 0.032789\n",
      "Train Epoch: 23 [1280/14860 (9%)]\tLoss: 0.015157\n",
      "Train Epoch: 23 [1408/14860 (9%)]\tLoss: 0.034899\n",
      "Train Epoch: 23 [1536/14860 (10%)]\tLoss: 0.022277\n",
      "Train Epoch: 23 [1664/14860 (11%)]\tLoss: 0.043589\n",
      "Train Epoch: 23 [1792/14860 (12%)]\tLoss: 0.029324\n",
      "Train Epoch: 23 [1920/14860 (13%)]\tLoss: 0.031477\n",
      "Train Epoch: 23 [2048/14860 (14%)]\tLoss: 0.022446\n",
      "Train Epoch: 23 [2176/14860 (15%)]\tLoss: 0.027728\n",
      "Train Epoch: 23 [2304/14860 (15%)]\tLoss: 0.030464\n",
      "Train Epoch: 23 [2432/14860 (16%)]\tLoss: 0.020955\n",
      "Train Epoch: 23 [2560/14860 (17%)]\tLoss: 0.026406\n",
      "Train Epoch: 23 [2688/14860 (18%)]\tLoss: 0.024729\n",
      "Train Epoch: 23 [2816/14860 (19%)]\tLoss: 0.029873\n",
      "Train Epoch: 23 [2944/14860 (20%)]\tLoss: 0.020354\n",
      "Train Epoch: 23 [3072/14860 (21%)]\tLoss: 0.020265\n",
      "Train Epoch: 23 [3200/14860 (21%)]\tLoss: 0.023486\n",
      "Train Epoch: 23 [3328/14860 (22%)]\tLoss: 0.014563\n",
      "Train Epoch: 23 [3456/14860 (23%)]\tLoss: 0.023274\n",
      "Train Epoch: 23 [3584/14860 (24%)]\tLoss: 0.017089\n",
      "Train Epoch: 23 [3712/14860 (25%)]\tLoss: 0.027551\n",
      "Train Epoch: 23 [3840/14860 (26%)]\tLoss: 0.018655\n",
      "Train Epoch: 23 [3968/14860 (26%)]\tLoss: 0.019620\n",
      "Train Epoch: 23 [4096/14860 (27%)]\tLoss: 0.023885\n",
      "Train Epoch: 23 [4224/14860 (28%)]\tLoss: 0.020634\n",
      "Train Epoch: 23 [4352/14860 (29%)]\tLoss: 0.027312\n",
      "Train Epoch: 23 [4480/14860 (30%)]\tLoss: 0.013970\n",
      "Train Epoch: 23 [4608/14860 (31%)]\tLoss: 0.022403\n",
      "Train Epoch: 23 [4736/14860 (32%)]\tLoss: 0.024665\n",
      "Train Epoch: 23 [4864/14860 (32%)]\tLoss: 0.021853\n",
      "Train Epoch: 23 [4992/14860 (33%)]\tLoss: 0.022496\n",
      "Train Epoch: 23 [5120/14860 (34%)]\tLoss: 0.018899\n",
      "Train Epoch: 23 [5248/14860 (35%)]\tLoss: 0.021962\n",
      "Train Epoch: 23 [5376/14860 (36%)]\tLoss: 0.026860\n",
      "Train Epoch: 23 [5504/14860 (37%)]\tLoss: 0.021995\n",
      "Train Epoch: 23 [5632/14860 (38%)]\tLoss: 0.026805\n",
      "Train Epoch: 23 [5760/14860 (38%)]\tLoss: 0.024238\n",
      "Train Epoch: 23 [5888/14860 (39%)]\tLoss: 0.019088\n",
      "Train Epoch: 23 [6016/14860 (40%)]\tLoss: 0.017718\n",
      "Train Epoch: 23 [6144/14860 (41%)]\tLoss: 0.024514\n",
      "Train Epoch: 23 [6272/14860 (42%)]\tLoss: 0.020077\n",
      "Train Epoch: 23 [6400/14860 (43%)]\tLoss: 0.028992\n",
      "Train Epoch: 23 [6528/14860 (44%)]\tLoss: 0.023746\n",
      "Train Epoch: 23 [6656/14860 (44%)]\tLoss: 0.026138\n",
      "Train Epoch: 23 [6784/14860 (45%)]\tLoss: 0.031522\n",
      "Train Epoch: 23 [6912/14860 (46%)]\tLoss: 0.023943\n",
      "Train Epoch: 23 [7040/14860 (47%)]\tLoss: 0.020364\n",
      "Train Epoch: 23 [7168/14860 (48%)]\tLoss: 0.017896\n",
      "Train Epoch: 23 [7296/14860 (49%)]\tLoss: 0.027997\n",
      "Train Epoch: 23 [7424/14860 (50%)]\tLoss: 0.022788\n",
      "Train Epoch: 23 [7552/14860 (50%)]\tLoss: 0.027973\n",
      "Train Epoch: 23 [7680/14860 (51%)]\tLoss: 0.035744\n",
      "Train Epoch: 23 [7808/14860 (52%)]\tLoss: 0.014796\n",
      "Train Epoch: 23 [7936/14860 (53%)]\tLoss: 0.049861\n",
      "Train Epoch: 23 [8064/14860 (54%)]\tLoss: 0.026345\n",
      "Train Epoch: 23 [8192/14860 (55%)]\tLoss: 0.033090\n",
      "Train Epoch: 23 [8320/14860 (56%)]\tLoss: 0.037944\n",
      "Train Epoch: 23 [8448/14860 (56%)]\tLoss: 0.019335\n",
      "Train Epoch: 23 [8576/14860 (57%)]\tLoss: 0.040478\n",
      "Train Epoch: 23 [8704/14860 (58%)]\tLoss: 0.022347\n",
      "Train Epoch: 23 [8832/14860 (59%)]\tLoss: 0.025104\n",
      "Train Epoch: 23 [8960/14860 (60%)]\tLoss: 0.038628\n",
      "Train Epoch: 23 [9088/14860 (61%)]\tLoss: 0.016435\n",
      "Train Epoch: 23 [9216/14860 (62%)]\tLoss: 0.028765\n",
      "Train Epoch: 23 [9344/14860 (62%)]\tLoss: 0.039498\n",
      "Train Epoch: 23 [9472/14860 (63%)]\tLoss: 0.021621\n",
      "Train Epoch: 23 [9600/14860 (64%)]\tLoss: 0.041067\n",
      "Train Epoch: 23 [9728/14860 (65%)]\tLoss: 0.021871\n",
      "Train Epoch: 23 [9856/14860 (66%)]\tLoss: 0.019098\n",
      "Train Epoch: 23 [9984/14860 (67%)]\tLoss: 0.044380\n",
      "Train Epoch: 23 [10112/14860 (68%)]\tLoss: 0.022749\n",
      "Train Epoch: 23 [10240/14860 (68%)]\tLoss: 0.024788\n",
      "Train Epoch: 23 [10368/14860 (69%)]\tLoss: 0.029721\n",
      "Train Epoch: 23 [10496/14860 (70%)]\tLoss: 0.029312\n",
      "Train Epoch: 23 [10624/14860 (71%)]\tLoss: 0.019006\n",
      "Train Epoch: 23 [10752/14860 (72%)]\tLoss: 0.026034\n",
      "Train Epoch: 23 [10880/14860 (73%)]\tLoss: 0.024161\n",
      "Train Epoch: 23 [11008/14860 (74%)]\tLoss: 0.026324\n",
      "Train Epoch: 23 [11136/14860 (74%)]\tLoss: 0.026472\n",
      "Train Epoch: 23 [11264/14860 (75%)]\tLoss: 0.021801\n",
      "Train Epoch: 23 [11392/14860 (76%)]\tLoss: 0.028868\n",
      "Train Epoch: 23 [11520/14860 (77%)]\tLoss: 0.036044\n",
      "Train Epoch: 23 [11648/14860 (78%)]\tLoss: 0.022740\n",
      "Train Epoch: 23 [11776/14860 (79%)]\tLoss: 0.027489\n",
      "Train Epoch: 23 [11904/14860 (79%)]\tLoss: 0.022279\n",
      "Train Epoch: 23 [12032/14860 (80%)]\tLoss: 0.014600\n",
      "Train Epoch: 23 [12160/14860 (81%)]\tLoss: 0.030744\n",
      "Train Epoch: 23 [12288/14860 (82%)]\tLoss: 0.024185\n",
      "Train Epoch: 23 [12416/14860 (83%)]\tLoss: 0.020814\n",
      "Train Epoch: 23 [12544/14860 (84%)]\tLoss: 0.017863\n",
      "Train Epoch: 23 [12672/14860 (85%)]\tLoss: 0.025272\n",
      "Train Epoch: 23 [12800/14860 (85%)]\tLoss: 0.019070\n",
      "Train Epoch: 23 [12928/14860 (86%)]\tLoss: 0.014387\n",
      "Train Epoch: 23 [13056/14860 (87%)]\tLoss: 0.023437\n",
      "Train Epoch: 23 [13184/14860 (88%)]\tLoss: 0.017987\n",
      "Train Epoch: 23 [13312/14860 (89%)]\tLoss: 0.020914\n",
      "Train Epoch: 23 [13440/14860 (90%)]\tLoss: 0.014346\n",
      "Train Epoch: 23 [13568/14860 (91%)]\tLoss: 0.030311\n",
      "Train Epoch: 23 [13696/14860 (91%)]\tLoss: 0.022578\n",
      "Train Epoch: 23 [13824/14860 (92%)]\tLoss: 0.022923\n",
      "Train Epoch: 23 [13952/14860 (93%)]\tLoss: 0.020901\n",
      "Train Epoch: 23 [14080/14860 (94%)]\tLoss: 0.024442\n",
      "Train Epoch: 23 [14208/14860 (95%)]\tLoss: 0.015980\n",
      "Train Epoch: 23 [14336/14860 (96%)]\tLoss: 0.021925\n",
      "Train Epoch: 23 [14464/14860 (97%)]\tLoss: 0.020194\n",
      "Train Epoch: 23 [14592/14860 (97%)]\tLoss: 0.019326\n",
      "Train Epoch: 23 [14720/14860 (98%)]\tLoss: 0.027790\n",
      "Train Epoch: 23 [1392/14860 (99%)]\tLoss: 0.022279\n",
      "epoch 23 training loss: 0.024846139921146072\n",
      "epoch 23 validation loss: 0.027728114953629906\n",
      "Train Epoch: 24 [0/14860 (0%)]\tLoss: 0.022222\n",
      "Train Epoch: 24 [128/14860 (1%)]\tLoss: 0.020252\n",
      "Train Epoch: 24 [256/14860 (2%)]\tLoss: 0.022092\n",
      "Train Epoch: 24 [384/14860 (3%)]\tLoss: 0.025237\n",
      "Train Epoch: 24 [512/14860 (3%)]\tLoss: 0.025660\n",
      "Train Epoch: 24 [640/14860 (4%)]\tLoss: 0.026071\n",
      "Train Epoch: 24 [768/14860 (5%)]\tLoss: 0.017876\n",
      "Train Epoch: 24 [896/14860 (6%)]\tLoss: 0.021217\n",
      "Train Epoch: 24 [1024/14860 (7%)]\tLoss: 0.019170\n",
      "Train Epoch: 24 [1152/14860 (8%)]\tLoss: 0.018850\n",
      "Train Epoch: 24 [1280/14860 (9%)]\tLoss: 0.018479\n",
      "Train Epoch: 24 [1408/14860 (9%)]\tLoss: 0.019519\n",
      "Train Epoch: 24 [1536/14860 (10%)]\tLoss: 0.022074\n",
      "Train Epoch: 24 [1664/14860 (11%)]\tLoss: 0.035268\n",
      "Train Epoch: 24 [1792/14860 (12%)]\tLoss: 0.022852\n",
      "Train Epoch: 24 [1920/14860 (13%)]\tLoss: 0.020947\n",
      "Train Epoch: 24 [2048/14860 (14%)]\tLoss: 0.020163\n",
      "Train Epoch: 24 [2176/14860 (15%)]\tLoss: 0.021413\n",
      "Train Epoch: 24 [2304/14860 (15%)]\tLoss: 0.014099\n",
      "Train Epoch: 24 [2432/14860 (16%)]\tLoss: 0.017569\n",
      "Train Epoch: 24 [2560/14860 (17%)]\tLoss: 0.012785\n",
      "Train Epoch: 24 [2688/14860 (18%)]\tLoss: 0.022672\n",
      "Train Epoch: 24 [2816/14860 (19%)]\tLoss: 0.017497\n",
      "Train Epoch: 24 [2944/14860 (20%)]\tLoss: 0.017135\n",
      "Train Epoch: 24 [3072/14860 (21%)]\tLoss: 0.018138\n",
      "Train Epoch: 24 [3200/14860 (21%)]\tLoss: 0.020934\n",
      "Train Epoch: 24 [3328/14860 (22%)]\tLoss: 0.019757\n",
      "Train Epoch: 24 [3456/14860 (23%)]\tLoss: 0.019818\n",
      "Train Epoch: 24 [3584/14860 (24%)]\tLoss: 0.020211\n",
      "Train Epoch: 24 [3712/14860 (25%)]\tLoss: 0.021525\n",
      "Train Epoch: 24 [3840/14860 (26%)]\tLoss: 0.027164\n",
      "Train Epoch: 24 [3968/14860 (26%)]\tLoss: 0.019464\n",
      "Train Epoch: 24 [4096/14860 (27%)]\tLoss: 0.021123\n",
      "Train Epoch: 24 [4224/14860 (28%)]\tLoss: 0.025829\n",
      "Train Epoch: 24 [4352/14860 (29%)]\tLoss: 0.020232\n",
      "Train Epoch: 24 [4480/14860 (30%)]\tLoss: 0.023406\n",
      "Train Epoch: 24 [4608/14860 (31%)]\tLoss: 0.017709\n",
      "Train Epoch: 24 [4736/14860 (32%)]\tLoss: 0.027652\n",
      "Train Epoch: 24 [4864/14860 (32%)]\tLoss: 0.017602\n",
      "Train Epoch: 24 [4992/14860 (33%)]\tLoss: 0.022839\n",
      "Train Epoch: 24 [5120/14860 (34%)]\tLoss: 0.018202\n",
      "Train Epoch: 24 [5248/14860 (35%)]\tLoss: 0.014535\n",
      "Train Epoch: 24 [5376/14860 (36%)]\tLoss: 0.012852\n",
      "Train Epoch: 24 [5504/14860 (37%)]\tLoss: 0.028576\n",
      "Train Epoch: 24 [5632/14860 (38%)]\tLoss: 0.017659\n",
      "Train Epoch: 24 [5760/14860 (38%)]\tLoss: 0.022919\n",
      "Train Epoch: 24 [5888/14860 (39%)]\tLoss: 0.018112\n",
      "Train Epoch: 24 [6016/14860 (40%)]\tLoss: 0.022135\n",
      "Train Epoch: 24 [6144/14860 (41%)]\tLoss: 0.026060\n",
      "Train Epoch: 24 [6272/14860 (42%)]\tLoss: 0.012210\n",
      "Train Epoch: 24 [6400/14860 (43%)]\tLoss: 0.019906\n",
      "Train Epoch: 24 [6528/14860 (44%)]\tLoss: 0.019170\n",
      "Train Epoch: 24 [6656/14860 (44%)]\tLoss: 0.017692\n",
      "Train Epoch: 24 [6784/14860 (45%)]\tLoss: 0.021739\n",
      "Train Epoch: 24 [6912/14860 (46%)]\tLoss: 0.031087\n",
      "Train Epoch: 24 [7040/14860 (47%)]\tLoss: 0.021403\n",
      "Train Epoch: 24 [7168/14860 (48%)]\tLoss: 0.015267\n",
      "Train Epoch: 24 [7296/14860 (49%)]\tLoss: 0.025474\n",
      "Train Epoch: 24 [7424/14860 (50%)]\tLoss: 0.015598\n",
      "Train Epoch: 24 [7552/14860 (50%)]\tLoss: 0.013688\n",
      "Train Epoch: 24 [7680/14860 (51%)]\tLoss: 0.021958\n",
      "Train Epoch: 24 [7808/14860 (52%)]\tLoss: 0.013406\n",
      "Train Epoch: 24 [7936/14860 (53%)]\tLoss: 0.018149\n",
      "Train Epoch: 24 [8064/14860 (54%)]\tLoss: 0.023639\n",
      "Train Epoch: 24 [8192/14860 (55%)]\tLoss: 0.021989\n",
      "Train Epoch: 24 [8320/14860 (56%)]\tLoss: 0.011509\n",
      "Train Epoch: 24 [8448/14860 (56%)]\tLoss: 0.023349\n",
      "Train Epoch: 24 [8576/14860 (57%)]\tLoss: 0.019383\n",
      "Train Epoch: 24 [8704/14860 (58%)]\tLoss: 0.019292\n",
      "Train Epoch: 24 [8832/14860 (59%)]\tLoss: 0.019880\n",
      "Train Epoch: 24 [8960/14860 (60%)]\tLoss: 0.015782\n",
      "Train Epoch: 24 [9088/14860 (61%)]\tLoss: 0.017470\n",
      "Train Epoch: 24 [9216/14860 (62%)]\tLoss: 0.020381\n",
      "Train Epoch: 24 [9344/14860 (62%)]\tLoss: 0.020827\n",
      "Train Epoch: 24 [9472/14860 (63%)]\tLoss: 0.030585\n",
      "Train Epoch: 24 [9600/14860 (64%)]\tLoss: 0.020217\n",
      "Train Epoch: 24 [9728/14860 (65%)]\tLoss: 0.020950\n",
      "Train Epoch: 24 [9856/14860 (66%)]\tLoss: 0.022522\n",
      "Train Epoch: 24 [9984/14860 (67%)]\tLoss: 0.024326\n",
      "Train Epoch: 24 [10112/14860 (68%)]\tLoss: 0.022729\n",
      "Train Epoch: 24 [10240/14860 (68%)]\tLoss: 0.021592\n",
      "Train Epoch: 24 [10368/14860 (69%)]\tLoss: 0.029511\n",
      "Train Epoch: 24 [10496/14860 (70%)]\tLoss: 0.017854\n",
      "Train Epoch: 24 [10624/14860 (71%)]\tLoss: 0.017736\n",
      "Train Epoch: 24 [10752/14860 (72%)]\tLoss: 0.018086\n",
      "Train Epoch: 24 [10880/14860 (73%)]\tLoss: 0.014798\n",
      "Train Epoch: 24 [11008/14860 (74%)]\tLoss: 0.017918\n",
      "Train Epoch: 24 [11136/14860 (74%)]\tLoss: 0.024037\n",
      "Train Epoch: 24 [11264/14860 (75%)]\tLoss: 0.014527\n",
      "Train Epoch: 24 [11392/14860 (76%)]\tLoss: 0.029038\n",
      "Train Epoch: 24 [11520/14860 (77%)]\tLoss: 0.021672\n",
      "Train Epoch: 24 [11648/14860 (78%)]\tLoss: 0.025075\n",
      "Train Epoch: 24 [11776/14860 (79%)]\tLoss: 0.018725\n",
      "Train Epoch: 24 [11904/14860 (79%)]\tLoss: 0.024204\n",
      "Train Epoch: 24 [12032/14860 (80%)]\tLoss: 0.028004\n",
      "Train Epoch: 24 [12160/14860 (81%)]\tLoss: 0.022181\n",
      "Train Epoch: 24 [12288/14860 (82%)]\tLoss: 0.024752\n",
      "Train Epoch: 24 [12416/14860 (83%)]\tLoss: 0.026206\n",
      "Train Epoch: 24 [12544/14860 (84%)]\tLoss: 0.014726\n",
      "Train Epoch: 24 [12672/14860 (85%)]\tLoss: 0.017545\n",
      "Train Epoch: 24 [12800/14860 (85%)]\tLoss: 0.026877\n",
      "Train Epoch: 24 [12928/14860 (86%)]\tLoss: 0.015443\n",
      "Train Epoch: 24 [13056/14860 (87%)]\tLoss: 0.017237\n",
      "Train Epoch: 24 [13184/14860 (88%)]\tLoss: 0.024318\n",
      "Train Epoch: 24 [13312/14860 (89%)]\tLoss: 0.022108\n",
      "Train Epoch: 24 [13440/14860 (90%)]\tLoss: 0.015033\n",
      "Train Epoch: 24 [13568/14860 (91%)]\tLoss: 0.023516\n",
      "Train Epoch: 24 [13696/14860 (91%)]\tLoss: 0.013869\n",
      "Train Epoch: 24 [13824/14860 (92%)]\tLoss: 0.018983\n",
      "Train Epoch: 24 [13952/14860 (93%)]\tLoss: 0.028387\n",
      "Train Epoch: 24 [14080/14860 (94%)]\tLoss: 0.021971\n",
      "Train Epoch: 24 [14208/14860 (95%)]\tLoss: 0.019100\n",
      "Train Epoch: 24 [14336/14860 (96%)]\tLoss: 0.018435\n",
      "Train Epoch: 24 [14464/14860 (97%)]\tLoss: 0.029603\n",
      "Train Epoch: 24 [14592/14860 (97%)]\tLoss: 0.028011\n",
      "Train Epoch: 24 [14720/14860 (98%)]\tLoss: 0.025128\n",
      "Train Epoch: 24 [1392/14860 (99%)]\tLoss: 0.034506\n",
      "epoch 24 training loss: 0.021007368739089396\n",
      "epoch 24 validation loss: 0.03176560168116203\n",
      "Train Epoch: 25 [0/14860 (0%)]\tLoss: 0.029471\n",
      "Train Epoch: 25 [128/14860 (1%)]\tLoss: 0.018249\n",
      "Train Epoch: 25 [256/14860 (2%)]\tLoss: 0.033695\n",
      "Train Epoch: 25 [384/14860 (3%)]\tLoss: 0.022502\n",
      "Train Epoch: 25 [512/14860 (3%)]\tLoss: 0.026192\n",
      "Train Epoch: 25 [640/14860 (4%)]\tLoss: 0.021722\n",
      "Train Epoch: 25 [768/14860 (5%)]\tLoss: 0.019620\n",
      "Train Epoch: 25 [896/14860 (6%)]\tLoss: 0.016557\n",
      "Train Epoch: 25 [1024/14860 (7%)]\tLoss: 0.015053\n",
      "Train Epoch: 25 [1152/14860 (8%)]\tLoss: 0.015899\n",
      "Train Epoch: 25 [1280/14860 (9%)]\tLoss: 0.018528\n",
      "Train Epoch: 25 [1408/14860 (9%)]\tLoss: 0.030399\n",
      "Train Epoch: 25 [1536/14860 (10%)]\tLoss: 0.023523\n",
      "Train Epoch: 25 [1664/14860 (11%)]\tLoss: 0.025549\n",
      "Train Epoch: 25 [1792/14860 (12%)]\tLoss: 0.022719\n",
      "Train Epoch: 25 [1920/14860 (13%)]\tLoss: 0.026505\n",
      "Train Epoch: 25 [2048/14860 (14%)]\tLoss: 0.024421\n",
      "Train Epoch: 25 [2176/14860 (15%)]\tLoss: 0.027224\n",
      "Train Epoch: 25 [2304/14860 (15%)]\tLoss: 0.022691\n",
      "Train Epoch: 25 [2432/14860 (16%)]\tLoss: 0.030923\n",
      "Train Epoch: 25 [2560/14860 (17%)]\tLoss: 0.020454\n",
      "Train Epoch: 25 [2688/14860 (18%)]\tLoss: 0.023370\n",
      "Train Epoch: 25 [2816/14860 (19%)]\tLoss: 0.019258\n",
      "Train Epoch: 25 [2944/14860 (20%)]\tLoss: 0.028421\n",
      "Train Epoch: 25 [3072/14860 (21%)]\tLoss: 0.016749\n",
      "Train Epoch: 25 [3200/14860 (21%)]\tLoss: 0.016223\n",
      "Train Epoch: 25 [3328/14860 (22%)]\tLoss: 0.015011\n",
      "Train Epoch: 25 [3456/14860 (23%)]\tLoss: 0.017011\n",
      "Train Epoch: 25 [3584/14860 (24%)]\tLoss: 0.025823\n",
      "Train Epoch: 25 [3712/14860 (25%)]\tLoss: 0.019351\n",
      "Train Epoch: 25 [3840/14860 (26%)]\tLoss: 0.021173\n",
      "Train Epoch: 25 [3968/14860 (26%)]\tLoss: 0.033852\n",
      "Train Epoch: 25 [4096/14860 (27%)]\tLoss: 0.020621\n",
      "Train Epoch: 25 [4224/14860 (28%)]\tLoss: 0.021548\n",
      "Train Epoch: 25 [4352/14860 (29%)]\tLoss: 0.021784\n",
      "Train Epoch: 25 [4480/14860 (30%)]\tLoss: 0.023088\n",
      "Train Epoch: 25 [4608/14860 (31%)]\tLoss: 0.017424\n",
      "Train Epoch: 25 [4736/14860 (32%)]\tLoss: 0.016951\n",
      "Train Epoch: 25 [4864/14860 (32%)]\tLoss: 0.031430\n",
      "Train Epoch: 25 [4992/14860 (33%)]\tLoss: 0.019640\n",
      "Train Epoch: 25 [5120/14860 (34%)]\tLoss: 0.019176\n",
      "Train Epoch: 25 [5248/14860 (35%)]\tLoss: 0.017613\n",
      "Train Epoch: 25 [5376/14860 (36%)]\tLoss: 0.024225\n",
      "Train Epoch: 25 [5504/14860 (37%)]\tLoss: 0.017122\n",
      "Train Epoch: 25 [5632/14860 (38%)]\tLoss: 0.026604\n",
      "Train Epoch: 25 [5760/14860 (38%)]\tLoss: 0.013644\n",
      "Train Epoch: 25 [5888/14860 (39%)]\tLoss: 0.014650\n",
      "Train Epoch: 25 [6016/14860 (40%)]\tLoss: 0.022071\n",
      "Train Epoch: 25 [6144/14860 (41%)]\tLoss: 0.016488\n",
      "Train Epoch: 25 [6272/14860 (42%)]\tLoss: 0.016421\n",
      "Train Epoch: 25 [6400/14860 (43%)]\tLoss: 0.021863\n",
      "Train Epoch: 25 [6528/14860 (44%)]\tLoss: 0.023802\n",
      "Train Epoch: 25 [6656/14860 (44%)]\tLoss: 0.024996\n",
      "Train Epoch: 25 [6784/14860 (45%)]\tLoss: 0.020839\n",
      "Train Epoch: 25 [6912/14860 (46%)]\tLoss: 0.020167\n",
      "Train Epoch: 25 [7040/14860 (47%)]\tLoss: 0.018239\n",
      "Train Epoch: 25 [7168/14860 (48%)]\tLoss: 0.020510\n",
      "Train Epoch: 25 [7296/14860 (49%)]\tLoss: 0.025650\n",
      "Train Epoch: 25 [7424/14860 (50%)]\tLoss: 0.017944\n",
      "Train Epoch: 25 [7552/14860 (50%)]\tLoss: 0.012225\n",
      "Train Epoch: 25 [7680/14860 (51%)]\tLoss: 0.022353\n",
      "Train Epoch: 25 [7808/14860 (52%)]\tLoss: 0.018066\n",
      "Train Epoch: 25 [7936/14860 (53%)]\tLoss: 0.024922\n",
      "Train Epoch: 25 [8064/14860 (54%)]\tLoss: 0.015269\n",
      "Train Epoch: 25 [8192/14860 (55%)]\tLoss: 0.019126\n",
      "Train Epoch: 25 [8320/14860 (56%)]\tLoss: 0.014974\n",
      "Train Epoch: 25 [8448/14860 (56%)]\tLoss: 0.017068\n",
      "Train Epoch: 25 [8576/14860 (57%)]\tLoss: 0.016817\n",
      "Train Epoch: 25 [8704/14860 (58%)]\tLoss: 0.021501\n",
      "Train Epoch: 25 [8832/14860 (59%)]\tLoss: 0.018896\n",
      "Train Epoch: 25 [8960/14860 (60%)]\tLoss: 0.017618\n",
      "Train Epoch: 25 [9088/14860 (61%)]\tLoss: 0.019953\n",
      "Train Epoch: 25 [9216/14860 (62%)]\tLoss: 0.025869\n",
      "Train Epoch: 25 [9344/14860 (62%)]\tLoss: 0.032871\n",
      "Train Epoch: 25 [9472/14860 (63%)]\tLoss: 0.033355\n",
      "Train Epoch: 25 [9600/14860 (64%)]\tLoss: 0.022496\n",
      "Train Epoch: 25 [9728/14860 (65%)]\tLoss: 0.019477\n",
      "Train Epoch: 25 [9856/14860 (66%)]\tLoss: 0.027161\n",
      "Train Epoch: 25 [9984/14860 (67%)]\tLoss: 0.020485\n",
      "Train Epoch: 25 [10112/14860 (68%)]\tLoss: 0.020919\n",
      "Train Epoch: 25 [10240/14860 (68%)]\tLoss: 0.025610\n",
      "Train Epoch: 25 [10368/14860 (69%)]\tLoss: 0.019332\n",
      "Train Epoch: 25 [10496/14860 (70%)]\tLoss: 0.021778\n",
      "Train Epoch: 25 [10624/14860 (71%)]\tLoss: 0.020004\n",
      "Train Epoch: 25 [10752/14860 (72%)]\tLoss: 0.013382\n",
      "Train Epoch: 25 [10880/14860 (73%)]\tLoss: 0.025168\n",
      "Train Epoch: 25 [11008/14860 (74%)]\tLoss: 0.016723\n",
      "Train Epoch: 25 [11136/14860 (74%)]\tLoss: 0.025178\n",
      "Train Epoch: 25 [11264/14860 (75%)]\tLoss: 0.019825\n",
      "Train Epoch: 25 [11392/14860 (76%)]\tLoss: 0.029089\n",
      "Train Epoch: 25 [11520/14860 (77%)]\tLoss: 0.019743\n",
      "Train Epoch: 25 [11648/14860 (78%)]\tLoss: 0.030017\n",
      "Train Epoch: 25 [11776/14860 (79%)]\tLoss: 0.017837\n",
      "Train Epoch: 25 [11904/14860 (79%)]\tLoss: 0.031767\n",
      "Train Epoch: 25 [12032/14860 (80%)]\tLoss: 0.024368\n",
      "Train Epoch: 25 [12160/14860 (81%)]\tLoss: 0.020074\n",
      "Train Epoch: 25 [12288/14860 (82%)]\tLoss: 0.025869\n",
      "Train Epoch: 25 [12416/14860 (83%)]\tLoss: 0.022724\n",
      "Train Epoch: 25 [12544/14860 (84%)]\tLoss: 0.018634\n",
      "Train Epoch: 25 [12672/14860 (85%)]\tLoss: 0.025504\n",
      "Train Epoch: 25 [12800/14860 (85%)]\tLoss: 0.030741\n",
      "Train Epoch: 25 [12928/14860 (86%)]\tLoss: 0.017583\n",
      "Train Epoch: 25 [13056/14860 (87%)]\tLoss: 0.023370\n",
      "Train Epoch: 25 [13184/14860 (88%)]\tLoss: 0.024741\n",
      "Train Epoch: 25 [13312/14860 (89%)]\tLoss: 0.022933\n",
      "Train Epoch: 25 [13440/14860 (90%)]\tLoss: 0.030502\n",
      "Train Epoch: 25 [13568/14860 (91%)]\tLoss: 0.024751\n",
      "Train Epoch: 25 [13696/14860 (91%)]\tLoss: 0.023108\n",
      "Train Epoch: 25 [13824/14860 (92%)]\tLoss: 0.026047\n",
      "Train Epoch: 25 [13952/14860 (93%)]\tLoss: 0.032099\n",
      "Train Epoch: 25 [14080/14860 (94%)]\tLoss: 0.031415\n",
      "Train Epoch: 25 [14208/14860 (95%)]\tLoss: 0.031085\n",
      "Train Epoch: 25 [14336/14860 (96%)]\tLoss: 0.055363\n",
      "Train Epoch: 25 [14464/14860 (97%)]\tLoss: 0.021633\n",
      "Train Epoch: 25 [14592/14860 (97%)]\tLoss: 0.028261\n",
      "Train Epoch: 25 [14720/14860 (98%)]\tLoss: 0.039149\n",
      "Train Epoch: 25 [1392/14860 (99%)]\tLoss: 0.029307\n",
      "epoch 25 training loss: 0.022810104183661632\n",
      "epoch 25 validation loss: 0.02835592591445036\n",
      "Train Epoch: 26 [0/14860 (0%)]\tLoss: 0.026732\n",
      "Train Epoch: 26 [128/14860 (1%)]\tLoss: 0.019394\n",
      "Train Epoch: 26 [256/14860 (2%)]\tLoss: 0.025420\n",
      "Train Epoch: 26 [384/14860 (3%)]\tLoss: 0.026955\n",
      "Train Epoch: 26 [512/14860 (3%)]\tLoss: 0.024898\n",
      "Train Epoch: 26 [640/14860 (4%)]\tLoss: 0.015657\n",
      "Train Epoch: 26 [768/14860 (5%)]\tLoss: 0.024539\n",
      "Train Epoch: 26 [896/14860 (6%)]\tLoss: 0.015672\n",
      "Train Epoch: 26 [1024/14860 (7%)]\tLoss: 0.020755\n",
      "Train Epoch: 26 [1152/14860 (8%)]\tLoss: 0.017932\n",
      "Train Epoch: 26 [1280/14860 (9%)]\tLoss: 0.014073\n",
      "Train Epoch: 26 [1408/14860 (9%)]\tLoss: 0.019187\n",
      "Train Epoch: 26 [1536/14860 (10%)]\tLoss: 0.023065\n",
      "Train Epoch: 26 [1664/14860 (11%)]\tLoss: 0.015913\n",
      "Train Epoch: 26 [1792/14860 (12%)]\tLoss: 0.025774\n",
      "Train Epoch: 26 [1920/14860 (13%)]\tLoss: 0.026743\n",
      "Train Epoch: 26 [2048/14860 (14%)]\tLoss: 0.017674\n",
      "Train Epoch: 26 [2176/14860 (15%)]\tLoss: 0.018482\n",
      "Train Epoch: 26 [2304/14860 (15%)]\tLoss: 0.022722\n",
      "Train Epoch: 26 [2432/14860 (16%)]\tLoss: 0.021414\n",
      "Train Epoch: 26 [2560/14860 (17%)]\tLoss: 0.024498\n",
      "Train Epoch: 26 [2688/14860 (18%)]\tLoss: 0.019300\n",
      "Train Epoch: 26 [2816/14860 (19%)]\tLoss: 0.023372\n",
      "Train Epoch: 26 [2944/14860 (20%)]\tLoss: 0.036273\n",
      "Train Epoch: 26 [3072/14860 (21%)]\tLoss: 0.021353\n",
      "Train Epoch: 26 [3200/14860 (21%)]\tLoss: 0.028380\n",
      "Train Epoch: 26 [3328/14860 (22%)]\tLoss: 0.025613\n",
      "Train Epoch: 26 [3456/14860 (23%)]\tLoss: 0.023880\n",
      "Train Epoch: 26 [3584/14860 (24%)]\tLoss: 0.017148\n",
      "Train Epoch: 26 [3712/14860 (25%)]\tLoss: 0.020289\n",
      "Train Epoch: 26 [3840/14860 (26%)]\tLoss: 0.014777\n",
      "Train Epoch: 26 [3968/14860 (26%)]\tLoss: 0.023772\n",
      "Train Epoch: 26 [4096/14860 (27%)]\tLoss: 0.020899\n",
      "Train Epoch: 26 [4224/14860 (28%)]\tLoss: 0.021011\n",
      "Train Epoch: 26 [4352/14860 (29%)]\tLoss: 0.013794\n",
      "Train Epoch: 26 [4480/14860 (30%)]\tLoss: 0.022311\n",
      "Train Epoch: 26 [4608/14860 (31%)]\tLoss: 0.029330\n",
      "Train Epoch: 26 [4736/14860 (32%)]\tLoss: 0.017952\n",
      "Train Epoch: 26 [4864/14860 (32%)]\tLoss: 0.018401\n",
      "Train Epoch: 26 [4992/14860 (33%)]\tLoss: 0.018863\n",
      "Train Epoch: 26 [5120/14860 (34%)]\tLoss: 0.023008\n",
      "Train Epoch: 26 [5248/14860 (35%)]\tLoss: 0.016169\n",
      "Train Epoch: 26 [5376/14860 (36%)]\tLoss: 0.017620\n",
      "Train Epoch: 26 [5504/14860 (37%)]\tLoss: 0.019178\n",
      "Train Epoch: 26 [5632/14860 (38%)]\tLoss: 0.024325\n",
      "Train Epoch: 26 [5760/14860 (38%)]\tLoss: 0.025718\n",
      "Train Epoch: 26 [5888/14860 (39%)]\tLoss: 0.033353\n",
      "Train Epoch: 26 [6016/14860 (40%)]\tLoss: 0.017343\n",
      "Train Epoch: 26 [6144/14860 (41%)]\tLoss: 0.029057\n",
      "Train Epoch: 26 [6272/14860 (42%)]\tLoss: 0.024756\n",
      "Train Epoch: 26 [6400/14860 (43%)]\tLoss: 0.025943\n",
      "Train Epoch: 26 [6528/14860 (44%)]\tLoss: 0.022775\n",
      "Train Epoch: 26 [6656/14860 (44%)]\tLoss: 0.020566\n",
      "Train Epoch: 26 [6784/14860 (45%)]\tLoss: 0.023358\n",
      "Train Epoch: 26 [6912/14860 (46%)]\tLoss: 0.017733\n",
      "Train Epoch: 26 [7040/14860 (47%)]\tLoss: 0.028450\n",
      "Train Epoch: 26 [7168/14860 (48%)]\tLoss: 0.020579\n",
      "Train Epoch: 26 [7296/14860 (49%)]\tLoss: 0.019833\n",
      "Train Epoch: 26 [7424/14860 (50%)]\tLoss: 0.017488\n",
      "Train Epoch: 26 [7552/14860 (50%)]\tLoss: 0.015950\n",
      "Train Epoch: 26 [7680/14860 (51%)]\tLoss: 0.019432\n",
      "Train Epoch: 26 [7808/14860 (52%)]\tLoss: 0.013514\n",
      "Train Epoch: 26 [7936/14860 (53%)]\tLoss: 0.020578\n",
      "Train Epoch: 26 [8064/14860 (54%)]\tLoss: 0.023853\n",
      "Train Epoch: 26 [8192/14860 (55%)]\tLoss: 0.024561\n",
      "Train Epoch: 26 [8320/14860 (56%)]\tLoss: 0.024035\n",
      "Train Epoch: 26 [8448/14860 (56%)]\tLoss: 0.017966\n",
      "Train Epoch: 26 [8576/14860 (57%)]\tLoss: 0.017829\n",
      "Train Epoch: 26 [8704/14860 (58%)]\tLoss: 0.019747\n",
      "Train Epoch: 26 [8832/14860 (59%)]\tLoss: 0.020223\n",
      "Train Epoch: 26 [8960/14860 (60%)]\tLoss: 0.024906\n",
      "Train Epoch: 26 [9088/14860 (61%)]\tLoss: 0.018091\n",
      "Train Epoch: 26 [9216/14860 (62%)]\tLoss: 0.017998\n",
      "Train Epoch: 26 [9344/14860 (62%)]\tLoss: 0.024880\n",
      "Train Epoch: 26 [9472/14860 (63%)]\tLoss: 0.019806\n",
      "Train Epoch: 26 [9600/14860 (64%)]\tLoss: 0.019015\n",
      "Train Epoch: 26 [9728/14860 (65%)]\tLoss: 0.023965\n",
      "Train Epoch: 26 [9856/14860 (66%)]\tLoss: 0.018979\n",
      "Train Epoch: 26 [9984/14860 (67%)]\tLoss: 0.020670\n",
      "Train Epoch: 26 [10112/14860 (68%)]\tLoss: 0.015973\n",
      "Train Epoch: 26 [10240/14860 (68%)]\tLoss: 0.020099\n",
      "Train Epoch: 26 [10368/14860 (69%)]\tLoss: 0.014602\n",
      "Train Epoch: 26 [10496/14860 (70%)]\tLoss: 0.018502\n",
      "Train Epoch: 26 [10624/14860 (71%)]\tLoss: 0.029838\n",
      "Train Epoch: 26 [10752/14860 (72%)]\tLoss: 0.023561\n",
      "Train Epoch: 26 [10880/14860 (73%)]\tLoss: 0.018878\n",
      "Train Epoch: 26 [11008/14860 (74%)]\tLoss: 0.016535\n",
      "Train Epoch: 26 [11136/14860 (74%)]\tLoss: 0.017769\n",
      "Train Epoch: 26 [11264/14860 (75%)]\tLoss: 0.025196\n",
      "Train Epoch: 26 [11392/14860 (76%)]\tLoss: 0.019049\n",
      "Train Epoch: 26 [11520/14860 (77%)]\tLoss: 0.014862\n",
      "Train Epoch: 26 [11648/14860 (78%)]\tLoss: 0.024967\n",
      "Train Epoch: 26 [11776/14860 (79%)]\tLoss: 0.024285\n",
      "Train Epoch: 26 [11904/14860 (79%)]\tLoss: 0.023161\n",
      "Train Epoch: 26 [12032/14860 (80%)]\tLoss: 0.034587\n",
      "Train Epoch: 26 [12160/14860 (81%)]\tLoss: 0.023478\n",
      "Train Epoch: 26 [12288/14860 (82%)]\tLoss: 0.039252\n",
      "Train Epoch: 26 [12416/14860 (83%)]\tLoss: 0.023119\n",
      "Train Epoch: 26 [12544/14860 (84%)]\tLoss: 0.036288\n",
      "Train Epoch: 26 [12672/14860 (85%)]\tLoss: 0.016648\n",
      "Train Epoch: 26 [12800/14860 (85%)]\tLoss: 0.025162\n",
      "Train Epoch: 26 [12928/14860 (86%)]\tLoss: 0.017215\n",
      "Train Epoch: 26 [13056/14860 (87%)]\tLoss: 0.038004\n",
      "Train Epoch: 26 [13184/14860 (88%)]\tLoss: 0.014519\n",
      "Train Epoch: 26 [13312/14860 (89%)]\tLoss: 0.032565\n",
      "Train Epoch: 26 [13440/14860 (90%)]\tLoss: 0.024798\n",
      "Train Epoch: 26 [13568/14860 (91%)]\tLoss: 0.025623\n",
      "Train Epoch: 26 [13696/14860 (91%)]\tLoss: 0.019363\n",
      "Train Epoch: 26 [13824/14860 (92%)]\tLoss: 0.017396\n",
      "Train Epoch: 26 [13952/14860 (93%)]\tLoss: 0.025053\n",
      "Train Epoch: 26 [14080/14860 (94%)]\tLoss: 0.022260\n",
      "Train Epoch: 26 [14208/14860 (95%)]\tLoss: 0.014416\n",
      "Train Epoch: 26 [14336/14860 (96%)]\tLoss: 0.018111\n",
      "Train Epoch: 26 [14464/14860 (97%)]\tLoss: 0.019990\n",
      "Train Epoch: 26 [14592/14860 (97%)]\tLoss: 0.021274\n",
      "Train Epoch: 26 [14720/14860 (98%)]\tLoss: 0.022121\n",
      "Train Epoch: 26 [1392/14860 (99%)]\tLoss: 0.015269\n",
      "epoch 26 training loss: 0.021805570349415652\n",
      "epoch 26 validation loss: 0.022677718438478704\n",
      "Train Epoch: 27 [0/14860 (0%)]\tLoss: 0.025386\n",
      "Train Epoch: 27 [128/14860 (1%)]\tLoss: 0.014348\n",
      "Train Epoch: 27 [256/14860 (2%)]\tLoss: 0.015742\n",
      "Train Epoch: 27 [384/14860 (3%)]\tLoss: 0.019011\n",
      "Train Epoch: 27 [512/14860 (3%)]\tLoss: 0.019098\n",
      "Train Epoch: 27 [640/14860 (4%)]\tLoss: 0.021333\n",
      "Train Epoch: 27 [768/14860 (5%)]\tLoss: 0.025881\n",
      "Train Epoch: 27 [896/14860 (6%)]\tLoss: 0.016950\n",
      "Train Epoch: 27 [1024/14860 (7%)]\tLoss: 0.013282\n",
      "Train Epoch: 27 [1152/14860 (8%)]\tLoss: 0.021658\n",
      "Train Epoch: 27 [1280/14860 (9%)]\tLoss: 0.013237\n",
      "Train Epoch: 27 [1408/14860 (9%)]\tLoss: 0.020353\n",
      "Train Epoch: 27 [1536/14860 (10%)]\tLoss: 0.015712\n",
      "Train Epoch: 27 [1664/14860 (11%)]\tLoss: 0.027309\n",
      "Train Epoch: 27 [1792/14860 (12%)]\tLoss: 0.019929\n",
      "Train Epoch: 27 [1920/14860 (13%)]\tLoss: 0.025721\n",
      "Train Epoch: 27 [2048/14860 (14%)]\tLoss: 0.025556\n",
      "Train Epoch: 27 [2176/14860 (15%)]\tLoss: 0.020976\n",
      "Train Epoch: 27 [2304/14860 (15%)]\tLoss: 0.020755\n",
      "Train Epoch: 27 [2432/14860 (16%)]\tLoss: 0.020576\n",
      "Train Epoch: 27 [2560/14860 (17%)]\tLoss: 0.022208\n",
      "Train Epoch: 27 [2688/14860 (18%)]\tLoss: 0.024659\n",
      "Train Epoch: 27 [2816/14860 (19%)]\tLoss: 0.023320\n",
      "Train Epoch: 27 [2944/14860 (20%)]\tLoss: 0.030289\n",
      "Train Epoch: 27 [3072/14860 (21%)]\tLoss: 0.017417\n",
      "Train Epoch: 27 [3200/14860 (21%)]\tLoss: 0.026209\n",
      "Train Epoch: 27 [3328/14860 (22%)]\tLoss: 0.020921\n",
      "Train Epoch: 27 [3456/14860 (23%)]\tLoss: 0.030749\n",
      "Train Epoch: 27 [3584/14860 (24%)]\tLoss: 0.019572\n",
      "Train Epoch: 27 [3712/14860 (25%)]\tLoss: 0.025047\n",
      "Train Epoch: 27 [3840/14860 (26%)]\tLoss: 0.023987\n",
      "Train Epoch: 27 [3968/14860 (26%)]\tLoss: 0.022357\n",
      "Train Epoch: 27 [4096/14860 (27%)]\tLoss: 0.018054\n",
      "Train Epoch: 27 [4224/14860 (28%)]\tLoss: 0.022257\n",
      "Train Epoch: 27 [4352/14860 (29%)]\tLoss: 0.018207\n",
      "Train Epoch: 27 [4480/14860 (30%)]\tLoss: 0.025971\n",
      "Train Epoch: 27 [4608/14860 (31%)]\tLoss: 0.035833\n",
      "Train Epoch: 27 [4736/14860 (32%)]\tLoss: 0.019575\n",
      "Train Epoch: 27 [4864/14860 (32%)]\tLoss: 0.030571\n",
      "Train Epoch: 27 [4992/14860 (33%)]\tLoss: 0.030876\n",
      "Train Epoch: 27 [5120/14860 (34%)]\tLoss: 0.035326\n",
      "Train Epoch: 27 [5248/14860 (35%)]\tLoss: 0.017407\n",
      "Train Epoch: 27 [5376/14860 (36%)]\tLoss: 0.035219\n",
      "Train Epoch: 27 [5504/14860 (37%)]\tLoss: 0.024109\n",
      "Train Epoch: 27 [5632/14860 (38%)]\tLoss: 0.027156\n",
      "Train Epoch: 27 [5760/14860 (38%)]\tLoss: 0.018838\n",
      "Train Epoch: 27 [5888/14860 (39%)]\tLoss: 0.024468\n",
      "Train Epoch: 27 [6016/14860 (40%)]\tLoss: 0.019475\n",
      "Train Epoch: 27 [6144/14860 (41%)]\tLoss: 0.022419\n",
      "Train Epoch: 27 [6272/14860 (42%)]\tLoss: 0.023606\n",
      "Train Epoch: 27 [6400/14860 (43%)]\tLoss: 0.021294\n",
      "Train Epoch: 27 [6528/14860 (44%)]\tLoss: 0.028101\n",
      "Train Epoch: 27 [6656/14860 (44%)]\tLoss: 0.019121\n",
      "Train Epoch: 27 [6784/14860 (45%)]\tLoss: 0.028921\n",
      "Train Epoch: 27 [6912/14860 (46%)]\tLoss: 0.020141\n",
      "Train Epoch: 27 [7040/14860 (47%)]\tLoss: 0.016474\n",
      "Train Epoch: 27 [7168/14860 (48%)]\tLoss: 0.026081\n",
      "Train Epoch: 27 [7296/14860 (49%)]\tLoss: 0.014704\n",
      "Train Epoch: 27 [7424/14860 (50%)]\tLoss: 0.022470\n",
      "Train Epoch: 27 [7552/14860 (50%)]\tLoss: 0.017810\n",
      "Train Epoch: 27 [7680/14860 (51%)]\tLoss: 0.015257\n",
      "Train Epoch: 27 [7808/14860 (52%)]\tLoss: 0.033396\n",
      "Train Epoch: 27 [7936/14860 (53%)]\tLoss: 0.020371\n",
      "Train Epoch: 27 [8064/14860 (54%)]\tLoss: 0.024543\n",
      "Train Epoch: 27 [8192/14860 (55%)]\tLoss: 0.025663\n",
      "Train Epoch: 27 [8320/14860 (56%)]\tLoss: 0.024821\n",
      "Train Epoch: 27 [8448/14860 (56%)]\tLoss: 0.014944\n",
      "Train Epoch: 27 [8576/14860 (57%)]\tLoss: 0.019487\n",
      "Train Epoch: 27 [8704/14860 (58%)]\tLoss: 0.022002\n",
      "Train Epoch: 27 [8832/14860 (59%)]\tLoss: 0.017336\n",
      "Train Epoch: 27 [8960/14860 (60%)]\tLoss: 0.017498\n",
      "Train Epoch: 27 [9088/14860 (61%)]\tLoss: 0.018210\n",
      "Train Epoch: 27 [9216/14860 (62%)]\tLoss: 0.032635\n",
      "Train Epoch: 27 [9344/14860 (62%)]\tLoss: 0.023056\n",
      "Train Epoch: 27 [9472/14860 (63%)]\tLoss: 0.012703\n",
      "Train Epoch: 27 [9600/14860 (64%)]\tLoss: 0.027654\n",
      "Train Epoch: 27 [9728/14860 (65%)]\tLoss: 0.023829\n",
      "Train Epoch: 27 [9856/14860 (66%)]\tLoss: 0.024653\n",
      "Train Epoch: 27 [9984/14860 (67%)]\tLoss: 0.020711\n",
      "Train Epoch: 27 [10112/14860 (68%)]\tLoss: 0.019915\n",
      "Train Epoch: 27 [10240/14860 (68%)]\tLoss: 0.025049\n",
      "Train Epoch: 27 [10368/14860 (69%)]\tLoss: 0.024524\n",
      "Train Epoch: 27 [10496/14860 (70%)]\tLoss: 0.028010\n",
      "Train Epoch: 27 [10624/14860 (71%)]\tLoss: 0.015803\n",
      "Train Epoch: 27 [10752/14860 (72%)]\tLoss: 0.030461\n",
      "Train Epoch: 27 [10880/14860 (73%)]\tLoss: 0.016720\n",
      "Train Epoch: 27 [11008/14860 (74%)]\tLoss: 0.023257\n",
      "Train Epoch: 27 [11136/14860 (74%)]\tLoss: 0.019980\n",
      "Train Epoch: 27 [11264/14860 (75%)]\tLoss: 0.020576\n",
      "Train Epoch: 27 [11392/14860 (76%)]\tLoss: 0.023901\n",
      "Train Epoch: 27 [11520/14860 (77%)]\tLoss: 0.023296\n",
      "Train Epoch: 27 [11648/14860 (78%)]\tLoss: 0.022991\n",
      "Train Epoch: 27 [11776/14860 (79%)]\tLoss: 0.023260\n",
      "Train Epoch: 27 [11904/14860 (79%)]\tLoss: 0.021345\n",
      "Train Epoch: 27 [12032/14860 (80%)]\tLoss: 0.025270\n",
      "Train Epoch: 27 [12160/14860 (81%)]\tLoss: 0.016342\n",
      "Train Epoch: 27 [12288/14860 (82%)]\tLoss: 0.019003\n",
      "Train Epoch: 27 [12416/14860 (83%)]\tLoss: 0.020937\n",
      "Train Epoch: 27 [12544/14860 (84%)]\tLoss: 0.023037\n",
      "Train Epoch: 27 [12672/14860 (85%)]\tLoss: 0.025312\n",
      "Train Epoch: 27 [12800/14860 (85%)]\tLoss: 0.021861\n",
      "Train Epoch: 27 [12928/14860 (86%)]\tLoss: 0.028627\n",
      "Train Epoch: 27 [13056/14860 (87%)]\tLoss: 0.014268\n",
      "Train Epoch: 27 [13184/14860 (88%)]\tLoss: 0.018447\n",
      "Train Epoch: 27 [13312/14860 (89%)]\tLoss: 0.020801\n",
      "Train Epoch: 27 [13440/14860 (90%)]\tLoss: 0.015383\n",
      "Train Epoch: 27 [13568/14860 (91%)]\tLoss: 0.015503\n",
      "Train Epoch: 27 [13696/14860 (91%)]\tLoss: 0.014333\n",
      "Train Epoch: 27 [13824/14860 (92%)]\tLoss: 0.026926\n",
      "Train Epoch: 27 [13952/14860 (93%)]\tLoss: 0.025213\n",
      "Train Epoch: 27 [14080/14860 (94%)]\tLoss: 0.023484\n",
      "Train Epoch: 27 [14208/14860 (95%)]\tLoss: 0.028063\n",
      "Train Epoch: 27 [14336/14860 (96%)]\tLoss: 0.021808\n",
      "Train Epoch: 27 [14464/14860 (97%)]\tLoss: 0.023574\n",
      "Train Epoch: 27 [14592/14860 (97%)]\tLoss: 0.022768\n",
      "Train Epoch: 27 [14720/14860 (98%)]\tLoss: 0.020622\n",
      "Train Epoch: 27 [1392/14860 (99%)]\tLoss: 0.044449\n",
      "epoch 27 training loss: 0.022460906201193474\n",
      "epoch 27 validation loss: 0.029180928812188617\n",
      "Train Epoch: 28 [0/14860 (0%)]\tLoss: 0.027180\n",
      "Train Epoch: 28 [128/14860 (1%)]\tLoss: 0.023704\n",
      "Train Epoch: 28 [256/14860 (2%)]\tLoss: 0.025328\n",
      "Train Epoch: 28 [384/14860 (3%)]\tLoss: 0.034616\n",
      "Train Epoch: 28 [512/14860 (3%)]\tLoss: 0.021680\n",
      "Train Epoch: 28 [640/14860 (4%)]\tLoss: 0.029573\n",
      "Train Epoch: 28 [768/14860 (5%)]\tLoss: 0.017598\n",
      "Train Epoch: 28 [896/14860 (6%)]\tLoss: 0.041440\n",
      "Train Epoch: 28 [1024/14860 (7%)]\tLoss: 0.019552\n",
      "Train Epoch: 28 [1152/14860 (8%)]\tLoss: 0.026675\n",
      "Train Epoch: 28 [1280/14860 (9%)]\tLoss: 0.014904\n",
      "Train Epoch: 28 [1408/14860 (9%)]\tLoss: 0.024915\n",
      "Train Epoch: 28 [1536/14860 (10%)]\tLoss: 0.011871\n",
      "Train Epoch: 28 [1664/14860 (11%)]\tLoss: 0.015265\n",
      "Train Epoch: 28 [1792/14860 (12%)]\tLoss: 0.020788\n",
      "Train Epoch: 28 [1920/14860 (13%)]\tLoss: 0.015059\n",
      "Train Epoch: 28 [2048/14860 (14%)]\tLoss: 0.036743\n",
      "Train Epoch: 28 [2176/14860 (15%)]\tLoss: 0.015986\n",
      "Train Epoch: 28 [2304/14860 (15%)]\tLoss: 0.019151\n",
      "Train Epoch: 28 [2432/14860 (16%)]\tLoss: 0.025249\n",
      "Train Epoch: 28 [2560/14860 (17%)]\tLoss: 0.014404\n",
      "Train Epoch: 28 [2688/14860 (18%)]\tLoss: 0.023538\n",
      "Train Epoch: 28 [2816/14860 (19%)]\tLoss: 0.026493\n",
      "Train Epoch: 28 [2944/14860 (20%)]\tLoss: 0.021812\n",
      "Train Epoch: 28 [3072/14860 (21%)]\tLoss: 0.017751\n",
      "Train Epoch: 28 [3200/14860 (21%)]\tLoss: 0.026414\n",
      "Train Epoch: 28 [3328/14860 (22%)]\tLoss: 0.021892\n",
      "Train Epoch: 28 [3456/14860 (23%)]\tLoss: 0.020692\n",
      "Train Epoch: 28 [3584/14860 (24%)]\tLoss: 0.029726\n",
      "Train Epoch: 28 [3712/14860 (25%)]\tLoss: 0.024407\n",
      "Train Epoch: 28 [3840/14860 (26%)]\tLoss: 0.020955\n",
      "Train Epoch: 28 [3968/14860 (26%)]\tLoss: 0.020496\n",
      "Train Epoch: 28 [4096/14860 (27%)]\tLoss: 0.023364\n",
      "Train Epoch: 28 [4224/14860 (28%)]\tLoss: 0.028587\n",
      "Train Epoch: 28 [4352/14860 (29%)]\tLoss: 0.015922\n",
      "Train Epoch: 28 [4480/14860 (30%)]\tLoss: 0.034997\n",
      "Train Epoch: 28 [4608/14860 (31%)]\tLoss: 0.025276\n",
      "Train Epoch: 28 [4736/14860 (32%)]\tLoss: 0.023018\n",
      "Train Epoch: 28 [4864/14860 (32%)]\tLoss: 0.023539\n",
      "Train Epoch: 28 [4992/14860 (33%)]\tLoss: 0.022582\n",
      "Train Epoch: 28 [5120/14860 (34%)]\tLoss: 0.021947\n",
      "Train Epoch: 28 [5248/14860 (35%)]\tLoss: 0.020936\n",
      "Train Epoch: 28 [5376/14860 (36%)]\tLoss: 0.026479\n",
      "Train Epoch: 28 [5504/14860 (37%)]\tLoss: 0.017046\n",
      "Train Epoch: 28 [5632/14860 (38%)]\tLoss: 0.019668\n",
      "Train Epoch: 28 [5760/14860 (38%)]\tLoss: 0.031023\n",
      "Train Epoch: 28 [5888/14860 (39%)]\tLoss: 0.027308\n",
      "Train Epoch: 28 [6016/14860 (40%)]\tLoss: 0.035563\n",
      "Train Epoch: 28 [6144/14860 (41%)]\tLoss: 0.020088\n",
      "Train Epoch: 28 [6272/14860 (42%)]\tLoss: 0.029167\n",
      "Train Epoch: 28 [6400/14860 (43%)]\tLoss: 0.015910\n",
      "Train Epoch: 28 [6528/14860 (44%)]\tLoss: 0.018308\n",
      "Train Epoch: 28 [6656/14860 (44%)]\tLoss: 0.030683\n",
      "Train Epoch: 28 [6784/14860 (45%)]\tLoss: 0.023431\n",
      "Train Epoch: 28 [6912/14860 (46%)]\tLoss: 0.019249\n",
      "Train Epoch: 28 [7040/14860 (47%)]\tLoss: 0.022065\n",
      "Train Epoch: 28 [7168/14860 (48%)]\tLoss: 0.018245\n",
      "Train Epoch: 28 [7296/14860 (49%)]\tLoss: 0.015515\n",
      "Train Epoch: 28 [7424/14860 (50%)]\tLoss: 0.028238\n",
      "Train Epoch: 28 [7552/14860 (50%)]\tLoss: 0.023956\n",
      "Train Epoch: 28 [7680/14860 (51%)]\tLoss: 0.019410\n",
      "Train Epoch: 28 [7808/14860 (52%)]\tLoss: 0.027506\n",
      "Train Epoch: 28 [7936/14860 (53%)]\tLoss: 0.022493\n",
      "Train Epoch: 28 [8064/14860 (54%)]\tLoss: 0.023215\n",
      "Train Epoch: 28 [8192/14860 (55%)]\tLoss: 0.024476\n",
      "Train Epoch: 28 [8320/14860 (56%)]\tLoss: 0.020111\n",
      "Train Epoch: 28 [8448/14860 (56%)]\tLoss: 0.021566\n",
      "Train Epoch: 28 [8576/14860 (57%)]\tLoss: 0.018726\n",
      "Train Epoch: 28 [8704/14860 (58%)]\tLoss: 0.024121\n",
      "Train Epoch: 28 [8832/14860 (59%)]\tLoss: 0.018874\n",
      "Train Epoch: 28 [8960/14860 (60%)]\tLoss: 0.021312\n",
      "Train Epoch: 28 [9088/14860 (61%)]\tLoss: 0.021389\n",
      "Train Epoch: 28 [9216/14860 (62%)]\tLoss: 0.014072\n",
      "Train Epoch: 28 [9344/14860 (62%)]\tLoss: 0.017219\n",
      "Train Epoch: 28 [9472/14860 (63%)]\tLoss: 0.020495\n",
      "Train Epoch: 28 [9600/14860 (64%)]\tLoss: 0.024769\n",
      "Train Epoch: 28 [9728/14860 (65%)]\tLoss: 0.028939\n",
      "Train Epoch: 28 [9856/14860 (66%)]\tLoss: 0.013883\n",
      "Train Epoch: 28 [9984/14860 (67%)]\tLoss: 0.030707\n",
      "Train Epoch: 28 [10112/14860 (68%)]\tLoss: 0.017370\n",
      "Train Epoch: 28 [10240/14860 (68%)]\tLoss: 0.023282\n",
      "Train Epoch: 28 [10368/14860 (69%)]\tLoss: 0.018324\n",
      "Train Epoch: 28 [10496/14860 (70%)]\tLoss: 0.015188\n",
      "Train Epoch: 28 [10624/14860 (71%)]\tLoss: 0.019248\n",
      "Train Epoch: 28 [10752/14860 (72%)]\tLoss: 0.026227\n",
      "Train Epoch: 28 [10880/14860 (73%)]\tLoss: 0.027177\n",
      "Train Epoch: 28 [11008/14860 (74%)]\tLoss: 0.024205\n",
      "Train Epoch: 28 [11136/14860 (74%)]\tLoss: 0.025061\n",
      "Train Epoch: 28 [11264/14860 (75%)]\tLoss: 0.017441\n",
      "Train Epoch: 28 [11392/14860 (76%)]\tLoss: 0.016442\n",
      "Train Epoch: 28 [11520/14860 (77%)]\tLoss: 0.029732\n",
      "Train Epoch: 28 [11648/14860 (78%)]\tLoss: 0.016921\n",
      "Train Epoch: 28 [11776/14860 (79%)]\tLoss: 0.026289\n",
      "Train Epoch: 28 [11904/14860 (79%)]\tLoss: 0.019711\n",
      "Train Epoch: 28 [12032/14860 (80%)]\tLoss: 0.028507\n",
      "Train Epoch: 28 [12160/14860 (81%)]\tLoss: 0.021960\n",
      "Train Epoch: 28 [12288/14860 (82%)]\tLoss: 0.018426\n",
      "Train Epoch: 28 [12416/14860 (83%)]\tLoss: 0.025704\n",
      "Train Epoch: 28 [12544/14860 (84%)]\tLoss: 0.023431\n",
      "Train Epoch: 28 [12672/14860 (85%)]\tLoss: 0.021203\n",
      "Train Epoch: 28 [12800/14860 (85%)]\tLoss: 0.028569\n",
      "Train Epoch: 28 [12928/14860 (86%)]\tLoss: 0.021223\n",
      "Train Epoch: 28 [13056/14860 (87%)]\tLoss: 0.018565\n",
      "Train Epoch: 28 [13184/14860 (88%)]\tLoss: 0.013103\n",
      "Train Epoch: 28 [13312/14860 (89%)]\tLoss: 0.024271\n",
      "Train Epoch: 28 [13440/14860 (90%)]\tLoss: 0.019861\n",
      "Train Epoch: 28 [13568/14860 (91%)]\tLoss: 0.019039\n",
      "Train Epoch: 28 [13696/14860 (91%)]\tLoss: 0.017782\n",
      "Train Epoch: 28 [13824/14860 (92%)]\tLoss: 0.017602\n",
      "Train Epoch: 28 [13952/14860 (93%)]\tLoss: 0.027357\n",
      "Train Epoch: 28 [14080/14860 (94%)]\tLoss: 0.021768\n",
      "Train Epoch: 28 [14208/14860 (95%)]\tLoss: 0.022260\n",
      "Train Epoch: 28 [14336/14860 (96%)]\tLoss: 0.026595\n",
      "Train Epoch: 28 [14464/14860 (97%)]\tLoss: 0.018876\n",
      "Train Epoch: 28 [14592/14860 (97%)]\tLoss: 0.018416\n",
      "Train Epoch: 28 [14720/14860 (98%)]\tLoss: 0.022145\n",
      "Train Epoch: 28 [1392/14860 (99%)]\tLoss: 0.024393\n",
      "epoch 28 training loss: 0.02252074713126207\n",
      "epoch 28 validation loss: 0.021934366255060525\n",
      "Train Epoch: 29 [0/14860 (0%)]\tLoss: 0.022352\n",
      "Train Epoch: 29 [128/14860 (1%)]\tLoss: 0.024444\n",
      "Train Epoch: 29 [256/14860 (2%)]\tLoss: 0.015668\n",
      "Train Epoch: 29 [384/14860 (3%)]\tLoss: 0.035524\n",
      "Train Epoch: 29 [512/14860 (3%)]\tLoss: 0.014163\n",
      "Train Epoch: 29 [640/14860 (4%)]\tLoss: 0.024748\n",
      "Train Epoch: 29 [768/14860 (5%)]\tLoss: 0.017376\n",
      "Train Epoch: 29 [896/14860 (6%)]\tLoss: 0.015273\n",
      "Train Epoch: 29 [1024/14860 (7%)]\tLoss: 0.018979\n",
      "Train Epoch: 29 [1152/14860 (8%)]\tLoss: 0.015524\n",
      "Train Epoch: 29 [1280/14860 (9%)]\tLoss: 0.021746\n",
      "Train Epoch: 29 [1408/14860 (9%)]\tLoss: 0.018169\n",
      "Train Epoch: 29 [1536/14860 (10%)]\tLoss: 0.019246\n",
      "Train Epoch: 29 [1664/14860 (11%)]\tLoss: 0.023351\n",
      "Train Epoch: 29 [1792/14860 (12%)]\tLoss: 0.020495\n",
      "Train Epoch: 29 [1920/14860 (13%)]\tLoss: 0.017063\n",
      "Train Epoch: 29 [2048/14860 (14%)]\tLoss: 0.015533\n",
      "Train Epoch: 29 [2176/14860 (15%)]\tLoss: 0.025693\n",
      "Train Epoch: 29 [2304/14860 (15%)]\tLoss: 0.019382\n",
      "Train Epoch: 29 [2432/14860 (16%)]\tLoss: 0.026195\n",
      "Train Epoch: 29 [2560/14860 (17%)]\tLoss: 0.018316\n",
      "Train Epoch: 29 [2688/14860 (18%)]\tLoss: 0.023498\n",
      "Train Epoch: 29 [2816/14860 (19%)]\tLoss: 0.022336\n",
      "Train Epoch: 29 [2944/14860 (20%)]\tLoss: 0.019130\n",
      "Train Epoch: 29 [3072/14860 (21%)]\tLoss: 0.023634\n",
      "Train Epoch: 29 [3200/14860 (21%)]\tLoss: 0.019245\n",
      "Train Epoch: 29 [3328/14860 (22%)]\tLoss: 0.026528\n",
      "Train Epoch: 29 [3456/14860 (23%)]\tLoss: 0.021162\n",
      "Train Epoch: 29 [3584/14860 (24%)]\tLoss: 0.026343\n",
      "Train Epoch: 29 [3712/14860 (25%)]\tLoss: 0.023013\n",
      "Train Epoch: 29 [3840/14860 (26%)]\tLoss: 0.022995\n",
      "Train Epoch: 29 [3968/14860 (26%)]\tLoss: 0.013662\n",
      "Train Epoch: 29 [4096/14860 (27%)]\tLoss: 0.019394\n",
      "Train Epoch: 29 [4224/14860 (28%)]\tLoss: 0.021672\n",
      "Train Epoch: 29 [4352/14860 (29%)]\tLoss: 0.015840\n",
      "Train Epoch: 29 [4480/14860 (30%)]\tLoss: 0.017921\n",
      "Train Epoch: 29 [4608/14860 (31%)]\tLoss: 0.020758\n",
      "Train Epoch: 29 [4736/14860 (32%)]\tLoss: 0.020203\n",
      "Train Epoch: 29 [4864/14860 (32%)]\tLoss: 0.015793\n",
      "Train Epoch: 29 [4992/14860 (33%)]\tLoss: 0.022146\n",
      "Train Epoch: 29 [5120/14860 (34%)]\tLoss: 0.019323\n",
      "Train Epoch: 29 [5248/14860 (35%)]\tLoss: 0.020369\n",
      "Train Epoch: 29 [5376/14860 (36%)]\tLoss: 0.021091\n",
      "Train Epoch: 29 [5504/14860 (37%)]\tLoss: 0.024868\n",
      "Train Epoch: 29 [5632/14860 (38%)]\tLoss: 0.024311\n",
      "Train Epoch: 29 [5760/14860 (38%)]\tLoss: 0.018167\n",
      "Train Epoch: 29 [5888/14860 (39%)]\tLoss: 0.015017\n",
      "Train Epoch: 29 [6016/14860 (40%)]\tLoss: 0.016754\n",
      "Train Epoch: 29 [6144/14860 (41%)]\tLoss: 0.019563\n",
      "Train Epoch: 29 [6272/14860 (42%)]\tLoss: 0.020891\n",
      "Train Epoch: 29 [6400/14860 (43%)]\tLoss: 0.023979\n",
      "Train Epoch: 29 [6528/14860 (44%)]\tLoss: 0.018001\n",
      "Train Epoch: 29 [6656/14860 (44%)]\tLoss: 0.021447\n",
      "Train Epoch: 29 [6784/14860 (45%)]\tLoss: 0.021204\n",
      "Train Epoch: 29 [6912/14860 (46%)]\tLoss: 0.018805\n",
      "Train Epoch: 29 [7040/14860 (47%)]\tLoss: 0.019242\n",
      "Train Epoch: 29 [7168/14860 (48%)]\tLoss: 0.024243\n",
      "Train Epoch: 29 [7296/14860 (49%)]\tLoss: 0.025908\n",
      "Train Epoch: 29 [7424/14860 (50%)]\tLoss: 0.023113\n",
      "Train Epoch: 29 [7552/14860 (50%)]\tLoss: 0.021970\n",
      "Train Epoch: 29 [7680/14860 (51%)]\tLoss: 0.017797\n",
      "Train Epoch: 29 [7808/14860 (52%)]\tLoss: 0.023413\n",
      "Train Epoch: 29 [7936/14860 (53%)]\tLoss: 0.017217\n",
      "Train Epoch: 29 [8064/14860 (54%)]\tLoss: 0.016165\n",
      "Train Epoch: 29 [8192/14860 (55%)]\tLoss: 0.017618\n",
      "Train Epoch: 29 [8320/14860 (56%)]\tLoss: 0.017648\n",
      "Train Epoch: 29 [8448/14860 (56%)]\tLoss: 0.018399\n",
      "Train Epoch: 29 [8576/14860 (57%)]\tLoss: 0.019872\n",
      "Train Epoch: 29 [8704/14860 (58%)]\tLoss: 0.020435\n",
      "Train Epoch: 29 [8832/14860 (59%)]\tLoss: 0.024837\n",
      "Train Epoch: 29 [8960/14860 (60%)]\tLoss: 0.022425\n",
      "Train Epoch: 29 [9088/14860 (61%)]\tLoss: 0.029219\n",
      "Train Epoch: 29 [9216/14860 (62%)]\tLoss: 0.019296\n",
      "Train Epoch: 29 [9344/14860 (62%)]\tLoss: 0.020349\n",
      "Train Epoch: 29 [9472/14860 (63%)]\tLoss: 0.018100\n",
      "Train Epoch: 29 [9600/14860 (64%)]\tLoss: 0.031623\n",
      "Train Epoch: 29 [9728/14860 (65%)]\tLoss: 0.021639\n",
      "Train Epoch: 29 [9856/14860 (66%)]\tLoss: 0.016020\n",
      "Train Epoch: 29 [9984/14860 (67%)]\tLoss: 0.025586\n",
      "Train Epoch: 29 [10112/14860 (68%)]\tLoss: 0.029802\n",
      "Train Epoch: 29 [10240/14860 (68%)]\tLoss: 0.029941\n",
      "Train Epoch: 29 [10368/14860 (69%)]\tLoss: 0.015990\n",
      "Train Epoch: 29 [10496/14860 (70%)]\tLoss: 0.022661\n",
      "Train Epoch: 29 [10624/14860 (71%)]\tLoss: 0.022169\n",
      "Train Epoch: 29 [10752/14860 (72%)]\tLoss: 0.027275\n",
      "Train Epoch: 29 [10880/14860 (73%)]\tLoss: 0.014844\n",
      "Train Epoch: 29 [11008/14860 (74%)]\tLoss: 0.024135\n",
      "Train Epoch: 29 [11136/14860 (74%)]\tLoss: 0.020058\n",
      "Train Epoch: 29 [11264/14860 (75%)]\tLoss: 0.024903\n",
      "Train Epoch: 29 [11392/14860 (76%)]\tLoss: 0.026258\n",
      "Train Epoch: 29 [11520/14860 (77%)]\tLoss: 0.013496\n",
      "Train Epoch: 29 [11648/14860 (78%)]\tLoss: 0.017095\n",
      "Train Epoch: 29 [11776/14860 (79%)]\tLoss: 0.013676\n",
      "Train Epoch: 29 [11904/14860 (79%)]\tLoss: 0.017437\n",
      "Train Epoch: 29 [12032/14860 (80%)]\tLoss: 0.020968\n",
      "Train Epoch: 29 [12160/14860 (81%)]\tLoss: 0.018740\n",
      "Train Epoch: 29 [12288/14860 (82%)]\tLoss: 0.015588\n",
      "Train Epoch: 29 [12416/14860 (83%)]\tLoss: 0.022509\n",
      "Train Epoch: 29 [12544/14860 (84%)]\tLoss: 0.019328\n",
      "Train Epoch: 29 [12672/14860 (85%)]\tLoss: 0.021929\n",
      "Train Epoch: 29 [12800/14860 (85%)]\tLoss: 0.019113\n",
      "Train Epoch: 29 [12928/14860 (86%)]\tLoss: 0.017433\n",
      "Train Epoch: 29 [13056/14860 (87%)]\tLoss: 0.023365\n",
      "Train Epoch: 29 [13184/14860 (88%)]\tLoss: 0.020189\n",
      "Train Epoch: 29 [13312/14860 (89%)]\tLoss: 0.024800\n",
      "Train Epoch: 29 [13440/14860 (90%)]\tLoss: 0.021813\n",
      "Train Epoch: 29 [13568/14860 (91%)]\tLoss: 0.017292\n",
      "Train Epoch: 29 [13696/14860 (91%)]\tLoss: 0.019308\n",
      "Train Epoch: 29 [13824/14860 (92%)]\tLoss: 0.020119\n",
      "Train Epoch: 29 [13952/14860 (93%)]\tLoss: 0.022914\n",
      "Train Epoch: 29 [14080/14860 (94%)]\tLoss: 0.015359\n",
      "Train Epoch: 29 [14208/14860 (95%)]\tLoss: 0.022459\n",
      "Train Epoch: 29 [14336/14860 (96%)]\tLoss: 0.026568\n",
      "Train Epoch: 29 [14464/14860 (97%)]\tLoss: 0.015307\n",
      "Train Epoch: 29 [14592/14860 (97%)]\tLoss: 0.018386\n",
      "Train Epoch: 29 [14720/14860 (98%)]\tLoss: 0.018877\n",
      "Train Epoch: 29 [1392/14860 (99%)]\tLoss: 0.010490\n",
      "epoch 29 training loss: 0.020624203766640436\n",
      "epoch 29 validation loss: 0.02433045248142455\n",
      "Train Epoch: 30 [0/14860 (0%)]\tLoss: 0.028891\n",
      "Train Epoch: 30 [128/14860 (1%)]\tLoss: 0.030282\n",
      "Train Epoch: 30 [256/14860 (2%)]\tLoss: 0.022804\n",
      "Train Epoch: 30 [384/14860 (3%)]\tLoss: 0.017016\n",
      "Train Epoch: 30 [512/14860 (3%)]\tLoss: 0.023418\n",
      "Train Epoch: 30 [640/14860 (4%)]\tLoss: 0.015524\n",
      "Train Epoch: 30 [768/14860 (5%)]\tLoss: 0.021006\n",
      "Train Epoch: 30 [896/14860 (6%)]\tLoss: 0.011891\n",
      "Train Epoch: 30 [1024/14860 (7%)]\tLoss: 0.036723\n",
      "Train Epoch: 30 [1152/14860 (8%)]\tLoss: 0.023910\n",
      "Train Epoch: 30 [1280/14860 (9%)]\tLoss: 0.039176\n",
      "Train Epoch: 30 [1408/14860 (9%)]\tLoss: 0.042036\n",
      "Train Epoch: 30 [1536/14860 (10%)]\tLoss: 0.023388\n",
      "Train Epoch: 30 [1664/14860 (11%)]\tLoss: 0.034901\n",
      "Train Epoch: 30 [1792/14860 (12%)]\tLoss: 0.014381\n",
      "Train Epoch: 30 [1920/14860 (13%)]\tLoss: 0.045300\n",
      "Train Epoch: 30 [2048/14860 (14%)]\tLoss: 0.019843\n",
      "Train Epoch: 30 [2176/14860 (15%)]\tLoss: 0.031500\n",
      "Train Epoch: 30 [2304/14860 (15%)]\tLoss: 0.020083\n",
      "Train Epoch: 30 [2432/14860 (16%)]\tLoss: 0.019269\n",
      "Train Epoch: 30 [2560/14860 (17%)]\tLoss: 0.024915\n",
      "Train Epoch: 30 [2688/14860 (18%)]\tLoss: 0.022928\n",
      "Train Epoch: 30 [2816/14860 (19%)]\tLoss: 0.023153\n",
      "Train Epoch: 30 [2944/14860 (20%)]\tLoss: 0.023846\n",
      "Train Epoch: 30 [3072/14860 (21%)]\tLoss: 0.020389\n",
      "Train Epoch: 30 [3200/14860 (21%)]\tLoss: 0.015416\n",
      "Train Epoch: 30 [3328/14860 (22%)]\tLoss: 0.024214\n",
      "Train Epoch: 30 [3456/14860 (23%)]\tLoss: 0.016934\n",
      "Train Epoch: 30 [3584/14860 (24%)]\tLoss: 0.019798\n",
      "Train Epoch: 30 [3712/14860 (25%)]\tLoss: 0.017854\n",
      "Train Epoch: 30 [3840/14860 (26%)]\tLoss: 0.023010\n",
      "Train Epoch: 30 [3968/14860 (26%)]\tLoss: 0.022512\n",
      "Train Epoch: 30 [4096/14860 (27%)]\tLoss: 0.022506\n",
      "Train Epoch: 30 [4224/14860 (28%)]\tLoss: 0.019203\n",
      "Train Epoch: 30 [4352/14860 (29%)]\tLoss: 0.025702\n",
      "Train Epoch: 30 [4480/14860 (30%)]\tLoss: 0.021702\n",
      "Train Epoch: 30 [4608/14860 (31%)]\tLoss: 0.013674\n",
      "Train Epoch: 30 [4736/14860 (32%)]\tLoss: 0.044420\n",
      "Train Epoch: 30 [4864/14860 (32%)]\tLoss: 0.024503\n",
      "Train Epoch: 30 [4992/14860 (33%)]\tLoss: 0.026647\n",
      "Train Epoch: 30 [5120/14860 (34%)]\tLoss: 0.022244\n",
      "Train Epoch: 30 [5248/14860 (35%)]\tLoss: 0.026260\n",
      "Train Epoch: 30 [5376/14860 (36%)]\tLoss: 0.021320\n",
      "Train Epoch: 30 [5504/14860 (37%)]\tLoss: 0.030700\n",
      "Train Epoch: 30 [5632/14860 (38%)]\tLoss: 0.022993\n",
      "Train Epoch: 30 [5760/14860 (38%)]\tLoss: 0.030495\n",
      "Train Epoch: 30 [5888/14860 (39%)]\tLoss: 0.023316\n",
      "Train Epoch: 30 [6016/14860 (40%)]\tLoss: 0.018776\n",
      "Train Epoch: 30 [6144/14860 (41%)]\tLoss: 0.024072\n",
      "Train Epoch: 30 [6272/14860 (42%)]\tLoss: 0.030137\n",
      "Train Epoch: 30 [6400/14860 (43%)]\tLoss: 0.032518\n",
      "Train Epoch: 30 [6528/14860 (44%)]\tLoss: 0.020116\n",
      "Train Epoch: 30 [6656/14860 (44%)]\tLoss: 0.018935\n",
      "Train Epoch: 30 [6784/14860 (45%)]\tLoss: 0.025345\n",
      "Train Epoch: 30 [6912/14860 (46%)]\tLoss: 0.024182\n",
      "Train Epoch: 30 [7040/14860 (47%)]\tLoss: 0.014013\n",
      "Train Epoch: 30 [7168/14860 (48%)]\tLoss: 0.029120\n",
      "Train Epoch: 30 [7296/14860 (49%)]\tLoss: 0.023232\n",
      "Train Epoch: 30 [7424/14860 (50%)]\tLoss: 0.017382\n",
      "Train Epoch: 30 [7552/14860 (50%)]\tLoss: 0.020218\n",
      "Train Epoch: 30 [7680/14860 (51%)]\tLoss: 0.020011\n",
      "Train Epoch: 30 [7808/14860 (52%)]\tLoss: 0.015828\n",
      "Train Epoch: 30 [7936/14860 (53%)]\tLoss: 0.014110\n",
      "Train Epoch: 30 [8064/14860 (54%)]\tLoss: 0.025091\n",
      "Train Epoch: 30 [8192/14860 (55%)]\tLoss: 0.027721\n",
      "Train Epoch: 30 [8320/14860 (56%)]\tLoss: 0.028314\n",
      "Train Epoch: 30 [8448/14860 (56%)]\tLoss: 0.015530\n",
      "Train Epoch: 30 [8576/14860 (57%)]\tLoss: 0.035560\n",
      "Train Epoch: 30 [8704/14860 (58%)]\tLoss: 0.026035\n",
      "Train Epoch: 30 [8832/14860 (59%)]\tLoss: 0.028339\n",
      "Train Epoch: 30 [8960/14860 (60%)]\tLoss: 0.020932\n",
      "Train Epoch: 30 [9088/14860 (61%)]\tLoss: 0.018232\n",
      "Train Epoch: 30 [9216/14860 (62%)]\tLoss: 0.020426\n",
      "Train Epoch: 30 [9344/14860 (62%)]\tLoss: 0.017132\n",
      "Train Epoch: 30 [9472/14860 (63%)]\tLoss: 0.026769\n",
      "Train Epoch: 30 [9600/14860 (64%)]\tLoss: 0.015026\n",
      "Train Epoch: 30 [9728/14860 (65%)]\tLoss: 0.025172\n",
      "Train Epoch: 30 [9856/14860 (66%)]\tLoss: 0.016691\n",
      "Train Epoch: 30 [9984/14860 (67%)]\tLoss: 0.019998\n",
      "Train Epoch: 30 [10112/14860 (68%)]\tLoss: 0.019112\n",
      "Train Epoch: 30 [10240/14860 (68%)]\tLoss: 0.016619\n",
      "Train Epoch: 30 [10368/14860 (69%)]\tLoss: 0.014582\n",
      "Train Epoch: 30 [10496/14860 (70%)]\tLoss: 0.021275\n",
      "Train Epoch: 30 [10624/14860 (71%)]\tLoss: 0.023959\n",
      "Train Epoch: 30 [10752/14860 (72%)]\tLoss: 0.016191\n",
      "Train Epoch: 30 [10880/14860 (73%)]\tLoss: 0.026179\n",
      "Train Epoch: 30 [11008/14860 (74%)]\tLoss: 0.022207\n",
      "Train Epoch: 30 [11136/14860 (74%)]\tLoss: 0.022686\n",
      "Train Epoch: 30 [11264/14860 (75%)]\tLoss: 0.020784\n",
      "Train Epoch: 30 [11392/14860 (76%)]\tLoss: 0.015067\n",
      "Train Epoch: 30 [11520/14860 (77%)]\tLoss: 0.024463\n",
      "Train Epoch: 30 [11648/14860 (78%)]\tLoss: 0.017853\n",
      "Train Epoch: 30 [11776/14860 (79%)]\tLoss: 0.021139\n",
      "Train Epoch: 30 [11904/14860 (79%)]\tLoss: 0.015956\n",
      "Train Epoch: 30 [12032/14860 (80%)]\tLoss: 0.020848\n",
      "Train Epoch: 30 [12160/14860 (81%)]\tLoss: 0.018489\n",
      "Train Epoch: 30 [12288/14860 (82%)]\tLoss: 0.016236\n",
      "Train Epoch: 30 [12416/14860 (83%)]\tLoss: 0.027373\n",
      "Train Epoch: 30 [12544/14860 (84%)]\tLoss: 0.020753\n",
      "Train Epoch: 30 [12672/14860 (85%)]\tLoss: 0.022213\n",
      "Train Epoch: 30 [12800/14860 (85%)]\tLoss: 0.014484\n",
      "Train Epoch: 30 [12928/14860 (86%)]\tLoss: 0.017063\n",
      "Train Epoch: 30 [13056/14860 (87%)]\tLoss: 0.022302\n",
      "Train Epoch: 30 [13184/14860 (88%)]\tLoss: 0.021365\n",
      "Train Epoch: 30 [13312/14860 (89%)]\tLoss: 0.019534\n",
      "Train Epoch: 30 [13440/14860 (90%)]\tLoss: 0.014586\n",
      "Train Epoch: 30 [13568/14860 (91%)]\tLoss: 0.027569\n",
      "Train Epoch: 30 [13696/14860 (91%)]\tLoss: 0.020213\n",
      "Train Epoch: 30 [13824/14860 (92%)]\tLoss: 0.026778\n",
      "Train Epoch: 30 [13952/14860 (93%)]\tLoss: 0.020209\n",
      "Train Epoch: 30 [14080/14860 (94%)]\tLoss: 0.038407\n",
      "Train Epoch: 30 [14208/14860 (95%)]\tLoss: 0.017490\n",
      "Train Epoch: 30 [14336/14860 (96%)]\tLoss: 0.032711\n",
      "Train Epoch: 30 [14464/14860 (97%)]\tLoss: 0.023359\n",
      "Train Epoch: 30 [14592/14860 (97%)]\tLoss: 0.030549\n",
      "Train Epoch: 30 [14720/14860 (98%)]\tLoss: 0.014623\n",
      "Train Epoch: 30 [1392/14860 (99%)]\tLoss: 0.015620\n",
      "epoch 30 training loss: 0.022801724867497243\n",
      "epoch 30 validation loss: 0.025158250447335603\n",
      "Train Epoch: 31 [0/14860 (0%)]\tLoss: 0.029325\n",
      "Train Epoch: 31 [128/14860 (1%)]\tLoss: 0.021493\n",
      "Train Epoch: 31 [256/14860 (2%)]\tLoss: 0.018802\n",
      "Train Epoch: 31 [384/14860 (3%)]\tLoss: 0.021579\n",
      "Train Epoch: 31 [512/14860 (3%)]\tLoss: 0.021751\n",
      "Train Epoch: 31 [640/14860 (4%)]\tLoss: 0.018199\n",
      "Train Epoch: 31 [768/14860 (5%)]\tLoss: 0.015278\n",
      "Train Epoch: 31 [896/14860 (6%)]\tLoss: 0.026971\n",
      "Train Epoch: 31 [1024/14860 (7%)]\tLoss: 0.020750\n",
      "Train Epoch: 31 [1152/14860 (8%)]\tLoss: 0.026941\n",
      "Train Epoch: 31 [1280/14860 (9%)]\tLoss: 0.013724\n",
      "Train Epoch: 31 [1408/14860 (9%)]\tLoss: 0.021459\n",
      "Train Epoch: 31 [1536/14860 (10%)]\tLoss: 0.015287\n",
      "Train Epoch: 31 [1664/14860 (11%)]\tLoss: 0.021905\n",
      "Train Epoch: 31 [1792/14860 (12%)]\tLoss: 0.021251\n",
      "Train Epoch: 31 [1920/14860 (13%)]\tLoss: 0.025148\n",
      "Train Epoch: 31 [2048/14860 (14%)]\tLoss: 0.019574\n",
      "Train Epoch: 31 [2176/14860 (15%)]\tLoss: 0.019798\n",
      "Train Epoch: 31 [2304/14860 (15%)]\tLoss: 0.014216\n",
      "Train Epoch: 31 [2432/14860 (16%)]\tLoss: 0.019170\n",
      "Train Epoch: 31 [2560/14860 (17%)]\tLoss: 0.019062\n",
      "Train Epoch: 31 [2688/14860 (18%)]\tLoss: 0.018734\n",
      "Train Epoch: 31 [2816/14860 (19%)]\tLoss: 0.021233\n",
      "Train Epoch: 31 [2944/14860 (20%)]\tLoss: 0.029655\n",
      "Train Epoch: 31 [3072/14860 (21%)]\tLoss: 0.019367\n",
      "Train Epoch: 31 [3200/14860 (21%)]\tLoss: 0.020198\n",
      "Train Epoch: 31 [3328/14860 (22%)]\tLoss: 0.015784\n",
      "Train Epoch: 31 [3456/14860 (23%)]\tLoss: 0.016272\n",
      "Train Epoch: 31 [3584/14860 (24%)]\tLoss: 0.021382\n",
      "Train Epoch: 31 [3712/14860 (25%)]\tLoss: 0.020183\n",
      "Train Epoch: 31 [3840/14860 (26%)]\tLoss: 0.023125\n",
      "Train Epoch: 31 [3968/14860 (26%)]\tLoss: 0.019104\n",
      "Train Epoch: 31 [4096/14860 (27%)]\tLoss: 0.018310\n",
      "Train Epoch: 31 [4224/14860 (28%)]\tLoss: 0.019472\n",
      "Train Epoch: 31 [4352/14860 (29%)]\tLoss: 0.031506\n",
      "Train Epoch: 31 [4480/14860 (30%)]\tLoss: 0.025068\n",
      "Train Epoch: 31 [4608/14860 (31%)]\tLoss: 0.025100\n",
      "Train Epoch: 31 [4736/14860 (32%)]\tLoss: 0.018022\n",
      "Train Epoch: 31 [4864/14860 (32%)]\tLoss: 0.028226\n",
      "Train Epoch: 31 [4992/14860 (33%)]\tLoss: 0.024821\n",
      "Train Epoch: 31 [5120/14860 (34%)]\tLoss: 0.017894\n",
      "Train Epoch: 31 [5248/14860 (35%)]\tLoss: 0.021420\n",
      "Train Epoch: 31 [5376/14860 (36%)]\tLoss: 0.016506\n",
      "Train Epoch: 31 [5504/14860 (37%)]\tLoss: 0.020480\n",
      "Train Epoch: 31 [5632/14860 (38%)]\tLoss: 0.024539\n",
      "Train Epoch: 31 [5760/14860 (38%)]\tLoss: 0.026875\n",
      "Train Epoch: 31 [5888/14860 (39%)]\tLoss: 0.019678\n",
      "Train Epoch: 31 [6016/14860 (40%)]\tLoss: 0.017765\n",
      "Train Epoch: 31 [6144/14860 (41%)]\tLoss: 0.018853\n",
      "Train Epoch: 31 [6272/14860 (42%)]\tLoss: 0.023527\n",
      "Train Epoch: 31 [6400/14860 (43%)]\tLoss: 0.019428\n",
      "Train Epoch: 31 [6528/14860 (44%)]\tLoss: 0.025451\n",
      "Train Epoch: 31 [6656/14860 (44%)]\tLoss: 0.022723\n",
      "Train Epoch: 31 [6784/14860 (45%)]\tLoss: 0.022859\n",
      "Train Epoch: 31 [6912/14860 (46%)]\tLoss: 0.021734\n",
      "Train Epoch: 31 [7040/14860 (47%)]\tLoss: 0.015623\n",
      "Train Epoch: 31 [7168/14860 (48%)]\tLoss: 0.032251\n",
      "Train Epoch: 31 [7296/14860 (49%)]\tLoss: 0.028944\n",
      "Train Epoch: 31 [7424/14860 (50%)]\tLoss: 0.031488\n",
      "Train Epoch: 31 [7552/14860 (50%)]\tLoss: 0.025016\n",
      "Train Epoch: 31 [7680/14860 (51%)]\tLoss: 0.029973\n",
      "Train Epoch: 31 [7808/14860 (52%)]\tLoss: 0.023534\n",
      "Train Epoch: 31 [7936/14860 (53%)]\tLoss: 0.035852\n",
      "Train Epoch: 31 [8064/14860 (54%)]\tLoss: 0.023338\n",
      "Train Epoch: 31 [8192/14860 (55%)]\tLoss: 0.035901\n",
      "Train Epoch: 31 [8320/14860 (56%)]\tLoss: 0.018560\n",
      "Train Epoch: 31 [8448/14860 (56%)]\tLoss: 0.037055\n",
      "Train Epoch: 31 [8576/14860 (57%)]\tLoss: 0.023295\n",
      "Train Epoch: 31 [8704/14860 (58%)]\tLoss: 0.024582\n",
      "Train Epoch: 31 [8832/14860 (59%)]\tLoss: 0.017311\n",
      "Train Epoch: 31 [8960/14860 (60%)]\tLoss: 0.024365\n",
      "Train Epoch: 31 [9088/14860 (61%)]\tLoss: 0.027446\n",
      "Train Epoch: 31 [9216/14860 (62%)]\tLoss: 0.029277\n",
      "Train Epoch: 31 [9344/14860 (62%)]\tLoss: 0.020540\n",
      "Train Epoch: 31 [9472/14860 (63%)]\tLoss: 0.024323\n",
      "Train Epoch: 31 [9600/14860 (64%)]\tLoss: 0.028167\n",
      "Train Epoch: 31 [9728/14860 (65%)]\tLoss: 0.017753\n",
      "Train Epoch: 31 [9856/14860 (66%)]\tLoss: 0.033696\n",
      "Train Epoch: 31 [9984/14860 (67%)]\tLoss: 0.022279\n",
      "Train Epoch: 31 [10112/14860 (68%)]\tLoss: 0.016817\n",
      "Train Epoch: 31 [10240/14860 (68%)]\tLoss: 0.016819\n",
      "Train Epoch: 31 [10368/14860 (69%)]\tLoss: 0.021571\n",
      "Train Epoch: 31 [10496/14860 (70%)]\tLoss: 0.021100\n",
      "Train Epoch: 31 [10624/14860 (71%)]\tLoss: 0.022196\n",
      "Train Epoch: 31 [10752/14860 (72%)]\tLoss: 0.023843\n",
      "Train Epoch: 31 [10880/14860 (73%)]\tLoss: 0.022867\n",
      "Train Epoch: 31 [11008/14860 (74%)]\tLoss: 0.025585\n",
      "Train Epoch: 31 [11136/14860 (74%)]\tLoss: 0.013146\n",
      "Train Epoch: 31 [11264/14860 (75%)]\tLoss: 0.018380\n",
      "Train Epoch: 31 [11392/14860 (76%)]\tLoss: 0.024347\n",
      "Train Epoch: 31 [11520/14860 (77%)]\tLoss: 0.013242\n",
      "Train Epoch: 31 [11648/14860 (78%)]\tLoss: 0.029023\n",
      "Train Epoch: 31 [11776/14860 (79%)]\tLoss: 0.017724\n",
      "Train Epoch: 31 [11904/14860 (79%)]\tLoss: 0.022813\n",
      "Train Epoch: 31 [12032/14860 (80%)]\tLoss: 0.029504\n",
      "Train Epoch: 31 [12160/14860 (81%)]\tLoss: 0.017375\n",
      "Train Epoch: 31 [12288/14860 (82%)]\tLoss: 0.025225\n",
      "Train Epoch: 31 [12416/14860 (83%)]\tLoss: 0.033046\n",
      "Train Epoch: 31 [12544/14860 (84%)]\tLoss: 0.028284\n",
      "Train Epoch: 31 [12672/14860 (85%)]\tLoss: 0.027985\n",
      "Train Epoch: 31 [12800/14860 (85%)]\tLoss: 0.031331\n",
      "Train Epoch: 31 [12928/14860 (86%)]\tLoss: 0.023928\n",
      "Train Epoch: 31 [13056/14860 (87%)]\tLoss: 0.017960\n",
      "Train Epoch: 31 [13184/14860 (88%)]\tLoss: 0.022022\n",
      "Train Epoch: 31 [13312/14860 (89%)]\tLoss: 0.025694\n",
      "Train Epoch: 31 [13440/14860 (90%)]\tLoss: 0.018060\n",
      "Train Epoch: 31 [13568/14860 (91%)]\tLoss: 0.030645\n",
      "Train Epoch: 31 [13696/14860 (91%)]\tLoss: 0.017061\n",
      "Train Epoch: 31 [13824/14860 (92%)]\tLoss: 0.021273\n",
      "Train Epoch: 31 [13952/14860 (93%)]\tLoss: 0.013448\n",
      "Train Epoch: 31 [14080/14860 (94%)]\tLoss: 0.023944\n",
      "Train Epoch: 31 [14208/14860 (95%)]\tLoss: 0.024308\n",
      "Train Epoch: 31 [14336/14860 (96%)]\tLoss: 0.026168\n",
      "Train Epoch: 31 [14464/14860 (97%)]\tLoss: 0.016251\n",
      "Train Epoch: 31 [14592/14860 (97%)]\tLoss: 0.021680\n",
      "Train Epoch: 31 [14720/14860 (98%)]\tLoss: 0.018241\n",
      "Train Epoch: 31 [1392/14860 (99%)]\tLoss: 0.009351\n",
      "epoch 31 training loss: 0.022476925506678402\n",
      "epoch 31 validation loss: 0.02180759294847022\n",
      "Train Epoch: 32 [0/14860 (0%)]\tLoss: 0.019036\n",
      "Train Epoch: 32 [128/14860 (1%)]\tLoss: 0.016098\n",
      "Train Epoch: 32 [256/14860 (2%)]\tLoss: 0.023288\n",
      "Train Epoch: 32 [384/14860 (3%)]\tLoss: 0.021210\n",
      "Train Epoch: 32 [512/14860 (3%)]\tLoss: 0.019804\n",
      "Train Epoch: 32 [640/14860 (4%)]\tLoss: 0.022151\n",
      "Train Epoch: 32 [768/14860 (5%)]\tLoss: 0.032706\n",
      "Train Epoch: 32 [896/14860 (6%)]\tLoss: 0.015431\n",
      "Train Epoch: 32 [1024/14860 (7%)]\tLoss: 0.022310\n",
      "Train Epoch: 32 [1152/14860 (8%)]\tLoss: 0.019281\n",
      "Train Epoch: 32 [1280/14860 (9%)]\tLoss: 0.023560\n",
      "Train Epoch: 32 [1408/14860 (9%)]\tLoss: 0.022427\n",
      "Train Epoch: 32 [1536/14860 (10%)]\tLoss: 0.024026\n",
      "Train Epoch: 32 [1664/14860 (11%)]\tLoss: 0.020426\n",
      "Train Epoch: 32 [1792/14860 (12%)]\tLoss: 0.011982\n",
      "Train Epoch: 32 [1920/14860 (13%)]\tLoss: 0.024900\n",
      "Train Epoch: 32 [2048/14860 (14%)]\tLoss: 0.023419\n",
      "Train Epoch: 32 [2176/14860 (15%)]\tLoss: 0.021365\n",
      "Train Epoch: 32 [2304/14860 (15%)]\tLoss: 0.013231\n",
      "Train Epoch: 32 [2432/14860 (16%)]\tLoss: 0.029995\n",
      "Train Epoch: 32 [2560/14860 (17%)]\tLoss: 0.023410\n",
      "Train Epoch: 32 [2688/14860 (18%)]\tLoss: 0.028392\n",
      "Train Epoch: 32 [2816/14860 (19%)]\tLoss: 0.026932\n",
      "Train Epoch: 32 [2944/14860 (20%)]\tLoss: 0.017406\n",
      "Train Epoch: 32 [3072/14860 (21%)]\tLoss: 0.020983\n",
      "Train Epoch: 32 [3200/14860 (21%)]\tLoss: 0.022844\n",
      "Train Epoch: 32 [3328/14860 (22%)]\tLoss: 0.027409\n",
      "Train Epoch: 32 [3456/14860 (23%)]\tLoss: 0.029468\n",
      "Train Epoch: 32 [3584/14860 (24%)]\tLoss: 0.021255\n",
      "Train Epoch: 32 [3712/14860 (25%)]\tLoss: 0.030141\n",
      "Train Epoch: 32 [3840/14860 (26%)]\tLoss: 0.016942\n",
      "Train Epoch: 32 [3968/14860 (26%)]\tLoss: 0.022464\n",
      "Train Epoch: 32 [4096/14860 (27%)]\tLoss: 0.028146\n",
      "Train Epoch: 32 [4224/14860 (28%)]\tLoss: 0.020119\n",
      "Train Epoch: 32 [4352/14860 (29%)]\tLoss: 0.018779\n",
      "Train Epoch: 32 [4480/14860 (30%)]\tLoss: 0.017640\n",
      "Train Epoch: 32 [4608/14860 (31%)]\tLoss: 0.021049\n",
      "Train Epoch: 32 [4736/14860 (32%)]\tLoss: 0.019672\n",
      "Train Epoch: 32 [4864/14860 (32%)]\tLoss: 0.026319\n",
      "Train Epoch: 32 [4992/14860 (33%)]\tLoss: 0.019016\n",
      "Train Epoch: 32 [5120/14860 (34%)]\tLoss: 0.021673\n",
      "Train Epoch: 32 [5248/14860 (35%)]\tLoss: 0.014938\n",
      "Train Epoch: 32 [5376/14860 (36%)]\tLoss: 0.014438\n",
      "Train Epoch: 32 [5504/14860 (37%)]\tLoss: 0.018323\n",
      "Train Epoch: 32 [5632/14860 (38%)]\tLoss: 0.019256\n",
      "Train Epoch: 32 [5760/14860 (38%)]\tLoss: 0.019332\n",
      "Train Epoch: 32 [5888/14860 (39%)]\tLoss: 0.026007\n",
      "Train Epoch: 32 [6016/14860 (40%)]\tLoss: 0.022823\n",
      "Train Epoch: 32 [6144/14860 (41%)]\tLoss: 0.029179\n",
      "Train Epoch: 32 [6272/14860 (42%)]\tLoss: 0.020645\n",
      "Train Epoch: 32 [6400/14860 (43%)]\tLoss: 0.024735\n",
      "Train Epoch: 32 [6528/14860 (44%)]\tLoss: 0.016039\n",
      "Train Epoch: 32 [6656/14860 (44%)]\tLoss: 0.017893\n",
      "Train Epoch: 32 [6784/14860 (45%)]\tLoss: 0.021185\n",
      "Train Epoch: 32 [6912/14860 (46%)]\tLoss: 0.017818\n",
      "Train Epoch: 32 [7040/14860 (47%)]\tLoss: 0.026326\n",
      "Train Epoch: 32 [7168/14860 (48%)]\tLoss: 0.015715\n",
      "Train Epoch: 32 [7296/14860 (49%)]\tLoss: 0.021828\n",
      "Train Epoch: 32 [7424/14860 (50%)]\tLoss: 0.019552\n",
      "Train Epoch: 32 [7552/14860 (50%)]\tLoss: 0.016241\n",
      "Train Epoch: 32 [7680/14860 (51%)]\tLoss: 0.019819\n",
      "Train Epoch: 32 [7808/14860 (52%)]\tLoss: 0.027620\n",
      "Train Epoch: 32 [7936/14860 (53%)]\tLoss: 0.022216\n",
      "Train Epoch: 32 [8064/14860 (54%)]\tLoss: 0.029972\n",
      "Train Epoch: 32 [8192/14860 (55%)]\tLoss: 0.016390\n",
      "Train Epoch: 32 [8320/14860 (56%)]\tLoss: 0.028187\n",
      "Train Epoch: 32 [8448/14860 (56%)]\tLoss: 0.024285\n",
      "Train Epoch: 32 [8576/14860 (57%)]\tLoss: 0.037993\n",
      "Train Epoch: 32 [8704/14860 (58%)]\tLoss: 0.019829\n",
      "Train Epoch: 32 [8832/14860 (59%)]\tLoss: 0.029241\n",
      "Train Epoch: 32 [8960/14860 (60%)]\tLoss: 0.020827\n",
      "Train Epoch: 32 [9088/14860 (61%)]\tLoss: 0.026808\n",
      "Train Epoch: 32 [9216/14860 (62%)]\tLoss: 0.018555\n",
      "Train Epoch: 32 [9344/14860 (62%)]\tLoss: 0.027310\n",
      "Train Epoch: 32 [9472/14860 (63%)]\tLoss: 0.020897\n",
      "Train Epoch: 32 [9600/14860 (64%)]\tLoss: 0.021120\n",
      "Train Epoch: 32 [9728/14860 (65%)]\tLoss: 0.020584\n",
      "Train Epoch: 32 [9856/14860 (66%)]\tLoss: 0.013912\n",
      "Train Epoch: 32 [9984/14860 (67%)]\tLoss: 0.022748\n",
      "Train Epoch: 32 [10112/14860 (68%)]\tLoss: 0.026380\n",
      "Train Epoch: 32 [10240/14860 (68%)]\tLoss: 0.040511\n",
      "Train Epoch: 32 [10368/14860 (69%)]\tLoss: 0.019732\n",
      "Train Epoch: 32 [10496/14860 (70%)]\tLoss: 0.047534\n",
      "Train Epoch: 32 [10624/14860 (71%)]\tLoss: 0.024756\n",
      "Train Epoch: 32 [10752/14860 (72%)]\tLoss: 0.030232\n",
      "Train Epoch: 32 [10880/14860 (73%)]\tLoss: 0.033005\n",
      "Train Epoch: 32 [11008/14860 (74%)]\tLoss: 0.015775\n",
      "Train Epoch: 32 [11136/14860 (74%)]\tLoss: 0.036746\n",
      "Train Epoch: 32 [11264/14860 (75%)]\tLoss: 0.021952\n",
      "Train Epoch: 32 [11392/14860 (76%)]\tLoss: 0.034989\n",
      "Train Epoch: 32 [11520/14860 (77%)]\tLoss: 0.031357\n",
      "Train Epoch: 32 [11648/14860 (78%)]\tLoss: 0.017082\n",
      "Train Epoch: 32 [11776/14860 (79%)]\tLoss: 0.042502\n",
      "Train Epoch: 32 [11904/14860 (79%)]\tLoss: 0.019046\n",
      "Train Epoch: 32 [12032/14860 (80%)]\tLoss: 0.024271\n",
      "Train Epoch: 32 [12160/14860 (81%)]\tLoss: 0.033400\n",
      "Train Epoch: 32 [12288/14860 (82%)]\tLoss: 0.018327\n",
      "Train Epoch: 32 [12416/14860 (83%)]\tLoss: 0.018313\n",
      "Train Epoch: 32 [12544/14860 (84%)]\tLoss: 0.019016\n",
      "Train Epoch: 32 [12672/14860 (85%)]\tLoss: 0.020010\n",
      "Train Epoch: 32 [12800/14860 (85%)]\tLoss: 0.023473\n",
      "Train Epoch: 32 [12928/14860 (86%)]\tLoss: 0.025344\n",
      "Train Epoch: 32 [13056/14860 (87%)]\tLoss: 0.018228\n",
      "Train Epoch: 32 [13184/14860 (88%)]\tLoss: 0.021215\n",
      "Train Epoch: 32 [13312/14860 (89%)]\tLoss: 0.022242\n",
      "Train Epoch: 32 [13440/14860 (90%)]\tLoss: 0.024576\n",
      "Train Epoch: 32 [13568/14860 (91%)]\tLoss: 0.022686\n",
      "Train Epoch: 32 [13696/14860 (91%)]\tLoss: 0.018578\n",
      "Train Epoch: 32 [13824/14860 (92%)]\tLoss: 0.027768\n",
      "Train Epoch: 32 [13952/14860 (93%)]\tLoss: 0.030780\n",
      "Train Epoch: 32 [14080/14860 (94%)]\tLoss: 0.022156\n",
      "Train Epoch: 32 [14208/14860 (95%)]\tLoss: 0.023029\n",
      "Train Epoch: 32 [14336/14860 (96%)]\tLoss: 0.016846\n",
      "Train Epoch: 32 [14464/14860 (97%)]\tLoss: 0.020331\n",
      "Train Epoch: 32 [14592/14860 (97%)]\tLoss: 0.025396\n",
      "Train Epoch: 32 [14720/14860 (98%)]\tLoss: 0.022826\n",
      "Train Epoch: 32 [1392/14860 (99%)]\tLoss: 0.021142\n",
      "epoch 32 training loss: 0.02306706019732942\n",
      "epoch 32 validation loss: 0.025038304109550272\n",
      "Train Epoch: 33 [0/14860 (0%)]\tLoss: 0.019922\n",
      "Train Epoch: 33 [128/14860 (1%)]\tLoss: 0.032267\n",
      "Train Epoch: 33 [256/14860 (2%)]\tLoss: 0.029882\n",
      "Train Epoch: 33 [384/14860 (3%)]\tLoss: 0.026510\n",
      "Train Epoch: 33 [512/14860 (3%)]\tLoss: 0.024690\n",
      "Train Epoch: 33 [640/14860 (4%)]\tLoss: 0.019115\n",
      "Train Epoch: 33 [768/14860 (5%)]\tLoss: 0.029941\n",
      "Train Epoch: 33 [896/14860 (6%)]\tLoss: 0.027068\n",
      "Train Epoch: 33 [1024/14860 (7%)]\tLoss: 0.025892\n",
      "Train Epoch: 33 [1152/14860 (8%)]\tLoss: 0.032606\n",
      "Train Epoch: 33 [1280/14860 (9%)]\tLoss: 0.025057\n",
      "Train Epoch: 33 [1408/14860 (9%)]\tLoss: 0.022072\n",
      "Train Epoch: 33 [1536/14860 (10%)]\tLoss: 0.033563\n",
      "Train Epoch: 33 [1664/14860 (11%)]\tLoss: 0.024363\n",
      "Train Epoch: 33 [1792/14860 (12%)]\tLoss: 0.022791\n",
      "Train Epoch: 33 [1920/14860 (13%)]\tLoss: 0.021743\n",
      "Train Epoch: 33 [2048/14860 (14%)]\tLoss: 0.029172\n",
      "Train Epoch: 33 [2176/14860 (15%)]\tLoss: 0.025686\n",
      "Train Epoch: 33 [2304/14860 (15%)]\tLoss: 0.026664\n",
      "Train Epoch: 33 [2432/14860 (16%)]\tLoss: 0.029866\n",
      "Train Epoch: 33 [2560/14860 (17%)]\tLoss: 0.025856\n",
      "Train Epoch: 33 [2688/14860 (18%)]\tLoss: 0.026351\n",
      "Train Epoch: 33 [2816/14860 (19%)]\tLoss: 0.026112\n",
      "Train Epoch: 33 [2944/14860 (20%)]\tLoss: 0.020969\n",
      "Train Epoch: 33 [3072/14860 (21%)]\tLoss: 0.023636\n",
      "Train Epoch: 33 [3200/14860 (21%)]\tLoss: 0.020450\n",
      "Train Epoch: 33 [3328/14860 (22%)]\tLoss: 0.019439\n",
      "Train Epoch: 33 [3456/14860 (23%)]\tLoss: 0.016640\n",
      "Train Epoch: 33 [3584/14860 (24%)]\tLoss: 0.022113\n",
      "Train Epoch: 33 [3712/14860 (25%)]\tLoss: 0.018629\n",
      "Train Epoch: 33 [3840/14860 (26%)]\tLoss: 0.021761\n",
      "Train Epoch: 33 [3968/14860 (26%)]\tLoss: 0.019152\n",
      "Train Epoch: 33 [4096/14860 (27%)]\tLoss: 0.020144\n",
      "Train Epoch: 33 [4224/14860 (28%)]\tLoss: 0.020115\n",
      "Train Epoch: 33 [4352/14860 (29%)]\tLoss: 0.021722\n",
      "Train Epoch: 33 [4480/14860 (30%)]\tLoss: 0.020329\n",
      "Train Epoch: 33 [4608/14860 (31%)]\tLoss: 0.022518\n",
      "Train Epoch: 33 [4736/14860 (32%)]\tLoss: 0.020858\n",
      "Train Epoch: 33 [4864/14860 (32%)]\tLoss: 0.019499\n",
      "Train Epoch: 33 [4992/14860 (33%)]\tLoss: 0.023759\n",
      "Train Epoch: 33 [5120/14860 (34%)]\tLoss: 0.024845\n",
      "Train Epoch: 33 [5248/14860 (35%)]\tLoss: 0.019938\n",
      "Train Epoch: 33 [5376/14860 (36%)]\tLoss: 0.016247\n",
      "Train Epoch: 33 [5504/14860 (37%)]\tLoss: 0.039635\n",
      "Train Epoch: 33 [5632/14860 (38%)]\tLoss: 0.015332\n",
      "Train Epoch: 33 [5760/14860 (38%)]\tLoss: 0.023186\n",
      "Train Epoch: 33 [5888/14860 (39%)]\tLoss: 0.020332\n",
      "Train Epoch: 33 [6016/14860 (40%)]\tLoss: 0.021622\n",
      "Train Epoch: 33 [6144/14860 (41%)]\tLoss: 0.017403\n",
      "Train Epoch: 33 [6272/14860 (42%)]\tLoss: 0.020681\n",
      "Train Epoch: 33 [6400/14860 (43%)]\tLoss: 0.019501\n",
      "Train Epoch: 33 [6528/14860 (44%)]\tLoss: 0.021410\n",
      "Train Epoch: 33 [6656/14860 (44%)]\tLoss: 0.021305\n",
      "Train Epoch: 33 [6784/14860 (45%)]\tLoss: 0.023875\n",
      "Train Epoch: 33 [6912/14860 (46%)]\tLoss: 0.022417\n",
      "Train Epoch: 33 [7040/14860 (47%)]\tLoss: 0.020637\n",
      "Train Epoch: 33 [7168/14860 (48%)]\tLoss: 0.026780\n",
      "Train Epoch: 33 [7296/14860 (49%)]\tLoss: 0.018713\n",
      "Train Epoch: 33 [7424/14860 (50%)]\tLoss: 0.020352\n",
      "Train Epoch: 33 [7552/14860 (50%)]\tLoss: 0.033698\n",
      "Train Epoch: 33 [7680/14860 (51%)]\tLoss: 0.022382\n",
      "Train Epoch: 33 [7808/14860 (52%)]\tLoss: 0.016733\n",
      "Train Epoch: 33 [7936/14860 (53%)]\tLoss: 0.029844\n",
      "Train Epoch: 33 [8064/14860 (54%)]\tLoss: 0.015572\n",
      "Train Epoch: 33 [8192/14860 (55%)]\tLoss: 0.025029\n",
      "Train Epoch: 33 [8320/14860 (56%)]\tLoss: 0.023447\n",
      "Train Epoch: 33 [8448/14860 (56%)]\tLoss: 0.024812\n",
      "Train Epoch: 33 [8576/14860 (57%)]\tLoss: 0.025549\n",
      "Train Epoch: 33 [8704/14860 (58%)]\tLoss: 0.024937\n",
      "Train Epoch: 33 [8832/14860 (59%)]\tLoss: 0.020096\n",
      "Train Epoch: 33 [8960/14860 (60%)]\tLoss: 0.025981\n",
      "Train Epoch: 33 [9088/14860 (61%)]\tLoss: 0.022601\n",
      "Train Epoch: 33 [9216/14860 (62%)]\tLoss: 0.027058\n",
      "Train Epoch: 33 [9344/14860 (62%)]\tLoss: 0.020846\n",
      "Train Epoch: 33 [9472/14860 (63%)]\tLoss: 0.022798\n",
      "Train Epoch: 33 [9600/14860 (64%)]\tLoss: 0.017520\n",
      "Train Epoch: 33 [9728/14860 (65%)]\tLoss: 0.031017\n",
      "Train Epoch: 33 [9856/14860 (66%)]\tLoss: 0.020733\n",
      "Train Epoch: 33 [9984/14860 (67%)]\tLoss: 0.030383\n",
      "Train Epoch: 33 [10112/14860 (68%)]\tLoss: 0.024143\n",
      "Train Epoch: 33 [10240/14860 (68%)]\tLoss: 0.025281\n",
      "Train Epoch: 33 [10368/14860 (69%)]\tLoss: 0.023864\n",
      "Train Epoch: 33 [10496/14860 (70%)]\tLoss: 0.018942\n",
      "Train Epoch: 33 [10624/14860 (71%)]\tLoss: 0.017125\n",
      "Train Epoch: 33 [10752/14860 (72%)]\tLoss: 0.019411\n",
      "Train Epoch: 33 [10880/14860 (73%)]\tLoss: 0.017407\n",
      "Train Epoch: 33 [11008/14860 (74%)]\tLoss: 0.020245\n",
      "Train Epoch: 33 [11136/14860 (74%)]\tLoss: 0.014804\n",
      "Train Epoch: 33 [11264/14860 (75%)]\tLoss: 0.018763\n",
      "Train Epoch: 33 [11392/14860 (76%)]\tLoss: 0.030716\n",
      "Train Epoch: 33 [11520/14860 (77%)]\tLoss: 0.020450\n",
      "Train Epoch: 33 [11648/14860 (78%)]\tLoss: 0.014046\n",
      "Train Epoch: 33 [11776/14860 (79%)]\tLoss: 0.017715\n",
      "Train Epoch: 33 [11904/14860 (79%)]\tLoss: 0.017125\n",
      "Train Epoch: 33 [12032/14860 (80%)]\tLoss: 0.023781\n",
      "Train Epoch: 33 [12160/14860 (81%)]\tLoss: 0.025727\n",
      "Train Epoch: 33 [12288/14860 (82%)]\tLoss: 0.026090\n",
      "Train Epoch: 33 [12416/14860 (83%)]\tLoss: 0.012299\n",
      "Train Epoch: 33 [12544/14860 (84%)]\tLoss: 0.022149\n",
      "Train Epoch: 33 [12672/14860 (85%)]\tLoss: 0.014459\n",
      "Train Epoch: 33 [12800/14860 (85%)]\tLoss: 0.018305\n",
      "Train Epoch: 33 [12928/14860 (86%)]\tLoss: 0.017405\n",
      "Train Epoch: 33 [13056/14860 (87%)]\tLoss: 0.016528\n",
      "Train Epoch: 33 [13184/14860 (88%)]\tLoss: 0.019177\n",
      "Train Epoch: 33 [13312/14860 (89%)]\tLoss: 0.020026\n",
      "Train Epoch: 33 [13440/14860 (90%)]\tLoss: 0.025485\n",
      "Train Epoch: 33 [13568/14860 (91%)]\tLoss: 0.021839\n",
      "Train Epoch: 33 [13696/14860 (91%)]\tLoss: 0.018964\n",
      "Train Epoch: 33 [13824/14860 (92%)]\tLoss: 0.023564\n",
      "Train Epoch: 33 [13952/14860 (93%)]\tLoss: 0.027426\n",
      "Train Epoch: 33 [14080/14860 (94%)]\tLoss: 0.017628\n",
      "Train Epoch: 33 [14208/14860 (95%)]\tLoss: 0.023896\n",
      "Train Epoch: 33 [14336/14860 (96%)]\tLoss: 0.020751\n",
      "Train Epoch: 33 [14464/14860 (97%)]\tLoss: 0.017972\n",
      "Train Epoch: 33 [14592/14860 (97%)]\tLoss: 0.022525\n",
      "Train Epoch: 33 [14720/14860 (98%)]\tLoss: 0.021357\n",
      "Train Epoch: 33 [1392/14860 (99%)]\tLoss: 0.011841\n",
      "epoch 33 training loss: 0.022422215996835478\n",
      "epoch 33 validation loss: 0.020977495368975994\n",
      "Train Epoch: 34 [0/14860 (0%)]\tLoss: 0.020109\n",
      "Train Epoch: 34 [128/14860 (1%)]\tLoss: 0.022837\n",
      "Train Epoch: 34 [256/14860 (2%)]\tLoss: 0.014431\n",
      "Train Epoch: 34 [384/14860 (3%)]\tLoss: 0.025004\n",
      "Train Epoch: 34 [512/14860 (3%)]\tLoss: 0.025276\n",
      "Train Epoch: 34 [640/14860 (4%)]\tLoss: 0.015128\n",
      "Train Epoch: 34 [768/14860 (5%)]\tLoss: 0.027041\n",
      "Train Epoch: 34 [896/14860 (6%)]\tLoss: 0.018586\n",
      "Train Epoch: 34 [1024/14860 (7%)]\tLoss: 0.023986\n",
      "Train Epoch: 34 [1152/14860 (8%)]\tLoss: 0.020696\n",
      "Train Epoch: 34 [1280/14860 (9%)]\tLoss: 0.021092\n",
      "Train Epoch: 34 [1408/14860 (9%)]\tLoss: 0.022885\n",
      "Train Epoch: 34 [1536/14860 (10%)]\tLoss: 0.024859\n",
      "Train Epoch: 34 [1664/14860 (11%)]\tLoss: 0.023320\n",
      "Train Epoch: 34 [1792/14860 (12%)]\tLoss: 0.020039\n",
      "Train Epoch: 34 [1920/14860 (13%)]\tLoss: 0.024369\n",
      "Train Epoch: 34 [2048/14860 (14%)]\tLoss: 0.012440\n",
      "Train Epoch: 34 [2176/14860 (15%)]\tLoss: 0.027926\n",
      "Train Epoch: 34 [2304/14860 (15%)]\tLoss: 0.029581\n",
      "Train Epoch: 34 [2432/14860 (16%)]\tLoss: 0.025178\n",
      "Train Epoch: 34 [2560/14860 (17%)]\tLoss: 0.016934\n",
      "Train Epoch: 34 [2688/14860 (18%)]\tLoss: 0.021434\n",
      "Train Epoch: 34 [2816/14860 (19%)]\tLoss: 0.021892\n",
      "Train Epoch: 34 [2944/14860 (20%)]\tLoss: 0.023599\n",
      "Train Epoch: 34 [3072/14860 (21%)]\tLoss: 0.021861\n",
      "Train Epoch: 34 [3200/14860 (21%)]\tLoss: 0.026427\n",
      "Train Epoch: 34 [3328/14860 (22%)]\tLoss: 0.020295\n",
      "Train Epoch: 34 [3456/14860 (23%)]\tLoss: 0.019286\n",
      "Train Epoch: 34 [3584/14860 (24%)]\tLoss: 0.016604\n",
      "Train Epoch: 34 [3712/14860 (25%)]\tLoss: 0.024776\n",
      "Train Epoch: 34 [3840/14860 (26%)]\tLoss: 0.021924\n",
      "Train Epoch: 34 [3968/14860 (26%)]\tLoss: 0.014250\n",
      "Train Epoch: 34 [4096/14860 (27%)]\tLoss: 0.019668\n",
      "Train Epoch: 34 [4224/14860 (28%)]\tLoss: 0.022176\n",
      "Train Epoch: 34 [4352/14860 (29%)]\tLoss: 0.020587\n",
      "Train Epoch: 34 [4480/14860 (30%)]\tLoss: 0.027046\n",
      "Train Epoch: 34 [4608/14860 (31%)]\tLoss: 0.016009\n",
      "Train Epoch: 34 [4736/14860 (32%)]\tLoss: 0.023503\n",
      "Train Epoch: 34 [4864/14860 (32%)]\tLoss: 0.029946\n",
      "Train Epoch: 34 [4992/14860 (33%)]\tLoss: 0.022624\n",
      "Train Epoch: 34 [5120/14860 (34%)]\tLoss: 0.022173\n",
      "Train Epoch: 34 [5248/14860 (35%)]\tLoss: 0.023555\n",
      "Train Epoch: 34 [5376/14860 (36%)]\tLoss: 0.024000\n",
      "Train Epoch: 34 [5504/14860 (37%)]\tLoss: 0.022806\n",
      "Train Epoch: 34 [5632/14860 (38%)]\tLoss: 0.028091\n",
      "Train Epoch: 34 [5760/14860 (38%)]\tLoss: 0.017787\n",
      "Train Epoch: 34 [5888/14860 (39%)]\tLoss: 0.026550\n",
      "Train Epoch: 34 [6016/14860 (40%)]\tLoss: 0.020962\n",
      "Train Epoch: 34 [6144/14860 (41%)]\tLoss: 0.021685\n",
      "Train Epoch: 34 [6272/14860 (42%)]\tLoss: 0.023623\n",
      "Train Epoch: 34 [6400/14860 (43%)]\tLoss: 0.029209\n",
      "Train Epoch: 34 [6528/14860 (44%)]\tLoss: 0.018111\n",
      "Train Epoch: 34 [6656/14860 (44%)]\tLoss: 0.023963\n",
      "Train Epoch: 34 [6784/14860 (45%)]\tLoss: 0.022799\n",
      "Train Epoch: 34 [6912/14860 (46%)]\tLoss: 0.021376\n",
      "Train Epoch: 34 [7040/14860 (47%)]\tLoss: 0.023194\n",
      "Train Epoch: 34 [7168/14860 (48%)]\tLoss: 0.013349\n",
      "Train Epoch: 34 [7296/14860 (49%)]\tLoss: 0.022596\n",
      "Train Epoch: 34 [7424/14860 (50%)]\tLoss: 0.019811\n",
      "Train Epoch: 34 [7552/14860 (50%)]\tLoss: 0.021328\n",
      "Train Epoch: 34 [7680/14860 (51%)]\tLoss: 0.018102\n",
      "Train Epoch: 34 [7808/14860 (52%)]\tLoss: 0.026101\n",
      "Train Epoch: 34 [7936/14860 (53%)]\tLoss: 0.019180\n",
      "Train Epoch: 34 [8064/14860 (54%)]\tLoss: 0.027753\n",
      "Train Epoch: 34 [8192/14860 (55%)]\tLoss: 0.016116\n",
      "Train Epoch: 34 [8320/14860 (56%)]\tLoss: 0.025108\n",
      "Train Epoch: 34 [8448/14860 (56%)]\tLoss: 0.017173\n",
      "Train Epoch: 34 [8576/14860 (57%)]\tLoss: 0.017397\n",
      "Train Epoch: 34 [8704/14860 (58%)]\tLoss: 0.028541\n",
      "Train Epoch: 34 [8832/14860 (59%)]\tLoss: 0.020183\n",
      "Train Epoch: 34 [8960/14860 (60%)]\tLoss: 0.013624\n",
      "Train Epoch: 34 [9088/14860 (61%)]\tLoss: 0.018822\n",
      "Train Epoch: 34 [9216/14860 (62%)]\tLoss: 0.017717\n",
      "Train Epoch: 34 [9344/14860 (62%)]\tLoss: 0.019176\n",
      "Train Epoch: 34 [9472/14860 (63%)]\tLoss: 0.016350\n",
      "Train Epoch: 34 [9600/14860 (64%)]\tLoss: 0.024683\n",
      "Train Epoch: 34 [9728/14860 (65%)]\tLoss: 0.011254\n",
      "Train Epoch: 34 [9856/14860 (66%)]\tLoss: 0.015406\n",
      "Train Epoch: 34 [9984/14860 (67%)]\tLoss: 0.012501\n",
      "Train Epoch: 34 [10112/14860 (68%)]\tLoss: 0.026227\n",
      "Train Epoch: 34 [10240/14860 (68%)]\tLoss: 0.026863\n",
      "Train Epoch: 34 [10368/14860 (69%)]\tLoss: 0.019359\n",
      "Train Epoch: 34 [10496/14860 (70%)]\tLoss: 0.015456\n",
      "Train Epoch: 34 [10624/14860 (71%)]\tLoss: 0.018913\n",
      "Train Epoch: 34 [10752/14860 (72%)]\tLoss: 0.020282\n",
      "Train Epoch: 34 [10880/14860 (73%)]\tLoss: 0.023221\n",
      "Train Epoch: 34 [11008/14860 (74%)]\tLoss: 0.028639\n",
      "Train Epoch: 34 [11136/14860 (74%)]\tLoss: 0.012054\n",
      "Train Epoch: 34 [11264/14860 (75%)]\tLoss: 0.018717\n",
      "Train Epoch: 34 [11392/14860 (76%)]\tLoss: 0.013333\n",
      "Train Epoch: 34 [11520/14860 (77%)]\tLoss: 0.022075\n",
      "Train Epoch: 34 [11648/14860 (78%)]\tLoss: 0.019903\n",
      "Train Epoch: 34 [11776/14860 (79%)]\tLoss: 0.027333\n",
      "Train Epoch: 34 [11904/14860 (79%)]\tLoss: 0.018143\n",
      "Train Epoch: 34 [12032/14860 (80%)]\tLoss: 0.021609\n",
      "Train Epoch: 34 [12160/14860 (81%)]\tLoss: 0.018510\n",
      "Train Epoch: 34 [12288/14860 (82%)]\tLoss: 0.020106\n",
      "Train Epoch: 34 [12416/14860 (83%)]\tLoss: 0.024950\n",
      "Train Epoch: 34 [12544/14860 (84%)]\tLoss: 0.020604\n",
      "Train Epoch: 34 [12672/14860 (85%)]\tLoss: 0.024190\n",
      "Train Epoch: 34 [12800/14860 (85%)]\tLoss: 0.024496\n",
      "Train Epoch: 34 [12928/14860 (86%)]\tLoss: 0.020918\n",
      "Train Epoch: 34 [13056/14860 (87%)]\tLoss: 0.020275\n",
      "Train Epoch: 34 [13184/14860 (88%)]\tLoss: 0.020155\n",
      "Train Epoch: 34 [13312/14860 (89%)]\tLoss: 0.025070\n",
      "Train Epoch: 34 [13440/14860 (90%)]\tLoss: 0.032702\n",
      "Train Epoch: 34 [13568/14860 (91%)]\tLoss: 0.017404\n",
      "Train Epoch: 34 [13696/14860 (91%)]\tLoss: 0.026617\n",
      "Train Epoch: 34 [13824/14860 (92%)]\tLoss: 0.014961\n",
      "Train Epoch: 34 [13952/14860 (93%)]\tLoss: 0.016253\n",
      "Train Epoch: 34 [14080/14860 (94%)]\tLoss: 0.018028\n",
      "Train Epoch: 34 [14208/14860 (95%)]\tLoss: 0.024182\n",
      "Train Epoch: 34 [14336/14860 (96%)]\tLoss: 0.017927\n",
      "Train Epoch: 34 [14464/14860 (97%)]\tLoss: 0.015657\n",
      "Train Epoch: 34 [14592/14860 (97%)]\tLoss: 0.024645\n",
      "Train Epoch: 34 [14720/14860 (98%)]\tLoss: 0.025252\n",
      "Train Epoch: 34 [1392/14860 (99%)]\tLoss: 0.014200\n",
      "epoch 34 training loss: 0.021256450181588147\n",
      "epoch 34 validation loss: 0.02146825504649349\n",
      "Train Epoch: 35 [0/14860 (0%)]\tLoss: 0.018925\n",
      "Train Epoch: 35 [128/14860 (1%)]\tLoss: 0.017064\n",
      "Train Epoch: 35 [256/14860 (2%)]\tLoss: 0.017516\n",
      "Train Epoch: 35 [384/14860 (3%)]\tLoss: 0.022928\n",
      "Train Epoch: 35 [512/14860 (3%)]\tLoss: 0.018814\n",
      "Train Epoch: 35 [640/14860 (4%)]\tLoss: 0.024931\n",
      "Train Epoch: 35 [768/14860 (5%)]\tLoss: 0.023668\n",
      "Train Epoch: 35 [896/14860 (6%)]\tLoss: 0.018108\n",
      "Train Epoch: 35 [1024/14860 (7%)]\tLoss: 0.025788\n",
      "Train Epoch: 35 [1152/14860 (8%)]\tLoss: 0.016740\n",
      "Train Epoch: 35 [1280/14860 (9%)]\tLoss: 0.021948\n",
      "Train Epoch: 35 [1408/14860 (9%)]\tLoss: 0.024200\n",
      "Train Epoch: 35 [1536/14860 (10%)]\tLoss: 0.023837\n",
      "Train Epoch: 35 [1664/14860 (11%)]\tLoss: 0.024002\n",
      "Train Epoch: 35 [1792/14860 (12%)]\tLoss: 0.015415\n",
      "Train Epoch: 35 [1920/14860 (13%)]\tLoss: 0.021169\n",
      "Train Epoch: 35 [2048/14860 (14%)]\tLoss: 0.019198\n",
      "Train Epoch: 35 [2176/14860 (15%)]\tLoss: 0.018486\n",
      "Train Epoch: 35 [2304/14860 (15%)]\tLoss: 0.021202\n",
      "Train Epoch: 35 [2432/14860 (16%)]\tLoss: 0.015882\n",
      "Train Epoch: 35 [2560/14860 (17%)]\tLoss: 0.025274\n",
      "Train Epoch: 35 [2688/14860 (18%)]\tLoss: 0.023002\n",
      "Train Epoch: 35 [2816/14860 (19%)]\tLoss: 0.019745\n",
      "Train Epoch: 35 [2944/14860 (20%)]\tLoss: 0.019517\n",
      "Train Epoch: 35 [3072/14860 (21%)]\tLoss: 0.017452\n",
      "Train Epoch: 35 [3200/14860 (21%)]\tLoss: 0.019710\n",
      "Train Epoch: 35 [3328/14860 (22%)]\tLoss: 0.023598\n",
      "Train Epoch: 35 [3456/14860 (23%)]\tLoss: 0.015417\n",
      "Train Epoch: 35 [3584/14860 (24%)]\tLoss: 0.015251\n",
      "Train Epoch: 35 [3712/14860 (25%)]\tLoss: 0.021460\n",
      "Train Epoch: 35 [3840/14860 (26%)]\tLoss: 0.019407\n",
      "Train Epoch: 35 [3968/14860 (26%)]\tLoss: 0.024846\n",
      "Train Epoch: 35 [4096/14860 (27%)]\tLoss: 0.024162\n",
      "Train Epoch: 35 [4224/14860 (28%)]\tLoss: 0.022416\n",
      "Train Epoch: 35 [4352/14860 (29%)]\tLoss: 0.015475\n",
      "Train Epoch: 35 [4480/14860 (30%)]\tLoss: 0.022716\n",
      "Train Epoch: 35 [4608/14860 (31%)]\tLoss: 0.020971\n",
      "Train Epoch: 35 [4736/14860 (32%)]\tLoss: 0.017060\n",
      "Train Epoch: 35 [4864/14860 (32%)]\tLoss: 0.039577\n",
      "Train Epoch: 35 [4992/14860 (33%)]\tLoss: 0.021008\n",
      "Train Epoch: 35 [5120/14860 (34%)]\tLoss: 0.027965\n",
      "Train Epoch: 35 [5248/14860 (35%)]\tLoss: 0.023688\n",
      "Train Epoch: 35 [5376/14860 (36%)]\tLoss: 0.016941\n",
      "Train Epoch: 35 [5504/14860 (37%)]\tLoss: 0.021668\n",
      "Train Epoch: 35 [5632/14860 (38%)]\tLoss: 0.020538\n",
      "Train Epoch: 35 [5760/14860 (38%)]\tLoss: 0.024448\n",
      "Train Epoch: 35 [5888/14860 (39%)]\tLoss: 0.018323\n",
      "Train Epoch: 35 [6016/14860 (40%)]\tLoss: 0.020690\n",
      "Train Epoch: 35 [6144/14860 (41%)]\tLoss: 0.025691\n",
      "Train Epoch: 35 [6272/14860 (42%)]\tLoss: 0.026934\n",
      "Train Epoch: 35 [6400/14860 (43%)]\tLoss: 0.022594\n",
      "Train Epoch: 35 [6528/14860 (44%)]\tLoss: 0.028457\n",
      "Train Epoch: 35 [6656/14860 (44%)]\tLoss: 0.023009\n",
      "Train Epoch: 35 [6784/14860 (45%)]\tLoss: 0.018027\n",
      "Train Epoch: 35 [6912/14860 (46%)]\tLoss: 0.024302\n",
      "Train Epoch: 35 [7040/14860 (47%)]\tLoss: 0.019544\n",
      "Train Epoch: 35 [7168/14860 (48%)]\tLoss: 0.017706\n",
      "Train Epoch: 35 [7296/14860 (49%)]\tLoss: 0.022066\n",
      "Train Epoch: 35 [7424/14860 (50%)]\tLoss: 0.017012\n",
      "Train Epoch: 35 [7552/14860 (50%)]\tLoss: 0.024379\n",
      "Train Epoch: 35 [7680/14860 (51%)]\tLoss: 0.020641\n",
      "Train Epoch: 35 [7808/14860 (52%)]\tLoss: 0.018458\n",
      "Train Epoch: 35 [7936/14860 (53%)]\tLoss: 0.026799\n",
      "Train Epoch: 35 [8064/14860 (54%)]\tLoss: 0.024540\n",
      "Train Epoch: 35 [8192/14860 (55%)]\tLoss: 0.016595\n",
      "Train Epoch: 35 [8320/14860 (56%)]\tLoss: 0.021066\n",
      "Train Epoch: 35 [8448/14860 (56%)]\tLoss: 0.019991\n",
      "Train Epoch: 35 [8576/14860 (57%)]\tLoss: 0.014851\n",
      "Train Epoch: 35 [8704/14860 (58%)]\tLoss: 0.021678\n",
      "Train Epoch: 35 [8832/14860 (59%)]\tLoss: 0.021167\n",
      "Train Epoch: 35 [8960/14860 (60%)]\tLoss: 0.016098\n",
      "Train Epoch: 35 [9088/14860 (61%)]\tLoss: 0.018644\n",
      "Train Epoch: 35 [9216/14860 (62%)]\tLoss: 0.022837\n",
      "Train Epoch: 35 [9344/14860 (62%)]\tLoss: 0.023646\n",
      "Train Epoch: 35 [9472/14860 (63%)]\tLoss: 0.018676\n",
      "Train Epoch: 35 [9600/14860 (64%)]\tLoss: 0.018477\n",
      "Train Epoch: 35 [9728/14860 (65%)]\tLoss: 0.022348\n",
      "Train Epoch: 35 [9856/14860 (66%)]\tLoss: 0.023707\n",
      "Train Epoch: 35 [9984/14860 (67%)]\tLoss: 0.017957\n",
      "Train Epoch: 35 [10112/14860 (68%)]\tLoss: 0.023159\n",
      "Train Epoch: 35 [10240/14860 (68%)]\tLoss: 0.018144\n",
      "Train Epoch: 35 [10368/14860 (69%)]\tLoss: 0.021586\n",
      "Train Epoch: 35 [10496/14860 (70%)]\tLoss: 0.025068\n",
      "Train Epoch: 35 [10624/14860 (71%)]\tLoss: 0.020115\n",
      "Train Epoch: 35 [10752/14860 (72%)]\tLoss: 0.028833\n",
      "Train Epoch: 35 [10880/14860 (73%)]\tLoss: 0.026888\n",
      "Train Epoch: 35 [11008/14860 (74%)]\tLoss: 0.018824\n",
      "Train Epoch: 35 [11136/14860 (74%)]\tLoss: 0.028939\n",
      "Train Epoch: 35 [11264/14860 (75%)]\tLoss: 0.016668\n",
      "Train Epoch: 35 [11392/14860 (76%)]\tLoss: 0.019224\n",
      "Train Epoch: 35 [11520/14860 (77%)]\tLoss: 0.022692\n",
      "Train Epoch: 35 [11648/14860 (78%)]\tLoss: 0.018676\n",
      "Train Epoch: 35 [11776/14860 (79%)]\tLoss: 0.022194\n",
      "Train Epoch: 35 [11904/14860 (79%)]\tLoss: 0.018684\n",
      "Train Epoch: 35 [12032/14860 (80%)]\tLoss: 0.021626\n",
      "Train Epoch: 35 [12160/14860 (81%)]\tLoss: 0.023539\n",
      "Train Epoch: 35 [12288/14860 (82%)]\tLoss: 0.024396\n",
      "Train Epoch: 35 [12416/14860 (83%)]\tLoss: 0.028269\n",
      "Train Epoch: 35 [12544/14860 (84%)]\tLoss: 0.017423\n",
      "Train Epoch: 35 [12672/14860 (85%)]\tLoss: 0.023187\n",
      "Train Epoch: 35 [12800/14860 (85%)]\tLoss: 0.024006\n",
      "Train Epoch: 35 [12928/14860 (86%)]\tLoss: 0.027014\n",
      "Train Epoch: 35 [13056/14860 (87%)]\tLoss: 0.016860\n",
      "Train Epoch: 35 [13184/14860 (88%)]\tLoss: 0.030373\n",
      "Train Epoch: 35 [13312/14860 (89%)]\tLoss: 0.025660\n",
      "Train Epoch: 35 [13440/14860 (90%)]\tLoss: 0.019234\n",
      "Train Epoch: 35 [13568/14860 (91%)]\tLoss: 0.027092\n",
      "Train Epoch: 35 [13696/14860 (91%)]\tLoss: 0.017987\n",
      "Train Epoch: 35 [13824/14860 (92%)]\tLoss: 0.028188\n",
      "Train Epoch: 35 [13952/14860 (93%)]\tLoss: 0.018921\n",
      "Train Epoch: 35 [14080/14860 (94%)]\tLoss: 0.024471\n",
      "Train Epoch: 35 [14208/14860 (95%)]\tLoss: 0.026666\n",
      "Train Epoch: 35 [14336/14860 (96%)]\tLoss: 0.030584\n",
      "Train Epoch: 35 [14464/14860 (97%)]\tLoss: 0.024231\n",
      "Train Epoch: 35 [14592/14860 (97%)]\tLoss: 0.018214\n",
      "Train Epoch: 35 [14720/14860 (98%)]\tLoss: 0.029634\n",
      "Train Epoch: 35 [1392/14860 (99%)]\tLoss: 0.014312\n",
      "epoch 35 training loss: 0.02172330925320713\n",
      "epoch 35 validation loss: 0.026602002523713194\n",
      "Train Epoch: 36 [0/14860 (0%)]\tLoss: 0.033244\n",
      "Train Epoch: 36 [128/14860 (1%)]\tLoss: 0.022669\n",
      "Train Epoch: 36 [256/14860 (2%)]\tLoss: 0.022261\n",
      "Train Epoch: 36 [384/14860 (3%)]\tLoss: 0.020222\n",
      "Train Epoch: 36 [512/14860 (3%)]\tLoss: 0.019586\n",
      "Train Epoch: 36 [640/14860 (4%)]\tLoss: 0.024205\n",
      "Train Epoch: 36 [768/14860 (5%)]\tLoss: 0.015160\n",
      "Train Epoch: 36 [896/14860 (6%)]\tLoss: 0.016401\n",
      "Train Epoch: 36 [1024/14860 (7%)]\tLoss: 0.017378\n",
      "Train Epoch: 36 [1152/14860 (8%)]\tLoss: 0.014857\n",
      "Train Epoch: 36 [1280/14860 (9%)]\tLoss: 0.016707\n",
      "Train Epoch: 36 [1408/14860 (9%)]\tLoss: 0.020619\n",
      "Train Epoch: 36 [1536/14860 (10%)]\tLoss: 0.019889\n",
      "Train Epoch: 36 [1664/14860 (11%)]\tLoss: 0.021337\n",
      "Train Epoch: 36 [1792/14860 (12%)]\tLoss: 0.020035\n",
      "Train Epoch: 36 [1920/14860 (13%)]\tLoss: 0.014922\n",
      "Train Epoch: 36 [2048/14860 (14%)]\tLoss: 0.022847\n",
      "Train Epoch: 36 [2176/14860 (15%)]\tLoss: 0.015297\n",
      "Train Epoch: 36 [2304/14860 (15%)]\tLoss: 0.020818\n",
      "Train Epoch: 36 [2432/14860 (16%)]\tLoss: 0.025298\n",
      "Train Epoch: 36 [2560/14860 (17%)]\tLoss: 0.018105\n",
      "Train Epoch: 36 [2688/14860 (18%)]\tLoss: 0.018507\n",
      "Train Epoch: 36 [2816/14860 (19%)]\tLoss: 0.016980\n",
      "Train Epoch: 36 [2944/14860 (20%)]\tLoss: 0.018546\n",
      "Train Epoch: 36 [3072/14860 (21%)]\tLoss: 0.021705\n",
      "Train Epoch: 36 [3200/14860 (21%)]\tLoss: 0.018316\n",
      "Train Epoch: 36 [3328/14860 (22%)]\tLoss: 0.017145\n",
      "Train Epoch: 36 [3456/14860 (23%)]\tLoss: 0.020576\n",
      "Train Epoch: 36 [3584/14860 (24%)]\tLoss: 0.014043\n",
      "Train Epoch: 36 [3712/14860 (25%)]\tLoss: 0.015988\n",
      "Train Epoch: 36 [3840/14860 (26%)]\tLoss: 0.016138\n",
      "Train Epoch: 36 [3968/14860 (26%)]\tLoss: 0.017952\n",
      "Train Epoch: 36 [4096/14860 (27%)]\tLoss: 0.020635\n",
      "Train Epoch: 36 [4224/14860 (28%)]\tLoss: 0.022083\n",
      "Train Epoch: 36 [4352/14860 (29%)]\tLoss: 0.018357\n",
      "Train Epoch: 36 [4480/14860 (30%)]\tLoss: 0.025578\n",
      "Train Epoch: 36 [4608/14860 (31%)]\tLoss: 0.016910\n",
      "Train Epoch: 36 [4736/14860 (32%)]\tLoss: 0.019355\n",
      "Train Epoch: 36 [4864/14860 (32%)]\tLoss: 0.016386\n",
      "Train Epoch: 36 [4992/14860 (33%)]\tLoss: 0.024081\n",
      "Train Epoch: 36 [5120/14860 (34%)]\tLoss: 0.020420\n",
      "Train Epoch: 36 [5248/14860 (35%)]\tLoss: 0.014892\n",
      "Train Epoch: 36 [5376/14860 (36%)]\tLoss: 0.013789\n",
      "Train Epoch: 36 [5504/14860 (37%)]\tLoss: 0.016527\n",
      "Train Epoch: 36 [5632/14860 (38%)]\tLoss: 0.019139\n",
      "Train Epoch: 36 [5760/14860 (38%)]\tLoss: 0.025714\n",
      "Train Epoch: 36 [5888/14860 (39%)]\tLoss: 0.024229\n",
      "Train Epoch: 36 [6016/14860 (40%)]\tLoss: 0.023006\n",
      "Train Epoch: 36 [6144/14860 (41%)]\tLoss: 0.031261\n",
      "Train Epoch: 36 [6272/14860 (42%)]\tLoss: 0.017385\n",
      "Train Epoch: 36 [6400/14860 (43%)]\tLoss: 0.046071\n",
      "Train Epoch: 36 [6528/14860 (44%)]\tLoss: 0.031347\n",
      "Train Epoch: 36 [6656/14860 (44%)]\tLoss: 0.045423\n",
      "Train Epoch: 36 [6784/14860 (45%)]\tLoss: 0.032931\n",
      "Train Epoch: 36 [6912/14860 (46%)]\tLoss: 0.031340\n",
      "Train Epoch: 36 [7040/14860 (47%)]\tLoss: 0.025804\n",
      "Train Epoch: 36 [7168/14860 (48%)]\tLoss: 0.031187\n",
      "Train Epoch: 36 [7296/14860 (49%)]\tLoss: 0.022704\n",
      "Train Epoch: 36 [7424/14860 (50%)]\tLoss: 0.040319\n",
      "Train Epoch: 36 [7552/14860 (50%)]\tLoss: 0.019933\n",
      "Train Epoch: 36 [7680/14860 (51%)]\tLoss: 0.028642\n",
      "Train Epoch: 36 [7808/14860 (52%)]\tLoss: 0.011989\n",
      "Train Epoch: 36 [7936/14860 (53%)]\tLoss: 0.031395\n",
      "Train Epoch: 36 [8064/14860 (54%)]\tLoss: 0.021299\n",
      "Train Epoch: 36 [8192/14860 (55%)]\tLoss: 0.023808\n",
      "Train Epoch: 36 [8320/14860 (56%)]\tLoss: 0.026849\n",
      "Train Epoch: 36 [8448/14860 (56%)]\tLoss: 0.017740\n",
      "Train Epoch: 36 [8576/14860 (57%)]\tLoss: 0.025094\n",
      "Train Epoch: 36 [8704/14860 (58%)]\tLoss: 0.019157\n",
      "Train Epoch: 36 [8832/14860 (59%)]\tLoss: 0.026286\n",
      "Train Epoch: 36 [8960/14860 (60%)]\tLoss: 0.018376\n",
      "Train Epoch: 36 [9088/14860 (61%)]\tLoss: 0.032410\n",
      "Train Epoch: 36 [9216/14860 (62%)]\tLoss: 0.019978\n",
      "Train Epoch: 36 [9344/14860 (62%)]\tLoss: 0.018016\n",
      "Train Epoch: 36 [9472/14860 (63%)]\tLoss: 0.022265\n",
      "Train Epoch: 36 [9600/14860 (64%)]\tLoss: 0.019147\n",
      "Train Epoch: 36 [9728/14860 (65%)]\tLoss: 0.013680\n",
      "Train Epoch: 36 [9856/14860 (66%)]\tLoss: 0.020622\n",
      "Train Epoch: 36 [9984/14860 (67%)]\tLoss: 0.022174\n",
      "Train Epoch: 36 [10112/14860 (68%)]\tLoss: 0.027601\n",
      "Train Epoch: 36 [10240/14860 (68%)]\tLoss: 0.021148\n",
      "Train Epoch: 36 [10368/14860 (69%)]\tLoss: 0.021635\n",
      "Train Epoch: 36 [10496/14860 (70%)]\tLoss: 0.029450\n",
      "Train Epoch: 36 [10624/14860 (71%)]\tLoss: 0.018730\n",
      "Train Epoch: 36 [10752/14860 (72%)]\tLoss: 0.028219\n",
      "Train Epoch: 36 [10880/14860 (73%)]\tLoss: 0.015831\n",
      "Train Epoch: 36 [11008/14860 (74%)]\tLoss: 0.030394\n",
      "Train Epoch: 36 [11136/14860 (74%)]\tLoss: 0.023770\n",
      "Train Epoch: 36 [11264/14860 (75%)]\tLoss: 0.023612\n",
      "Train Epoch: 36 [11392/14860 (76%)]\tLoss: 0.021214\n",
      "Train Epoch: 36 [11520/14860 (77%)]\tLoss: 0.025005\n",
      "Train Epoch: 36 [11648/14860 (78%)]\tLoss: 0.017700\n",
      "Train Epoch: 36 [11776/14860 (79%)]\tLoss: 0.016869\n",
      "Train Epoch: 36 [11904/14860 (79%)]\tLoss: 0.021343\n",
      "Train Epoch: 36 [12032/14860 (80%)]\tLoss: 0.029324\n",
      "Train Epoch: 36 [12160/14860 (81%)]\tLoss: 0.027645\n",
      "Train Epoch: 36 [12288/14860 (82%)]\tLoss: 0.012956\n",
      "Train Epoch: 36 [12416/14860 (83%)]\tLoss: 0.023027\n",
      "Train Epoch: 36 [12544/14860 (84%)]\tLoss: 0.019871\n",
      "Train Epoch: 36 [12672/14860 (85%)]\tLoss: 0.015063\n",
      "Train Epoch: 36 [12800/14860 (85%)]\tLoss: 0.021109\n",
      "Train Epoch: 36 [12928/14860 (86%)]\tLoss: 0.025357\n",
      "Train Epoch: 36 [13056/14860 (87%)]\tLoss: 0.024079\n",
      "Train Epoch: 36 [13184/14860 (88%)]\tLoss: 0.022772\n",
      "Train Epoch: 36 [13312/14860 (89%)]\tLoss: 0.016687\n",
      "Train Epoch: 36 [13440/14860 (90%)]\tLoss: 0.022046\n",
      "Train Epoch: 36 [13568/14860 (91%)]\tLoss: 0.013881\n",
      "Train Epoch: 36 [13696/14860 (91%)]\tLoss: 0.020867\n",
      "Train Epoch: 36 [13824/14860 (92%)]\tLoss: 0.019698\n",
      "Train Epoch: 36 [13952/14860 (93%)]\tLoss: 0.019287\n",
      "Train Epoch: 36 [14080/14860 (94%)]\tLoss: 0.024843\n",
      "Train Epoch: 36 [14208/14860 (95%)]\tLoss: 0.027747\n",
      "Train Epoch: 36 [14336/14860 (96%)]\tLoss: 0.018194\n",
      "Train Epoch: 36 [14464/14860 (97%)]\tLoss: 0.024120\n",
      "Train Epoch: 36 [14592/14860 (97%)]\tLoss: 0.024222\n",
      "Train Epoch: 36 [14720/14860 (98%)]\tLoss: 0.026311\n",
      "Train Epoch: 36 [1392/14860 (99%)]\tLoss: 0.026272\n",
      "epoch 36 training loss: 0.02206309715238137\n",
      "epoch 36 validation loss: 0.031443152531584584\n",
      "Train Epoch: 37 [0/14860 (0%)]\tLoss: 0.027748\n",
      "Train Epoch: 37 [128/14860 (1%)]\tLoss: 0.021748\n",
      "Train Epoch: 37 [256/14860 (2%)]\tLoss: 0.015200\n",
      "Train Epoch: 37 [384/14860 (3%)]\tLoss: 0.021853\n",
      "Train Epoch: 37 [512/14860 (3%)]\tLoss: 0.023791\n",
      "Train Epoch: 37 [640/14860 (4%)]\tLoss: 0.027601\n",
      "Train Epoch: 37 [768/14860 (5%)]\tLoss: 0.027098\n",
      "Train Epoch: 37 [896/14860 (6%)]\tLoss: 0.024930\n",
      "Train Epoch: 37 [1024/14860 (7%)]\tLoss: 0.022446\n",
      "Train Epoch: 37 [1152/14860 (8%)]\tLoss: 0.028658\n",
      "Train Epoch: 37 [1280/14860 (9%)]\tLoss: 0.023551\n",
      "Train Epoch: 37 [1408/14860 (9%)]\tLoss: 0.017258\n",
      "Train Epoch: 37 [1536/14860 (10%)]\tLoss: 0.020028\n",
      "Train Epoch: 37 [1664/14860 (11%)]\tLoss: 0.021966\n",
      "Train Epoch: 37 [1792/14860 (12%)]\tLoss: 0.018071\n",
      "Train Epoch: 37 [1920/14860 (13%)]\tLoss: 0.015131\n",
      "Train Epoch: 37 [2048/14860 (14%)]\tLoss: 0.021989\n",
      "Train Epoch: 37 [2176/14860 (15%)]\tLoss: 0.017551\n",
      "Train Epoch: 37 [2304/14860 (15%)]\tLoss: 0.020276\n",
      "Train Epoch: 37 [2432/14860 (16%)]\tLoss: 0.020298\n",
      "Train Epoch: 37 [2560/14860 (17%)]\tLoss: 0.015473\n",
      "Train Epoch: 37 [2688/14860 (18%)]\tLoss: 0.020433\n",
      "Train Epoch: 37 [2816/14860 (19%)]\tLoss: 0.020421\n",
      "Train Epoch: 37 [2944/14860 (20%)]\tLoss: 0.021297\n",
      "Train Epoch: 37 [3072/14860 (21%)]\tLoss: 0.024461\n",
      "Train Epoch: 37 [3200/14860 (21%)]\tLoss: 0.015058\n",
      "Train Epoch: 37 [3328/14860 (22%)]\tLoss: 0.019644\n",
      "Train Epoch: 37 [3456/14860 (23%)]\tLoss: 0.030017\n",
      "Train Epoch: 37 [3584/14860 (24%)]\tLoss: 0.021570\n",
      "Train Epoch: 37 [3712/14860 (25%)]\tLoss: 0.022689\n",
      "Train Epoch: 37 [3840/14860 (26%)]\tLoss: 0.023624\n",
      "Train Epoch: 37 [3968/14860 (26%)]\tLoss: 0.018395\n",
      "Train Epoch: 37 [4096/14860 (27%)]\tLoss: 0.017970\n",
      "Train Epoch: 37 [4224/14860 (28%)]\tLoss: 0.019424\n",
      "Train Epoch: 37 [4352/14860 (29%)]\tLoss: 0.025126\n",
      "Train Epoch: 37 [4480/14860 (30%)]\tLoss: 0.018666\n",
      "Train Epoch: 37 [4608/14860 (31%)]\tLoss: 0.023972\n",
      "Train Epoch: 37 [4736/14860 (32%)]\tLoss: 0.020613\n",
      "Train Epoch: 37 [4864/14860 (32%)]\tLoss: 0.033489\n",
      "Train Epoch: 37 [4992/14860 (33%)]\tLoss: 0.013793\n",
      "Train Epoch: 37 [5120/14860 (34%)]\tLoss: 0.017502\n",
      "Train Epoch: 37 [5248/14860 (35%)]\tLoss: 0.024317\n",
      "Train Epoch: 37 [5376/14860 (36%)]\tLoss: 0.029177\n",
      "Train Epoch: 37 [5504/14860 (37%)]\tLoss: 0.021245\n",
      "Train Epoch: 37 [5632/14860 (38%)]\tLoss: 0.022582\n",
      "Train Epoch: 37 [5760/14860 (38%)]\tLoss: 0.018965\n",
      "Train Epoch: 37 [5888/14860 (39%)]\tLoss: 0.016331\n",
      "Train Epoch: 37 [6016/14860 (40%)]\tLoss: 0.026811\n",
      "Train Epoch: 37 [6144/14860 (41%)]\tLoss: 0.012931\n",
      "Train Epoch: 37 [6272/14860 (42%)]\tLoss: 0.026008\n",
      "Train Epoch: 37 [6400/14860 (43%)]\tLoss: 0.012366\n",
      "Train Epoch: 37 [6528/14860 (44%)]\tLoss: 0.021890\n",
      "Train Epoch: 37 [6656/14860 (44%)]\tLoss: 0.012669\n",
      "Train Epoch: 37 [6784/14860 (45%)]\tLoss: 0.024741\n",
      "Train Epoch: 37 [6912/14860 (46%)]\tLoss: 0.021919\n",
      "Train Epoch: 37 [7040/14860 (47%)]\tLoss: 0.017122\n",
      "Train Epoch: 37 [7168/14860 (48%)]\tLoss: 0.017933\n",
      "Train Epoch: 37 [7296/14860 (49%)]\tLoss: 0.017404\n",
      "Train Epoch: 37 [7424/14860 (50%)]\tLoss: 0.021762\n",
      "Train Epoch: 37 [7552/14860 (50%)]\tLoss: 0.026652\n",
      "Train Epoch: 37 [7680/14860 (51%)]\tLoss: 0.020991\n",
      "Train Epoch: 37 [7808/14860 (52%)]\tLoss: 0.020952\n",
      "Train Epoch: 37 [7936/14860 (53%)]\tLoss: 0.016158\n",
      "Train Epoch: 37 [8064/14860 (54%)]\tLoss: 0.023552\n",
      "Train Epoch: 37 [8192/14860 (55%)]\tLoss: 0.021498\n",
      "Train Epoch: 37 [8320/14860 (56%)]\tLoss: 0.019631\n",
      "Train Epoch: 37 [8448/14860 (56%)]\tLoss: 0.020045\n",
      "Train Epoch: 37 [8576/14860 (57%)]\tLoss: 0.030526\n",
      "Train Epoch: 37 [8704/14860 (58%)]\tLoss: 0.024390\n",
      "Train Epoch: 37 [8832/14860 (59%)]\tLoss: 0.022445\n",
      "Train Epoch: 37 [8960/14860 (60%)]\tLoss: 0.025528\n",
      "Train Epoch: 37 [9088/14860 (61%)]\tLoss: 0.015735\n",
      "Train Epoch: 37 [9216/14860 (62%)]\tLoss: 0.017187\n",
      "Train Epoch: 37 [9344/14860 (62%)]\tLoss: 0.013788\n",
      "Train Epoch: 37 [9472/14860 (63%)]\tLoss: 0.016211\n",
      "Train Epoch: 37 [9600/14860 (64%)]\tLoss: 0.018408\n",
      "Train Epoch: 37 [9728/14860 (65%)]\tLoss: 0.029950\n",
      "Train Epoch: 37 [9856/14860 (66%)]\tLoss: 0.020623\n",
      "Train Epoch: 37 [9984/14860 (67%)]\tLoss: 0.012424\n",
      "Train Epoch: 37 [10112/14860 (68%)]\tLoss: 0.019386\n",
      "Train Epoch: 37 [10240/14860 (68%)]\tLoss: 0.017785\n",
      "Train Epoch: 37 [10368/14860 (69%)]\tLoss: 0.014713\n",
      "Train Epoch: 37 [10496/14860 (70%)]\tLoss: 0.018909\n",
      "Train Epoch: 37 [10624/14860 (71%)]\tLoss: 0.016079\n",
      "Train Epoch: 37 [10752/14860 (72%)]\tLoss: 0.014505\n",
      "Train Epoch: 37 [10880/14860 (73%)]\tLoss: 0.016771\n",
      "Train Epoch: 37 [11008/14860 (74%)]\tLoss: 0.019796\n",
      "Train Epoch: 37 [11136/14860 (74%)]\tLoss: 0.020817\n",
      "Train Epoch: 37 [11264/14860 (75%)]\tLoss: 0.035367\n",
      "Train Epoch: 37 [11392/14860 (76%)]\tLoss: 0.025107\n",
      "Train Epoch: 37 [11520/14860 (77%)]\tLoss: 0.029978\n",
      "Train Epoch: 37 [11648/14860 (78%)]\tLoss: 0.016267\n",
      "Train Epoch: 37 [11776/14860 (79%)]\tLoss: 0.038969\n",
      "Train Epoch: 37 [11904/14860 (79%)]\tLoss: 0.021398\n",
      "Train Epoch: 37 [12032/14860 (80%)]\tLoss: 0.025119\n",
      "Train Epoch: 37 [12160/14860 (81%)]\tLoss: 0.029901\n",
      "Train Epoch: 37 [12288/14860 (82%)]\tLoss: 0.031765\n",
      "Train Epoch: 37 [12416/14860 (83%)]\tLoss: 0.023910\n",
      "Train Epoch: 37 [12544/14860 (84%)]\tLoss: 0.021255\n",
      "Train Epoch: 37 [12672/14860 (85%)]\tLoss: 0.026404\n",
      "Train Epoch: 37 [12800/14860 (85%)]\tLoss: 0.021909\n",
      "Train Epoch: 37 [12928/14860 (86%)]\tLoss: 0.022843\n",
      "Train Epoch: 37 [13056/14860 (87%)]\tLoss: 0.028948\n",
      "Train Epoch: 37 [13184/14860 (88%)]\tLoss: 0.022037\n",
      "Train Epoch: 37 [13312/14860 (89%)]\tLoss: 0.027374\n",
      "Train Epoch: 37 [13440/14860 (90%)]\tLoss: 0.022233\n",
      "Train Epoch: 37 [13568/14860 (91%)]\tLoss: 0.015346\n",
      "Train Epoch: 37 [13696/14860 (91%)]\tLoss: 0.025154\n",
      "Train Epoch: 37 [13824/14860 (92%)]\tLoss: 0.019122\n",
      "Train Epoch: 37 [13952/14860 (93%)]\tLoss: 0.016501\n",
      "Train Epoch: 37 [14080/14860 (94%)]\tLoss: 0.022685\n",
      "Train Epoch: 37 [14208/14860 (95%)]\tLoss: 0.025842\n",
      "Train Epoch: 37 [14336/14860 (96%)]\tLoss: 0.014472\n",
      "Train Epoch: 37 [14464/14860 (97%)]\tLoss: 0.033846\n",
      "Train Epoch: 37 [14592/14860 (97%)]\tLoss: 0.017579\n",
      "Train Epoch: 37 [14720/14860 (98%)]\tLoss: 0.023323\n",
      "Train Epoch: 37 [1392/14860 (99%)]\tLoss: 0.047999\n",
      "epoch 37 training loss: 0.021838514818849727\n",
      "epoch 37 validation loss: 0.03853532693576582\n",
      "Train Epoch: 38 [0/14860 (0%)]\tLoss: 0.045021\n",
      "Train Epoch: 38 [128/14860 (1%)]\tLoss: 0.020285\n",
      "Train Epoch: 38 [256/14860 (2%)]\tLoss: 0.035402\n",
      "Train Epoch: 38 [384/14860 (3%)]\tLoss: 0.029061\n",
      "Train Epoch: 38 [512/14860 (3%)]\tLoss: 0.025106\n",
      "Train Epoch: 38 [640/14860 (4%)]\tLoss: 0.018751\n",
      "Train Epoch: 38 [768/14860 (5%)]\tLoss: 0.016854\n",
      "Train Epoch: 38 [896/14860 (6%)]\tLoss: 0.021382\n",
      "Train Epoch: 38 [1024/14860 (7%)]\tLoss: 0.018558\n",
      "Train Epoch: 38 [1152/14860 (8%)]\tLoss: 0.018335\n",
      "Train Epoch: 38 [1280/14860 (9%)]\tLoss: 0.033247\n",
      "Train Epoch: 38 [1408/14860 (9%)]\tLoss: 0.021732\n",
      "Train Epoch: 38 [1536/14860 (10%)]\tLoss: 0.029321\n",
      "Train Epoch: 38 [1664/14860 (11%)]\tLoss: 0.017473\n",
      "Train Epoch: 38 [1792/14860 (12%)]\tLoss: 0.027320\n",
      "Train Epoch: 38 [1920/14860 (13%)]\tLoss: 0.019381\n",
      "Train Epoch: 38 [2048/14860 (14%)]\tLoss: 0.021604\n",
      "Train Epoch: 38 [2176/14860 (15%)]\tLoss: 0.019874\n",
      "Train Epoch: 38 [2304/14860 (15%)]\tLoss: 0.028018\n",
      "Train Epoch: 38 [2432/14860 (16%)]\tLoss: 0.027366\n",
      "Train Epoch: 38 [2560/14860 (17%)]\tLoss: 0.024083\n",
      "Train Epoch: 38 [2688/14860 (18%)]\tLoss: 0.026185\n",
      "Train Epoch: 38 [2816/14860 (19%)]\tLoss: 0.020154\n",
      "Train Epoch: 38 [2944/14860 (20%)]\tLoss: 0.023446\n",
      "Train Epoch: 38 [3072/14860 (21%)]\tLoss: 0.016195\n",
      "Train Epoch: 38 [3200/14860 (21%)]\tLoss: 0.021729\n",
      "Train Epoch: 38 [3328/14860 (22%)]\tLoss: 0.015716\n",
      "Train Epoch: 38 [3456/14860 (23%)]\tLoss: 0.018655\n",
      "Train Epoch: 38 [3584/14860 (24%)]\tLoss: 0.020684\n",
      "Train Epoch: 38 [3712/14860 (25%)]\tLoss: 0.030727\n",
      "Train Epoch: 38 [3840/14860 (26%)]\tLoss: 0.026365\n",
      "Train Epoch: 38 [3968/14860 (26%)]\tLoss: 0.015409\n",
      "Train Epoch: 38 [4096/14860 (27%)]\tLoss: 0.015444\n",
      "Train Epoch: 38 [4224/14860 (28%)]\tLoss: 0.019849\n",
      "Train Epoch: 38 [4352/14860 (29%)]\tLoss: 0.018880\n",
      "Train Epoch: 38 [4480/14860 (30%)]\tLoss: 0.031940\n",
      "Train Epoch: 38 [4608/14860 (31%)]\tLoss: 0.022465\n",
      "Train Epoch: 38 [4736/14860 (32%)]\tLoss: 0.021150\n",
      "Train Epoch: 38 [4864/14860 (32%)]\tLoss: 0.029763\n",
      "Train Epoch: 38 [4992/14860 (33%)]\tLoss: 0.020110\n",
      "Train Epoch: 38 [5120/14860 (34%)]\tLoss: 0.037579\n",
      "Train Epoch: 38 [5248/14860 (35%)]\tLoss: 0.020231\n",
      "Train Epoch: 38 [5376/14860 (36%)]\tLoss: 0.026522\n",
      "Train Epoch: 38 [5504/14860 (37%)]\tLoss: 0.015805\n",
      "Train Epoch: 38 [5632/14860 (38%)]\tLoss: 0.020850\n",
      "Train Epoch: 38 [5760/14860 (38%)]\tLoss: 0.036198\n",
      "Train Epoch: 38 [5888/14860 (39%)]\tLoss: 0.026128\n",
      "Train Epoch: 38 [6016/14860 (40%)]\tLoss: 0.017055\n",
      "Train Epoch: 38 [6144/14860 (41%)]\tLoss: 0.032352\n",
      "Train Epoch: 38 [6272/14860 (42%)]\tLoss: 0.027063\n",
      "Train Epoch: 38 [6400/14860 (43%)]\tLoss: 0.041698\n",
      "Train Epoch: 38 [6528/14860 (44%)]\tLoss: 0.024736\n",
      "Train Epoch: 38 [6656/14860 (44%)]\tLoss: 0.020209\n",
      "Train Epoch: 38 [6784/14860 (45%)]\tLoss: 0.031733\n",
      "Train Epoch: 38 [6912/14860 (46%)]\tLoss: 0.022779\n",
      "Train Epoch: 38 [7040/14860 (47%)]\tLoss: 0.031718\n",
      "Train Epoch: 38 [7168/14860 (48%)]\tLoss: 0.025777\n",
      "Train Epoch: 38 [7296/14860 (49%)]\tLoss: 0.022296\n",
      "Train Epoch: 38 [7424/14860 (50%)]\tLoss: 0.025340\n",
      "Train Epoch: 38 [7552/14860 (50%)]\tLoss: 0.017603\n",
      "Train Epoch: 38 [7680/14860 (51%)]\tLoss: 0.022673\n",
      "Train Epoch: 38 [7808/14860 (52%)]\tLoss: 0.017421\n",
      "Train Epoch: 38 [7936/14860 (53%)]\tLoss: 0.021315\n",
      "Train Epoch: 38 [8064/14860 (54%)]\tLoss: 0.018145\n",
      "Train Epoch: 38 [8192/14860 (55%)]\tLoss: 0.015336\n",
      "Train Epoch: 38 [8320/14860 (56%)]\tLoss: 0.021080\n",
      "Train Epoch: 38 [8448/14860 (56%)]\tLoss: 0.013628\n",
      "Train Epoch: 38 [8576/14860 (57%)]\tLoss: 0.019145\n",
      "Train Epoch: 38 [8704/14860 (58%)]\tLoss: 0.022674\n",
      "Train Epoch: 38 [8832/14860 (59%)]\tLoss: 0.018870\n",
      "Train Epoch: 38 [8960/14860 (60%)]\tLoss: 0.019957\n",
      "Train Epoch: 38 [9088/14860 (61%)]\tLoss: 0.022730\n",
      "Train Epoch: 38 [9216/14860 (62%)]\tLoss: 0.018164\n",
      "Train Epoch: 38 [9344/14860 (62%)]\tLoss: 0.014919\n",
      "Train Epoch: 38 [9472/14860 (63%)]\tLoss: 0.021501\n",
      "Train Epoch: 38 [9600/14860 (64%)]\tLoss: 0.017138\n",
      "Train Epoch: 38 [9728/14860 (65%)]\tLoss: 0.019067\n",
      "Train Epoch: 38 [9856/14860 (66%)]\tLoss: 0.023192\n",
      "Train Epoch: 38 [9984/14860 (67%)]\tLoss: 0.022861\n",
      "Train Epoch: 38 [10112/14860 (68%)]\tLoss: 0.017642\n",
      "Train Epoch: 38 [10240/14860 (68%)]\tLoss: 0.022474\n",
      "Train Epoch: 38 [10368/14860 (69%)]\tLoss: 0.029529\n",
      "Train Epoch: 38 [10496/14860 (70%)]\tLoss: 0.029649\n",
      "Train Epoch: 38 [10624/14860 (71%)]\tLoss: 0.030028\n",
      "Train Epoch: 38 [10752/14860 (72%)]\tLoss: 0.019591\n",
      "Train Epoch: 38 [10880/14860 (73%)]\tLoss: 0.020612\n",
      "Train Epoch: 38 [11008/14860 (74%)]\tLoss: 0.024547\n",
      "Train Epoch: 38 [11136/14860 (74%)]\tLoss: 0.015734\n",
      "Train Epoch: 38 [11264/14860 (75%)]\tLoss: 0.014184\n",
      "Train Epoch: 38 [11392/14860 (76%)]\tLoss: 0.039613\n",
      "Train Epoch: 38 [11520/14860 (77%)]\tLoss: 0.014374\n",
      "Train Epoch: 38 [11648/14860 (78%)]\tLoss: 0.027540\n",
      "Train Epoch: 38 [11776/14860 (79%)]\tLoss: 0.021921\n",
      "Train Epoch: 38 [11904/14860 (79%)]\tLoss: 0.016742\n",
      "Train Epoch: 38 [12032/14860 (80%)]\tLoss: 0.017776\n",
      "Train Epoch: 38 [12160/14860 (81%)]\tLoss: 0.018319\n",
      "Train Epoch: 38 [12288/14860 (82%)]\tLoss: 0.023239\n",
      "Train Epoch: 38 [12416/14860 (83%)]\tLoss: 0.021645\n",
      "Train Epoch: 38 [12544/14860 (84%)]\tLoss: 0.025659\n",
      "Train Epoch: 38 [12672/14860 (85%)]\tLoss: 0.021921\n",
      "Train Epoch: 38 [12800/14860 (85%)]\tLoss: 0.019482\n",
      "Train Epoch: 38 [12928/14860 (86%)]\tLoss: 0.019765\n",
      "Train Epoch: 38 [13056/14860 (87%)]\tLoss: 0.021624\n",
      "Train Epoch: 38 [13184/14860 (88%)]\tLoss: 0.021709\n",
      "Train Epoch: 38 [13312/14860 (89%)]\tLoss: 0.025088\n",
      "Train Epoch: 38 [13440/14860 (90%)]\tLoss: 0.021470\n",
      "Train Epoch: 38 [13568/14860 (91%)]\tLoss: 0.018563\n",
      "Train Epoch: 38 [13696/14860 (91%)]\tLoss: 0.014371\n",
      "Train Epoch: 38 [13824/14860 (92%)]\tLoss: 0.017585\n",
      "Train Epoch: 38 [13952/14860 (93%)]\tLoss: 0.019014\n",
      "Train Epoch: 38 [14080/14860 (94%)]\tLoss: 0.021495\n",
      "Train Epoch: 38 [14208/14860 (95%)]\tLoss: 0.011896\n",
      "Train Epoch: 38 [14336/14860 (96%)]\tLoss: 0.014917\n",
      "Train Epoch: 38 [14464/14860 (97%)]\tLoss: 0.017739\n",
      "Train Epoch: 38 [14592/14860 (97%)]\tLoss: 0.017424\n",
      "Train Epoch: 38 [14720/14860 (98%)]\tLoss: 0.022711\n",
      "Train Epoch: 38 [1392/14860 (99%)]\tLoss: 0.026678\n",
      "epoch 38 training loss: 0.02248548258605421\n",
      "epoch 38 validation loss: 0.020984441691391693\n",
      "Train Epoch: 39 [0/14860 (0%)]\tLoss: 0.023199\n",
      "Train Epoch: 39 [128/14860 (1%)]\tLoss: 0.018199\n",
      "Train Epoch: 39 [256/14860 (2%)]\tLoss: 0.021301\n",
      "Train Epoch: 39 [384/14860 (3%)]\tLoss: 0.015363\n",
      "Train Epoch: 39 [512/14860 (3%)]\tLoss: 0.018943\n",
      "Train Epoch: 39 [640/14860 (4%)]\tLoss: 0.016524\n",
      "Train Epoch: 39 [768/14860 (5%)]\tLoss: 0.025544\n",
      "Train Epoch: 39 [896/14860 (6%)]\tLoss: 0.018840\n",
      "Train Epoch: 39 [1024/14860 (7%)]\tLoss: 0.016592\n",
      "Train Epoch: 39 [1152/14860 (8%)]\tLoss: 0.014653\n",
      "Train Epoch: 39 [1280/14860 (9%)]\tLoss: 0.013458\n",
      "Train Epoch: 39 [1408/14860 (9%)]\tLoss: 0.030799\n",
      "Train Epoch: 39 [1536/14860 (10%)]\tLoss: 0.022928\n",
      "Train Epoch: 39 [1664/14860 (11%)]\tLoss: 0.019321\n",
      "Train Epoch: 39 [1792/14860 (12%)]\tLoss: 0.013084\n",
      "Train Epoch: 39 [1920/14860 (13%)]\tLoss: 0.017366\n",
      "Train Epoch: 39 [2048/14860 (14%)]\tLoss: 0.018511\n",
      "Train Epoch: 39 [2176/14860 (15%)]\tLoss: 0.018476\n",
      "Train Epoch: 39 [2304/14860 (15%)]\tLoss: 0.011002\n",
      "Train Epoch: 39 [2432/14860 (16%)]\tLoss: 0.023684\n",
      "Train Epoch: 39 [2560/14860 (17%)]\tLoss: 0.020636\n",
      "Train Epoch: 39 [2688/14860 (18%)]\tLoss: 0.025342\n",
      "Train Epoch: 39 [2816/14860 (19%)]\tLoss: 0.019452\n",
      "Train Epoch: 39 [2944/14860 (20%)]\tLoss: 0.023079\n",
      "Train Epoch: 39 [3072/14860 (21%)]\tLoss: 0.022320\n",
      "Train Epoch: 39 [3200/14860 (21%)]\tLoss: 0.030481\n",
      "Train Epoch: 39 [3328/14860 (22%)]\tLoss: 0.022378\n",
      "Train Epoch: 39 [3456/14860 (23%)]\tLoss: 0.026351\n",
      "Train Epoch: 39 [3584/14860 (24%)]\tLoss: 0.018172\n",
      "Train Epoch: 39 [3712/14860 (25%)]\tLoss: 0.011790\n",
      "Train Epoch: 39 [3840/14860 (26%)]\tLoss: 0.017393\n",
      "Train Epoch: 39 [3968/14860 (26%)]\tLoss: 0.016940\n",
      "Train Epoch: 39 [4096/14860 (27%)]\tLoss: 0.017259\n",
      "Train Epoch: 39 [4224/14860 (28%)]\tLoss: 0.016017\n",
      "Train Epoch: 39 [4352/14860 (29%)]\tLoss: 0.023869\n",
      "Train Epoch: 39 [4480/14860 (30%)]\tLoss: 0.016143\n",
      "Train Epoch: 39 [4608/14860 (31%)]\tLoss: 0.018690\n",
      "Train Epoch: 39 [4736/14860 (32%)]\tLoss: 0.019932\n",
      "Train Epoch: 39 [4864/14860 (32%)]\tLoss: 0.032632\n",
      "Train Epoch: 39 [4992/14860 (33%)]\tLoss: 0.023449\n",
      "Train Epoch: 39 [5120/14860 (34%)]\tLoss: 0.024963\n",
      "Train Epoch: 39 [5248/14860 (35%)]\tLoss: 0.021748\n",
      "Train Epoch: 39 [5376/14860 (36%)]\tLoss: 0.021454\n",
      "Train Epoch: 39 [5504/14860 (37%)]\tLoss: 0.027030\n",
      "Train Epoch: 39 [5632/14860 (38%)]\tLoss: 0.029171\n",
      "Train Epoch: 39 [5760/14860 (38%)]\tLoss: 0.044822\n",
      "Train Epoch: 39 [5888/14860 (39%)]\tLoss: 0.022166\n",
      "Train Epoch: 39 [6016/14860 (40%)]\tLoss: 0.031668\n",
      "Train Epoch: 39 [6144/14860 (41%)]\tLoss: 0.018749\n",
      "Train Epoch: 39 [6272/14860 (42%)]\tLoss: 0.032387\n",
      "Train Epoch: 39 [6400/14860 (43%)]\tLoss: 0.021641\n",
      "Train Epoch: 39 [6528/14860 (44%)]\tLoss: 0.028087\n",
      "Train Epoch: 39 [6656/14860 (44%)]\tLoss: 0.017706\n",
      "Train Epoch: 39 [6784/14860 (45%)]\tLoss: 0.025444\n",
      "Train Epoch: 39 [6912/14860 (46%)]\tLoss: 0.027336\n",
      "Train Epoch: 39 [7040/14860 (47%)]\tLoss: 0.033511\n",
      "Train Epoch: 39 [7168/14860 (48%)]\tLoss: 0.020125\n",
      "Train Epoch: 39 [7296/14860 (49%)]\tLoss: 0.028187\n",
      "Train Epoch: 39 [7424/14860 (50%)]\tLoss: 0.025806\n",
      "Train Epoch: 39 [7552/14860 (50%)]\tLoss: 0.017191\n",
      "Train Epoch: 39 [7680/14860 (51%)]\tLoss: 0.026692\n",
      "Train Epoch: 39 [7808/14860 (52%)]\tLoss: 0.024152\n",
      "Train Epoch: 39 [7936/14860 (53%)]\tLoss: 0.024874\n",
      "Train Epoch: 39 [8064/14860 (54%)]\tLoss: 0.014708\n",
      "Train Epoch: 39 [8192/14860 (55%)]\tLoss: 0.014333\n",
      "Train Epoch: 39 [8320/14860 (56%)]\tLoss: 0.018350\n",
      "Train Epoch: 39 [8448/14860 (56%)]\tLoss: 0.015088\n",
      "Train Epoch: 39 [8576/14860 (57%)]\tLoss: 0.023687\n",
      "Train Epoch: 39 [8704/14860 (58%)]\tLoss: 0.013670\n",
      "Train Epoch: 39 [8832/14860 (59%)]\tLoss: 0.019128\n",
      "Train Epoch: 39 [8960/14860 (60%)]\tLoss: 0.022166\n",
      "Train Epoch: 39 [9088/14860 (61%)]\tLoss: 0.023506\n",
      "Train Epoch: 39 [9216/14860 (62%)]\tLoss: 0.015226\n",
      "Train Epoch: 39 [9344/14860 (62%)]\tLoss: 0.025677\n",
      "Train Epoch: 39 [9472/14860 (63%)]\tLoss: 0.024936\n",
      "Train Epoch: 39 [9600/14860 (64%)]\tLoss: 0.015443\n",
      "Train Epoch: 39 [9728/14860 (65%)]\tLoss: 0.026425\n",
      "Train Epoch: 39 [9856/14860 (66%)]\tLoss: 0.019165\n",
      "Train Epoch: 39 [9984/14860 (67%)]\tLoss: 0.018579\n",
      "Train Epoch: 39 [10112/14860 (68%)]\tLoss: 0.021372\n",
      "Train Epoch: 39 [10240/14860 (68%)]\tLoss: 0.018436\n",
      "Train Epoch: 39 [10368/14860 (69%)]\tLoss: 0.027499\n",
      "Train Epoch: 39 [10496/14860 (70%)]\tLoss: 0.017389\n",
      "Train Epoch: 39 [10624/14860 (71%)]\tLoss: 0.018354\n",
      "Train Epoch: 39 [10752/14860 (72%)]\tLoss: 0.018805\n",
      "Train Epoch: 39 [10880/14860 (73%)]\tLoss: 0.034071\n",
      "Train Epoch: 39 [11008/14860 (74%)]\tLoss: 0.022325\n",
      "Train Epoch: 39 [11136/14860 (74%)]\tLoss: 0.017738\n",
      "Train Epoch: 39 [11264/14860 (75%)]\tLoss: 0.017311\n",
      "Train Epoch: 39 [11392/14860 (76%)]\tLoss: 0.022095\n",
      "Train Epoch: 39 [11520/14860 (77%)]\tLoss: 0.016332\n",
      "Train Epoch: 39 [11648/14860 (78%)]\tLoss: 0.021949\n",
      "Train Epoch: 39 [11776/14860 (79%)]\tLoss: 0.015704\n",
      "Train Epoch: 39 [11904/14860 (79%)]\tLoss: 0.017514\n",
      "Train Epoch: 39 [12032/14860 (80%)]\tLoss: 0.021113\n",
      "Train Epoch: 39 [12160/14860 (81%)]\tLoss: 0.020265\n",
      "Train Epoch: 39 [12288/14860 (82%)]\tLoss: 0.023194\n",
      "Train Epoch: 39 [12416/14860 (83%)]\tLoss: 0.016819\n",
      "Train Epoch: 39 [12544/14860 (84%)]\tLoss: 0.035618\n",
      "Train Epoch: 39 [12672/14860 (85%)]\tLoss: 0.025585\n",
      "Train Epoch: 39 [12800/14860 (85%)]\tLoss: 0.023170\n",
      "Train Epoch: 39 [12928/14860 (86%)]\tLoss: 0.021982\n",
      "Train Epoch: 39 [13056/14860 (87%)]\tLoss: 0.023907\n",
      "Train Epoch: 39 [13184/14860 (88%)]\tLoss: 0.024140\n",
      "Train Epoch: 39 [13312/14860 (89%)]\tLoss: 0.018634\n",
      "Train Epoch: 39 [13440/14860 (90%)]\tLoss: 0.023065\n",
      "Train Epoch: 39 [13568/14860 (91%)]\tLoss: 0.018801\n",
      "Train Epoch: 39 [13696/14860 (91%)]\tLoss: 0.021708\n",
      "Train Epoch: 39 [13824/14860 (92%)]\tLoss: 0.016931\n",
      "Train Epoch: 39 [13952/14860 (93%)]\tLoss: 0.020671\n",
      "Train Epoch: 39 [14080/14860 (94%)]\tLoss: 0.027667\n",
      "Train Epoch: 39 [14208/14860 (95%)]\tLoss: 0.023159\n",
      "Train Epoch: 39 [14336/14860 (96%)]\tLoss: 0.017497\n",
      "Train Epoch: 39 [14464/14860 (97%)]\tLoss: 0.018235\n",
      "Train Epoch: 39 [14592/14860 (97%)]\tLoss: 0.019894\n",
      "Train Epoch: 39 [14720/14860 (98%)]\tLoss: 0.019337\n",
      "Train Epoch: 39 [1392/14860 (99%)]\tLoss: 0.013860\n",
      "epoch 39 training loss: 0.021429545285864774\n",
      "epoch 39 validation loss: 0.03624096260232441\n",
      "Train Epoch: 40 [0/14860 (0%)]\tLoss: 0.028187\n",
      "Train Epoch: 40 [128/14860 (1%)]\tLoss: 0.023124\n",
      "Train Epoch: 40 [256/14860 (2%)]\tLoss: 0.027482\n",
      "Train Epoch: 40 [384/14860 (3%)]\tLoss: 0.025667\n",
      "Train Epoch: 40 [512/14860 (3%)]\tLoss: 0.021277\n",
      "Train Epoch: 40 [640/14860 (4%)]\tLoss: 0.023773\n",
      "Train Epoch: 40 [768/14860 (5%)]\tLoss: 0.023608\n",
      "Train Epoch: 40 [896/14860 (6%)]\tLoss: 0.021398\n",
      "Train Epoch: 40 [1024/14860 (7%)]\tLoss: 0.023482\n",
      "Train Epoch: 40 [1152/14860 (8%)]\tLoss: 0.016043\n",
      "Train Epoch: 40 [1280/14860 (9%)]\tLoss: 0.023699\n",
      "Train Epoch: 40 [1408/14860 (9%)]\tLoss: 0.023635\n",
      "Train Epoch: 40 [1536/14860 (10%)]\tLoss: 0.022317\n",
      "Train Epoch: 40 [1664/14860 (11%)]\tLoss: 0.019384\n",
      "Train Epoch: 40 [1792/14860 (12%)]\tLoss: 0.031817\n",
      "Train Epoch: 40 [1920/14860 (13%)]\tLoss: 0.019997\n",
      "Train Epoch: 40 [2048/14860 (14%)]\tLoss: 0.026283\n",
      "Train Epoch: 40 [2176/14860 (15%)]\tLoss: 0.027947\n",
      "Train Epoch: 40 [2304/14860 (15%)]\tLoss: 0.017288\n",
      "Train Epoch: 40 [2432/14860 (16%)]\tLoss: 0.033572\n",
      "Train Epoch: 40 [2560/14860 (17%)]\tLoss: 0.021936\n",
      "Train Epoch: 40 [2688/14860 (18%)]\tLoss: 0.022403\n",
      "Train Epoch: 40 [2816/14860 (19%)]\tLoss: 0.019412\n",
      "Train Epoch: 40 [2944/14860 (20%)]\tLoss: 0.038997\n",
      "Train Epoch: 40 [3072/14860 (21%)]\tLoss: 0.018891\n",
      "Train Epoch: 40 [3200/14860 (21%)]\tLoss: 0.031277\n",
      "Train Epoch: 40 [3328/14860 (22%)]\tLoss: 0.024599\n",
      "Train Epoch: 40 [3456/14860 (23%)]\tLoss: 0.034952\n",
      "Train Epoch: 40 [3584/14860 (24%)]\tLoss: 0.018500\n",
      "Train Epoch: 40 [3712/14860 (25%)]\tLoss: 0.028414\n",
      "Train Epoch: 40 [3840/14860 (26%)]\tLoss: 0.019800\n",
      "Train Epoch: 40 [3968/14860 (26%)]\tLoss: 0.025387\n",
      "Train Epoch: 40 [4096/14860 (27%)]\tLoss: 0.021466\n",
      "Train Epoch: 40 [4224/14860 (28%)]\tLoss: 0.022925\n",
      "Train Epoch: 40 [4352/14860 (29%)]\tLoss: 0.018892\n",
      "Train Epoch: 40 [4480/14860 (30%)]\tLoss: 0.019670\n",
      "Train Epoch: 40 [4608/14860 (31%)]\tLoss: 0.022282\n",
      "Train Epoch: 40 [4736/14860 (32%)]\tLoss: 0.015101\n",
      "Train Epoch: 40 [4864/14860 (32%)]\tLoss: 0.023837\n",
      "Train Epoch: 40 [4992/14860 (33%)]\tLoss: 0.025780\n",
      "Train Epoch: 40 [5120/14860 (34%)]\tLoss: 0.019400\n",
      "Train Epoch: 40 [5248/14860 (35%)]\tLoss: 0.016138\n",
      "Train Epoch: 40 [5376/14860 (36%)]\tLoss: 0.016536\n",
      "Train Epoch: 40 [5504/14860 (37%)]\tLoss: 0.026513\n",
      "Train Epoch: 40 [5632/14860 (38%)]\tLoss: 0.025342\n",
      "Train Epoch: 40 [5760/14860 (38%)]\tLoss: 0.025939\n",
      "Train Epoch: 40 [5888/14860 (39%)]\tLoss: 0.019479\n",
      "Train Epoch: 40 [6016/14860 (40%)]\tLoss: 0.024606\n",
      "Train Epoch: 40 [6144/14860 (41%)]\tLoss: 0.019080\n",
      "Train Epoch: 40 [6272/14860 (42%)]\tLoss: 0.019006\n",
      "Train Epoch: 40 [6400/14860 (43%)]\tLoss: 0.023631\n",
      "Train Epoch: 40 [6528/14860 (44%)]\tLoss: 0.030710\n",
      "Train Epoch: 40 [6656/14860 (44%)]\tLoss: 0.019278\n",
      "Train Epoch: 40 [6784/14860 (45%)]\tLoss: 0.020947\n",
      "Train Epoch: 40 [6912/14860 (46%)]\tLoss: 0.019321\n",
      "Train Epoch: 40 [7040/14860 (47%)]\tLoss: 0.016886\n",
      "Train Epoch: 40 [7168/14860 (48%)]\tLoss: 0.023285\n",
      "Train Epoch: 40 [7296/14860 (49%)]\tLoss: 0.020047\n",
      "Train Epoch: 40 [7424/14860 (50%)]\tLoss: 0.020452\n",
      "Train Epoch: 40 [7552/14860 (50%)]\tLoss: 0.017792\n",
      "Train Epoch: 40 [7680/14860 (51%)]\tLoss: 0.017381\n",
      "Train Epoch: 40 [7808/14860 (52%)]\tLoss: 0.015787\n",
      "Train Epoch: 40 [7936/14860 (53%)]\tLoss: 0.022295\n",
      "Train Epoch: 40 [8064/14860 (54%)]\tLoss: 0.014966\n",
      "Train Epoch: 40 [8192/14860 (55%)]\tLoss: 0.022727\n",
      "Train Epoch: 40 [8320/14860 (56%)]\tLoss: 0.024275\n",
      "Train Epoch: 40 [8448/14860 (56%)]\tLoss: 0.013437\n",
      "Train Epoch: 40 [8576/14860 (57%)]\tLoss: 0.032086\n",
      "Train Epoch: 40 [8704/14860 (58%)]\tLoss: 0.022694\n",
      "Train Epoch: 40 [8832/14860 (59%)]\tLoss: 0.034369\n",
      "Train Epoch: 40 [8960/14860 (60%)]\tLoss: 0.024913\n",
      "Train Epoch: 40 [9088/14860 (61%)]\tLoss: 0.029580\n",
      "Train Epoch: 40 [9216/14860 (62%)]\tLoss: 0.028148\n",
      "Train Epoch: 40 [9344/14860 (62%)]\tLoss: 0.039734\n",
      "Train Epoch: 40 [9472/14860 (63%)]\tLoss: 0.016872\n",
      "Train Epoch: 40 [9600/14860 (64%)]\tLoss: 0.027402\n",
      "Train Epoch: 40 [9728/14860 (65%)]\tLoss: 0.018094\n",
      "Train Epoch: 40 [9856/14860 (66%)]\tLoss: 0.026204\n",
      "Train Epoch: 40 [9984/14860 (67%)]\tLoss: 0.023259\n",
      "Train Epoch: 40 [10112/14860 (68%)]\tLoss: 0.022636\n",
      "Train Epoch: 40 [10240/14860 (68%)]\tLoss: 0.016388\n",
      "Train Epoch: 40 [10368/14860 (69%)]\tLoss: 0.018236\n",
      "Train Epoch: 40 [10496/14860 (70%)]\tLoss: 0.020546\n",
      "Train Epoch: 40 [10624/14860 (71%)]\tLoss: 0.017218\n",
      "Train Epoch: 40 [10752/14860 (72%)]\tLoss: 0.020897\n",
      "Train Epoch: 40 [10880/14860 (73%)]\tLoss: 0.012217\n",
      "Train Epoch: 40 [11008/14860 (74%)]\tLoss: 0.014710\n",
      "Train Epoch: 40 [11136/14860 (74%)]\tLoss: 0.024116\n",
      "Train Epoch: 40 [11264/14860 (75%)]\tLoss: 0.017828\n",
      "Train Epoch: 40 [11392/14860 (76%)]\tLoss: 0.030108\n",
      "Train Epoch: 40 [11520/14860 (77%)]\tLoss: 0.021022\n",
      "Train Epoch: 40 [11648/14860 (78%)]\tLoss: 0.022129\n",
      "Train Epoch: 40 [11776/14860 (79%)]\tLoss: 0.017661\n",
      "Train Epoch: 40 [11904/14860 (79%)]\tLoss: 0.027555\n",
      "Train Epoch: 40 [12032/14860 (80%)]\tLoss: 0.022089\n",
      "Train Epoch: 40 [12160/14860 (81%)]\tLoss: 0.012026\n",
      "Train Epoch: 40 [12288/14860 (82%)]\tLoss: 0.026796\n",
      "Train Epoch: 40 [12416/14860 (83%)]\tLoss: 0.017994\n",
      "Train Epoch: 40 [12544/14860 (84%)]\tLoss: 0.017436\n",
      "Train Epoch: 40 [12672/14860 (85%)]\tLoss: 0.026426\n",
      "Train Epoch: 40 [12800/14860 (85%)]\tLoss: 0.018676\n",
      "Train Epoch: 40 [12928/14860 (86%)]\tLoss: 0.018801\n",
      "Train Epoch: 40 [13056/14860 (87%)]\tLoss: 0.022134\n",
      "Train Epoch: 40 [13184/14860 (88%)]\tLoss: 0.021005\n",
      "Train Epoch: 40 [13312/14860 (89%)]\tLoss: 0.015805\n",
      "Train Epoch: 40 [13440/14860 (90%)]\tLoss: 0.022758\n",
      "Train Epoch: 40 [13568/14860 (91%)]\tLoss: 0.011463\n",
      "Train Epoch: 40 [13696/14860 (91%)]\tLoss: 0.021769\n",
      "Train Epoch: 40 [13824/14860 (92%)]\tLoss: 0.014309\n",
      "Train Epoch: 40 [13952/14860 (93%)]\tLoss: 0.020452\n",
      "Train Epoch: 40 [14080/14860 (94%)]\tLoss: 0.011947\n",
      "Train Epoch: 40 [14208/14860 (95%)]\tLoss: 0.017990\n",
      "Train Epoch: 40 [14336/14860 (96%)]\tLoss: 0.011926\n",
      "Train Epoch: 40 [14464/14860 (97%)]\tLoss: 0.021439\n",
      "Train Epoch: 40 [14592/14860 (97%)]\tLoss: 0.022055\n",
      "Train Epoch: 40 [14720/14860 (98%)]\tLoss: 0.013574\n",
      "Train Epoch: 40 [1392/14860 (99%)]\tLoss: 0.014304\n",
      "epoch 40 training loss: 0.021876541077772267\n",
      "epoch 40 validation loss: 0.031413845519465335\n",
      "Train Epoch: 41 [0/14860 (0%)]\tLoss: 0.024207\n",
      "Train Epoch: 41 [128/14860 (1%)]\tLoss: 0.020788\n",
      "Train Epoch: 41 [256/14860 (2%)]\tLoss: 0.025552\n",
      "Train Epoch: 41 [384/14860 (3%)]\tLoss: 0.016662\n",
      "Train Epoch: 41 [512/14860 (3%)]\tLoss: 0.021027\n",
      "Train Epoch: 41 [640/14860 (4%)]\tLoss: 0.020176\n",
      "Train Epoch: 41 [768/14860 (5%)]\tLoss: 0.015687\n",
      "Train Epoch: 41 [896/14860 (6%)]\tLoss: 0.013762\n",
      "Train Epoch: 41 [1024/14860 (7%)]\tLoss: 0.020886\n",
      "Train Epoch: 41 [1152/14860 (8%)]\tLoss: 0.029038\n",
      "Train Epoch: 41 [1280/14860 (9%)]\tLoss: 0.028100\n",
      "Train Epoch: 41 [1408/14860 (9%)]\tLoss: 0.022987\n",
      "Train Epoch: 41 [1536/14860 (10%)]\tLoss: 0.025505\n",
      "Train Epoch: 41 [1664/14860 (11%)]\tLoss: 0.029330\n",
      "Train Epoch: 41 [1792/14860 (12%)]\tLoss: 0.024277\n",
      "Train Epoch: 41 [1920/14860 (13%)]\tLoss: 0.019569\n",
      "Train Epoch: 41 [2048/14860 (14%)]\tLoss: 0.026256\n",
      "Train Epoch: 41 [2176/14860 (15%)]\tLoss: 0.025304\n",
      "Train Epoch: 41 [2304/14860 (15%)]\tLoss: 0.027472\n",
      "Train Epoch: 41 [2432/14860 (16%)]\tLoss: 0.032867\n",
      "Train Epoch: 41 [2560/14860 (17%)]\tLoss: 0.024712\n",
      "Train Epoch: 41 [2688/14860 (18%)]\tLoss: 0.028137\n",
      "Train Epoch: 41 [2816/14860 (19%)]\tLoss: 0.022466\n",
      "Train Epoch: 41 [2944/14860 (20%)]\tLoss: 0.024060\n",
      "Train Epoch: 41 [3072/14860 (21%)]\tLoss: 0.024018\n",
      "Train Epoch: 41 [3200/14860 (21%)]\tLoss: 0.035095\n",
      "Train Epoch: 41 [3328/14860 (22%)]\tLoss: 0.020851\n",
      "Train Epoch: 41 [3456/14860 (23%)]\tLoss: 0.025536\n",
      "Train Epoch: 41 [3584/14860 (24%)]\tLoss: 0.023624\n",
      "Train Epoch: 41 [3712/14860 (25%)]\tLoss: 0.019524\n",
      "Train Epoch: 41 [3840/14860 (26%)]\tLoss: 0.020996\n",
      "Train Epoch: 41 [3968/14860 (26%)]\tLoss: 0.017389\n",
      "Train Epoch: 41 [4096/14860 (27%)]\tLoss: 0.019618\n",
      "Train Epoch: 41 [4224/14860 (28%)]\tLoss: 0.023499\n",
      "Train Epoch: 41 [4352/14860 (29%)]\tLoss: 0.017053\n",
      "Train Epoch: 41 [4480/14860 (30%)]\tLoss: 0.024719\n",
      "Train Epoch: 41 [4608/14860 (31%)]\tLoss: 0.016830\n",
      "Train Epoch: 41 [4736/14860 (32%)]\tLoss: 0.017627\n",
      "Train Epoch: 41 [4864/14860 (32%)]\tLoss: 0.020638\n",
      "Train Epoch: 41 [4992/14860 (33%)]\tLoss: 0.024744\n",
      "Train Epoch: 41 [5120/14860 (34%)]\tLoss: 0.016501\n",
      "Train Epoch: 41 [5248/14860 (35%)]\tLoss: 0.018564\n",
      "Train Epoch: 41 [5376/14860 (36%)]\tLoss: 0.021137\n",
      "Train Epoch: 41 [5504/14860 (37%)]\tLoss: 0.013005\n",
      "Train Epoch: 41 [5632/14860 (38%)]\tLoss: 0.027938\n",
      "Train Epoch: 41 [5760/14860 (38%)]\tLoss: 0.028552\n",
      "Train Epoch: 41 [5888/14860 (39%)]\tLoss: 0.035780\n",
      "Train Epoch: 41 [6016/14860 (40%)]\tLoss: 0.015329\n",
      "Train Epoch: 41 [6144/14860 (41%)]\tLoss: 0.035054\n",
      "Train Epoch: 41 [6272/14860 (42%)]\tLoss: 0.029356\n",
      "Train Epoch: 41 [6400/14860 (43%)]\tLoss: 0.031308\n",
      "Train Epoch: 41 [6528/14860 (44%)]\tLoss: 0.033723\n",
      "Train Epoch: 41 [6656/14860 (44%)]\tLoss: 0.024381\n",
      "Train Epoch: 41 [6784/14860 (45%)]\tLoss: 0.031617\n",
      "Train Epoch: 41 [6912/14860 (46%)]\tLoss: 0.029293\n",
      "Train Epoch: 41 [7040/14860 (47%)]\tLoss: 0.029857\n",
      "Train Epoch: 41 [7168/14860 (48%)]\tLoss: 0.035261\n",
      "Train Epoch: 41 [7296/14860 (49%)]\tLoss: 0.020437\n",
      "Train Epoch: 41 [7424/14860 (50%)]\tLoss: 0.028448\n",
      "Train Epoch: 41 [7552/14860 (50%)]\tLoss: 0.025838\n",
      "Train Epoch: 41 [7680/14860 (51%)]\tLoss: 0.020192\n",
      "Train Epoch: 41 [7808/14860 (52%)]\tLoss: 0.029213\n",
      "Train Epoch: 41 [7936/14860 (53%)]\tLoss: 0.013973\n",
      "Train Epoch: 41 [8064/14860 (54%)]\tLoss: 0.022751\n",
      "Train Epoch: 41 [8192/14860 (55%)]\tLoss: 0.031062\n",
      "Train Epoch: 41 [8320/14860 (56%)]\tLoss: 0.028501\n",
      "Train Epoch: 41 [8448/14860 (56%)]\tLoss: 0.041222\n",
      "Train Epoch: 41 [8576/14860 (57%)]\tLoss: 0.027788\n",
      "Train Epoch: 41 [8704/14860 (58%)]\tLoss: 0.025045\n",
      "Train Epoch: 41 [8832/14860 (59%)]\tLoss: 0.027380\n",
      "Train Epoch: 41 [8960/14860 (60%)]\tLoss: 0.024756\n",
      "Train Epoch: 41 [9088/14860 (61%)]\tLoss: 0.019569\n",
      "Train Epoch: 41 [9216/14860 (62%)]\tLoss: 0.025568\n",
      "Train Epoch: 41 [9344/14860 (62%)]\tLoss: 0.018948\n",
      "Train Epoch: 41 [9472/14860 (63%)]\tLoss: 0.022399\n",
      "Train Epoch: 41 [9600/14860 (64%)]\tLoss: 0.028457\n",
      "Train Epoch: 41 [9728/14860 (65%)]\tLoss: 0.019666\n",
      "Train Epoch: 41 [9856/14860 (66%)]\tLoss: 0.028516\n",
      "Train Epoch: 41 [9984/14860 (67%)]\tLoss: 0.029871\n",
      "Train Epoch: 41 [10112/14860 (68%)]\tLoss: 0.016772\n",
      "Train Epoch: 41 [10240/14860 (68%)]\tLoss: 0.015736\n",
      "Train Epoch: 41 [10368/14860 (69%)]\tLoss: 0.023817\n",
      "Train Epoch: 41 [10496/14860 (70%)]\tLoss: 0.029472\n",
      "Train Epoch: 41 [10624/14860 (71%)]\tLoss: 0.027636\n",
      "Train Epoch: 41 [10752/14860 (72%)]\tLoss: 0.025743\n",
      "Train Epoch: 41 [10880/14860 (73%)]\tLoss: 0.015253\n",
      "Train Epoch: 41 [11008/14860 (74%)]\tLoss: 0.018829\n",
      "Train Epoch: 41 [11136/14860 (74%)]\tLoss: 0.031018\n",
      "Train Epoch: 41 [11264/14860 (75%)]\tLoss: 0.019519\n",
      "Train Epoch: 41 [11392/14860 (76%)]\tLoss: 0.019367\n",
      "Train Epoch: 41 [11520/14860 (77%)]\tLoss: 0.019082\n",
      "Train Epoch: 41 [11648/14860 (78%)]\tLoss: 0.022541\n",
      "Train Epoch: 41 [11776/14860 (79%)]\tLoss: 0.019571\n",
      "Train Epoch: 41 [11904/14860 (79%)]\tLoss: 0.019402\n",
      "Train Epoch: 41 [12032/14860 (80%)]\tLoss: 0.032402\n",
      "Train Epoch: 41 [12160/14860 (81%)]\tLoss: 0.028674\n",
      "Train Epoch: 41 [12288/14860 (82%)]\tLoss: 0.024016\n",
      "Train Epoch: 41 [12416/14860 (83%)]\tLoss: 0.018684\n",
      "Train Epoch: 41 [12544/14860 (84%)]\tLoss: 0.027489\n",
      "Train Epoch: 41 [12672/14860 (85%)]\tLoss: 0.023929\n",
      "Train Epoch: 41 [12800/14860 (85%)]\tLoss: 0.020320\n",
      "Train Epoch: 41 [12928/14860 (86%)]\tLoss: 0.026583\n",
      "Train Epoch: 41 [13056/14860 (87%)]\tLoss: 0.027169\n",
      "Train Epoch: 41 [13184/14860 (88%)]\tLoss: 0.020448\n",
      "Train Epoch: 41 [13312/14860 (89%)]\tLoss: 0.024496\n",
      "Train Epoch: 41 [13440/14860 (90%)]\tLoss: 0.019188\n",
      "Train Epoch: 41 [13568/14860 (91%)]\tLoss: 0.015725\n",
      "Train Epoch: 41 [13696/14860 (91%)]\tLoss: 0.015492\n",
      "Train Epoch: 41 [13824/14860 (92%)]\tLoss: 0.014578\n",
      "Train Epoch: 41 [13952/14860 (93%)]\tLoss: 0.020652\n",
      "Train Epoch: 41 [14080/14860 (94%)]\tLoss: 0.020319\n",
      "Train Epoch: 41 [14208/14860 (95%)]\tLoss: 0.019698\n",
      "Train Epoch: 41 [14336/14860 (96%)]\tLoss: 0.021900\n",
      "Train Epoch: 41 [14464/14860 (97%)]\tLoss: 0.015337\n",
      "Train Epoch: 41 [14592/14860 (97%)]\tLoss: 0.015709\n",
      "Train Epoch: 41 [14720/14860 (98%)]\tLoss: 0.016980\n",
      "Train Epoch: 41 [1392/14860 (99%)]\tLoss: 0.026260\n",
      "epoch 41 training loss: 0.02356112014470447\n",
      "epoch 41 validation loss: 0.02119151313426131\n",
      "Train Epoch: 42 [0/14860 (0%)]\tLoss: 0.019036\n",
      "Train Epoch: 42 [128/14860 (1%)]\tLoss: 0.020333\n",
      "Train Epoch: 42 [256/14860 (2%)]\tLoss: 0.017995\n",
      "Train Epoch: 42 [384/14860 (3%)]\tLoss: 0.027777\n",
      "Train Epoch: 42 [512/14860 (3%)]\tLoss: 0.026864\n",
      "Train Epoch: 42 [640/14860 (4%)]\tLoss: 0.024852\n",
      "Train Epoch: 42 [768/14860 (5%)]\tLoss: 0.024084\n",
      "Train Epoch: 42 [896/14860 (6%)]\tLoss: 0.019970\n",
      "Train Epoch: 42 [1024/14860 (7%)]\tLoss: 0.024173\n",
      "Train Epoch: 42 [1152/14860 (8%)]\tLoss: 0.018657\n",
      "Train Epoch: 42 [1280/14860 (9%)]\tLoss: 0.024055\n",
      "Train Epoch: 42 [1408/14860 (9%)]\tLoss: 0.021244\n",
      "Train Epoch: 42 [1536/14860 (10%)]\tLoss: 0.022548\n",
      "Train Epoch: 42 [1664/14860 (11%)]\tLoss: 0.016733\n",
      "Train Epoch: 42 [1792/14860 (12%)]\tLoss: 0.017650\n",
      "Train Epoch: 42 [1920/14860 (13%)]\tLoss: 0.017695\n",
      "Train Epoch: 42 [2048/14860 (14%)]\tLoss: 0.017319\n",
      "Train Epoch: 42 [2176/14860 (15%)]\tLoss: 0.014943\n",
      "Train Epoch: 42 [2304/14860 (15%)]\tLoss: 0.016659\n",
      "Train Epoch: 42 [2432/14860 (16%)]\tLoss: 0.030179\n",
      "Train Epoch: 42 [2560/14860 (17%)]\tLoss: 0.021323\n",
      "Train Epoch: 42 [2688/14860 (18%)]\tLoss: 0.013987\n",
      "Train Epoch: 42 [2816/14860 (19%)]\tLoss: 0.026086\n",
      "Train Epoch: 42 [2944/14860 (20%)]\tLoss: 0.017936\n",
      "Train Epoch: 42 [3072/14860 (21%)]\tLoss: 0.019703\n",
      "Train Epoch: 42 [3200/14860 (21%)]\tLoss: 0.015546\n",
      "Train Epoch: 42 [3328/14860 (22%)]\tLoss: 0.019724\n",
      "Train Epoch: 42 [3456/14860 (23%)]\tLoss: 0.023267\n",
      "Train Epoch: 42 [3584/14860 (24%)]\tLoss: 0.018946\n",
      "Train Epoch: 42 [3712/14860 (25%)]\tLoss: 0.013264\n",
      "Train Epoch: 42 [3840/14860 (26%)]\tLoss: 0.019668\n",
      "Train Epoch: 42 [3968/14860 (26%)]\tLoss: 0.025092\n",
      "Train Epoch: 42 [4096/14860 (27%)]\tLoss: 0.023535\n",
      "Train Epoch: 42 [4224/14860 (28%)]\tLoss: 0.029981\n",
      "Train Epoch: 42 [4352/14860 (29%)]\tLoss: 0.028738\n",
      "Train Epoch: 42 [4480/14860 (30%)]\tLoss: 0.026144\n",
      "Train Epoch: 42 [4608/14860 (31%)]\tLoss: 0.024239\n",
      "Train Epoch: 42 [4736/14860 (32%)]\tLoss: 0.028518\n",
      "Train Epoch: 42 [4864/14860 (32%)]\tLoss: 0.025300\n",
      "Train Epoch: 42 [4992/14860 (33%)]\tLoss: 0.021709\n",
      "Train Epoch: 42 [5120/14860 (34%)]\tLoss: 0.025117\n",
      "Train Epoch: 42 [5248/14860 (35%)]\tLoss: 0.028705\n",
      "Train Epoch: 42 [5376/14860 (36%)]\tLoss: 0.012159\n",
      "Train Epoch: 42 [5504/14860 (37%)]\tLoss: 0.027029\n",
      "Train Epoch: 42 [5632/14860 (38%)]\tLoss: 0.023091\n",
      "Train Epoch: 42 [5760/14860 (38%)]\tLoss: 0.018280\n",
      "Train Epoch: 42 [5888/14860 (39%)]\tLoss: 0.025458\n",
      "Train Epoch: 42 [6016/14860 (40%)]\tLoss: 0.019154\n",
      "Train Epoch: 42 [6144/14860 (41%)]\tLoss: 0.021719\n",
      "Train Epoch: 42 [6272/14860 (42%)]\tLoss: 0.021360\n",
      "Train Epoch: 42 [6400/14860 (43%)]\tLoss: 0.023887\n",
      "Train Epoch: 42 [6528/14860 (44%)]\tLoss: 0.026914\n",
      "Train Epoch: 42 [6656/14860 (44%)]\tLoss: 0.020400\n",
      "Train Epoch: 42 [6784/14860 (45%)]\tLoss: 0.022715\n",
      "Train Epoch: 42 [6912/14860 (46%)]\tLoss: 0.023244\n",
      "Train Epoch: 42 [7040/14860 (47%)]\tLoss: 0.024125\n",
      "Train Epoch: 42 [7168/14860 (48%)]\tLoss: 0.025500\n",
      "Train Epoch: 42 [7296/14860 (49%)]\tLoss: 0.023787\n",
      "Train Epoch: 42 [7424/14860 (50%)]\tLoss: 0.018788\n",
      "Train Epoch: 42 [7552/14860 (50%)]\tLoss: 0.025574\n",
      "Train Epoch: 42 [7680/14860 (51%)]\tLoss: 0.021288\n",
      "Train Epoch: 42 [7808/14860 (52%)]\tLoss: 0.020112\n",
      "Train Epoch: 42 [7936/14860 (53%)]\tLoss: 0.024499\n",
      "Train Epoch: 42 [8064/14860 (54%)]\tLoss: 0.015660\n",
      "Train Epoch: 42 [8192/14860 (55%)]\tLoss: 0.033064\n",
      "Train Epoch: 42 [8320/14860 (56%)]\tLoss: 0.019944\n",
      "Train Epoch: 42 [8448/14860 (56%)]\tLoss: 0.019978\n",
      "Train Epoch: 42 [8576/14860 (57%)]\tLoss: 0.030047\n",
      "Train Epoch: 42 [8704/14860 (58%)]\tLoss: 0.019987\n",
      "Train Epoch: 42 [8832/14860 (59%)]\tLoss: 0.029109\n",
      "Train Epoch: 42 [8960/14860 (60%)]\tLoss: 0.018029\n",
      "Train Epoch: 42 [9088/14860 (61%)]\tLoss: 0.027441\n",
      "Train Epoch: 42 [9216/14860 (62%)]\tLoss: 0.018472\n",
      "Train Epoch: 42 [9344/14860 (62%)]\tLoss: 0.025044\n",
      "Train Epoch: 42 [9472/14860 (63%)]\tLoss: 0.031685\n",
      "Train Epoch: 42 [9600/14860 (64%)]\tLoss: 0.032439\n",
      "Train Epoch: 42 [9728/14860 (65%)]\tLoss: 0.021479\n",
      "Train Epoch: 42 [9856/14860 (66%)]\tLoss: 0.021552\n",
      "Train Epoch: 42 [9984/14860 (67%)]\tLoss: 0.015953\n",
      "Train Epoch: 42 [10112/14860 (68%)]\tLoss: 0.020574\n",
      "Train Epoch: 42 [10240/14860 (68%)]\tLoss: 0.021282\n",
      "Train Epoch: 42 [10368/14860 (69%)]\tLoss: 0.021758\n",
      "Train Epoch: 42 [10496/14860 (70%)]\tLoss: 0.021892\n",
      "Train Epoch: 42 [10624/14860 (71%)]\tLoss: 0.027937\n",
      "Train Epoch: 42 [10752/14860 (72%)]\tLoss: 0.018640\n",
      "Train Epoch: 42 [10880/14860 (73%)]\tLoss: 0.018791\n",
      "Train Epoch: 42 [11008/14860 (74%)]\tLoss: 0.021490\n",
      "Train Epoch: 42 [11136/14860 (74%)]\tLoss: 0.024212\n",
      "Train Epoch: 42 [11264/14860 (75%)]\tLoss: 0.030391\n",
      "Train Epoch: 42 [11392/14860 (76%)]\tLoss: 0.020508\n",
      "Train Epoch: 42 [11520/14860 (77%)]\tLoss: 0.019548\n",
      "Train Epoch: 42 [11648/14860 (78%)]\tLoss: 0.021050\n",
      "Train Epoch: 42 [11776/14860 (79%)]\tLoss: 0.021383\n",
      "Train Epoch: 42 [11904/14860 (79%)]\tLoss: 0.015994\n",
      "Train Epoch: 42 [12032/14860 (80%)]\tLoss: 0.015630\n",
      "Train Epoch: 42 [12160/14860 (81%)]\tLoss: 0.016415\n",
      "Train Epoch: 42 [12288/14860 (82%)]\tLoss: 0.016095\n",
      "Train Epoch: 42 [12416/14860 (83%)]\tLoss: 0.020875\n",
      "Train Epoch: 42 [12544/14860 (84%)]\tLoss: 0.017980\n",
      "Train Epoch: 42 [12672/14860 (85%)]\tLoss: 0.016668\n",
      "Train Epoch: 42 [12800/14860 (85%)]\tLoss: 0.020113\n",
      "Train Epoch: 42 [12928/14860 (86%)]\tLoss: 0.013987\n",
      "Train Epoch: 42 [13056/14860 (87%)]\tLoss: 0.024799\n",
      "Train Epoch: 42 [13184/14860 (88%)]\tLoss: 0.021082\n",
      "Train Epoch: 42 [13312/14860 (89%)]\tLoss: 0.019756\n",
      "Train Epoch: 42 [13440/14860 (90%)]\tLoss: 0.020676\n",
      "Train Epoch: 42 [13568/14860 (91%)]\tLoss: 0.021885\n",
      "Train Epoch: 42 [13696/14860 (91%)]\tLoss: 0.028010\n",
      "Train Epoch: 42 [13824/14860 (92%)]\tLoss: 0.020477\n",
      "Train Epoch: 42 [13952/14860 (93%)]\tLoss: 0.014007\n",
      "Train Epoch: 42 [14080/14860 (94%)]\tLoss: 0.025142\n",
      "Train Epoch: 42 [14208/14860 (95%)]\tLoss: 0.020304\n",
      "Train Epoch: 42 [14336/14860 (96%)]\tLoss: 0.014034\n",
      "Train Epoch: 42 [14464/14860 (97%)]\tLoss: 0.019311\n",
      "Train Epoch: 42 [14592/14860 (97%)]\tLoss: 0.017761\n",
      "Train Epoch: 42 [14720/14860 (98%)]\tLoss: 0.021707\n",
      "Train Epoch: 42 [1392/14860 (99%)]\tLoss: 0.011091\n",
      "epoch 42 training loss: 0.02163691633245629\n",
      "epoch 42 validation loss: 0.02531640884662656\n",
      "Train Epoch: 43 [0/14860 (0%)]\tLoss: 0.025065\n",
      "Train Epoch: 43 [128/14860 (1%)]\tLoss: 0.020798\n",
      "Train Epoch: 43 [256/14860 (2%)]\tLoss: 0.022861\n",
      "Train Epoch: 43 [384/14860 (3%)]\tLoss: 0.020996\n",
      "Train Epoch: 43 [512/14860 (3%)]\tLoss: 0.020627\n",
      "Train Epoch: 43 [640/14860 (4%)]\tLoss: 0.023411\n",
      "Train Epoch: 43 [768/14860 (5%)]\tLoss: 0.021025\n",
      "Train Epoch: 43 [896/14860 (6%)]\tLoss: 0.018130\n",
      "Train Epoch: 43 [1024/14860 (7%)]\tLoss: 0.013326\n",
      "Train Epoch: 43 [1152/14860 (8%)]\tLoss: 0.020765\n",
      "Train Epoch: 43 [1280/14860 (9%)]\tLoss: 0.025549\n",
      "Train Epoch: 43 [1408/14860 (9%)]\tLoss: 0.015133\n",
      "Train Epoch: 43 [1536/14860 (10%)]\tLoss: 0.030071\n",
      "Train Epoch: 43 [1664/14860 (11%)]\tLoss: 0.017905\n",
      "Train Epoch: 43 [1792/14860 (12%)]\tLoss: 0.026008\n",
      "Train Epoch: 43 [1920/14860 (13%)]\tLoss: 0.019358\n",
      "Train Epoch: 43 [2048/14860 (14%)]\tLoss: 0.023196\n",
      "Train Epoch: 43 [2176/14860 (15%)]\tLoss: 0.019267\n",
      "Train Epoch: 43 [2304/14860 (15%)]\tLoss: 0.018985\n",
      "Train Epoch: 43 [2432/14860 (16%)]\tLoss: 0.021426\n",
      "Train Epoch: 43 [2560/14860 (17%)]\tLoss: 0.019150\n",
      "Train Epoch: 43 [2688/14860 (18%)]\tLoss: 0.026592\n",
      "Train Epoch: 43 [2816/14860 (19%)]\tLoss: 0.021800\n",
      "Train Epoch: 43 [2944/14860 (20%)]\tLoss: 0.027080\n",
      "Train Epoch: 43 [3072/14860 (21%)]\tLoss: 0.026738\n",
      "Train Epoch: 43 [3200/14860 (21%)]\tLoss: 0.032649\n",
      "Train Epoch: 43 [3328/14860 (22%)]\tLoss: 0.024773\n",
      "Train Epoch: 43 [3456/14860 (23%)]\tLoss: 0.021335\n",
      "Train Epoch: 43 [3584/14860 (24%)]\tLoss: 0.028157\n",
      "Train Epoch: 43 [3712/14860 (25%)]\tLoss: 0.015228\n",
      "Train Epoch: 43 [3840/14860 (26%)]\tLoss: 0.019990\n",
      "Train Epoch: 43 [3968/14860 (26%)]\tLoss: 0.017243\n",
      "Train Epoch: 43 [4096/14860 (27%)]\tLoss: 0.018056\n",
      "Train Epoch: 43 [4224/14860 (28%)]\tLoss: 0.019809\n",
      "Train Epoch: 43 [4352/14860 (29%)]\tLoss: 0.020482\n",
      "Train Epoch: 43 [4480/14860 (30%)]\tLoss: 0.027999\n",
      "Train Epoch: 43 [4608/14860 (31%)]\tLoss: 0.017483\n",
      "Train Epoch: 43 [4736/14860 (32%)]\tLoss: 0.019149\n",
      "Train Epoch: 43 [4864/14860 (32%)]\tLoss: 0.019958\n",
      "Train Epoch: 43 [4992/14860 (33%)]\tLoss: 0.019931\n",
      "Train Epoch: 43 [5120/14860 (34%)]\tLoss: 0.024471\n",
      "Train Epoch: 43 [5248/14860 (35%)]\tLoss: 0.021304\n",
      "Train Epoch: 43 [5376/14860 (36%)]\tLoss: 0.022352\n",
      "Train Epoch: 43 [5504/14860 (37%)]\tLoss: 0.029226\n",
      "Train Epoch: 43 [5632/14860 (38%)]\tLoss: 0.014694\n",
      "Train Epoch: 43 [5760/14860 (38%)]\tLoss: 0.035644\n",
      "Train Epoch: 43 [5888/14860 (39%)]\tLoss: 0.019630\n",
      "Train Epoch: 43 [6016/14860 (40%)]\tLoss: 0.017420\n",
      "Train Epoch: 43 [6144/14860 (41%)]\tLoss: 0.023257\n",
      "Train Epoch: 43 [6272/14860 (42%)]\tLoss: 0.016720\n",
      "Train Epoch: 43 [6400/14860 (43%)]\tLoss: 0.026086\n",
      "Train Epoch: 43 [6528/14860 (44%)]\tLoss: 0.023365\n",
      "Train Epoch: 43 [6656/14860 (44%)]\tLoss: 0.020305\n",
      "Train Epoch: 43 [6784/14860 (45%)]\tLoss: 0.025983\n",
      "Train Epoch: 43 [6912/14860 (46%)]\tLoss: 0.016045\n",
      "Train Epoch: 43 [7040/14860 (47%)]\tLoss: 0.018660\n",
      "Train Epoch: 43 [7168/14860 (48%)]\tLoss: 0.024567\n",
      "Train Epoch: 43 [7296/14860 (49%)]\tLoss: 0.018955\n",
      "Train Epoch: 43 [7424/14860 (50%)]\tLoss: 0.026294\n",
      "Train Epoch: 43 [7552/14860 (50%)]\tLoss: 0.024763\n",
      "Train Epoch: 43 [7680/14860 (51%)]\tLoss: 0.024375\n",
      "Train Epoch: 43 [7808/14860 (52%)]\tLoss: 0.018019\n",
      "Train Epoch: 43 [7936/14860 (53%)]\tLoss: 0.023959\n",
      "Train Epoch: 43 [8064/14860 (54%)]\tLoss: 0.020617\n",
      "Train Epoch: 43 [8192/14860 (55%)]\tLoss: 0.025089\n",
      "Train Epoch: 43 [8320/14860 (56%)]\tLoss: 0.021546\n",
      "Train Epoch: 43 [8448/14860 (56%)]\tLoss: 0.017299\n",
      "Train Epoch: 43 [8576/14860 (57%)]\tLoss: 0.020224\n",
      "Train Epoch: 43 [8704/14860 (58%)]\tLoss: 0.020379\n",
      "Train Epoch: 43 [8832/14860 (59%)]\tLoss: 0.022891\n",
      "Train Epoch: 43 [8960/14860 (60%)]\tLoss: 0.021001\n",
      "Train Epoch: 43 [9088/14860 (61%)]\tLoss: 0.014364\n",
      "Train Epoch: 43 [9216/14860 (62%)]\tLoss: 0.021660\n",
      "Train Epoch: 43 [9344/14860 (62%)]\tLoss: 0.023419\n",
      "Train Epoch: 43 [9472/14860 (63%)]\tLoss: 0.017198\n",
      "Train Epoch: 43 [9600/14860 (64%)]\tLoss: 0.026492\n",
      "Train Epoch: 43 [9728/14860 (65%)]\tLoss: 0.023389\n",
      "Train Epoch: 43 [9856/14860 (66%)]\tLoss: 0.022982\n",
      "Train Epoch: 43 [9984/14860 (67%)]\tLoss: 0.018763\n",
      "Train Epoch: 43 [10112/14860 (68%)]\tLoss: 0.014742\n",
      "Train Epoch: 43 [10240/14860 (68%)]\tLoss: 0.016908\n",
      "Train Epoch: 43 [10368/14860 (69%)]\tLoss: 0.022166\n",
      "Train Epoch: 43 [10496/14860 (70%)]\tLoss: 0.017559\n",
      "Train Epoch: 43 [10624/14860 (71%)]\tLoss: 0.024328\n",
      "Train Epoch: 43 [10752/14860 (72%)]\tLoss: 0.019260\n",
      "Train Epoch: 43 [10880/14860 (73%)]\tLoss: 0.016072\n",
      "Train Epoch: 43 [11008/14860 (74%)]\tLoss: 0.018069\n",
      "Train Epoch: 43 [11136/14860 (74%)]\tLoss: 0.013823\n",
      "Train Epoch: 43 [11264/14860 (75%)]\tLoss: 0.021230\n",
      "Train Epoch: 43 [11392/14860 (76%)]\tLoss: 0.019877\n",
      "Train Epoch: 43 [11520/14860 (77%)]\tLoss: 0.017745\n",
      "Train Epoch: 43 [11648/14860 (78%)]\tLoss: 0.021603\n",
      "Train Epoch: 43 [11776/14860 (79%)]\tLoss: 0.026141\n",
      "Train Epoch: 43 [11904/14860 (79%)]\tLoss: 0.025003\n",
      "Train Epoch: 43 [12032/14860 (80%)]\tLoss: 0.026343\n",
      "Train Epoch: 43 [12160/14860 (81%)]\tLoss: 0.020231\n",
      "Train Epoch: 43 [12288/14860 (82%)]\tLoss: 0.017853\n",
      "Train Epoch: 43 [12416/14860 (83%)]\tLoss: 0.015427\n",
      "Train Epoch: 43 [12544/14860 (84%)]\tLoss: 0.024302\n",
      "Train Epoch: 43 [12672/14860 (85%)]\tLoss: 0.021453\n",
      "Train Epoch: 43 [12800/14860 (85%)]\tLoss: 0.016166\n",
      "Train Epoch: 43 [12928/14860 (86%)]\tLoss: 0.020886\n",
      "Train Epoch: 43 [13056/14860 (87%)]\tLoss: 0.020730\n",
      "Train Epoch: 43 [13184/14860 (88%)]\tLoss: 0.023336\n",
      "Train Epoch: 43 [13312/14860 (89%)]\tLoss: 0.015037\n",
      "Train Epoch: 43 [13440/14860 (90%)]\tLoss: 0.026130\n",
      "Train Epoch: 43 [13568/14860 (91%)]\tLoss: 0.022454\n",
      "Train Epoch: 43 [13696/14860 (91%)]\tLoss: 0.014242\n",
      "Train Epoch: 43 [13824/14860 (92%)]\tLoss: 0.019747\n",
      "Train Epoch: 43 [13952/14860 (93%)]\tLoss: 0.024125\n",
      "Train Epoch: 43 [14080/14860 (94%)]\tLoss: 0.027830\n",
      "Train Epoch: 43 [14208/14860 (95%)]\tLoss: 0.022429\n",
      "Train Epoch: 43 [14336/14860 (96%)]\tLoss: 0.016706\n",
      "Train Epoch: 43 [14464/14860 (97%)]\tLoss: 0.017915\n",
      "Train Epoch: 43 [14592/14860 (97%)]\tLoss: 0.023567\n",
      "Train Epoch: 43 [14720/14860 (98%)]\tLoss: 0.026608\n",
      "Train Epoch: 43 [1392/14860 (99%)]\tLoss: 0.043072\n",
      "epoch 43 training loss: 0.02155573830868189\n",
      "epoch 43 validation loss: 0.023075192517287506\n",
      "Train Epoch: 44 [0/14860 (0%)]\tLoss: 0.024583\n",
      "Train Epoch: 44 [128/14860 (1%)]\tLoss: 0.015165\n",
      "Train Epoch: 44 [256/14860 (2%)]\tLoss: 0.024162\n",
      "Train Epoch: 44 [384/14860 (3%)]\tLoss: 0.021708\n",
      "Train Epoch: 44 [512/14860 (3%)]\tLoss: 0.024470\n",
      "Train Epoch: 44 [640/14860 (4%)]\tLoss: 0.022410\n",
      "Train Epoch: 44 [768/14860 (5%)]\tLoss: 0.017026\n",
      "Train Epoch: 44 [896/14860 (6%)]\tLoss: 0.025268\n",
      "Train Epoch: 44 [1024/14860 (7%)]\tLoss: 0.021066\n",
      "Train Epoch: 44 [1152/14860 (8%)]\tLoss: 0.023463\n",
      "Train Epoch: 44 [1280/14860 (9%)]\tLoss: 0.032957\n",
      "Train Epoch: 44 [1408/14860 (9%)]\tLoss: 0.016263\n",
      "Train Epoch: 44 [1536/14860 (10%)]\tLoss: 0.028336\n",
      "Train Epoch: 44 [1664/14860 (11%)]\tLoss: 0.014885\n",
      "Train Epoch: 44 [1792/14860 (12%)]\tLoss: 0.018290\n",
      "Train Epoch: 44 [1920/14860 (13%)]\tLoss: 0.023191\n",
      "Train Epoch: 44 [2048/14860 (14%)]\tLoss: 0.018654\n",
      "Train Epoch: 44 [2176/14860 (15%)]\tLoss: 0.020470\n",
      "Train Epoch: 44 [2304/14860 (15%)]\tLoss: 0.022088\n",
      "Train Epoch: 44 [2432/14860 (16%)]\tLoss: 0.026901\n",
      "Train Epoch: 44 [2560/14860 (17%)]\tLoss: 0.022771\n",
      "Train Epoch: 44 [2688/14860 (18%)]\tLoss: 0.024566\n",
      "Train Epoch: 44 [2816/14860 (19%)]\tLoss: 0.022162\n",
      "Train Epoch: 44 [2944/14860 (20%)]\tLoss: 0.017582\n",
      "Train Epoch: 44 [3072/14860 (21%)]\tLoss: 0.021929\n",
      "Train Epoch: 44 [3200/14860 (21%)]\tLoss: 0.019124\n",
      "Train Epoch: 44 [3328/14860 (22%)]\tLoss: 0.023017\n",
      "Train Epoch: 44 [3456/14860 (23%)]\tLoss: 0.017333\n",
      "Train Epoch: 44 [3584/14860 (24%)]\tLoss: 0.024848\n",
      "Train Epoch: 44 [3712/14860 (25%)]\tLoss: 0.019610\n",
      "Train Epoch: 44 [3840/14860 (26%)]\tLoss: 0.019654\n",
      "Train Epoch: 44 [3968/14860 (26%)]\tLoss: 0.025944\n",
      "Train Epoch: 44 [4096/14860 (27%)]\tLoss: 0.014935\n",
      "Train Epoch: 44 [4224/14860 (28%)]\tLoss: 0.018461\n",
      "Train Epoch: 44 [4352/14860 (29%)]\tLoss: 0.018214\n",
      "Train Epoch: 44 [4480/14860 (30%)]\tLoss: 0.023096\n",
      "Train Epoch: 44 [4608/14860 (31%)]\tLoss: 0.035119\n",
      "Train Epoch: 44 [4736/14860 (32%)]\tLoss: 0.019047\n",
      "Train Epoch: 44 [4864/14860 (32%)]\tLoss: 0.038651\n",
      "Train Epoch: 44 [4992/14860 (33%)]\tLoss: 0.023225\n",
      "Train Epoch: 44 [5120/14860 (34%)]\tLoss: 0.031010\n",
      "Train Epoch: 44 [5248/14860 (35%)]\tLoss: 0.015917\n",
      "Train Epoch: 44 [5376/14860 (36%)]\tLoss: 0.033155\n",
      "Train Epoch: 44 [5504/14860 (37%)]\tLoss: 0.022546\n",
      "Train Epoch: 44 [5632/14860 (38%)]\tLoss: 0.036111\n",
      "Train Epoch: 44 [5760/14860 (38%)]\tLoss: 0.021009\n",
      "Train Epoch: 44 [5888/14860 (39%)]\tLoss: 0.023327\n",
      "Train Epoch: 44 [6016/14860 (40%)]\tLoss: 0.036455\n",
      "Train Epoch: 44 [6144/14860 (41%)]\tLoss: 0.023898\n",
      "Train Epoch: 44 [6272/14860 (42%)]\tLoss: 0.039441\n",
      "Train Epoch: 44 [6400/14860 (43%)]\tLoss: 0.023180\n",
      "Train Epoch: 44 [6528/14860 (44%)]\tLoss: 0.028146\n",
      "Train Epoch: 44 [6656/14860 (44%)]\tLoss: 0.029874\n",
      "Train Epoch: 44 [6784/14860 (45%)]\tLoss: 0.021025\n",
      "Train Epoch: 44 [6912/14860 (46%)]\tLoss: 0.031559\n",
      "Train Epoch: 44 [7040/14860 (47%)]\tLoss: 0.022790\n",
      "Train Epoch: 44 [7168/14860 (48%)]\tLoss: 0.032554\n",
      "Train Epoch: 44 [7296/14860 (49%)]\tLoss: 0.022439\n",
      "Train Epoch: 44 [7424/14860 (50%)]\tLoss: 0.017858\n",
      "Train Epoch: 44 [7552/14860 (50%)]\tLoss: 0.026426\n",
      "Train Epoch: 44 [7680/14860 (51%)]\tLoss: 0.026711\n",
      "Train Epoch: 44 [7808/14860 (52%)]\tLoss: 0.022820\n",
      "Train Epoch: 44 [7936/14860 (53%)]\tLoss: 0.027030\n",
      "Train Epoch: 44 [8064/14860 (54%)]\tLoss: 0.024550\n",
      "Train Epoch: 44 [8192/14860 (55%)]\tLoss: 0.019101\n",
      "Train Epoch: 44 [8320/14860 (56%)]\tLoss: 0.023210\n",
      "Train Epoch: 44 [8448/14860 (56%)]\tLoss: 0.021741\n",
      "Train Epoch: 44 [8576/14860 (57%)]\tLoss: 0.021048\n",
      "Train Epoch: 44 [8704/14860 (58%)]\tLoss: 0.024537\n",
      "Train Epoch: 44 [8832/14860 (59%)]\tLoss: 0.018606\n",
      "Train Epoch: 44 [8960/14860 (60%)]\tLoss: 0.016994\n",
      "Train Epoch: 44 [9088/14860 (61%)]\tLoss: 0.026055\n",
      "Train Epoch: 44 [9216/14860 (62%)]\tLoss: 0.016946\n",
      "Train Epoch: 44 [9344/14860 (62%)]\tLoss: 0.019658\n",
      "Train Epoch: 44 [9472/14860 (63%)]\tLoss: 0.023645\n",
      "Train Epoch: 44 [9600/14860 (64%)]\tLoss: 0.019384\n",
      "Train Epoch: 44 [9728/14860 (65%)]\tLoss: 0.018197\n",
      "Train Epoch: 44 [9856/14860 (66%)]\tLoss: 0.025099\n",
      "Train Epoch: 44 [9984/14860 (67%)]\tLoss: 0.021817\n",
      "Train Epoch: 44 [10112/14860 (68%)]\tLoss: 0.018505\n",
      "Train Epoch: 44 [10240/14860 (68%)]\tLoss: 0.015156\n",
      "Train Epoch: 44 [10368/14860 (69%)]\tLoss: 0.020000\n",
      "Train Epoch: 44 [10496/14860 (70%)]\tLoss: 0.020805\n",
      "Train Epoch: 44 [10624/14860 (71%)]\tLoss: 0.020789\n",
      "Train Epoch: 44 [10752/14860 (72%)]\tLoss: 0.026961\n",
      "Train Epoch: 44 [10880/14860 (73%)]\tLoss: 0.019360\n",
      "Train Epoch: 44 [11008/14860 (74%)]\tLoss: 0.015875\n",
      "Train Epoch: 44 [11136/14860 (74%)]\tLoss: 0.019479\n",
      "Train Epoch: 44 [11264/14860 (75%)]\tLoss: 0.021948\n",
      "Train Epoch: 44 [11392/14860 (76%)]\tLoss: 0.017229\n",
      "Train Epoch: 44 [11520/14860 (77%)]\tLoss: 0.027374\n",
      "Train Epoch: 44 [11648/14860 (78%)]\tLoss: 0.019562\n",
      "Train Epoch: 44 [11776/14860 (79%)]\tLoss: 0.013902\n",
      "Train Epoch: 44 [11904/14860 (79%)]\tLoss: 0.014128\n",
      "Train Epoch: 44 [12032/14860 (80%)]\tLoss: 0.016857\n",
      "Train Epoch: 44 [12160/14860 (81%)]\tLoss: 0.019204\n",
      "Train Epoch: 44 [12288/14860 (82%)]\tLoss: 0.020632\n",
      "Train Epoch: 44 [12416/14860 (83%)]\tLoss: 0.018525\n",
      "Train Epoch: 44 [12544/14860 (84%)]\tLoss: 0.015505\n",
      "Train Epoch: 44 [12672/14860 (85%)]\tLoss: 0.018564\n",
      "Train Epoch: 44 [12800/14860 (85%)]\tLoss: 0.020234\n",
      "Train Epoch: 44 [12928/14860 (86%)]\tLoss: 0.015253\n",
      "Train Epoch: 44 [13056/14860 (87%)]\tLoss: 0.026979\n",
      "Train Epoch: 44 [13184/14860 (88%)]\tLoss: 0.024870\n",
      "Train Epoch: 44 [13312/14860 (89%)]\tLoss: 0.022440\n",
      "Train Epoch: 44 [13440/14860 (90%)]\tLoss: 0.020707\n",
      "Train Epoch: 44 [13568/14860 (91%)]\tLoss: 0.014317\n",
      "Train Epoch: 44 [13696/14860 (91%)]\tLoss: 0.024613\n",
      "Train Epoch: 44 [13824/14860 (92%)]\tLoss: 0.012926\n",
      "Train Epoch: 44 [13952/14860 (93%)]\tLoss: 0.024409\n",
      "Train Epoch: 44 [14080/14860 (94%)]\tLoss: 0.022523\n",
      "Train Epoch: 44 [14208/14860 (95%)]\tLoss: 0.016345\n",
      "Train Epoch: 44 [14336/14860 (96%)]\tLoss: 0.012941\n",
      "Train Epoch: 44 [14464/14860 (97%)]\tLoss: 0.017122\n",
      "Train Epoch: 44 [14592/14860 (97%)]\tLoss: 0.023904\n",
      "Train Epoch: 44 [14720/14860 (98%)]\tLoss: 0.019309\n",
      "Train Epoch: 44 [1392/14860 (99%)]\tLoss: 0.019873\n",
      "epoch 44 training loss: 0.02209949139187224\n",
      "epoch 44 validation loss: 0.025428862894995737\n",
      "Train Epoch: 45 [0/14860 (0%)]\tLoss: 0.024311\n",
      "Train Epoch: 45 [128/14860 (1%)]\tLoss: 0.017899\n",
      "Train Epoch: 45 [256/14860 (2%)]\tLoss: 0.025365\n",
      "Train Epoch: 45 [384/14860 (3%)]\tLoss: 0.013437\n",
      "Train Epoch: 45 [512/14860 (3%)]\tLoss: 0.024317\n",
      "Train Epoch: 45 [640/14860 (4%)]\tLoss: 0.019712\n",
      "Train Epoch: 45 [768/14860 (5%)]\tLoss: 0.023042\n",
      "Train Epoch: 45 [896/14860 (6%)]\tLoss: 0.017286\n",
      "Train Epoch: 45 [1024/14860 (7%)]\tLoss: 0.026442\n",
      "Train Epoch: 45 [1152/14860 (8%)]\tLoss: 0.022653\n",
      "Train Epoch: 45 [1280/14860 (9%)]\tLoss: 0.025734\n",
      "Train Epoch: 45 [1408/14860 (9%)]\tLoss: 0.031593\n",
      "Train Epoch: 45 [1536/14860 (10%)]\tLoss: 0.026054\n",
      "Train Epoch: 45 [1664/14860 (11%)]\tLoss: 0.035351\n",
      "Train Epoch: 45 [1792/14860 (12%)]\tLoss: 0.016720\n",
      "Train Epoch: 45 [1920/14860 (13%)]\tLoss: 0.022547\n",
      "Train Epoch: 45 [2048/14860 (14%)]\tLoss: 0.024525\n",
      "Train Epoch: 45 [2176/14860 (15%)]\tLoss: 0.014898\n",
      "Train Epoch: 45 [2304/14860 (15%)]\tLoss: 0.033579\n",
      "Train Epoch: 45 [2432/14860 (16%)]\tLoss: 0.014535\n",
      "Train Epoch: 45 [2560/14860 (17%)]\tLoss: 0.017670\n",
      "Train Epoch: 45 [2688/14860 (18%)]\tLoss: 0.021724\n",
      "Train Epoch: 45 [2816/14860 (19%)]\tLoss: 0.018660\n",
      "Train Epoch: 45 [2944/14860 (20%)]\tLoss: 0.016170\n",
      "Train Epoch: 45 [3072/14860 (21%)]\tLoss: 0.017609\n",
      "Train Epoch: 45 [3200/14860 (21%)]\tLoss: 0.020002\n",
      "Train Epoch: 45 [3328/14860 (22%)]\tLoss: 0.024244\n",
      "Train Epoch: 45 [3456/14860 (23%)]\tLoss: 0.020113\n",
      "Train Epoch: 45 [3584/14860 (24%)]\tLoss: 0.025180\n",
      "Train Epoch: 45 [3712/14860 (25%)]\tLoss: 0.019804\n",
      "Train Epoch: 45 [3840/14860 (26%)]\tLoss: 0.016520\n",
      "Train Epoch: 45 [3968/14860 (26%)]\tLoss: 0.018616\n",
      "Train Epoch: 45 [4096/14860 (27%)]\tLoss: 0.019460\n",
      "Train Epoch: 45 [4224/14860 (28%)]\tLoss: 0.022809\n",
      "Train Epoch: 45 [4352/14860 (29%)]\tLoss: 0.017417\n",
      "Train Epoch: 45 [4480/14860 (30%)]\tLoss: 0.021121\n",
      "Train Epoch: 45 [4608/14860 (31%)]\tLoss: 0.017221\n",
      "Train Epoch: 45 [4736/14860 (32%)]\tLoss: 0.016795\n",
      "Train Epoch: 45 [4864/14860 (32%)]\tLoss: 0.025920\n",
      "Train Epoch: 45 [4992/14860 (33%)]\tLoss: 0.017487\n",
      "Train Epoch: 45 [5120/14860 (34%)]\tLoss: 0.016324\n",
      "Train Epoch: 45 [5248/14860 (35%)]\tLoss: 0.012581\n",
      "Train Epoch: 45 [5376/14860 (36%)]\tLoss: 0.030661\n",
      "Train Epoch: 45 [5504/14860 (37%)]\tLoss: 0.021029\n",
      "Train Epoch: 45 [5632/14860 (38%)]\tLoss: 0.012629\n",
      "Train Epoch: 45 [5760/14860 (38%)]\tLoss: 0.022340\n",
      "Train Epoch: 45 [5888/14860 (39%)]\tLoss: 0.024449\n",
      "Train Epoch: 45 [6016/14860 (40%)]\tLoss: 0.021225\n",
      "Train Epoch: 45 [6144/14860 (41%)]\tLoss: 0.024164\n",
      "Train Epoch: 45 [6272/14860 (42%)]\tLoss: 0.025748\n",
      "Train Epoch: 45 [6400/14860 (43%)]\tLoss: 0.016764\n",
      "Train Epoch: 45 [6528/14860 (44%)]\tLoss: 0.017108\n",
      "Train Epoch: 45 [6656/14860 (44%)]\tLoss: 0.026553\n",
      "Train Epoch: 45 [6784/14860 (45%)]\tLoss: 0.018101\n",
      "Train Epoch: 45 [6912/14860 (46%)]\tLoss: 0.018296\n",
      "Train Epoch: 45 [7040/14860 (47%)]\tLoss: 0.020140\n",
      "Train Epoch: 45 [7168/14860 (48%)]\tLoss: 0.025102\n",
      "Train Epoch: 45 [7296/14860 (49%)]\tLoss: 0.015116\n",
      "Train Epoch: 45 [7424/14860 (50%)]\tLoss: 0.016954\n",
      "Train Epoch: 45 [7552/14860 (50%)]\tLoss: 0.028830\n",
      "Train Epoch: 45 [7680/14860 (51%)]\tLoss: 0.017341\n",
      "Train Epoch: 45 [7808/14860 (52%)]\tLoss: 0.025749\n",
      "Train Epoch: 45 [7936/14860 (53%)]\tLoss: 0.014813\n",
      "Train Epoch: 45 [8064/14860 (54%)]\tLoss: 0.019692\n",
      "Train Epoch: 45 [8192/14860 (55%)]\tLoss: 0.021987\n",
      "Train Epoch: 45 [8320/14860 (56%)]\tLoss: 0.022953\n",
      "Train Epoch: 45 [8448/14860 (56%)]\tLoss: 0.018603\n",
      "Train Epoch: 45 [8576/14860 (57%)]\tLoss: 0.024378\n",
      "Train Epoch: 45 [8704/14860 (58%)]\tLoss: 0.016395\n",
      "Train Epoch: 45 [8832/14860 (59%)]\tLoss: 0.021040\n",
      "Train Epoch: 45 [8960/14860 (60%)]\tLoss: 0.017068\n",
      "Train Epoch: 45 [9088/14860 (61%)]\tLoss: 0.022460\n",
      "Train Epoch: 45 [9216/14860 (62%)]\tLoss: 0.023987\n",
      "Train Epoch: 45 [9344/14860 (62%)]\tLoss: 0.024009\n",
      "Train Epoch: 45 [9472/14860 (63%)]\tLoss: 0.017648\n",
      "Train Epoch: 45 [9600/14860 (64%)]\tLoss: 0.021254\n",
      "Train Epoch: 45 [9728/14860 (65%)]\tLoss: 0.033041\n",
      "Train Epoch: 45 [9856/14860 (66%)]\tLoss: 0.015089\n",
      "Train Epoch: 45 [9984/14860 (67%)]\tLoss: 0.029874\n",
      "Train Epoch: 45 [10112/14860 (68%)]\tLoss: 0.022836\n",
      "Train Epoch: 45 [10240/14860 (68%)]\tLoss: 0.016186\n",
      "Train Epoch: 45 [10368/14860 (69%)]\tLoss: 0.015598\n",
      "Train Epoch: 45 [10496/14860 (70%)]\tLoss: 0.017419\n",
      "Train Epoch: 45 [10624/14860 (71%)]\tLoss: 0.022718\n",
      "Train Epoch: 45 [10752/14860 (72%)]\tLoss: 0.016351\n",
      "Train Epoch: 45 [10880/14860 (73%)]\tLoss: 0.017786\n",
      "Train Epoch: 45 [11008/14860 (74%)]\tLoss: 0.022980\n",
      "Train Epoch: 45 [11136/14860 (74%)]\tLoss: 0.018011\n",
      "Train Epoch: 45 [11264/14860 (75%)]\tLoss: 0.026404\n",
      "Train Epoch: 45 [11392/14860 (76%)]\tLoss: 0.017676\n",
      "Train Epoch: 45 [11520/14860 (77%)]\tLoss: 0.024561\n",
      "Train Epoch: 45 [11648/14860 (78%)]\tLoss: 0.024217\n",
      "Train Epoch: 45 [11776/14860 (79%)]\tLoss: 0.023138\n",
      "Train Epoch: 45 [11904/14860 (79%)]\tLoss: 0.022946\n",
      "Train Epoch: 45 [12032/14860 (80%)]\tLoss: 0.023690\n",
      "Train Epoch: 45 [12160/14860 (81%)]\tLoss: 0.019360\n",
      "Train Epoch: 45 [12288/14860 (82%)]\tLoss: 0.025950\n",
      "Train Epoch: 45 [12416/14860 (83%)]\tLoss: 0.021212\n",
      "Train Epoch: 45 [12544/14860 (84%)]\tLoss: 0.032008\n",
      "Train Epoch: 45 [12672/14860 (85%)]\tLoss: 0.021261\n",
      "Train Epoch: 45 [12800/14860 (85%)]\tLoss: 0.016287\n",
      "Train Epoch: 45 [12928/14860 (86%)]\tLoss: 0.030530\n",
      "Train Epoch: 45 [13056/14860 (87%)]\tLoss: 0.014238\n",
      "Train Epoch: 45 [13184/14860 (88%)]\tLoss: 0.020242\n",
      "Train Epoch: 45 [13312/14860 (89%)]\tLoss: 0.022095\n",
      "Train Epoch: 45 [13440/14860 (90%)]\tLoss: 0.025698\n",
      "Train Epoch: 45 [13568/14860 (91%)]\tLoss: 0.018895\n",
      "Train Epoch: 45 [13696/14860 (91%)]\tLoss: 0.024153\n",
      "Train Epoch: 45 [13824/14860 (92%)]\tLoss: 0.022635\n",
      "Train Epoch: 45 [13952/14860 (93%)]\tLoss: 0.019793\n",
      "Train Epoch: 45 [14080/14860 (94%)]\tLoss: 0.029556\n",
      "Train Epoch: 45 [14208/14860 (95%)]\tLoss: 0.023074\n",
      "Train Epoch: 45 [14336/14860 (96%)]\tLoss: 0.022162\n",
      "Train Epoch: 45 [14464/14860 (97%)]\tLoss: 0.026675\n",
      "Train Epoch: 45 [14592/14860 (97%)]\tLoss: 0.020646\n",
      "Train Epoch: 45 [14720/14860 (98%)]\tLoss: 0.016879\n",
      "Train Epoch: 45 [1392/14860 (99%)]\tLoss: 0.033352\n",
      "epoch 45 training loss: 0.021497915427272137\n",
      "epoch 45 validation loss: 0.020946410175674477\n",
      "Train Epoch: 46 [0/14860 (0%)]\tLoss: 0.018764\n",
      "Train Epoch: 46 [128/14860 (1%)]\tLoss: 0.022884\n",
      "Train Epoch: 46 [256/14860 (2%)]\tLoss: 0.017300\n",
      "Train Epoch: 46 [384/14860 (3%)]\tLoss: 0.021483\n",
      "Train Epoch: 46 [512/14860 (3%)]\tLoss: 0.019827\n",
      "Train Epoch: 46 [640/14860 (4%)]\tLoss: 0.015101\n",
      "Train Epoch: 46 [768/14860 (5%)]\tLoss: 0.022010\n",
      "Train Epoch: 46 [896/14860 (6%)]\tLoss: 0.021364\n",
      "Train Epoch: 46 [1024/14860 (7%)]\tLoss: 0.024803\n",
      "Train Epoch: 46 [1152/14860 (8%)]\tLoss: 0.013359\n",
      "Train Epoch: 46 [1280/14860 (9%)]\tLoss: 0.016101\n",
      "Train Epoch: 46 [1408/14860 (9%)]\tLoss: 0.025224\n",
      "Train Epoch: 46 [1536/14860 (10%)]\tLoss: 0.025367\n",
      "Train Epoch: 46 [1664/14860 (11%)]\tLoss: 0.018262\n",
      "Train Epoch: 46 [1792/14860 (12%)]\tLoss: 0.020373\n",
      "Train Epoch: 46 [1920/14860 (13%)]\tLoss: 0.018717\n",
      "Train Epoch: 46 [2048/14860 (14%)]\tLoss: 0.012077\n",
      "Train Epoch: 46 [2176/14860 (15%)]\tLoss: 0.013914\n",
      "Train Epoch: 46 [2304/14860 (15%)]\tLoss: 0.016521\n",
      "Train Epoch: 46 [2432/14860 (16%)]\tLoss: 0.019171\n",
      "Train Epoch: 46 [2560/14860 (17%)]\tLoss: 0.021577\n",
      "Train Epoch: 46 [2688/14860 (18%)]\tLoss: 0.019826\n",
      "Train Epoch: 46 [2816/14860 (19%)]\tLoss: 0.020496\n",
      "Train Epoch: 46 [2944/14860 (20%)]\tLoss: 0.020550\n",
      "Train Epoch: 46 [3072/14860 (21%)]\tLoss: 0.020007\n",
      "Train Epoch: 46 [3200/14860 (21%)]\tLoss: 0.018034\n",
      "Train Epoch: 46 [3328/14860 (22%)]\tLoss: 0.019173\n",
      "Train Epoch: 46 [3456/14860 (23%)]\tLoss: 0.018248\n",
      "Train Epoch: 46 [3584/14860 (24%)]\tLoss: 0.020660\n",
      "Train Epoch: 46 [3712/14860 (25%)]\tLoss: 0.028522\n",
      "Train Epoch: 46 [3840/14860 (26%)]\tLoss: 0.017528\n",
      "Train Epoch: 46 [3968/14860 (26%)]\tLoss: 0.015822\n",
      "Train Epoch: 46 [4096/14860 (27%)]\tLoss: 0.021396\n",
      "Train Epoch: 46 [4224/14860 (28%)]\tLoss: 0.020084\n",
      "Train Epoch: 46 [4352/14860 (29%)]\tLoss: 0.035269\n",
      "Train Epoch: 46 [4480/14860 (30%)]\tLoss: 0.024898\n",
      "Train Epoch: 46 [4608/14860 (31%)]\tLoss: 0.028641\n",
      "Train Epoch: 46 [4736/14860 (32%)]\tLoss: 0.039323\n",
      "Train Epoch: 46 [4864/14860 (32%)]\tLoss: 0.021085\n",
      "Train Epoch: 46 [4992/14860 (33%)]\tLoss: 0.019541\n",
      "Train Epoch: 46 [5120/14860 (34%)]\tLoss: 0.013936\n",
      "Train Epoch: 46 [5248/14860 (35%)]\tLoss: 0.026467\n",
      "Train Epoch: 46 [5376/14860 (36%)]\tLoss: 0.026286\n",
      "Train Epoch: 46 [5504/14860 (37%)]\tLoss: 0.019039\n",
      "Train Epoch: 46 [5632/14860 (38%)]\tLoss: 0.028039\n",
      "Train Epoch: 46 [5760/14860 (38%)]\tLoss: 0.019459\n",
      "Train Epoch: 46 [5888/14860 (39%)]\tLoss: 0.035726\n",
      "Train Epoch: 46 [6016/14860 (40%)]\tLoss: 0.019085\n",
      "Train Epoch: 46 [6144/14860 (41%)]\tLoss: 0.035948\n",
      "Train Epoch: 46 [6272/14860 (42%)]\tLoss: 0.017059\n",
      "Train Epoch: 46 [6400/14860 (43%)]\tLoss: 0.036552\n",
      "Train Epoch: 46 [6528/14860 (44%)]\tLoss: 0.026599\n",
      "Train Epoch: 46 [6656/14860 (44%)]\tLoss: 0.026492\n",
      "Train Epoch: 46 [6784/14860 (45%)]\tLoss: 0.038550\n",
      "Train Epoch: 46 [6912/14860 (46%)]\tLoss: 0.016339\n",
      "Train Epoch: 46 [7040/14860 (47%)]\tLoss: 0.030642\n",
      "Train Epoch: 46 [7168/14860 (48%)]\tLoss: 0.025818\n",
      "Train Epoch: 46 [7296/14860 (49%)]\tLoss: 0.019135\n",
      "Train Epoch: 46 [7424/14860 (50%)]\tLoss: 0.027399\n",
      "Train Epoch: 46 [7552/14860 (50%)]\tLoss: 0.022401\n",
      "Train Epoch: 46 [7680/14860 (51%)]\tLoss: 0.019165\n",
      "Train Epoch: 46 [7808/14860 (52%)]\tLoss: 0.023967\n",
      "Train Epoch: 46 [7936/14860 (53%)]\tLoss: 0.015294\n",
      "Train Epoch: 46 [8064/14860 (54%)]\tLoss: 0.018301\n",
      "Train Epoch: 46 [8192/14860 (55%)]\tLoss: 0.013870\n",
      "Train Epoch: 46 [8320/14860 (56%)]\tLoss: 0.020773\n",
      "Train Epoch: 46 [8448/14860 (56%)]\tLoss: 0.023153\n",
      "Train Epoch: 46 [8576/14860 (57%)]\tLoss: 0.025587\n",
      "Train Epoch: 46 [8704/14860 (58%)]\tLoss: 0.021270\n",
      "Train Epoch: 46 [8832/14860 (59%)]\tLoss: 0.025638\n",
      "Train Epoch: 46 [8960/14860 (60%)]\tLoss: 0.022256\n",
      "Train Epoch: 46 [9088/14860 (61%)]\tLoss: 0.027216\n",
      "Train Epoch: 46 [9216/14860 (62%)]\tLoss: 0.021885\n",
      "Train Epoch: 46 [9344/14860 (62%)]\tLoss: 0.018701\n",
      "Train Epoch: 46 [9472/14860 (63%)]\tLoss: 0.017181\n",
      "Train Epoch: 46 [9600/14860 (64%)]\tLoss: 0.017269\n",
      "Train Epoch: 46 [9728/14860 (65%)]\tLoss: 0.017893\n",
      "Train Epoch: 46 [9856/14860 (66%)]\tLoss: 0.022488\n",
      "Train Epoch: 46 [9984/14860 (67%)]\tLoss: 0.021748\n",
      "Train Epoch: 46 [10112/14860 (68%)]\tLoss: 0.013483\n",
      "Train Epoch: 46 [10240/14860 (68%)]\tLoss: 0.014549\n",
      "Train Epoch: 46 [10368/14860 (69%)]\tLoss: 0.024523\n",
      "Train Epoch: 46 [10496/14860 (70%)]\tLoss: 0.018722\n",
      "Train Epoch: 46 [10624/14860 (71%)]\tLoss: 0.017181\n",
      "Train Epoch: 46 [10752/14860 (72%)]\tLoss: 0.021951\n",
      "Train Epoch: 46 [10880/14860 (73%)]\tLoss: 0.028043\n",
      "Train Epoch: 46 [11008/14860 (74%)]\tLoss: 0.021533\n",
      "Train Epoch: 46 [11136/14860 (74%)]\tLoss: 0.026658\n",
      "Train Epoch: 46 [11264/14860 (75%)]\tLoss: 0.014552\n",
      "Train Epoch: 46 [11392/14860 (76%)]\tLoss: 0.023081\n",
      "Train Epoch: 46 [11520/14860 (77%)]\tLoss: 0.032487\n",
      "Train Epoch: 46 [11648/14860 (78%)]\tLoss: 0.020780\n",
      "Train Epoch: 46 [11776/14860 (79%)]\tLoss: 0.025368\n",
      "Train Epoch: 46 [11904/14860 (79%)]\tLoss: 0.025637\n",
      "Train Epoch: 46 [12032/14860 (80%)]\tLoss: 0.022333\n",
      "Train Epoch: 46 [12160/14860 (81%)]\tLoss: 0.021133\n",
      "Train Epoch: 46 [12288/14860 (82%)]\tLoss: 0.022429\n",
      "Train Epoch: 46 [12416/14860 (83%)]\tLoss: 0.017395\n",
      "Train Epoch: 46 [12544/14860 (84%)]\tLoss: 0.012667\n",
      "Train Epoch: 46 [12672/14860 (85%)]\tLoss: 0.023411\n",
      "Train Epoch: 46 [12800/14860 (85%)]\tLoss: 0.022820\n",
      "Train Epoch: 46 [12928/14860 (86%)]\tLoss: 0.022145\n",
      "Train Epoch: 46 [13056/14860 (87%)]\tLoss: 0.016614\n",
      "Train Epoch: 46 [13184/14860 (88%)]\tLoss: 0.028053\n",
      "Train Epoch: 46 [13312/14860 (89%)]\tLoss: 0.019514\n",
      "Train Epoch: 46 [13440/14860 (90%)]\tLoss: 0.020846\n",
      "Train Epoch: 46 [13568/14860 (91%)]\tLoss: 0.021245\n",
      "Train Epoch: 46 [13696/14860 (91%)]\tLoss: 0.020760\n",
      "Train Epoch: 46 [13824/14860 (92%)]\tLoss: 0.015774\n",
      "Train Epoch: 46 [13952/14860 (93%)]\tLoss: 0.021554\n",
      "Train Epoch: 46 [14080/14860 (94%)]\tLoss: 0.022090\n",
      "Train Epoch: 46 [14208/14860 (95%)]\tLoss: 0.024608\n",
      "Train Epoch: 46 [14336/14860 (96%)]\tLoss: 0.017108\n",
      "Train Epoch: 46 [14464/14860 (97%)]\tLoss: 0.019100\n",
      "Train Epoch: 46 [14592/14860 (97%)]\tLoss: 0.023150\n",
      "Train Epoch: 46 [14720/14860 (98%)]\tLoss: 0.019809\n",
      "Train Epoch: 46 [1392/14860 (99%)]\tLoss: 0.006100\n",
      "epoch 46 training loss: 0.021599413978302073\n",
      "epoch 46 validation loss: 0.04187976491364671\n",
      "Train Epoch: 47 [0/14860 (0%)]\tLoss: 0.052550\n",
      "Train Epoch: 47 [128/14860 (1%)]\tLoss: 0.014716\n",
      "Train Epoch: 47 [256/14860 (2%)]\tLoss: 0.024222\n",
      "Train Epoch: 47 [384/14860 (3%)]\tLoss: 0.025873\n",
      "Train Epoch: 47 [512/14860 (3%)]\tLoss: 0.021906\n",
      "Train Epoch: 47 [640/14860 (4%)]\tLoss: 0.016884\n",
      "Train Epoch: 47 [768/14860 (5%)]\tLoss: 0.024757\n",
      "Train Epoch: 47 [896/14860 (6%)]\tLoss: 0.022773\n",
      "Train Epoch: 47 [1024/14860 (7%)]\tLoss: 0.021187\n",
      "Train Epoch: 47 [1152/14860 (8%)]\tLoss: 0.026710\n",
      "Train Epoch: 47 [1280/14860 (9%)]\tLoss: 0.030461\n",
      "Train Epoch: 47 [1408/14860 (9%)]\tLoss: 0.015721\n",
      "Train Epoch: 47 [1536/14860 (10%)]\tLoss: 0.023331\n",
      "Train Epoch: 47 [1664/14860 (11%)]\tLoss: 0.016042\n",
      "Train Epoch: 47 [1792/14860 (12%)]\tLoss: 0.024853\n",
      "Train Epoch: 47 [1920/14860 (13%)]\tLoss: 0.029220\n",
      "Train Epoch: 47 [2048/14860 (14%)]\tLoss: 0.023487\n",
      "Train Epoch: 47 [2176/14860 (15%)]\tLoss: 0.023998\n",
      "Train Epoch: 47 [2304/14860 (15%)]\tLoss: 0.019075\n",
      "Train Epoch: 47 [2432/14860 (16%)]\tLoss: 0.014925\n",
      "Train Epoch: 47 [2560/14860 (17%)]\tLoss: 0.025223\n",
      "Train Epoch: 47 [2688/14860 (18%)]\tLoss: 0.020630\n",
      "Train Epoch: 47 [2816/14860 (19%)]\tLoss: 0.027018\n",
      "Train Epoch: 47 [2944/14860 (20%)]\tLoss: 0.023266\n",
      "Train Epoch: 47 [3072/14860 (21%)]\tLoss: 0.015953\n",
      "Train Epoch: 47 [3200/14860 (21%)]\tLoss: 0.020759\n",
      "Train Epoch: 47 [3328/14860 (22%)]\tLoss: 0.022638\n",
      "Train Epoch: 47 [3456/14860 (23%)]\tLoss: 0.021789\n",
      "Train Epoch: 47 [3584/14860 (24%)]\tLoss: 0.014005\n",
      "Train Epoch: 47 [3712/14860 (25%)]\tLoss: 0.023401\n",
      "Train Epoch: 47 [3840/14860 (26%)]\tLoss: 0.017912\n",
      "Train Epoch: 47 [3968/14860 (26%)]\tLoss: 0.014203\n",
      "Train Epoch: 47 [4096/14860 (27%)]\tLoss: 0.011869\n",
      "Train Epoch: 47 [4224/14860 (28%)]\tLoss: 0.017763\n",
      "Train Epoch: 47 [4352/14860 (29%)]\tLoss: 0.018891\n",
      "Train Epoch: 47 [4480/14860 (30%)]\tLoss: 0.018528\n",
      "Train Epoch: 47 [4608/14860 (31%)]\tLoss: 0.017854\n",
      "Train Epoch: 47 [4736/14860 (32%)]\tLoss: 0.020747\n",
      "Train Epoch: 47 [4864/14860 (32%)]\tLoss: 0.025267\n",
      "Train Epoch: 47 [4992/14860 (33%)]\tLoss: 0.022542\n",
      "Train Epoch: 47 [5120/14860 (34%)]\tLoss: 0.028288\n",
      "Train Epoch: 47 [5248/14860 (35%)]\tLoss: 0.022019\n",
      "Train Epoch: 47 [5376/14860 (36%)]\tLoss: 0.029332\n",
      "Train Epoch: 47 [5504/14860 (37%)]\tLoss: 0.020798\n",
      "Train Epoch: 47 [5632/14860 (38%)]\tLoss: 0.030503\n",
      "Train Epoch: 47 [5760/14860 (38%)]\tLoss: 0.021440\n",
      "Train Epoch: 47 [5888/14860 (39%)]\tLoss: 0.019799\n",
      "Train Epoch: 47 [6016/14860 (40%)]\tLoss: 0.019589\n",
      "Train Epoch: 47 [6144/14860 (41%)]\tLoss: 0.019816\n",
      "Train Epoch: 47 [6272/14860 (42%)]\tLoss: 0.025923\n",
      "Train Epoch: 47 [6400/14860 (43%)]\tLoss: 0.019252\n",
      "Train Epoch: 47 [6528/14860 (44%)]\tLoss: 0.016572\n",
      "Train Epoch: 47 [6656/14860 (44%)]\tLoss: 0.021862\n",
      "Train Epoch: 47 [6784/14860 (45%)]\tLoss: 0.025513\n",
      "Train Epoch: 47 [6912/14860 (46%)]\tLoss: 0.022088\n",
      "Train Epoch: 47 [7040/14860 (47%)]\tLoss: 0.021489\n",
      "Train Epoch: 47 [7168/14860 (48%)]\tLoss: 0.018918\n",
      "Train Epoch: 47 [7296/14860 (49%)]\tLoss: 0.021556\n",
      "Train Epoch: 47 [7424/14860 (50%)]\tLoss: 0.026851\n",
      "Train Epoch: 47 [7552/14860 (50%)]\tLoss: 0.020432\n",
      "Train Epoch: 47 [7680/14860 (51%)]\tLoss: 0.027161\n",
      "Train Epoch: 47 [7808/14860 (52%)]\tLoss: 0.011937\n",
      "Train Epoch: 47 [7936/14860 (53%)]\tLoss: 0.026968\n",
      "Train Epoch: 47 [8064/14860 (54%)]\tLoss: 0.020368\n",
      "Train Epoch: 47 [8192/14860 (55%)]\tLoss: 0.013941\n",
      "Train Epoch: 47 [8320/14860 (56%)]\tLoss: 0.014906\n",
      "Train Epoch: 47 [8448/14860 (56%)]\tLoss: 0.020654\n",
      "Train Epoch: 47 [8576/14860 (57%)]\tLoss: 0.024132\n",
      "Train Epoch: 47 [8704/14860 (58%)]\tLoss: 0.021820\n",
      "Train Epoch: 47 [8832/14860 (59%)]\tLoss: 0.015456\n",
      "Train Epoch: 47 [8960/14860 (60%)]\tLoss: 0.025939\n",
      "Train Epoch: 47 [9088/14860 (61%)]\tLoss: 0.022144\n",
      "Train Epoch: 47 [9216/14860 (62%)]\tLoss: 0.022289\n",
      "Train Epoch: 47 [9344/14860 (62%)]\tLoss: 0.021572\n",
      "Train Epoch: 47 [9472/14860 (63%)]\tLoss: 0.016446\n",
      "Train Epoch: 47 [9600/14860 (64%)]\tLoss: 0.018699\n",
      "Train Epoch: 47 [9728/14860 (65%)]\tLoss: 0.026202\n",
      "Train Epoch: 47 [9856/14860 (66%)]\tLoss: 0.021105\n",
      "Train Epoch: 47 [9984/14860 (67%)]\tLoss: 0.016437\n",
      "Train Epoch: 47 [10112/14860 (68%)]\tLoss: 0.011857\n",
      "Train Epoch: 47 [10240/14860 (68%)]\tLoss: 0.025564\n",
      "Train Epoch: 47 [10368/14860 (69%)]\tLoss: 0.021307\n",
      "Train Epoch: 47 [10496/14860 (70%)]\tLoss: 0.018376\n",
      "Train Epoch: 47 [10624/14860 (71%)]\tLoss: 0.022730\n",
      "Train Epoch: 47 [10752/14860 (72%)]\tLoss: 0.019102\n",
      "Train Epoch: 47 [10880/14860 (73%)]\tLoss: 0.017826\n",
      "Train Epoch: 47 [11008/14860 (74%)]\tLoss: 0.019760\n",
      "Train Epoch: 47 [11136/14860 (74%)]\tLoss: 0.036164\n",
      "Train Epoch: 47 [11264/14860 (75%)]\tLoss: 0.030735\n",
      "Train Epoch: 47 [11392/14860 (76%)]\tLoss: 0.021080\n",
      "Train Epoch: 47 [11520/14860 (77%)]\tLoss: 0.033821\n",
      "Train Epoch: 47 [11648/14860 (78%)]\tLoss: 0.017783\n",
      "Train Epoch: 47 [11776/14860 (79%)]\tLoss: 0.024341\n",
      "Train Epoch: 47 [11904/14860 (79%)]\tLoss: 0.020184\n",
      "Train Epoch: 47 [12032/14860 (80%)]\tLoss: 0.020191\n",
      "Train Epoch: 47 [12160/14860 (81%)]\tLoss: 0.015028\n",
      "Train Epoch: 47 [12288/14860 (82%)]\tLoss: 0.018080\n",
      "Train Epoch: 47 [12416/14860 (83%)]\tLoss: 0.015444\n",
      "Train Epoch: 47 [12544/14860 (84%)]\tLoss: 0.018127\n",
      "Train Epoch: 47 [12672/14860 (85%)]\tLoss: 0.019180\n",
      "Train Epoch: 47 [12800/14860 (85%)]\tLoss: 0.020979\n",
      "Train Epoch: 47 [12928/14860 (86%)]\tLoss: 0.017412\n",
      "Train Epoch: 47 [13056/14860 (87%)]\tLoss: 0.014752\n",
      "Train Epoch: 47 [13184/14860 (88%)]\tLoss: 0.021382\n",
      "Train Epoch: 47 [13312/14860 (89%)]\tLoss: 0.017671\n",
      "Train Epoch: 47 [13440/14860 (90%)]\tLoss: 0.015375\n",
      "Train Epoch: 47 [13568/14860 (91%)]\tLoss: 0.018452\n",
      "Train Epoch: 47 [13696/14860 (91%)]\tLoss: 0.015338\n",
      "Train Epoch: 47 [13824/14860 (92%)]\tLoss: 0.021106\n",
      "Train Epoch: 47 [13952/14860 (93%)]\tLoss: 0.026343\n",
      "Train Epoch: 47 [14080/14860 (94%)]\tLoss: 0.019551\n",
      "Train Epoch: 47 [14208/14860 (95%)]\tLoss: 0.019327\n",
      "Train Epoch: 47 [14336/14860 (96%)]\tLoss: 0.028312\n",
      "Train Epoch: 47 [14464/14860 (97%)]\tLoss: 0.026958\n",
      "Train Epoch: 47 [14592/14860 (97%)]\tLoss: 0.017203\n",
      "Train Epoch: 47 [14720/14860 (98%)]\tLoss: 0.026277\n",
      "Train Epoch: 47 [1392/14860 (99%)]\tLoss: 0.022318\n",
      "epoch 47 training loss: 0.021441024505238757\n",
      "epoch 47 validation loss: 0.023978038215175378\n",
      "Train Epoch: 48 [0/14860 (0%)]\tLoss: 0.024274\n",
      "Train Epoch: 48 [128/14860 (1%)]\tLoss: 0.019198\n",
      "Train Epoch: 48 [256/14860 (2%)]\tLoss: 0.024816\n",
      "Train Epoch: 48 [384/14860 (3%)]\tLoss: 0.018562\n",
      "Train Epoch: 48 [512/14860 (3%)]\tLoss: 0.020592\n",
      "Train Epoch: 48 [640/14860 (4%)]\tLoss: 0.027208\n",
      "Train Epoch: 48 [768/14860 (5%)]\tLoss: 0.020424\n",
      "Train Epoch: 48 [896/14860 (6%)]\tLoss: 0.025431\n",
      "Train Epoch: 48 [1024/14860 (7%)]\tLoss: 0.020194\n",
      "Train Epoch: 48 [1152/14860 (8%)]\tLoss: 0.019712\n",
      "Train Epoch: 48 [1280/14860 (9%)]\tLoss: 0.023028\n",
      "Train Epoch: 48 [1408/14860 (9%)]\tLoss: 0.019689\n",
      "Train Epoch: 48 [1536/14860 (10%)]\tLoss: 0.016780\n",
      "Train Epoch: 48 [1664/14860 (11%)]\tLoss: 0.015393\n",
      "Train Epoch: 48 [1792/14860 (12%)]\tLoss: 0.022915\n",
      "Train Epoch: 48 [1920/14860 (13%)]\tLoss: 0.012623\n",
      "Train Epoch: 48 [2048/14860 (14%)]\tLoss: 0.024190\n",
      "Train Epoch: 48 [2176/14860 (15%)]\tLoss: 0.027609\n",
      "Train Epoch: 48 [2304/14860 (15%)]\tLoss: 0.022412\n",
      "Train Epoch: 48 [2432/14860 (16%)]\tLoss: 0.024829\n",
      "Train Epoch: 48 [2560/14860 (17%)]\tLoss: 0.019820\n",
      "Train Epoch: 48 [2688/14860 (18%)]\tLoss: 0.016251\n",
      "Train Epoch: 48 [2816/14860 (19%)]\tLoss: 0.019822\n",
      "Train Epoch: 48 [2944/14860 (20%)]\tLoss: 0.017396\n",
      "Train Epoch: 48 [3072/14860 (21%)]\tLoss: 0.019526\n",
      "Train Epoch: 48 [3200/14860 (21%)]\tLoss: 0.026351\n",
      "Train Epoch: 48 [3328/14860 (22%)]\tLoss: 0.014713\n",
      "Train Epoch: 48 [3456/14860 (23%)]\tLoss: 0.018779\n",
      "Train Epoch: 48 [3584/14860 (24%)]\tLoss: 0.022229\n",
      "Train Epoch: 48 [3712/14860 (25%)]\tLoss: 0.021685\n",
      "Train Epoch: 48 [3840/14860 (26%)]\tLoss: 0.019486\n",
      "Train Epoch: 48 [3968/14860 (26%)]\tLoss: 0.025679\n",
      "Train Epoch: 48 [4096/14860 (27%)]\tLoss: 0.016828\n",
      "Train Epoch: 48 [4224/14860 (28%)]\tLoss: 0.019700\n",
      "Train Epoch: 48 [4352/14860 (29%)]\tLoss: 0.016067\n",
      "Train Epoch: 48 [4480/14860 (30%)]\tLoss: 0.026276\n",
      "Train Epoch: 48 [4608/14860 (31%)]\tLoss: 0.022208\n",
      "Train Epoch: 48 [4736/14860 (32%)]\tLoss: 0.026875\n",
      "Train Epoch: 48 [4864/14860 (32%)]\tLoss: 0.012966\n",
      "Train Epoch: 48 [4992/14860 (33%)]\tLoss: 0.031124\n",
      "Train Epoch: 48 [5120/14860 (34%)]\tLoss: 0.014664\n",
      "Train Epoch: 48 [5248/14860 (35%)]\tLoss: 0.025030\n",
      "Train Epoch: 48 [5376/14860 (36%)]\tLoss: 0.018431\n",
      "Train Epoch: 48 [5504/14860 (37%)]\tLoss: 0.023736\n",
      "Train Epoch: 48 [5632/14860 (38%)]\tLoss: 0.020340\n",
      "Train Epoch: 48 [5760/14860 (38%)]\tLoss: 0.016975\n",
      "Train Epoch: 48 [5888/14860 (39%)]\tLoss: 0.012658\n",
      "Train Epoch: 48 [6016/14860 (40%)]\tLoss: 0.030973\n",
      "Train Epoch: 48 [6144/14860 (41%)]\tLoss: 0.022674\n",
      "Train Epoch: 48 [6272/14860 (42%)]\tLoss: 0.027745\n",
      "Train Epoch: 48 [6400/14860 (43%)]\tLoss: 0.017666\n",
      "Train Epoch: 48 [6528/14860 (44%)]\tLoss: 0.018664\n",
      "Train Epoch: 48 [6656/14860 (44%)]\tLoss: 0.024263\n",
      "Train Epoch: 48 [6784/14860 (45%)]\tLoss: 0.025882\n",
      "Train Epoch: 48 [6912/14860 (46%)]\tLoss: 0.026437\n",
      "Train Epoch: 48 [7040/14860 (47%)]\tLoss: 0.022637\n",
      "Train Epoch: 48 [7168/14860 (48%)]\tLoss: 0.020037\n",
      "Train Epoch: 48 [7296/14860 (49%)]\tLoss: 0.021163\n",
      "Train Epoch: 48 [7424/14860 (50%)]\tLoss: 0.021667\n",
      "Train Epoch: 48 [7552/14860 (50%)]\tLoss: 0.019190\n",
      "Train Epoch: 48 [7680/14860 (51%)]\tLoss: 0.024317\n",
      "Train Epoch: 48 [7808/14860 (52%)]\tLoss: 0.019082\n",
      "Train Epoch: 48 [7936/14860 (53%)]\tLoss: 0.016927\n",
      "Train Epoch: 48 [8064/14860 (54%)]\tLoss: 0.015524\n",
      "Train Epoch: 48 [8192/14860 (55%)]\tLoss: 0.021453\n",
      "Train Epoch: 48 [8320/14860 (56%)]\tLoss: 0.018837\n",
      "Train Epoch: 48 [8448/14860 (56%)]\tLoss: 0.022349\n",
      "Train Epoch: 48 [8576/14860 (57%)]\tLoss: 0.017872\n",
      "Train Epoch: 48 [8704/14860 (58%)]\tLoss: 0.018630\n",
      "Train Epoch: 48 [8832/14860 (59%)]\tLoss: 0.029267\n",
      "Train Epoch: 48 [8960/14860 (60%)]\tLoss: 0.016718\n",
      "Train Epoch: 48 [9088/14860 (61%)]\tLoss: 0.023130\n",
      "Train Epoch: 48 [9216/14860 (62%)]\tLoss: 0.027212\n",
      "Train Epoch: 48 [9344/14860 (62%)]\tLoss: 0.023759\n",
      "Train Epoch: 48 [9472/14860 (63%)]\tLoss: 0.020545\n",
      "Train Epoch: 48 [9600/14860 (64%)]\tLoss: 0.017873\n",
      "Train Epoch: 48 [9728/14860 (65%)]\tLoss: 0.024820\n",
      "Train Epoch: 48 [9856/14860 (66%)]\tLoss: 0.018913\n",
      "Train Epoch: 48 [9984/14860 (67%)]\tLoss: 0.021266\n",
      "Train Epoch: 48 [10112/14860 (68%)]\tLoss: 0.022714\n",
      "Train Epoch: 48 [10240/14860 (68%)]\tLoss: 0.022710\n",
      "Train Epoch: 48 [10368/14860 (69%)]\tLoss: 0.025744\n",
      "Train Epoch: 48 [10496/14860 (70%)]\tLoss: 0.024155\n",
      "Train Epoch: 48 [10624/14860 (71%)]\tLoss: 0.025696\n",
      "Train Epoch: 48 [10752/14860 (72%)]\tLoss: 0.016180\n",
      "Train Epoch: 48 [10880/14860 (73%)]\tLoss: 0.034164\n",
      "Train Epoch: 48 [11008/14860 (74%)]\tLoss: 0.019015\n",
      "Train Epoch: 48 [11136/14860 (74%)]\tLoss: 0.019390\n",
      "Train Epoch: 48 [11264/14860 (75%)]\tLoss: 0.021038\n",
      "Train Epoch: 48 [11392/14860 (76%)]\tLoss: 0.026276\n",
      "Train Epoch: 48 [11520/14860 (77%)]\tLoss: 0.030148\n",
      "Train Epoch: 48 [11648/14860 (78%)]\tLoss: 0.024330\n",
      "Train Epoch: 48 [11776/14860 (79%)]\tLoss: 0.018406\n",
      "Train Epoch: 48 [11904/14860 (79%)]\tLoss: 0.029435\n",
      "Train Epoch: 48 [12032/14860 (80%)]\tLoss: 0.027434\n",
      "Train Epoch: 48 [12160/14860 (81%)]\tLoss: 0.021429\n",
      "Train Epoch: 48 [12288/14860 (82%)]\tLoss: 0.018934\n",
      "Train Epoch: 48 [12416/14860 (83%)]\tLoss: 0.024354\n",
      "Train Epoch: 48 [12544/14860 (84%)]\tLoss: 0.020106\n",
      "Train Epoch: 48 [12672/14860 (85%)]\tLoss: 0.019460\n",
      "Train Epoch: 48 [12800/14860 (85%)]\tLoss: 0.020120\n",
      "Train Epoch: 48 [12928/14860 (86%)]\tLoss: 0.022520\n",
      "Train Epoch: 48 [13056/14860 (87%)]\tLoss: 0.018988\n",
      "Train Epoch: 48 [13184/14860 (88%)]\tLoss: 0.018789\n",
      "Train Epoch: 48 [13312/14860 (89%)]\tLoss: 0.024231\n",
      "Train Epoch: 48 [13440/14860 (90%)]\tLoss: 0.024136\n",
      "Train Epoch: 48 [13568/14860 (91%)]\tLoss: 0.024760\n",
      "Train Epoch: 48 [13696/14860 (91%)]\tLoss: 0.014125\n",
      "Train Epoch: 48 [13824/14860 (92%)]\tLoss: 0.016744\n",
      "Train Epoch: 48 [13952/14860 (93%)]\tLoss: 0.020874\n",
      "Train Epoch: 48 [14080/14860 (94%)]\tLoss: 0.013120\n",
      "Train Epoch: 48 [14208/14860 (95%)]\tLoss: 0.017698\n",
      "Train Epoch: 48 [14336/14860 (96%)]\tLoss: 0.023689\n",
      "Train Epoch: 48 [14464/14860 (97%)]\tLoss: 0.018874\n",
      "Train Epoch: 48 [14592/14860 (97%)]\tLoss: 0.015883\n",
      "Train Epoch: 48 [14720/14860 (98%)]\tLoss: 0.018196\n",
      "Train Epoch: 48 [1392/14860 (99%)]\tLoss: 0.026678\n",
      "epoch 48 training loss: 0.02139767117670968\n",
      "epoch 48 validation loss: 0.020827535133962193\n",
      "Train Epoch: 49 [0/14860 (0%)]\tLoss: 0.014231\n",
      "Train Epoch: 49 [128/14860 (1%)]\tLoss: 0.023861\n",
      "Train Epoch: 49 [256/14860 (2%)]\tLoss: 0.016215\n",
      "Train Epoch: 49 [384/14860 (3%)]\tLoss: 0.017773\n",
      "Train Epoch: 49 [512/14860 (3%)]\tLoss: 0.025413\n",
      "Train Epoch: 49 [640/14860 (4%)]\tLoss: 0.021442\n",
      "Train Epoch: 49 [768/14860 (5%)]\tLoss: 0.019659\n",
      "Train Epoch: 49 [896/14860 (6%)]\tLoss: 0.018652\n",
      "Train Epoch: 49 [1024/14860 (7%)]\tLoss: 0.012633\n",
      "Train Epoch: 49 [1152/14860 (8%)]\tLoss: 0.020009\n",
      "Train Epoch: 49 [1280/14860 (9%)]\tLoss: 0.028219\n",
      "Train Epoch: 49 [1408/14860 (9%)]\tLoss: 0.021180\n",
      "Train Epoch: 49 [1536/14860 (10%)]\tLoss: 0.018254\n",
      "Train Epoch: 49 [1664/14860 (11%)]\tLoss: 0.023790\n",
      "Train Epoch: 49 [1792/14860 (12%)]\tLoss: 0.016366\n",
      "Train Epoch: 49 [1920/14860 (13%)]\tLoss: 0.025963\n",
      "Train Epoch: 49 [2048/14860 (14%)]\tLoss: 0.015607\n",
      "Train Epoch: 49 [2176/14860 (15%)]\tLoss: 0.015644\n",
      "Train Epoch: 49 [2304/14860 (15%)]\tLoss: 0.028548\n",
      "Train Epoch: 49 [2432/14860 (16%)]\tLoss: 0.021435\n",
      "Train Epoch: 49 [2560/14860 (17%)]\tLoss: 0.021288\n",
      "Train Epoch: 49 [2688/14860 (18%)]\tLoss: 0.025125\n",
      "Train Epoch: 49 [2816/14860 (19%)]\tLoss: 0.015576\n",
      "Train Epoch: 49 [2944/14860 (20%)]\tLoss: 0.024018\n",
      "Train Epoch: 49 [3072/14860 (21%)]\tLoss: 0.022624\n",
      "Train Epoch: 49 [3200/14860 (21%)]\tLoss: 0.022140\n",
      "Train Epoch: 49 [3328/14860 (22%)]\tLoss: 0.026786\n",
      "Train Epoch: 49 [3456/14860 (23%)]\tLoss: 0.016884\n",
      "Train Epoch: 49 [3584/14860 (24%)]\tLoss: 0.017532\n",
      "Train Epoch: 49 [3712/14860 (25%)]\tLoss: 0.014956\n",
      "Train Epoch: 49 [3840/14860 (26%)]\tLoss: 0.020809\n",
      "Train Epoch: 49 [3968/14860 (26%)]\tLoss: 0.020259\n",
      "Train Epoch: 49 [4096/14860 (27%)]\tLoss: 0.013992\n",
      "Train Epoch: 49 [4224/14860 (28%)]\tLoss: 0.020891\n",
      "Train Epoch: 49 [4352/14860 (29%)]\tLoss: 0.021515\n",
      "Train Epoch: 49 [4480/14860 (30%)]\tLoss: 0.021063\n",
      "Train Epoch: 49 [4608/14860 (31%)]\tLoss: 0.025793\n",
      "Train Epoch: 49 [4736/14860 (32%)]\tLoss: 0.017544\n",
      "Train Epoch: 49 [4864/14860 (32%)]\tLoss: 0.019869\n",
      "Train Epoch: 49 [4992/14860 (33%)]\tLoss: 0.018663\n",
      "Train Epoch: 49 [5120/14860 (34%)]\tLoss: 0.014782\n",
      "Train Epoch: 49 [5248/14860 (35%)]\tLoss: 0.016193\n",
      "Train Epoch: 49 [5376/14860 (36%)]\tLoss: 0.023332\n",
      "Train Epoch: 49 [5504/14860 (37%)]\tLoss: 0.017955\n",
      "Train Epoch: 49 [5632/14860 (38%)]\tLoss: 0.018281\n",
      "Train Epoch: 49 [5760/14860 (38%)]\tLoss: 0.019554\n",
      "Train Epoch: 49 [5888/14860 (39%)]\tLoss: 0.017749\n",
      "Train Epoch: 49 [6016/14860 (40%)]\tLoss: 0.015751\n",
      "Train Epoch: 49 [6144/14860 (41%)]\tLoss: 0.020054\n",
      "Train Epoch: 49 [6272/14860 (42%)]\tLoss: 0.021996\n",
      "Train Epoch: 49 [6400/14860 (43%)]\tLoss: 0.021235\n",
      "Train Epoch: 49 [6528/14860 (44%)]\tLoss: 0.022031\n",
      "Train Epoch: 49 [6656/14860 (44%)]\tLoss: 0.024201\n",
      "Train Epoch: 49 [6784/14860 (45%)]\tLoss: 0.017686\n",
      "Train Epoch: 49 [6912/14860 (46%)]\tLoss: 0.020563\n",
      "Train Epoch: 49 [7040/14860 (47%)]\tLoss: 0.029296\n",
      "Train Epoch: 49 [7168/14860 (48%)]\tLoss: 0.014343\n",
      "Train Epoch: 49 [7296/14860 (49%)]\tLoss: 0.025913\n",
      "Train Epoch: 49 [7424/14860 (50%)]\tLoss: 0.016389\n",
      "Train Epoch: 49 [7552/14860 (50%)]\tLoss: 0.028755\n",
      "Train Epoch: 49 [7680/14860 (51%)]\tLoss: 0.024894\n",
      "Train Epoch: 49 [7808/14860 (52%)]\tLoss: 0.016636\n",
      "Train Epoch: 49 [7936/14860 (53%)]\tLoss: 0.019575\n",
      "Train Epoch: 49 [8064/14860 (54%)]\tLoss: 0.013428\n",
      "Train Epoch: 49 [8192/14860 (55%)]\tLoss: 0.023354\n",
      "Train Epoch: 49 [8320/14860 (56%)]\tLoss: 0.023001\n",
      "Train Epoch: 49 [8448/14860 (56%)]\tLoss: 0.019419\n",
      "Train Epoch: 49 [8576/14860 (57%)]\tLoss: 0.020114\n",
      "Train Epoch: 49 [8704/14860 (58%)]\tLoss: 0.017027\n",
      "Train Epoch: 49 [8832/14860 (59%)]\tLoss: 0.020545\n",
      "Train Epoch: 49 [8960/14860 (60%)]\tLoss: 0.014223\n",
      "Train Epoch: 49 [9088/14860 (61%)]\tLoss: 0.023275\n",
      "Train Epoch: 49 [9216/14860 (62%)]\tLoss: 0.020913\n",
      "Train Epoch: 49 [9344/14860 (62%)]\tLoss: 0.030969\n",
      "Train Epoch: 49 [9472/14860 (63%)]\tLoss: 0.021881\n",
      "Train Epoch: 49 [9600/14860 (64%)]\tLoss: 0.020091\n",
      "Train Epoch: 49 [9728/14860 (65%)]\tLoss: 0.016378\n",
      "Train Epoch: 49 [9856/14860 (66%)]\tLoss: 0.027440\n",
      "Train Epoch: 49 [9984/14860 (67%)]\tLoss: 0.021343\n",
      "Train Epoch: 49 [10112/14860 (68%)]\tLoss: 0.021877\n",
      "Train Epoch: 49 [10240/14860 (68%)]\tLoss: 0.023212\n",
      "Train Epoch: 49 [10368/14860 (69%)]\tLoss: 0.025943\n",
      "Train Epoch: 49 [10496/14860 (70%)]\tLoss: 0.023366\n",
      "Train Epoch: 49 [10624/14860 (71%)]\tLoss: 0.017072\n",
      "Train Epoch: 49 [10752/14860 (72%)]\tLoss: 0.019442\n",
      "Train Epoch: 49 [10880/14860 (73%)]\tLoss: 0.016640\n",
      "Train Epoch: 49 [11008/14860 (74%)]\tLoss: 0.030520\n",
      "Train Epoch: 49 [11136/14860 (74%)]\tLoss: 0.021925\n",
      "Train Epoch: 49 [11264/14860 (75%)]\tLoss: 0.021532\n",
      "Train Epoch: 49 [11392/14860 (76%)]\tLoss: 0.021434\n",
      "Train Epoch: 49 [11520/14860 (77%)]\tLoss: 0.019548\n",
      "Train Epoch: 49 [11648/14860 (78%)]\tLoss: 0.022713\n",
      "Train Epoch: 49 [11776/14860 (79%)]\tLoss: 0.021720\n",
      "Train Epoch: 49 [11904/14860 (79%)]\tLoss: 0.028041\n",
      "Train Epoch: 49 [12032/14860 (80%)]\tLoss: 0.024479\n",
      "Train Epoch: 49 [12160/14860 (81%)]\tLoss: 0.028737\n",
      "Train Epoch: 49 [12288/14860 (82%)]\tLoss: 0.016787\n",
      "Train Epoch: 49 [12416/14860 (83%)]\tLoss: 0.038118\n",
      "Train Epoch: 49 [12544/14860 (84%)]\tLoss: 0.020253\n",
      "Train Epoch: 49 [12672/14860 (85%)]\tLoss: 0.028615\n",
      "Train Epoch: 49 [12800/14860 (85%)]\tLoss: 0.026104\n",
      "Train Epoch: 49 [12928/14860 (86%)]\tLoss: 0.013641\n",
      "Train Epoch: 49 [13056/14860 (87%)]\tLoss: 0.025999\n",
      "Train Epoch: 49 [13184/14860 (88%)]\tLoss: 0.021137\n",
      "Train Epoch: 49 [13312/14860 (89%)]\tLoss: 0.013546\n",
      "Train Epoch: 49 [13440/14860 (90%)]\tLoss: 0.019583\n",
      "Train Epoch: 49 [13568/14860 (91%)]\tLoss: 0.025291\n",
      "Train Epoch: 49 [13696/14860 (91%)]\tLoss: 0.023817\n",
      "Train Epoch: 49 [13824/14860 (92%)]\tLoss: 0.025507\n",
      "Train Epoch: 49 [13952/14860 (93%)]\tLoss: 0.018965\n",
      "Train Epoch: 49 [14080/14860 (94%)]\tLoss: 0.028040\n",
      "Train Epoch: 49 [14208/14860 (95%)]\tLoss: 0.026618\n",
      "Train Epoch: 49 [14336/14860 (96%)]\tLoss: 0.021348\n",
      "Train Epoch: 49 [14464/14860 (97%)]\tLoss: 0.024220\n",
      "Train Epoch: 49 [14592/14860 (97%)]\tLoss: 0.015938\n",
      "Train Epoch: 49 [14720/14860 (98%)]\tLoss: 0.016164\n",
      "Train Epoch: 49 [1392/14860 (99%)]\tLoss: 0.016239\n",
      "epoch 49 training loss: 0.02108474603543679\n",
      "epoch 49 validation loss: 0.02504919761606914\n",
      "Train Epoch: 50 [0/14860 (0%)]\tLoss: 0.025012\n",
      "Train Epoch: 50 [128/14860 (1%)]\tLoss: 0.023901\n",
      "Train Epoch: 50 [256/14860 (2%)]\tLoss: 0.025378\n",
      "Train Epoch: 50 [384/14860 (3%)]\tLoss: 0.033426\n",
      "Train Epoch: 50 [512/14860 (3%)]\tLoss: 0.016570\n",
      "Train Epoch: 50 [640/14860 (4%)]\tLoss: 0.031166\n",
      "Train Epoch: 50 [768/14860 (5%)]\tLoss: 0.022078\n",
      "Train Epoch: 50 [896/14860 (6%)]\tLoss: 0.020615\n",
      "Train Epoch: 50 [1024/14860 (7%)]\tLoss: 0.020145\n",
      "Train Epoch: 50 [1152/14860 (8%)]\tLoss: 0.015923\n",
      "Train Epoch: 50 [1280/14860 (9%)]\tLoss: 0.027138\n",
      "Train Epoch: 50 [1408/14860 (9%)]\tLoss: 0.029123\n",
      "Train Epoch: 50 [1536/14860 (10%)]\tLoss: 0.019595\n",
      "Train Epoch: 50 [1664/14860 (11%)]\tLoss: 0.012744\n",
      "Train Epoch: 50 [1792/14860 (12%)]\tLoss: 0.017704\n",
      "Train Epoch: 50 [1920/14860 (13%)]\tLoss: 0.029449\n",
      "Train Epoch: 50 [2048/14860 (14%)]\tLoss: 0.025649\n",
      "Train Epoch: 50 [2176/14860 (15%)]\tLoss: 0.022753\n",
      "Train Epoch: 50 [2304/14860 (15%)]\tLoss: 0.019018\n",
      "Train Epoch: 50 [2432/14860 (16%)]\tLoss: 0.021369\n",
      "Train Epoch: 50 [2560/14860 (17%)]\tLoss: 0.022617\n",
      "Train Epoch: 50 [2688/14860 (18%)]\tLoss: 0.025121\n",
      "Train Epoch: 50 [2816/14860 (19%)]\tLoss: 0.023576\n",
      "Train Epoch: 50 [2944/14860 (20%)]\tLoss: 0.031137\n",
      "Train Epoch: 50 [3072/14860 (21%)]\tLoss: 0.028562\n",
      "Train Epoch: 50 [3200/14860 (21%)]\tLoss: 0.031348\n",
      "Train Epoch: 50 [3328/14860 (22%)]\tLoss: 0.012386\n",
      "Train Epoch: 50 [3456/14860 (23%)]\tLoss: 0.035496\n",
      "Train Epoch: 50 [3584/14860 (24%)]\tLoss: 0.022060\n",
      "Train Epoch: 50 [3712/14860 (25%)]\tLoss: 0.022576\n",
      "Train Epoch: 50 [3840/14860 (26%)]\tLoss: 0.023692\n",
      "Train Epoch: 50 [3968/14860 (26%)]\tLoss: 0.017914\n",
      "Train Epoch: 50 [4096/14860 (27%)]\tLoss: 0.025882\n",
      "Train Epoch: 50 [4224/14860 (28%)]\tLoss: 0.017581\n",
      "Train Epoch: 50 [4352/14860 (29%)]\tLoss: 0.019111\n",
      "Train Epoch: 50 [4480/14860 (30%)]\tLoss: 0.021807\n",
      "Train Epoch: 50 [4608/14860 (31%)]\tLoss: 0.025672\n",
      "Train Epoch: 50 [4736/14860 (32%)]\tLoss: 0.023878\n",
      "Train Epoch: 50 [4864/14860 (32%)]\tLoss: 0.019922\n",
      "Train Epoch: 50 [4992/14860 (33%)]\tLoss: 0.027640\n",
      "Train Epoch: 50 [5120/14860 (34%)]\tLoss: 0.019834\n",
      "Train Epoch: 50 [5248/14860 (35%)]\tLoss: 0.019349\n",
      "Train Epoch: 50 [5376/14860 (36%)]\tLoss: 0.017652\n",
      "Train Epoch: 50 [5504/14860 (37%)]\tLoss: 0.016208\n",
      "Train Epoch: 50 [5632/14860 (38%)]\tLoss: 0.017562\n",
      "Train Epoch: 50 [5760/14860 (38%)]\tLoss: 0.018270\n",
      "Train Epoch: 50 [5888/14860 (39%)]\tLoss: 0.020462\n",
      "Train Epoch: 50 [6016/14860 (40%)]\tLoss: 0.026476\n",
      "Train Epoch: 50 [6144/14860 (41%)]\tLoss: 0.022902\n",
      "Train Epoch: 50 [6272/14860 (42%)]\tLoss: 0.014418\n",
      "Train Epoch: 50 [6400/14860 (43%)]\tLoss: 0.016995\n",
      "Train Epoch: 50 [6528/14860 (44%)]\tLoss: 0.020227\n",
      "Train Epoch: 50 [6656/14860 (44%)]\tLoss: 0.027813\n",
      "Train Epoch: 50 [6784/14860 (45%)]\tLoss: 0.020567\n",
      "Train Epoch: 50 [6912/14860 (46%)]\tLoss: 0.022439\n",
      "Train Epoch: 50 [7040/14860 (47%)]\tLoss: 0.019093\n",
      "Train Epoch: 50 [7168/14860 (48%)]\tLoss: 0.027860\n",
      "Train Epoch: 50 [7296/14860 (49%)]\tLoss: 0.020179\n",
      "Train Epoch: 50 [7424/14860 (50%)]\tLoss: 0.023650\n",
      "Train Epoch: 50 [7552/14860 (50%)]\tLoss: 0.017170\n",
      "Train Epoch: 50 [7680/14860 (51%)]\tLoss: 0.018628\n",
      "Train Epoch: 50 [7808/14860 (52%)]\tLoss: 0.015713\n",
      "Train Epoch: 50 [7936/14860 (53%)]\tLoss: 0.010648\n",
      "Train Epoch: 50 [8064/14860 (54%)]\tLoss: 0.029911\n",
      "Train Epoch: 50 [8192/14860 (55%)]\tLoss: 0.018490\n",
      "Train Epoch: 50 [8320/14860 (56%)]\tLoss: 0.021814\n",
      "Train Epoch: 50 [8448/14860 (56%)]\tLoss: 0.021129\n",
      "Train Epoch: 50 [8576/14860 (57%)]\tLoss: 0.016049\n",
      "Train Epoch: 50 [8704/14860 (58%)]\tLoss: 0.021210\n",
      "Train Epoch: 50 [8832/14860 (59%)]\tLoss: 0.022413\n",
      "Train Epoch: 50 [8960/14860 (60%)]\tLoss: 0.024387\n",
      "Train Epoch: 50 [9088/14860 (61%)]\tLoss: 0.020271\n",
      "Train Epoch: 50 [9216/14860 (62%)]\tLoss: 0.014990\n",
      "Train Epoch: 50 [9344/14860 (62%)]\tLoss: 0.014152\n",
      "Train Epoch: 50 [9472/14860 (63%)]\tLoss: 0.022888\n",
      "Train Epoch: 50 [9600/14860 (64%)]\tLoss: 0.013438\n",
      "Train Epoch: 50 [9728/14860 (65%)]\tLoss: 0.018681\n",
      "Train Epoch: 50 [9856/14860 (66%)]\tLoss: 0.019686\n",
      "Train Epoch: 50 [9984/14860 (67%)]\tLoss: 0.018239\n",
      "Train Epoch: 50 [10112/14860 (68%)]\tLoss: 0.016881\n",
      "Train Epoch: 50 [10240/14860 (68%)]\tLoss: 0.015051\n",
      "Train Epoch: 50 [10368/14860 (69%)]\tLoss: 0.020761\n",
      "Train Epoch: 50 [10496/14860 (70%)]\tLoss: 0.019073\n",
      "Train Epoch: 50 [10624/14860 (71%)]\tLoss: 0.022341\n",
      "Train Epoch: 50 [10752/14860 (72%)]\tLoss: 0.025701\n",
      "Train Epoch: 50 [10880/14860 (73%)]\tLoss: 0.025828\n",
      "Train Epoch: 50 [11008/14860 (74%)]\tLoss: 0.015863\n",
      "Train Epoch: 50 [11136/14860 (74%)]\tLoss: 0.016623\n",
      "Train Epoch: 50 [11264/14860 (75%)]\tLoss: 0.020134\n",
      "Train Epoch: 50 [11392/14860 (76%)]\tLoss: 0.024944\n",
      "Train Epoch: 50 [11520/14860 (77%)]\tLoss: 0.017549\n",
      "Train Epoch: 50 [11648/14860 (78%)]\tLoss: 0.022214\n",
      "Train Epoch: 50 [11776/14860 (79%)]\tLoss: 0.023311\n",
      "Train Epoch: 50 [11904/14860 (79%)]\tLoss: 0.018521\n",
      "Train Epoch: 50 [12032/14860 (80%)]\tLoss: 0.027645\n",
      "Train Epoch: 50 [12160/14860 (81%)]\tLoss: 0.021617\n",
      "Train Epoch: 50 [12288/14860 (82%)]\tLoss: 0.020375\n",
      "Train Epoch: 50 [12416/14860 (83%)]\tLoss: 0.022164\n",
      "Train Epoch: 50 [12544/14860 (84%)]\tLoss: 0.019829\n",
      "Train Epoch: 50 [12672/14860 (85%)]\tLoss: 0.022758\n",
      "Train Epoch: 50 [12800/14860 (85%)]\tLoss: 0.025073\n",
      "Train Epoch: 50 [12928/14860 (86%)]\tLoss: 0.017242\n",
      "Train Epoch: 50 [13056/14860 (87%)]\tLoss: 0.020337\n",
      "Train Epoch: 50 [13184/14860 (88%)]\tLoss: 0.017019\n",
      "Train Epoch: 50 [13312/14860 (89%)]\tLoss: 0.014857\n",
      "Train Epoch: 50 [13440/14860 (90%)]\tLoss: 0.022367\n",
      "Train Epoch: 50 [13568/14860 (91%)]\tLoss: 0.024414\n",
      "Train Epoch: 50 [13696/14860 (91%)]\tLoss: 0.022260\n",
      "Train Epoch: 50 [13824/14860 (92%)]\tLoss: 0.022618\n",
      "Train Epoch: 50 [13952/14860 (93%)]\tLoss: 0.018358\n",
      "Train Epoch: 50 [14080/14860 (94%)]\tLoss: 0.023568\n",
      "Train Epoch: 50 [14208/14860 (95%)]\tLoss: 0.019747\n",
      "Train Epoch: 50 [14336/14860 (96%)]\tLoss: 0.020443\n",
      "Train Epoch: 50 [14464/14860 (97%)]\tLoss: 0.016224\n",
      "Train Epoch: 50 [14592/14860 (97%)]\tLoss: 0.017494\n",
      "Train Epoch: 50 [14720/14860 (98%)]\tLoss: 0.018173\n",
      "Train Epoch: 50 [1392/14860 (99%)]\tLoss: 0.011092\n",
      "epoch 50 training loss: 0.021188583193171736\n",
      "epoch 50 validation loss: 0.022720501151558273\n",
      "Train Epoch: 51 [0/14860 (0%)]\tLoss: 0.023778\n",
      "Train Epoch: 51 [128/14860 (1%)]\tLoss: 0.020616\n",
      "Train Epoch: 51 [256/14860 (2%)]\tLoss: 0.018359\n",
      "Train Epoch: 51 [384/14860 (3%)]\tLoss: 0.016779\n",
      "Train Epoch: 51 [512/14860 (3%)]\tLoss: 0.016729\n",
      "Train Epoch: 51 [640/14860 (4%)]\tLoss: 0.023246\n",
      "Train Epoch: 51 [768/14860 (5%)]\tLoss: 0.015581\n",
      "Train Epoch: 51 [896/14860 (6%)]\tLoss: 0.017237\n",
      "Train Epoch: 51 [1024/14860 (7%)]\tLoss: 0.014330\n",
      "Train Epoch: 51 [1152/14860 (8%)]\tLoss: 0.014413\n",
      "Train Epoch: 51 [1280/14860 (9%)]\tLoss: 0.021449\n",
      "Train Epoch: 51 [1408/14860 (9%)]\tLoss: 0.021762\n",
      "Train Epoch: 51 [1536/14860 (10%)]\tLoss: 0.020016\n",
      "Train Epoch: 51 [1664/14860 (11%)]\tLoss: 0.015331\n",
      "Train Epoch: 51 [1792/14860 (12%)]\tLoss: 0.024157\n",
      "Train Epoch: 51 [1920/14860 (13%)]\tLoss: 0.011230\n",
      "Train Epoch: 51 [2048/14860 (14%)]\tLoss: 0.020791\n",
      "Train Epoch: 51 [2176/14860 (15%)]\tLoss: 0.020683\n",
      "Train Epoch: 51 [2304/14860 (15%)]\tLoss: 0.032283\n",
      "Train Epoch: 51 [2432/14860 (16%)]\tLoss: 0.030383\n",
      "Train Epoch: 51 [2560/14860 (17%)]\tLoss: 0.021009\n",
      "Train Epoch: 51 [2688/14860 (18%)]\tLoss: 0.016164\n",
      "Train Epoch: 51 [2816/14860 (19%)]\tLoss: 0.018730\n",
      "Train Epoch: 51 [2944/14860 (20%)]\tLoss: 0.016193\n",
      "Train Epoch: 51 [3072/14860 (21%)]\tLoss: 0.018138\n",
      "Train Epoch: 51 [3200/14860 (21%)]\tLoss: 0.015540\n",
      "Train Epoch: 51 [3328/14860 (22%)]\tLoss: 0.024387\n",
      "Train Epoch: 51 [3456/14860 (23%)]\tLoss: 0.018340\n",
      "Train Epoch: 51 [3584/14860 (24%)]\tLoss: 0.020609\n",
      "Train Epoch: 51 [3712/14860 (25%)]\tLoss: 0.019979\n",
      "Train Epoch: 51 [3840/14860 (26%)]\tLoss: 0.022508\n",
      "Train Epoch: 51 [3968/14860 (26%)]\tLoss: 0.021310\n",
      "Train Epoch: 51 [4096/14860 (27%)]\tLoss: 0.020787\n",
      "Train Epoch: 51 [4224/14860 (28%)]\tLoss: 0.020835\n",
      "Train Epoch: 51 [4352/14860 (29%)]\tLoss: 0.018739\n",
      "Train Epoch: 51 [4480/14860 (30%)]\tLoss: 0.018451\n",
      "Train Epoch: 51 [4608/14860 (31%)]\tLoss: 0.021567\n",
      "Train Epoch: 51 [4736/14860 (32%)]\tLoss: 0.017077\n",
      "Train Epoch: 51 [4864/14860 (32%)]\tLoss: 0.024184\n",
      "Train Epoch: 51 [4992/14860 (33%)]\tLoss: 0.020068\n",
      "Train Epoch: 51 [5120/14860 (34%)]\tLoss: 0.016459\n",
      "Train Epoch: 51 [5248/14860 (35%)]\tLoss: 0.022891\n",
      "Train Epoch: 51 [5376/14860 (36%)]\tLoss: 0.017419\n",
      "Train Epoch: 51 [5504/14860 (37%)]\tLoss: 0.020284\n",
      "Train Epoch: 51 [5632/14860 (38%)]\tLoss: 0.012732\n",
      "Train Epoch: 51 [5760/14860 (38%)]\tLoss: 0.022229\n",
      "Train Epoch: 51 [5888/14860 (39%)]\tLoss: 0.017586\n",
      "Train Epoch: 51 [6016/14860 (40%)]\tLoss: 0.023675\n",
      "Train Epoch: 51 [6144/14860 (41%)]\tLoss: 0.021270\n",
      "Train Epoch: 51 [6272/14860 (42%)]\tLoss: 0.025510\n",
      "Train Epoch: 51 [6400/14860 (43%)]\tLoss: 0.016471\n",
      "Train Epoch: 51 [6528/14860 (44%)]\tLoss: 0.016580\n",
      "Train Epoch: 51 [6656/14860 (44%)]\tLoss: 0.028819\n",
      "Train Epoch: 51 [6784/14860 (45%)]\tLoss: 0.023875\n",
      "Train Epoch: 51 [6912/14860 (46%)]\tLoss: 0.031459\n",
      "Train Epoch: 51 [7040/14860 (47%)]\tLoss: 0.026210\n",
      "Train Epoch: 51 [7168/14860 (48%)]\tLoss: 0.024819\n",
      "Train Epoch: 51 [7296/14860 (49%)]\tLoss: 0.036727\n",
      "Train Epoch: 51 [7424/14860 (50%)]\tLoss: 0.031309\n",
      "Train Epoch: 51 [7552/14860 (50%)]\tLoss: 0.016261\n",
      "Train Epoch: 51 [7680/14860 (51%)]\tLoss: 0.020625\n",
      "Train Epoch: 51 [7808/14860 (52%)]\tLoss: 0.019515\n",
      "Train Epoch: 51 [7936/14860 (53%)]\tLoss: 0.020092\n",
      "Train Epoch: 51 [8064/14860 (54%)]\tLoss: 0.024903\n",
      "Train Epoch: 51 [8192/14860 (55%)]\tLoss: 0.013507\n",
      "Train Epoch: 51 [8320/14860 (56%)]\tLoss: 0.020362\n",
      "Train Epoch: 51 [8448/14860 (56%)]\tLoss: 0.015191\n",
      "Train Epoch: 51 [8576/14860 (57%)]\tLoss: 0.028877\n",
      "Train Epoch: 51 [8704/14860 (58%)]\tLoss: 0.020372\n",
      "Train Epoch: 51 [8832/14860 (59%)]\tLoss: 0.013558\n",
      "Train Epoch: 51 [8960/14860 (60%)]\tLoss: 0.023905\n",
      "Train Epoch: 51 [9088/14860 (61%)]\tLoss: 0.015566\n",
      "Train Epoch: 51 [9216/14860 (62%)]\tLoss: 0.020286\n",
      "Train Epoch: 51 [9344/14860 (62%)]\tLoss: 0.018266\n",
      "Train Epoch: 51 [9472/14860 (63%)]\tLoss: 0.015073\n",
      "Train Epoch: 51 [9600/14860 (64%)]\tLoss: 0.023142\n",
      "Train Epoch: 51 [9728/14860 (65%)]\tLoss: 0.020913\n",
      "Train Epoch: 51 [9856/14860 (66%)]\tLoss: 0.029191\n",
      "Train Epoch: 51 [9984/14860 (67%)]\tLoss: 0.017658\n",
      "Train Epoch: 51 [10112/14860 (68%)]\tLoss: 0.026295\n",
      "Train Epoch: 51 [10240/14860 (68%)]\tLoss: 0.017746\n",
      "Train Epoch: 51 [10368/14860 (69%)]\tLoss: 0.021598\n",
      "Train Epoch: 51 [10496/14860 (70%)]\tLoss: 0.018810\n",
      "Train Epoch: 51 [10624/14860 (71%)]\tLoss: 0.030014\n",
      "Train Epoch: 51 [10752/14860 (72%)]\tLoss: 0.015404\n",
      "Train Epoch: 51 [10880/14860 (73%)]\tLoss: 0.024374\n",
      "Train Epoch: 51 [11008/14860 (74%)]\tLoss: 0.021775\n",
      "Train Epoch: 51 [11136/14860 (74%)]\tLoss: 0.033747\n",
      "Train Epoch: 51 [11264/14860 (75%)]\tLoss: 0.023176\n",
      "Train Epoch: 51 [11392/14860 (76%)]\tLoss: 0.016137\n",
      "Train Epoch: 51 [11520/14860 (77%)]\tLoss: 0.014270\n",
      "Train Epoch: 51 [11648/14860 (78%)]\tLoss: 0.019689\n",
      "Train Epoch: 51 [11776/14860 (79%)]\tLoss: 0.017922\n",
      "Train Epoch: 51 [11904/14860 (79%)]\tLoss: 0.017484\n",
      "Train Epoch: 51 [12032/14860 (80%)]\tLoss: 0.020957\n",
      "Train Epoch: 51 [12160/14860 (81%)]\tLoss: 0.021918\n",
      "Train Epoch: 51 [12288/14860 (82%)]\tLoss: 0.028227\n",
      "Train Epoch: 51 [12416/14860 (83%)]\tLoss: 0.023648\n",
      "Train Epoch: 51 [12544/14860 (84%)]\tLoss: 0.021416\n",
      "Train Epoch: 51 [12672/14860 (85%)]\tLoss: 0.022969\n",
      "Train Epoch: 51 [12800/14860 (85%)]\tLoss: 0.029492\n",
      "Train Epoch: 51 [12928/14860 (86%)]\tLoss: 0.028853\n",
      "Train Epoch: 51 [13056/14860 (87%)]\tLoss: 0.021151\n",
      "Train Epoch: 51 [13184/14860 (88%)]\tLoss: 0.024077\n",
      "Train Epoch: 51 [13312/14860 (89%)]\tLoss: 0.018475\n",
      "Train Epoch: 51 [13440/14860 (90%)]\tLoss: 0.025134\n",
      "Train Epoch: 51 [13568/14860 (91%)]\tLoss: 0.022575\n",
      "Train Epoch: 51 [13696/14860 (91%)]\tLoss: 0.019695\n",
      "Train Epoch: 51 [13824/14860 (92%)]\tLoss: 0.021541\n",
      "Train Epoch: 51 [13952/14860 (93%)]\tLoss: 0.016474\n",
      "Train Epoch: 51 [14080/14860 (94%)]\tLoss: 0.031232\n",
      "Train Epoch: 51 [14208/14860 (95%)]\tLoss: 0.020824\n",
      "Train Epoch: 51 [14336/14860 (96%)]\tLoss: 0.029601\n",
      "Train Epoch: 51 [14464/14860 (97%)]\tLoss: 0.022498\n",
      "Train Epoch: 51 [14592/14860 (97%)]\tLoss: 0.027778\n",
      "Train Epoch: 51 [14720/14860 (98%)]\tLoss: 0.023744\n",
      "Train Epoch: 51 [1392/14860 (99%)]\tLoss: 0.013513\n",
      "epoch 51 training loss: 0.021210175803583912\n",
      "epoch 51 validation loss: 0.021123964330474632\n",
      "Train Epoch: 52 [0/14860 (0%)]\tLoss: 0.022554\n",
      "Train Epoch: 52 [128/14860 (1%)]\tLoss: 0.016899\n",
      "Train Epoch: 52 [256/14860 (2%)]\tLoss: 0.016263\n",
      "Train Epoch: 52 [384/14860 (3%)]\tLoss: 0.025138\n",
      "Train Epoch: 52 [512/14860 (3%)]\tLoss: 0.018911\n",
      "Train Epoch: 52 [640/14860 (4%)]\tLoss: 0.019675\n",
      "Train Epoch: 52 [768/14860 (5%)]\tLoss: 0.018643\n",
      "Train Epoch: 52 [896/14860 (6%)]\tLoss: 0.017046\n",
      "Train Epoch: 52 [1024/14860 (7%)]\tLoss: 0.021106\n",
      "Train Epoch: 52 [1152/14860 (8%)]\tLoss: 0.024348\n",
      "Train Epoch: 52 [1280/14860 (9%)]\tLoss: 0.017406\n",
      "Train Epoch: 52 [1408/14860 (9%)]\tLoss: 0.021153\n",
      "Train Epoch: 52 [1536/14860 (10%)]\tLoss: 0.023292\n",
      "Train Epoch: 52 [1664/14860 (11%)]\tLoss: 0.022483\n",
      "Train Epoch: 52 [1792/14860 (12%)]\tLoss: 0.023334\n",
      "Train Epoch: 52 [1920/14860 (13%)]\tLoss: 0.014908\n",
      "Train Epoch: 52 [2048/14860 (14%)]\tLoss: 0.014612\n",
      "Train Epoch: 52 [2176/14860 (15%)]\tLoss: 0.022179\n",
      "Train Epoch: 52 [2304/14860 (15%)]\tLoss: 0.022595\n",
      "Train Epoch: 52 [2432/14860 (16%)]\tLoss: 0.021299\n",
      "Train Epoch: 52 [2560/14860 (17%)]\tLoss: 0.013724\n",
      "Train Epoch: 52 [2688/14860 (18%)]\tLoss: 0.015493\n",
      "Train Epoch: 52 [2816/14860 (19%)]\tLoss: 0.020624\n",
      "Train Epoch: 52 [2944/14860 (20%)]\tLoss: 0.022629\n",
      "Train Epoch: 52 [3072/14860 (21%)]\tLoss: 0.019830\n",
      "Train Epoch: 52 [3200/14860 (21%)]\tLoss: 0.024526\n",
      "Train Epoch: 52 [3328/14860 (22%)]\tLoss: 0.017049\n",
      "Train Epoch: 52 [3456/14860 (23%)]\tLoss: 0.019841\n",
      "Train Epoch: 52 [3584/14860 (24%)]\tLoss: 0.026843\n",
      "Train Epoch: 52 [3712/14860 (25%)]\tLoss: 0.020366\n",
      "Train Epoch: 52 [3840/14860 (26%)]\tLoss: 0.018429\n",
      "Train Epoch: 52 [3968/14860 (26%)]\tLoss: 0.022679\n",
      "Train Epoch: 52 [4096/14860 (27%)]\tLoss: 0.020936\n",
      "Train Epoch: 52 [4224/14860 (28%)]\tLoss: 0.027150\n",
      "Train Epoch: 52 [4352/14860 (29%)]\tLoss: 0.022418\n",
      "Train Epoch: 52 [4480/14860 (30%)]\tLoss: 0.016879\n",
      "Train Epoch: 52 [4608/14860 (31%)]\tLoss: 0.018850\n",
      "Train Epoch: 52 [4736/14860 (32%)]\tLoss: 0.020828\n",
      "Train Epoch: 52 [4864/14860 (32%)]\tLoss: 0.023728\n",
      "Train Epoch: 52 [4992/14860 (33%)]\tLoss: 0.018026\n",
      "Train Epoch: 52 [5120/14860 (34%)]\tLoss: 0.015253\n",
      "Train Epoch: 52 [5248/14860 (35%)]\tLoss: 0.019580\n",
      "Train Epoch: 52 [5376/14860 (36%)]\tLoss: 0.023657\n",
      "Train Epoch: 52 [5504/14860 (37%)]\tLoss: 0.022051\n",
      "Train Epoch: 52 [5632/14860 (38%)]\tLoss: 0.021470\n",
      "Train Epoch: 52 [5760/14860 (38%)]\tLoss: 0.014298\n",
      "Train Epoch: 52 [5888/14860 (39%)]\tLoss: 0.020055\n",
      "Train Epoch: 52 [6016/14860 (40%)]\tLoss: 0.020270\n",
      "Train Epoch: 52 [6144/14860 (41%)]\tLoss: 0.022101\n",
      "Train Epoch: 52 [6272/14860 (42%)]\tLoss: 0.018026\n",
      "Train Epoch: 52 [6400/14860 (43%)]\tLoss: 0.038805\n",
      "Train Epoch: 52 [6528/14860 (44%)]\tLoss: 0.022087\n",
      "Train Epoch: 52 [6656/14860 (44%)]\tLoss: 0.023339\n",
      "Train Epoch: 52 [6784/14860 (45%)]\tLoss: 0.020798\n",
      "Train Epoch: 52 [6912/14860 (46%)]\tLoss: 0.017049\n",
      "Train Epoch: 52 [7040/14860 (47%)]\tLoss: 0.023305\n",
      "Train Epoch: 52 [7168/14860 (48%)]\tLoss: 0.014266\n",
      "Train Epoch: 52 [7296/14860 (49%)]\tLoss: 0.025640\n",
      "Train Epoch: 52 [7424/14860 (50%)]\tLoss: 0.018219\n",
      "Train Epoch: 52 [7552/14860 (50%)]\tLoss: 0.022180\n",
      "Train Epoch: 52 [7680/14860 (51%)]\tLoss: 0.021382\n",
      "Train Epoch: 52 [7808/14860 (52%)]\tLoss: 0.021106\n",
      "Train Epoch: 52 [7936/14860 (53%)]\tLoss: 0.021244\n",
      "Train Epoch: 52 [8064/14860 (54%)]\tLoss: 0.020751\n",
      "Train Epoch: 52 [8192/14860 (55%)]\tLoss: 0.022505\n",
      "Train Epoch: 52 [8320/14860 (56%)]\tLoss: 0.020896\n",
      "Train Epoch: 52 [8448/14860 (56%)]\tLoss: 0.018774\n",
      "Train Epoch: 52 [8576/14860 (57%)]\tLoss: 0.019492\n",
      "Train Epoch: 52 [8704/14860 (58%)]\tLoss: 0.020231\n",
      "Train Epoch: 52 [8832/14860 (59%)]\tLoss: 0.019999\n",
      "Train Epoch: 52 [8960/14860 (60%)]\tLoss: 0.024096\n",
      "Train Epoch: 52 [9088/14860 (61%)]\tLoss: 0.023931\n",
      "Train Epoch: 52 [9216/14860 (62%)]\tLoss: 0.023267\n",
      "Train Epoch: 52 [9344/14860 (62%)]\tLoss: 0.021972\n",
      "Train Epoch: 52 [9472/14860 (63%)]\tLoss: 0.018052\n",
      "Train Epoch: 52 [9600/14860 (64%)]\tLoss: 0.017809\n",
      "Train Epoch: 52 [9728/14860 (65%)]\tLoss: 0.017157\n",
      "Train Epoch: 52 [9856/14860 (66%)]\tLoss: 0.023530\n",
      "Train Epoch: 52 [9984/14860 (67%)]\tLoss: 0.015133\n",
      "Train Epoch: 52 [10112/14860 (68%)]\tLoss: 0.014029\n",
      "Train Epoch: 52 [10240/14860 (68%)]\tLoss: 0.015604\n",
      "Train Epoch: 52 [10368/14860 (69%)]\tLoss: 0.016576\n",
      "Train Epoch: 52 [10496/14860 (70%)]\tLoss: 0.018918\n",
      "Train Epoch: 52 [10624/14860 (71%)]\tLoss: 0.018141\n",
      "Train Epoch: 52 [10752/14860 (72%)]\tLoss: 0.027526\n",
      "Train Epoch: 52 [10880/14860 (73%)]\tLoss: 0.018381\n",
      "Train Epoch: 52 [11008/14860 (74%)]\tLoss: 0.015519\n",
      "Train Epoch: 52 [11136/14860 (74%)]\tLoss: 0.026325\n",
      "Train Epoch: 52 [11264/14860 (75%)]\tLoss: 0.032151\n",
      "Train Epoch: 52 [11392/14860 (76%)]\tLoss: 0.019214\n",
      "Train Epoch: 52 [11520/14860 (77%)]\tLoss: 0.042921\n",
      "Train Epoch: 52 [11648/14860 (78%)]\tLoss: 0.025055\n",
      "Train Epoch: 52 [11776/14860 (79%)]\tLoss: 0.034914\n",
      "Train Epoch: 52 [11904/14860 (79%)]\tLoss: 0.023900\n",
      "Train Epoch: 52 [12032/14860 (80%)]\tLoss: 0.025409\n",
      "Train Epoch: 52 [12160/14860 (81%)]\tLoss: 0.019441\n",
      "Train Epoch: 52 [12288/14860 (82%)]\tLoss: 0.024811\n",
      "Train Epoch: 52 [12416/14860 (83%)]\tLoss: 0.012529\n",
      "Train Epoch: 52 [12544/14860 (84%)]\tLoss: 0.028034\n",
      "Train Epoch: 52 [12672/14860 (85%)]\tLoss: 0.025724\n",
      "Train Epoch: 52 [12800/14860 (85%)]\tLoss: 0.030802\n",
      "Train Epoch: 52 [12928/14860 (86%)]\tLoss: 0.020868\n",
      "Train Epoch: 52 [13056/14860 (87%)]\tLoss: 0.019688\n",
      "Train Epoch: 52 [13184/14860 (88%)]\tLoss: 0.019522\n",
      "Train Epoch: 52 [13312/14860 (89%)]\tLoss: 0.022705\n",
      "Train Epoch: 52 [13440/14860 (90%)]\tLoss: 0.024534\n",
      "Train Epoch: 52 [13568/14860 (91%)]\tLoss: 0.021520\n",
      "Train Epoch: 52 [13696/14860 (91%)]\tLoss: 0.021490\n",
      "Train Epoch: 52 [13824/14860 (92%)]\tLoss: 0.029108\n",
      "Train Epoch: 52 [13952/14860 (93%)]\tLoss: 0.020621\n",
      "Train Epoch: 52 [14080/14860 (94%)]\tLoss: 0.023042\n",
      "Train Epoch: 52 [14208/14860 (95%)]\tLoss: 0.020317\n",
      "Train Epoch: 52 [14336/14860 (96%)]\tLoss: 0.031701\n",
      "Train Epoch: 52 [14464/14860 (97%)]\tLoss: 0.020102\n",
      "Train Epoch: 52 [14592/14860 (97%)]\tLoss: 0.018778\n",
      "Train Epoch: 52 [14720/14860 (98%)]\tLoss: 0.017484\n",
      "Train Epoch: 52 [1392/14860 (99%)]\tLoss: 0.009954\n",
      "epoch 52 training loss: 0.021246404148256168\n",
      "epoch 52 validation loss: 0.03122436841521367\n",
      "Train Epoch: 53 [0/14860 (0%)]\tLoss: 0.028608\n",
      "Train Epoch: 53 [128/14860 (1%)]\tLoss: 0.016096\n",
      "Train Epoch: 53 [256/14860 (2%)]\tLoss: 0.019946\n",
      "Train Epoch: 53 [384/14860 (3%)]\tLoss: 0.021786\n",
      "Train Epoch: 53 [512/14860 (3%)]\tLoss: 0.029572\n",
      "Train Epoch: 53 [640/14860 (4%)]\tLoss: 0.019552\n",
      "Train Epoch: 53 [768/14860 (5%)]\tLoss: 0.018575\n",
      "Train Epoch: 53 [896/14860 (6%)]\tLoss: 0.020909\n",
      "Train Epoch: 53 [1024/14860 (7%)]\tLoss: 0.024518\n",
      "Train Epoch: 53 [1152/14860 (8%)]\tLoss: 0.027573\n",
      "Train Epoch: 53 [1280/14860 (9%)]\tLoss: 0.017313\n",
      "Train Epoch: 53 [1408/14860 (9%)]\tLoss: 0.013751\n",
      "Train Epoch: 53 [1536/14860 (10%)]\tLoss: 0.013294\n",
      "Train Epoch: 53 [1664/14860 (11%)]\tLoss: 0.012785\n",
      "Train Epoch: 53 [1792/14860 (12%)]\tLoss: 0.013913\n",
      "Train Epoch: 53 [1920/14860 (13%)]\tLoss: 0.018916\n",
      "Train Epoch: 53 [2048/14860 (14%)]\tLoss: 0.017264\n",
      "Train Epoch: 53 [2176/14860 (15%)]\tLoss: 0.018532\n",
      "Train Epoch: 53 [2304/14860 (15%)]\tLoss: 0.025530\n",
      "Train Epoch: 53 [2432/14860 (16%)]\tLoss: 0.020819\n",
      "Train Epoch: 53 [2560/14860 (17%)]\tLoss: 0.022990\n",
      "Train Epoch: 53 [2688/14860 (18%)]\tLoss: 0.020502\n",
      "Train Epoch: 53 [2816/14860 (19%)]\tLoss: 0.023586\n",
      "Train Epoch: 53 [2944/14860 (20%)]\tLoss: 0.020139\n",
      "Train Epoch: 53 [3072/14860 (21%)]\tLoss: 0.022266\n",
      "Train Epoch: 53 [3200/14860 (21%)]\tLoss: 0.019717\n",
      "Train Epoch: 53 [3328/14860 (22%)]\tLoss: 0.032931\n",
      "Train Epoch: 53 [3456/14860 (23%)]\tLoss: 0.025202\n",
      "Train Epoch: 53 [3584/14860 (24%)]\tLoss: 0.014607\n",
      "Train Epoch: 53 [3712/14860 (25%)]\tLoss: 0.019978\n",
      "Train Epoch: 53 [3840/14860 (26%)]\tLoss: 0.033119\n",
      "Train Epoch: 53 [3968/14860 (26%)]\tLoss: 0.016328\n",
      "Train Epoch: 53 [4096/14860 (27%)]\tLoss: 0.026063\n",
      "Train Epoch: 53 [4224/14860 (28%)]\tLoss: 0.021857\n",
      "Train Epoch: 53 [4352/14860 (29%)]\tLoss: 0.028843\n",
      "Train Epoch: 53 [4480/14860 (30%)]\tLoss: 0.021623\n",
      "Train Epoch: 53 [4608/14860 (31%)]\tLoss: 0.026038\n",
      "Train Epoch: 53 [4736/14860 (32%)]\tLoss: 0.022751\n",
      "Train Epoch: 53 [4864/14860 (32%)]\tLoss: 0.024526\n",
      "Train Epoch: 53 [4992/14860 (33%)]\tLoss: 0.027013\n",
      "Train Epoch: 53 [5120/14860 (34%)]\tLoss: 0.022418\n",
      "Train Epoch: 53 [5248/14860 (35%)]\tLoss: 0.031008\n",
      "Train Epoch: 53 [5376/14860 (36%)]\tLoss: 0.025744\n",
      "Train Epoch: 53 [5504/14860 (37%)]\tLoss: 0.043654\n",
      "Train Epoch: 53 [5632/14860 (38%)]\tLoss: 0.021926\n",
      "Train Epoch: 53 [5760/14860 (38%)]\tLoss: 0.025116\n",
      "Train Epoch: 53 [5888/14860 (39%)]\tLoss: 0.023362\n",
      "Train Epoch: 53 [6016/14860 (40%)]\tLoss: 0.019729\n",
      "Train Epoch: 53 [6144/14860 (41%)]\tLoss: 0.024801\n",
      "Train Epoch: 53 [6272/14860 (42%)]\tLoss: 0.025721\n",
      "Train Epoch: 53 [6400/14860 (43%)]\tLoss: 0.019593\n",
      "Train Epoch: 53 [6528/14860 (44%)]\tLoss: 0.015457\n",
      "Train Epoch: 53 [6656/14860 (44%)]\tLoss: 0.015381\n",
      "Train Epoch: 53 [6784/14860 (45%)]\tLoss: 0.022415\n",
      "Train Epoch: 53 [6912/14860 (46%)]\tLoss: 0.022449\n",
      "Train Epoch: 53 [7040/14860 (47%)]\tLoss: 0.027120\n",
      "Train Epoch: 53 [7168/14860 (48%)]\tLoss: 0.021175\n",
      "Train Epoch: 53 [7296/14860 (49%)]\tLoss: 0.013849\n",
      "Train Epoch: 53 [7424/14860 (50%)]\tLoss: 0.026791\n",
      "Train Epoch: 53 [7552/14860 (50%)]\tLoss: 0.016932\n",
      "Train Epoch: 53 [7680/14860 (51%)]\tLoss: 0.029176\n",
      "Train Epoch: 53 [7808/14860 (52%)]\tLoss: 0.021717\n",
      "Train Epoch: 53 [7936/14860 (53%)]\tLoss: 0.023253\n",
      "Train Epoch: 53 [8064/14860 (54%)]\tLoss: 0.015540\n",
      "Train Epoch: 53 [8192/14860 (55%)]\tLoss: 0.019693\n",
      "Train Epoch: 53 [8320/14860 (56%)]\tLoss: 0.022779\n",
      "Train Epoch: 53 [8448/14860 (56%)]\tLoss: 0.015289\n",
      "Train Epoch: 53 [8576/14860 (57%)]\tLoss: 0.023324\n",
      "Train Epoch: 53 [8704/14860 (58%)]\tLoss: 0.015445\n",
      "Train Epoch: 53 [8832/14860 (59%)]\tLoss: 0.019158\n",
      "Train Epoch: 53 [8960/14860 (60%)]\tLoss: 0.021123\n",
      "Train Epoch: 53 [9088/14860 (61%)]\tLoss: 0.018115\n",
      "Train Epoch: 53 [9216/14860 (62%)]\tLoss: 0.024788\n",
      "Train Epoch: 53 [9344/14860 (62%)]\tLoss: 0.018834\n",
      "Train Epoch: 53 [9472/14860 (63%)]\tLoss: 0.019971\n",
      "Train Epoch: 53 [9600/14860 (64%)]\tLoss: 0.026403\n",
      "Train Epoch: 53 [9728/14860 (65%)]\tLoss: 0.018830\n",
      "Train Epoch: 53 [9856/14860 (66%)]\tLoss: 0.031013\n",
      "Train Epoch: 53 [9984/14860 (67%)]\tLoss: 0.023980\n",
      "Train Epoch: 53 [10112/14860 (68%)]\tLoss: 0.022670\n",
      "Train Epoch: 53 [10240/14860 (68%)]\tLoss: 0.017991\n",
      "Train Epoch: 53 [10368/14860 (69%)]\tLoss: 0.033105\n",
      "Train Epoch: 53 [10496/14860 (70%)]\tLoss: 0.020318\n",
      "Train Epoch: 53 [10624/14860 (71%)]\tLoss: 0.025497\n",
      "Train Epoch: 53 [10752/14860 (72%)]\tLoss: 0.020758\n",
      "Train Epoch: 53 [10880/14860 (73%)]\tLoss: 0.023882\n",
      "Train Epoch: 53 [11008/14860 (74%)]\tLoss: 0.021882\n",
      "Train Epoch: 53 [11136/14860 (74%)]\tLoss: 0.019771\n",
      "Train Epoch: 53 [11264/14860 (75%)]\tLoss: 0.016081\n",
      "Train Epoch: 53 [11392/14860 (76%)]\tLoss: 0.018149\n",
      "Train Epoch: 53 [11520/14860 (77%)]\tLoss: 0.020511\n",
      "Train Epoch: 53 [11648/14860 (78%)]\tLoss: 0.020308\n",
      "Train Epoch: 53 [11776/14860 (79%)]\tLoss: 0.022021\n",
      "Train Epoch: 53 [11904/14860 (79%)]\tLoss: 0.025223\n",
      "Train Epoch: 53 [12032/14860 (80%)]\tLoss: 0.017827\n",
      "Train Epoch: 53 [12160/14860 (81%)]\tLoss: 0.032917\n",
      "Train Epoch: 53 [12288/14860 (82%)]\tLoss: 0.019242\n",
      "Train Epoch: 53 [12416/14860 (83%)]\tLoss: 0.022013\n",
      "Train Epoch: 53 [12544/14860 (84%)]\tLoss: 0.017558\n",
      "Train Epoch: 53 [12672/14860 (85%)]\tLoss: 0.030678\n",
      "Train Epoch: 53 [12800/14860 (85%)]\tLoss: 0.022189\n",
      "Train Epoch: 53 [12928/14860 (86%)]\tLoss: 0.020344\n",
      "Train Epoch: 53 [13056/14860 (87%)]\tLoss: 0.020929\n",
      "Train Epoch: 53 [13184/14860 (88%)]\tLoss: 0.024620\n",
      "Train Epoch: 53 [13312/14860 (89%)]\tLoss: 0.014171\n",
      "Train Epoch: 53 [13440/14860 (90%)]\tLoss: 0.020348\n",
      "Train Epoch: 53 [13568/14860 (91%)]\tLoss: 0.015726\n",
      "Train Epoch: 53 [13696/14860 (91%)]\tLoss: 0.016291\n",
      "Train Epoch: 53 [13824/14860 (92%)]\tLoss: 0.029640\n",
      "Train Epoch: 53 [13952/14860 (93%)]\tLoss: 0.011944\n",
      "Train Epoch: 53 [14080/14860 (94%)]\tLoss: 0.017670\n",
      "Train Epoch: 53 [14208/14860 (95%)]\tLoss: 0.020737\n",
      "Train Epoch: 53 [14336/14860 (96%)]\tLoss: 0.027503\n",
      "Train Epoch: 53 [14464/14860 (97%)]\tLoss: 0.023888\n",
      "Train Epoch: 53 [14592/14860 (97%)]\tLoss: 0.024902\n",
      "Train Epoch: 53 [14720/14860 (98%)]\tLoss: 0.029209\n",
      "Train Epoch: 53 [1392/14860 (99%)]\tLoss: 0.017664\n",
      "epoch 53 training loss: 0.021953701821721006\n",
      "epoch 53 validation loss: 0.027815328383272553\n",
      "Train Epoch: 54 [0/14860 (0%)]\tLoss: 0.021069\n",
      "Train Epoch: 54 [128/14860 (1%)]\tLoss: 0.018675\n",
      "Train Epoch: 54 [256/14860 (2%)]\tLoss: 0.036591\n",
      "Train Epoch: 54 [384/14860 (3%)]\tLoss: 0.014341\n",
      "Train Epoch: 54 [512/14860 (3%)]\tLoss: 0.029705\n",
      "Train Epoch: 54 [640/14860 (4%)]\tLoss: 0.016124\n",
      "Train Epoch: 54 [768/14860 (5%)]\tLoss: 0.028346\n",
      "Train Epoch: 54 [896/14860 (6%)]\tLoss: 0.030889\n",
      "Train Epoch: 54 [1024/14860 (7%)]\tLoss: 0.030124\n",
      "Train Epoch: 54 [1152/14860 (8%)]\tLoss: 0.020180\n",
      "Train Epoch: 54 [1280/14860 (9%)]\tLoss: 0.022230\n",
      "Train Epoch: 54 [1408/14860 (9%)]\tLoss: 0.019514\n",
      "Train Epoch: 54 [1536/14860 (10%)]\tLoss: 0.018601\n",
      "Train Epoch: 54 [1664/14860 (11%)]\tLoss: 0.025142\n",
      "Train Epoch: 54 [1792/14860 (12%)]\tLoss: 0.017885\n",
      "Train Epoch: 54 [1920/14860 (13%)]\tLoss: 0.017667\n",
      "Train Epoch: 54 [2048/14860 (14%)]\tLoss: 0.019502\n",
      "Train Epoch: 54 [2176/14860 (15%)]\tLoss: 0.015551\n",
      "Train Epoch: 54 [2304/14860 (15%)]\tLoss: 0.016560\n",
      "Train Epoch: 54 [2432/14860 (16%)]\tLoss: 0.029907\n",
      "Train Epoch: 54 [2560/14860 (17%)]\tLoss: 0.015733\n",
      "Train Epoch: 54 [2688/14860 (18%)]\tLoss: 0.023182\n",
      "Train Epoch: 54 [2816/14860 (19%)]\tLoss: 0.014645\n",
      "Train Epoch: 54 [2944/14860 (20%)]\tLoss: 0.019575\n",
      "Train Epoch: 54 [3072/14860 (21%)]\tLoss: 0.024927\n",
      "Train Epoch: 54 [3200/14860 (21%)]\tLoss: 0.016286\n",
      "Train Epoch: 54 [3328/14860 (22%)]\tLoss: 0.025229\n",
      "Train Epoch: 54 [3456/14860 (23%)]\tLoss: 0.031917\n",
      "Train Epoch: 54 [3584/14860 (24%)]\tLoss: 0.023224\n",
      "Train Epoch: 54 [3712/14860 (25%)]\tLoss: 0.022616\n",
      "Train Epoch: 54 [3840/14860 (26%)]\tLoss: 0.019773\n",
      "Train Epoch: 54 [3968/14860 (26%)]\tLoss: 0.025503\n",
      "Train Epoch: 54 [4096/14860 (27%)]\tLoss: 0.014522\n",
      "Train Epoch: 54 [4224/14860 (28%)]\tLoss: 0.023280\n",
      "Train Epoch: 54 [4352/14860 (29%)]\tLoss: 0.020480\n",
      "Train Epoch: 54 [4480/14860 (30%)]\tLoss: 0.022846\n",
      "Train Epoch: 54 [4608/14860 (31%)]\tLoss: 0.020138\n",
      "Train Epoch: 54 [4736/14860 (32%)]\tLoss: 0.022062\n",
      "Train Epoch: 54 [4864/14860 (32%)]\tLoss: 0.023758\n",
      "Train Epoch: 54 [4992/14860 (33%)]\tLoss: 0.023766\n",
      "Train Epoch: 54 [5120/14860 (34%)]\tLoss: 0.022865\n",
      "Train Epoch: 54 [5248/14860 (35%)]\tLoss: 0.023160\n",
      "Train Epoch: 54 [5376/14860 (36%)]\tLoss: 0.018826\n",
      "Train Epoch: 54 [5504/14860 (37%)]\tLoss: 0.017872\n",
      "Train Epoch: 54 [5632/14860 (38%)]\tLoss: 0.013664\n",
      "Train Epoch: 54 [5760/14860 (38%)]\tLoss: 0.019533\n",
      "Train Epoch: 54 [5888/14860 (39%)]\tLoss: 0.020835\n",
      "Train Epoch: 54 [6016/14860 (40%)]\tLoss: 0.017599\n",
      "Train Epoch: 54 [6144/14860 (41%)]\tLoss: 0.028680\n",
      "Train Epoch: 54 [6272/14860 (42%)]\tLoss: 0.022255\n",
      "Train Epoch: 54 [6400/14860 (43%)]\tLoss: 0.023156\n",
      "Train Epoch: 54 [6528/14860 (44%)]\tLoss: 0.019868\n",
      "Train Epoch: 54 [6656/14860 (44%)]\tLoss: 0.027139\n",
      "Train Epoch: 54 [6784/14860 (45%)]\tLoss: 0.014677\n",
      "Train Epoch: 54 [6912/14860 (46%)]\tLoss: 0.018732\n",
      "Train Epoch: 54 [7040/14860 (47%)]\tLoss: 0.024841\n",
      "Train Epoch: 54 [7168/14860 (48%)]\tLoss: 0.018787\n",
      "Train Epoch: 54 [7296/14860 (49%)]\tLoss: 0.028802\n",
      "Train Epoch: 54 [7424/14860 (50%)]\tLoss: 0.020768\n",
      "Train Epoch: 54 [7552/14860 (50%)]\tLoss: 0.014469\n",
      "Train Epoch: 54 [7680/14860 (51%)]\tLoss: 0.014021\n",
      "Train Epoch: 54 [7808/14860 (52%)]\tLoss: 0.018959\n",
      "Train Epoch: 54 [7936/14860 (53%)]\tLoss: 0.022311\n",
      "Train Epoch: 54 [8064/14860 (54%)]\tLoss: 0.021765\n",
      "Train Epoch: 54 [8192/14860 (55%)]\tLoss: 0.019241\n",
      "Train Epoch: 54 [8320/14860 (56%)]\tLoss: 0.021809\n",
      "Train Epoch: 54 [8448/14860 (56%)]\tLoss: 0.022955\n",
      "Train Epoch: 54 [8576/14860 (57%)]\tLoss: 0.021826\n",
      "Train Epoch: 54 [8704/14860 (58%)]\tLoss: 0.015913\n",
      "Train Epoch: 54 [8832/14860 (59%)]\tLoss: 0.015993\n",
      "Train Epoch: 54 [8960/14860 (60%)]\tLoss: 0.019333\n",
      "Train Epoch: 54 [9088/14860 (61%)]\tLoss: 0.016224\n",
      "Train Epoch: 54 [9216/14860 (62%)]\tLoss: 0.015056\n",
      "Train Epoch: 54 [9344/14860 (62%)]\tLoss: 0.017672\n",
      "Train Epoch: 54 [9472/14860 (63%)]\tLoss: 0.025514\n",
      "Train Epoch: 54 [9600/14860 (64%)]\tLoss: 0.019665\n",
      "Train Epoch: 54 [9728/14860 (65%)]\tLoss: 0.018349\n",
      "Train Epoch: 54 [9856/14860 (66%)]\tLoss: 0.018064\n",
      "Train Epoch: 54 [9984/14860 (67%)]\tLoss: 0.015644\n",
      "Train Epoch: 54 [10112/14860 (68%)]\tLoss: 0.018294\n",
      "Train Epoch: 54 [10240/14860 (68%)]\tLoss: 0.020981\n",
      "Train Epoch: 54 [10368/14860 (69%)]\tLoss: 0.027245\n",
      "Train Epoch: 54 [10496/14860 (70%)]\tLoss: 0.016973\n",
      "Train Epoch: 54 [10624/14860 (71%)]\tLoss: 0.031614\n",
      "Train Epoch: 54 [10752/14860 (72%)]\tLoss: 0.025112\n",
      "Train Epoch: 54 [10880/14860 (73%)]\tLoss: 0.022528\n",
      "Train Epoch: 54 [11008/14860 (74%)]\tLoss: 0.017929\n",
      "Train Epoch: 54 [11136/14860 (74%)]\tLoss: 0.022093\n",
      "Train Epoch: 54 [11264/14860 (75%)]\tLoss: 0.019609\n",
      "Train Epoch: 54 [11392/14860 (76%)]\tLoss: 0.021183\n",
      "Train Epoch: 54 [11520/14860 (77%)]\tLoss: 0.024877\n",
      "Train Epoch: 54 [11648/14860 (78%)]\tLoss: 0.021322\n",
      "Train Epoch: 54 [11776/14860 (79%)]\tLoss: 0.020116\n",
      "Train Epoch: 54 [11904/14860 (79%)]\tLoss: 0.026534\n",
      "Train Epoch: 54 [12032/14860 (80%)]\tLoss: 0.026523\n",
      "Train Epoch: 54 [12160/14860 (81%)]\tLoss: 0.019840\n",
      "Train Epoch: 54 [12288/14860 (82%)]\tLoss: 0.021178\n",
      "Train Epoch: 54 [12416/14860 (83%)]\tLoss: 0.025721\n",
      "Train Epoch: 54 [12544/14860 (84%)]\tLoss: 0.019460\n",
      "Train Epoch: 54 [12672/14860 (85%)]\tLoss: 0.021588\n",
      "Train Epoch: 54 [12800/14860 (85%)]\tLoss: 0.021140\n",
      "Train Epoch: 54 [12928/14860 (86%)]\tLoss: 0.021905\n",
      "Train Epoch: 54 [13056/14860 (87%)]\tLoss: 0.021014\n",
      "Train Epoch: 54 [13184/14860 (88%)]\tLoss: 0.027241\n",
      "Train Epoch: 54 [13312/14860 (89%)]\tLoss: 0.023015\n",
      "Train Epoch: 54 [13440/14860 (90%)]\tLoss: 0.025519\n",
      "Train Epoch: 54 [13568/14860 (91%)]\tLoss: 0.021038\n",
      "Train Epoch: 54 [13696/14860 (91%)]\tLoss: 0.019361\n",
      "Train Epoch: 54 [13824/14860 (92%)]\tLoss: 0.014920\n",
      "Train Epoch: 54 [13952/14860 (93%)]\tLoss: 0.020557\n",
      "Train Epoch: 54 [14080/14860 (94%)]\tLoss: 0.027066\n",
      "Train Epoch: 54 [14208/14860 (95%)]\tLoss: 0.019824\n",
      "Train Epoch: 54 [14336/14860 (96%)]\tLoss: 0.021385\n",
      "Train Epoch: 54 [14464/14860 (97%)]\tLoss: 0.012690\n",
      "Train Epoch: 54 [14592/14860 (97%)]\tLoss: 0.023782\n",
      "Train Epoch: 54 [14720/14860 (98%)]\tLoss: 0.018593\n",
      "Train Epoch: 54 [1392/14860 (99%)]\tLoss: 0.008909\n",
      "epoch 54 training loss: 0.02117593726541242\n",
      "epoch 54 validation loss: 0.05453670746477695\n",
      "Train Epoch: 55 [0/14860 (0%)]\tLoss: 0.058843\n",
      "Train Epoch: 55 [128/14860 (1%)]\tLoss: 0.026877\n",
      "Train Epoch: 55 [256/14860 (2%)]\tLoss: 0.048046\n",
      "Train Epoch: 55 [384/14860 (3%)]\tLoss: 0.018823\n",
      "Train Epoch: 55 [512/14860 (3%)]\tLoss: 0.036239\n",
      "Train Epoch: 55 [640/14860 (4%)]\tLoss: 0.026510\n",
      "Train Epoch: 55 [768/14860 (5%)]\tLoss: 0.029587\n",
      "Train Epoch: 55 [896/14860 (6%)]\tLoss: 0.026895\n",
      "Train Epoch: 55 [1024/14860 (7%)]\tLoss: 0.015820\n",
      "Train Epoch: 55 [1152/14860 (8%)]\tLoss: 0.037204\n",
      "Train Epoch: 55 [1280/14860 (9%)]\tLoss: 0.017380\n",
      "Train Epoch: 55 [1408/14860 (9%)]\tLoss: 0.022616\n",
      "Train Epoch: 55 [1536/14860 (10%)]\tLoss: 0.022246\n",
      "Train Epoch: 55 [1664/14860 (11%)]\tLoss: 0.027700\n",
      "Train Epoch: 55 [1792/14860 (12%)]\tLoss: 0.024921\n",
      "Train Epoch: 55 [1920/14860 (13%)]\tLoss: 0.021093\n",
      "Train Epoch: 55 [2048/14860 (14%)]\tLoss: 0.013481\n",
      "Train Epoch: 55 [2176/14860 (15%)]\tLoss: 0.021870\n",
      "Train Epoch: 55 [2304/14860 (15%)]\tLoss: 0.019210\n",
      "Train Epoch: 55 [2432/14860 (16%)]\tLoss: 0.025096\n",
      "Train Epoch: 55 [2560/14860 (17%)]\tLoss: 0.019258\n",
      "Train Epoch: 55 [2688/14860 (18%)]\tLoss: 0.022006\n",
      "Train Epoch: 55 [2816/14860 (19%)]\tLoss: 0.015459\n",
      "Train Epoch: 55 [2944/14860 (20%)]\tLoss: 0.021911\n",
      "Train Epoch: 55 [3072/14860 (21%)]\tLoss: 0.017767\n",
      "Train Epoch: 55 [3200/14860 (21%)]\tLoss: 0.017410\n",
      "Train Epoch: 55 [3328/14860 (22%)]\tLoss: 0.012945\n",
      "Train Epoch: 55 [3456/14860 (23%)]\tLoss: 0.019578\n",
      "Train Epoch: 55 [3584/14860 (24%)]\tLoss: 0.013929\n",
      "Train Epoch: 55 [3712/14860 (25%)]\tLoss: 0.019335\n",
      "Train Epoch: 55 [3840/14860 (26%)]\tLoss: 0.019301\n",
      "Train Epoch: 55 [3968/14860 (26%)]\tLoss: 0.026066\n",
      "Train Epoch: 55 [4096/14860 (27%)]\tLoss: 0.022381\n",
      "Train Epoch: 55 [4224/14860 (28%)]\tLoss: 0.019354\n",
      "Train Epoch: 55 [4352/14860 (29%)]\tLoss: 0.022191\n",
      "Train Epoch: 55 [4480/14860 (30%)]\tLoss: 0.017273\n",
      "Train Epoch: 55 [4608/14860 (31%)]\tLoss: 0.019345\n",
      "Train Epoch: 55 [4736/14860 (32%)]\tLoss: 0.019512\n",
      "Train Epoch: 55 [4864/14860 (32%)]\tLoss: 0.024242\n",
      "Train Epoch: 55 [4992/14860 (33%)]\tLoss: 0.021330\n",
      "Train Epoch: 55 [5120/14860 (34%)]\tLoss: 0.027270\n",
      "Train Epoch: 55 [5248/14860 (35%)]\tLoss: 0.016850\n",
      "Train Epoch: 55 [5376/14860 (36%)]\tLoss: 0.012581\n",
      "Train Epoch: 55 [5504/14860 (37%)]\tLoss: 0.019898\n",
      "Train Epoch: 55 [5632/14860 (38%)]\tLoss: 0.014408\n",
      "Train Epoch: 55 [5760/14860 (38%)]\tLoss: 0.019885\n",
      "Train Epoch: 55 [5888/14860 (39%)]\tLoss: 0.021993\n",
      "Train Epoch: 55 [6016/14860 (40%)]\tLoss: 0.015500\n",
      "Train Epoch: 55 [6144/14860 (41%)]\tLoss: 0.021325\n",
      "Train Epoch: 55 [6272/14860 (42%)]\tLoss: 0.015314\n",
      "Train Epoch: 55 [6400/14860 (43%)]\tLoss: 0.019130\n",
      "Train Epoch: 55 [6528/14860 (44%)]\tLoss: 0.023935\n",
      "Train Epoch: 55 [6656/14860 (44%)]\tLoss: 0.016259\n",
      "Train Epoch: 55 [6784/14860 (45%)]\tLoss: 0.023360\n",
      "Train Epoch: 55 [6912/14860 (46%)]\tLoss: 0.016305\n",
      "Train Epoch: 55 [7040/14860 (47%)]\tLoss: 0.019210\n",
      "Train Epoch: 55 [7168/14860 (48%)]\tLoss: 0.022164\n",
      "Train Epoch: 55 [7296/14860 (49%)]\tLoss: 0.013550\n",
      "Train Epoch: 55 [7424/14860 (50%)]\tLoss: 0.016633\n",
      "Train Epoch: 55 [7552/14860 (50%)]\tLoss: 0.016488\n",
      "Train Epoch: 55 [7680/14860 (51%)]\tLoss: 0.015708\n",
      "Train Epoch: 55 [7808/14860 (52%)]\tLoss: 0.020022\n",
      "Train Epoch: 55 [7936/14860 (53%)]\tLoss: 0.018890\n",
      "Train Epoch: 55 [8064/14860 (54%)]\tLoss: 0.021995\n",
      "Train Epoch: 55 [8192/14860 (55%)]\tLoss: 0.019251\n",
      "Train Epoch: 55 [8320/14860 (56%)]\tLoss: 0.022449\n",
      "Train Epoch: 55 [8448/14860 (56%)]\tLoss: 0.011900\n",
      "Train Epoch: 55 [8576/14860 (57%)]\tLoss: 0.024245\n",
      "Train Epoch: 55 [8704/14860 (58%)]\tLoss: 0.015714\n",
      "Train Epoch: 55 [8832/14860 (59%)]\tLoss: 0.020029\n",
      "Train Epoch: 55 [8960/14860 (60%)]\tLoss: 0.023218\n",
      "Train Epoch: 55 [9088/14860 (61%)]\tLoss: 0.019686\n",
      "Train Epoch: 55 [9216/14860 (62%)]\tLoss: 0.024129\n",
      "Train Epoch: 55 [9344/14860 (62%)]\tLoss: 0.022410\n",
      "Train Epoch: 55 [9472/14860 (63%)]\tLoss: 0.018868\n",
      "Train Epoch: 55 [9600/14860 (64%)]\tLoss: 0.018914\n",
      "Train Epoch: 55 [9728/14860 (65%)]\tLoss: 0.024994\n",
      "Train Epoch: 55 [9856/14860 (66%)]\tLoss: 0.014766\n",
      "Train Epoch: 55 [9984/14860 (67%)]\tLoss: 0.029477\n",
      "Train Epoch: 55 [10112/14860 (68%)]\tLoss: 0.029453\n",
      "Train Epoch: 55 [10240/14860 (68%)]\tLoss: 0.032776\n",
      "Train Epoch: 55 [10368/14860 (69%)]\tLoss: 0.019220\n",
      "Train Epoch: 55 [10496/14860 (70%)]\tLoss: 0.030017\n",
      "Train Epoch: 55 [10624/14860 (71%)]\tLoss: 0.022876\n",
      "Train Epoch: 55 [10752/14860 (72%)]\tLoss: 0.033060\n",
      "Train Epoch: 55 [10880/14860 (73%)]\tLoss: 0.026251\n",
      "Train Epoch: 55 [11008/14860 (74%)]\tLoss: 0.021689\n",
      "Train Epoch: 55 [11136/14860 (74%)]\tLoss: 0.024551\n",
      "Train Epoch: 55 [11264/14860 (75%)]\tLoss: 0.021098\n",
      "Train Epoch: 55 [11392/14860 (76%)]\tLoss: 0.024019\n",
      "Train Epoch: 55 [11520/14860 (77%)]\tLoss: 0.018047\n",
      "Train Epoch: 55 [11648/14860 (78%)]\tLoss: 0.018296\n",
      "Train Epoch: 55 [11776/14860 (79%)]\tLoss: 0.027354\n",
      "Train Epoch: 55 [11904/14860 (79%)]\tLoss: 0.018229\n",
      "Train Epoch: 55 [12032/14860 (80%)]\tLoss: 0.026253\n",
      "Train Epoch: 55 [12160/14860 (81%)]\tLoss: 0.030249\n",
      "Train Epoch: 55 [12288/14860 (82%)]\tLoss: 0.020164\n",
      "Train Epoch: 55 [12416/14860 (83%)]\tLoss: 0.023163\n",
      "Train Epoch: 55 [12544/14860 (84%)]\tLoss: 0.025062\n",
      "Train Epoch: 55 [12672/14860 (85%)]\tLoss: 0.017547\n",
      "Train Epoch: 55 [12800/14860 (85%)]\tLoss: 0.013963\n",
      "Train Epoch: 55 [12928/14860 (86%)]\tLoss: 0.023284\n",
      "Train Epoch: 55 [13056/14860 (87%)]\tLoss: 0.024091\n",
      "Train Epoch: 55 [13184/14860 (88%)]\tLoss: 0.019703\n",
      "Train Epoch: 55 [13312/14860 (89%)]\tLoss: 0.025391\n",
      "Train Epoch: 55 [13440/14860 (90%)]\tLoss: 0.023771\n",
      "Train Epoch: 55 [13568/14860 (91%)]\tLoss: 0.024210\n",
      "Train Epoch: 55 [13696/14860 (91%)]\tLoss: 0.020530\n",
      "Train Epoch: 55 [13824/14860 (92%)]\tLoss: 0.017019\n",
      "Train Epoch: 55 [13952/14860 (93%)]\tLoss: 0.019666\n",
      "Train Epoch: 55 [14080/14860 (94%)]\tLoss: 0.020731\n",
      "Train Epoch: 55 [14208/14860 (95%)]\tLoss: 0.019886\n",
      "Train Epoch: 55 [14336/14860 (96%)]\tLoss: 0.031326\n",
      "Train Epoch: 55 [14464/14860 (97%)]\tLoss: 0.021014\n",
      "Train Epoch: 55 [14592/14860 (97%)]\tLoss: 0.017859\n",
      "Train Epoch: 55 [14720/14860 (98%)]\tLoss: 0.013146\n",
      "Train Epoch: 55 [1392/14860 (99%)]\tLoss: 0.022642\n",
      "epoch 55 training loss: 0.021857937057621967\n",
      "epoch 55 validation loss: 0.027269568772350615\n",
      "Train Epoch: 56 [0/14860 (0%)]\tLoss: 0.025716\n",
      "Train Epoch: 56 [128/14860 (1%)]\tLoss: 0.013041\n",
      "Train Epoch: 56 [256/14860 (2%)]\tLoss: 0.033406\n",
      "Train Epoch: 56 [384/14860 (3%)]\tLoss: 0.018838\n",
      "Train Epoch: 56 [512/14860 (3%)]\tLoss: 0.027814\n",
      "Train Epoch: 56 [640/14860 (4%)]\tLoss: 0.024134\n",
      "Train Epoch: 56 [768/14860 (5%)]\tLoss: 0.024183\n",
      "Train Epoch: 56 [896/14860 (6%)]\tLoss: 0.022699\n",
      "Train Epoch: 56 [1024/14860 (7%)]\tLoss: 0.015004\n",
      "Train Epoch: 56 [1152/14860 (8%)]\tLoss: 0.024518\n",
      "Train Epoch: 56 [1280/14860 (9%)]\tLoss: 0.013927\n",
      "Train Epoch: 56 [1408/14860 (9%)]\tLoss: 0.029746\n",
      "Train Epoch: 56 [1536/14860 (10%)]\tLoss: 0.015677\n",
      "Train Epoch: 56 [1664/14860 (11%)]\tLoss: 0.029528\n",
      "Train Epoch: 56 [1792/14860 (12%)]\tLoss: 0.029601\n",
      "Train Epoch: 56 [1920/14860 (13%)]\tLoss: 0.022179\n",
      "Train Epoch: 56 [2048/14860 (14%)]\tLoss: 0.018250\n",
      "Train Epoch: 56 [2176/14860 (15%)]\tLoss: 0.023301\n",
      "Train Epoch: 56 [2304/14860 (15%)]\tLoss: 0.018942\n",
      "Train Epoch: 56 [2432/14860 (16%)]\tLoss: 0.020611\n",
      "Train Epoch: 56 [2560/14860 (17%)]\tLoss: 0.022179\n",
      "Train Epoch: 56 [2688/14860 (18%)]\tLoss: 0.024151\n",
      "Train Epoch: 56 [2816/14860 (19%)]\tLoss: 0.023506\n",
      "Train Epoch: 56 [2944/14860 (20%)]\tLoss: 0.019692\n",
      "Train Epoch: 56 [3072/14860 (21%)]\tLoss: 0.017555\n",
      "Train Epoch: 56 [3200/14860 (21%)]\tLoss: 0.014688\n",
      "Train Epoch: 56 [3328/14860 (22%)]\tLoss: 0.019062\n",
      "Train Epoch: 56 [3456/14860 (23%)]\tLoss: 0.022805\n",
      "Train Epoch: 56 [3584/14860 (24%)]\tLoss: 0.014839\n",
      "Train Epoch: 56 [3712/14860 (25%)]\tLoss: 0.023481\n",
      "Train Epoch: 56 [3840/14860 (26%)]\tLoss: 0.023719\n",
      "Train Epoch: 56 [3968/14860 (26%)]\tLoss: 0.025001\n",
      "Train Epoch: 56 [4096/14860 (27%)]\tLoss: 0.015694\n",
      "Train Epoch: 56 [4224/14860 (28%)]\tLoss: 0.021190\n",
      "Train Epoch: 56 [4352/14860 (29%)]\tLoss: 0.021270\n",
      "Train Epoch: 56 [4480/14860 (30%)]\tLoss: 0.022495\n",
      "Train Epoch: 56 [4608/14860 (31%)]\tLoss: 0.021982\n",
      "Train Epoch: 56 [4736/14860 (32%)]\tLoss: 0.026652\n",
      "Train Epoch: 56 [4864/14860 (32%)]\tLoss: 0.031911\n",
      "Train Epoch: 56 [4992/14860 (33%)]\tLoss: 0.023126\n",
      "Train Epoch: 56 [5120/14860 (34%)]\tLoss: 0.014423\n",
      "Train Epoch: 56 [5248/14860 (35%)]\tLoss: 0.017985\n",
      "Train Epoch: 56 [5376/14860 (36%)]\tLoss: 0.014850\n",
      "Train Epoch: 56 [5504/14860 (37%)]\tLoss: 0.017620\n",
      "Train Epoch: 56 [5632/14860 (38%)]\tLoss: 0.029992\n",
      "Train Epoch: 56 [5760/14860 (38%)]\tLoss: 0.018846\n",
      "Train Epoch: 56 [5888/14860 (39%)]\tLoss: 0.015695\n",
      "Train Epoch: 56 [6016/14860 (40%)]\tLoss: 0.018468\n",
      "Train Epoch: 56 [6144/14860 (41%)]\tLoss: 0.021988\n",
      "Train Epoch: 56 [6272/14860 (42%)]\tLoss: 0.026136\n",
      "Train Epoch: 56 [6400/14860 (43%)]\tLoss: 0.016771\n",
      "Train Epoch: 56 [6528/14860 (44%)]\tLoss: 0.026017\n",
      "Train Epoch: 56 [6656/14860 (44%)]\tLoss: 0.017370\n",
      "Train Epoch: 56 [6784/14860 (45%)]\tLoss: 0.021504\n",
      "Train Epoch: 56 [6912/14860 (46%)]\tLoss: 0.021522\n",
      "Train Epoch: 56 [7040/14860 (47%)]\tLoss: 0.020281\n",
      "Train Epoch: 56 [7168/14860 (48%)]\tLoss: 0.016656\n",
      "Train Epoch: 56 [7296/14860 (49%)]\tLoss: 0.025706\n",
      "Train Epoch: 56 [7424/14860 (50%)]\tLoss: 0.017941\n",
      "Train Epoch: 56 [7552/14860 (50%)]\tLoss: 0.026582\n",
      "Train Epoch: 56 [7680/14860 (51%)]\tLoss: 0.023964\n",
      "Train Epoch: 56 [7808/14860 (52%)]\tLoss: 0.022846\n",
      "Train Epoch: 56 [7936/14860 (53%)]\tLoss: 0.022884\n",
      "Train Epoch: 56 [8064/14860 (54%)]\tLoss: 0.032119\n",
      "Train Epoch: 56 [8192/14860 (55%)]\tLoss: 0.015178\n",
      "Train Epoch: 56 [8320/14860 (56%)]\tLoss: 0.019745\n",
      "Train Epoch: 56 [8448/14860 (56%)]\tLoss: 0.023405\n",
      "Train Epoch: 56 [8576/14860 (57%)]\tLoss: 0.022258\n",
      "Train Epoch: 56 [8704/14860 (58%)]\tLoss: 0.020974\n",
      "Train Epoch: 56 [8832/14860 (59%)]\tLoss: 0.020203\n",
      "Train Epoch: 56 [8960/14860 (60%)]\tLoss: 0.014886\n",
      "Train Epoch: 56 [9088/14860 (61%)]\tLoss: 0.023317\n",
      "Train Epoch: 56 [9216/14860 (62%)]\tLoss: 0.018713\n",
      "Train Epoch: 56 [9344/14860 (62%)]\tLoss: 0.026431\n",
      "Train Epoch: 56 [9472/14860 (63%)]\tLoss: 0.017668\n",
      "Train Epoch: 56 [9600/14860 (64%)]\tLoss: 0.029604\n",
      "Train Epoch: 56 [9728/14860 (65%)]\tLoss: 0.015201\n",
      "Train Epoch: 56 [9856/14860 (66%)]\tLoss: 0.019572\n",
      "Train Epoch: 56 [9984/14860 (67%)]\tLoss: 0.023182\n",
      "Train Epoch: 56 [10112/14860 (68%)]\tLoss: 0.023190\n",
      "Train Epoch: 56 [10240/14860 (68%)]\tLoss: 0.026191\n",
      "Train Epoch: 56 [10368/14860 (69%)]\tLoss: 0.013631\n",
      "Train Epoch: 56 [10496/14860 (70%)]\tLoss: 0.016111\n",
      "Train Epoch: 56 [10624/14860 (71%)]\tLoss: 0.015673\n",
      "Train Epoch: 56 [10752/14860 (72%)]\tLoss: 0.022956\n",
      "Train Epoch: 56 [10880/14860 (73%)]\tLoss: 0.028436\n",
      "Train Epoch: 56 [11008/14860 (74%)]\tLoss: 0.025263\n",
      "Train Epoch: 56 [11136/14860 (74%)]\tLoss: 0.019777\n",
      "Train Epoch: 56 [11264/14860 (75%)]\tLoss: 0.013588\n",
      "Train Epoch: 56 [11392/14860 (76%)]\tLoss: 0.019238\n",
      "Train Epoch: 56 [11520/14860 (77%)]\tLoss: 0.019733\n",
      "Train Epoch: 56 [11648/14860 (78%)]\tLoss: 0.024989\n",
      "Train Epoch: 56 [11776/14860 (79%)]\tLoss: 0.013456\n",
      "Train Epoch: 56 [11904/14860 (79%)]\tLoss: 0.018253\n",
      "Train Epoch: 56 [12032/14860 (80%)]\tLoss: 0.027857\n",
      "Train Epoch: 56 [12160/14860 (81%)]\tLoss: 0.022917\n",
      "Train Epoch: 56 [12288/14860 (82%)]\tLoss: 0.022304\n",
      "Train Epoch: 56 [12416/14860 (83%)]\tLoss: 0.028301\n",
      "Train Epoch: 56 [12544/14860 (84%)]\tLoss: 0.024991\n",
      "Train Epoch: 56 [12672/14860 (85%)]\tLoss: 0.027372\n",
      "Train Epoch: 56 [12800/14860 (85%)]\tLoss: 0.016351\n",
      "Train Epoch: 56 [12928/14860 (86%)]\tLoss: 0.014759\n",
      "Train Epoch: 56 [13056/14860 (87%)]\tLoss: 0.020246\n",
      "Train Epoch: 56 [13184/14860 (88%)]\tLoss: 0.017022\n",
      "Train Epoch: 56 [13312/14860 (89%)]\tLoss: 0.017831\n",
      "Train Epoch: 56 [13440/14860 (90%)]\tLoss: 0.020313\n",
      "Train Epoch: 56 [13568/14860 (91%)]\tLoss: 0.021661\n",
      "Train Epoch: 56 [13696/14860 (91%)]\tLoss: 0.018350\n",
      "Train Epoch: 56 [13824/14860 (92%)]\tLoss: 0.022243\n",
      "Train Epoch: 56 [13952/14860 (93%)]\tLoss: 0.022742\n",
      "Train Epoch: 56 [14080/14860 (94%)]\tLoss: 0.018385\n",
      "Train Epoch: 56 [14208/14860 (95%)]\tLoss: 0.019654\n",
      "Train Epoch: 56 [14336/14860 (96%)]\tLoss: 0.020730\n",
      "Train Epoch: 56 [14464/14860 (97%)]\tLoss: 0.020814\n",
      "Train Epoch: 56 [14592/14860 (97%)]\tLoss: 0.023504\n",
      "Train Epoch: 56 [14720/14860 (98%)]\tLoss: 0.020158\n",
      "Train Epoch: 56 [1392/14860 (99%)]\tLoss: 0.011488\n",
      "epoch 56 training loss: 0.021240137334371734\n",
      "epoch 56 validation loss: 0.05553083818126244\n",
      "Train Epoch: 57 [0/14860 (0%)]\tLoss: 0.051600\n",
      "Train Epoch: 57 [128/14860 (1%)]\tLoss: 0.016045\n",
      "Train Epoch: 57 [256/14860 (2%)]\tLoss: 0.046679\n",
      "Train Epoch: 57 [384/14860 (3%)]\tLoss: 0.017776\n",
      "Train Epoch: 57 [512/14860 (3%)]\tLoss: 0.042599\n",
      "Train Epoch: 57 [640/14860 (4%)]\tLoss: 0.029267\n",
      "Train Epoch: 57 [768/14860 (5%)]\tLoss: 0.027498\n",
      "Train Epoch: 57 [896/14860 (6%)]\tLoss: 0.043021\n",
      "Train Epoch: 57 [1024/14860 (7%)]\tLoss: 0.027197\n",
      "Train Epoch: 57 [1152/14860 (8%)]\tLoss: 0.036770\n",
      "Train Epoch: 57 [1280/14860 (9%)]\tLoss: 0.024959\n",
      "Train Epoch: 57 [1408/14860 (9%)]\tLoss: 0.021555\n",
      "Train Epoch: 57 [1536/14860 (10%)]\tLoss: 0.042398\n",
      "Train Epoch: 57 [1664/14860 (11%)]\tLoss: 0.018153\n",
      "Train Epoch: 57 [1792/14860 (12%)]\tLoss: 0.023045\n",
      "Train Epoch: 57 [1920/14860 (13%)]\tLoss: 0.038137\n",
      "Train Epoch: 57 [2048/14860 (14%)]\tLoss: 0.022163\n",
      "Train Epoch: 57 [2176/14860 (15%)]\tLoss: 0.022313\n",
      "Train Epoch: 57 [2304/14860 (15%)]\tLoss: 0.033273\n",
      "Train Epoch: 57 [2432/14860 (16%)]\tLoss: 0.021162\n",
      "Train Epoch: 57 [2560/14860 (17%)]\tLoss: 0.029733\n",
      "Train Epoch: 57 [2688/14860 (18%)]\tLoss: 0.027986\n",
      "Train Epoch: 57 [2816/14860 (19%)]\tLoss: 0.018558\n",
      "Train Epoch: 57 [2944/14860 (20%)]\tLoss: 0.022893\n",
      "Train Epoch: 57 [3072/14860 (21%)]\tLoss: 0.024832\n",
      "Train Epoch: 57 [3200/14860 (21%)]\tLoss: 0.020736\n",
      "Train Epoch: 57 [3328/14860 (22%)]\tLoss: 0.017490\n",
      "Train Epoch: 57 [3456/14860 (23%)]\tLoss: 0.033961\n",
      "Train Epoch: 57 [3584/14860 (24%)]\tLoss: 0.023577\n",
      "Train Epoch: 57 [3712/14860 (25%)]\tLoss: 0.019568\n",
      "Train Epoch: 57 [3840/14860 (26%)]\tLoss: 0.027740\n",
      "Train Epoch: 57 [3968/14860 (26%)]\tLoss: 0.021172\n",
      "Train Epoch: 57 [4096/14860 (27%)]\tLoss: 0.022643\n",
      "Train Epoch: 57 [4224/14860 (28%)]\tLoss: 0.024920\n",
      "Train Epoch: 57 [4352/14860 (29%)]\tLoss: 0.024195\n",
      "Train Epoch: 57 [4480/14860 (30%)]\tLoss: 0.021491\n",
      "Train Epoch: 57 [4608/14860 (31%)]\tLoss: 0.026455\n",
      "Train Epoch: 57 [4736/14860 (32%)]\tLoss: 0.020328\n",
      "Train Epoch: 57 [4864/14860 (32%)]\tLoss: 0.019473\n",
      "Train Epoch: 57 [4992/14860 (33%)]\tLoss: 0.022495\n",
      "Train Epoch: 57 [5120/14860 (34%)]\tLoss: 0.019561\n",
      "Train Epoch: 57 [5248/14860 (35%)]\tLoss: 0.020898\n",
      "Train Epoch: 57 [5376/14860 (36%)]\tLoss: 0.031908\n",
      "Train Epoch: 57 [5504/14860 (37%)]\tLoss: 0.018121\n",
      "Train Epoch: 57 [5632/14860 (38%)]\tLoss: 0.015227\n",
      "Train Epoch: 57 [5760/14860 (38%)]\tLoss: 0.023709\n",
      "Train Epoch: 57 [5888/14860 (39%)]\tLoss: 0.017095\n",
      "Train Epoch: 57 [6016/14860 (40%)]\tLoss: 0.019048\n",
      "Train Epoch: 57 [6144/14860 (41%)]\tLoss: 0.016066\n",
      "Train Epoch: 57 [6272/14860 (42%)]\tLoss: 0.018354\n",
      "Train Epoch: 57 [6400/14860 (43%)]\tLoss: 0.018155\n",
      "Train Epoch: 57 [6528/14860 (44%)]\tLoss: 0.016720\n",
      "Train Epoch: 57 [6656/14860 (44%)]\tLoss: 0.016817\n",
      "Train Epoch: 57 [6784/14860 (45%)]\tLoss: 0.014761\n",
      "Train Epoch: 57 [6912/14860 (46%)]\tLoss: 0.021994\n",
      "Train Epoch: 57 [7040/14860 (47%)]\tLoss: 0.017797\n",
      "Train Epoch: 57 [7168/14860 (48%)]\tLoss: 0.019889\n",
      "Train Epoch: 57 [7296/14860 (49%)]\tLoss: 0.017642\n",
      "Train Epoch: 57 [7424/14860 (50%)]\tLoss: 0.024295\n",
      "Train Epoch: 57 [7552/14860 (50%)]\tLoss: 0.018489\n",
      "Train Epoch: 57 [7680/14860 (51%)]\tLoss: 0.024521\n",
      "Train Epoch: 57 [7808/14860 (52%)]\tLoss: 0.024659\n",
      "Train Epoch: 57 [7936/14860 (53%)]\tLoss: 0.018669\n",
      "Train Epoch: 57 [8064/14860 (54%)]\tLoss: 0.023054\n",
      "Train Epoch: 57 [8192/14860 (55%)]\tLoss: 0.018744\n",
      "Train Epoch: 57 [8320/14860 (56%)]\tLoss: 0.022626\n",
      "Train Epoch: 57 [8448/14860 (56%)]\tLoss: 0.023485\n",
      "Train Epoch: 57 [8576/14860 (57%)]\tLoss: 0.019003\n",
      "Train Epoch: 57 [8704/14860 (58%)]\tLoss: 0.021728\n",
      "Train Epoch: 57 [8832/14860 (59%)]\tLoss: 0.015396\n",
      "Train Epoch: 57 [8960/14860 (60%)]\tLoss: 0.020969\n",
      "Train Epoch: 57 [9088/14860 (61%)]\tLoss: 0.018554\n",
      "Train Epoch: 57 [9216/14860 (62%)]\tLoss: 0.025691\n",
      "Train Epoch: 57 [9344/14860 (62%)]\tLoss: 0.016757\n",
      "Train Epoch: 57 [9472/14860 (63%)]\tLoss: 0.022826\n",
      "Train Epoch: 57 [9600/14860 (64%)]\tLoss: 0.034770\n",
      "Train Epoch: 57 [9728/14860 (65%)]\tLoss: 0.016894\n",
      "Train Epoch: 57 [9856/14860 (66%)]\tLoss: 0.026634\n",
      "Train Epoch: 57 [9984/14860 (67%)]\tLoss: 0.018834\n",
      "Train Epoch: 57 [10112/14860 (68%)]\tLoss: 0.022858\n",
      "Train Epoch: 57 [10240/14860 (68%)]\tLoss: 0.021276\n",
      "Train Epoch: 57 [10368/14860 (69%)]\tLoss: 0.020506\n",
      "Train Epoch: 57 [10496/14860 (70%)]\tLoss: 0.017054\n",
      "Train Epoch: 57 [10624/14860 (71%)]\tLoss: 0.023057\n",
      "Train Epoch: 57 [10752/14860 (72%)]\tLoss: 0.018125\n",
      "Train Epoch: 57 [10880/14860 (73%)]\tLoss: 0.016499\n",
      "Train Epoch: 57 [11008/14860 (74%)]\tLoss: 0.018832\n",
      "Train Epoch: 57 [11136/14860 (74%)]\tLoss: 0.027274\n",
      "Train Epoch: 57 [11264/14860 (75%)]\tLoss: 0.019714\n",
      "Train Epoch: 57 [11392/14860 (76%)]\tLoss: 0.016744\n",
      "Train Epoch: 57 [11520/14860 (77%)]\tLoss: 0.014965\n",
      "Train Epoch: 57 [11648/14860 (78%)]\tLoss: 0.024214\n",
      "Train Epoch: 57 [11776/14860 (79%)]\tLoss: 0.022495\n",
      "Train Epoch: 57 [11904/14860 (79%)]\tLoss: 0.027345\n",
      "Train Epoch: 57 [12032/14860 (80%)]\tLoss: 0.017612\n",
      "Train Epoch: 57 [12160/14860 (81%)]\tLoss: 0.035393\n",
      "Train Epoch: 57 [12288/14860 (82%)]\tLoss: 0.017300\n",
      "Train Epoch: 57 [12416/14860 (83%)]\tLoss: 0.027536\n",
      "Train Epoch: 57 [12544/14860 (84%)]\tLoss: 0.018678\n",
      "Train Epoch: 57 [12672/14860 (85%)]\tLoss: 0.027200\n",
      "Train Epoch: 57 [12800/14860 (85%)]\tLoss: 0.023742\n",
      "Train Epoch: 57 [12928/14860 (86%)]\tLoss: 0.020957\n",
      "Train Epoch: 57 [13056/14860 (87%)]\tLoss: 0.026022\n",
      "Train Epoch: 57 [13184/14860 (88%)]\tLoss: 0.024280\n",
      "Train Epoch: 57 [13312/14860 (89%)]\tLoss: 0.026112\n",
      "Train Epoch: 57 [13440/14860 (90%)]\tLoss: 0.023522\n",
      "Train Epoch: 57 [13568/14860 (91%)]\tLoss: 0.023643\n",
      "Train Epoch: 57 [13696/14860 (91%)]\tLoss: 0.024609\n",
      "Train Epoch: 57 [13824/14860 (92%)]\tLoss: 0.016566\n",
      "Train Epoch: 57 [13952/14860 (93%)]\tLoss: 0.021533\n",
      "Train Epoch: 57 [14080/14860 (94%)]\tLoss: 0.021335\n",
      "Train Epoch: 57 [14208/14860 (95%)]\tLoss: 0.018249\n",
      "Train Epoch: 57 [14336/14860 (96%)]\tLoss: 0.020454\n",
      "Train Epoch: 57 [14464/14860 (97%)]\tLoss: 0.020846\n",
      "Train Epoch: 57 [14592/14860 (97%)]\tLoss: 0.017487\n",
      "Train Epoch: 57 [14720/14860 (98%)]\tLoss: 0.021619\n",
      "Train Epoch: 57 [1392/14860 (99%)]\tLoss: 0.034459\n",
      "epoch 57 training loss: 0.023216482267802596\n",
      "epoch 57 validation loss: 0.0312558131125591\n",
      "Train Epoch: 58 [0/14860 (0%)]\tLoss: 0.028863\n",
      "Train Epoch: 58 [128/14860 (1%)]\tLoss: 0.024252\n",
      "Train Epoch: 58 [256/14860 (2%)]\tLoss: 0.020944\n",
      "Train Epoch: 58 [384/14860 (3%)]\tLoss: 0.023703\n",
      "Train Epoch: 58 [512/14860 (3%)]\tLoss: 0.020221\n",
      "Train Epoch: 58 [640/14860 (4%)]\tLoss: 0.018543\n",
      "Train Epoch: 58 [768/14860 (5%)]\tLoss: 0.016550\n",
      "Train Epoch: 58 [896/14860 (6%)]\tLoss: 0.011817\n",
      "Train Epoch: 58 [1024/14860 (7%)]\tLoss: 0.028171\n",
      "Train Epoch: 58 [1152/14860 (8%)]\tLoss: 0.014464\n",
      "Train Epoch: 58 [1280/14860 (9%)]\tLoss: 0.013211\n",
      "Train Epoch: 58 [1408/14860 (9%)]\tLoss: 0.021754\n",
      "Train Epoch: 58 [1536/14860 (10%)]\tLoss: 0.021366\n",
      "Train Epoch: 58 [1664/14860 (11%)]\tLoss: 0.016230\n",
      "Train Epoch: 58 [1792/14860 (12%)]\tLoss: 0.029411\n",
      "Train Epoch: 58 [1920/14860 (13%)]\tLoss: 0.023471\n",
      "Train Epoch: 58 [2048/14860 (14%)]\tLoss: 0.021646\n",
      "Train Epoch: 58 [2176/14860 (15%)]\tLoss: 0.017956\n",
      "Train Epoch: 58 [2304/14860 (15%)]\tLoss: 0.019346\n",
      "Train Epoch: 58 [2432/14860 (16%)]\tLoss: 0.018896\n",
      "Train Epoch: 58 [2560/14860 (17%)]\tLoss: 0.015466\n",
      "Train Epoch: 58 [2688/14860 (18%)]\tLoss: 0.022050\n",
      "Train Epoch: 58 [2816/14860 (19%)]\tLoss: 0.022486\n",
      "Train Epoch: 58 [2944/14860 (20%)]\tLoss: 0.032523\n",
      "Train Epoch: 58 [3072/14860 (21%)]\tLoss: 0.019190\n",
      "Train Epoch: 58 [3200/14860 (21%)]\tLoss: 0.022702\n",
      "Train Epoch: 58 [3328/14860 (22%)]\tLoss: 0.017961\n",
      "Train Epoch: 58 [3456/14860 (23%)]\tLoss: 0.019299\n",
      "Train Epoch: 58 [3584/14860 (24%)]\tLoss: 0.020568\n",
      "Train Epoch: 58 [3712/14860 (25%)]\tLoss: 0.017103\n",
      "Train Epoch: 58 [3840/14860 (26%)]\tLoss: 0.027310\n",
      "Train Epoch: 58 [3968/14860 (26%)]\tLoss: 0.016543\n",
      "Train Epoch: 58 [4096/14860 (27%)]\tLoss: 0.018835\n",
      "Train Epoch: 58 [4224/14860 (28%)]\tLoss: 0.015495\n",
      "Train Epoch: 58 [4352/14860 (29%)]\tLoss: 0.027052\n",
      "Train Epoch: 58 [4480/14860 (30%)]\tLoss: 0.017082\n",
      "Train Epoch: 58 [4608/14860 (31%)]\tLoss: 0.018897\n",
      "Train Epoch: 58 [4736/14860 (32%)]\tLoss: 0.016424\n",
      "Train Epoch: 58 [4864/14860 (32%)]\tLoss: 0.025385\n",
      "Train Epoch: 58 [4992/14860 (33%)]\tLoss: 0.018854\n",
      "Train Epoch: 58 [5120/14860 (34%)]\tLoss: 0.020191\n",
      "Train Epoch: 58 [5248/14860 (35%)]\tLoss: 0.017427\n",
      "Train Epoch: 58 [5376/14860 (36%)]\tLoss: 0.019016\n",
      "Train Epoch: 58 [5504/14860 (37%)]\tLoss: 0.029587\n",
      "Train Epoch: 58 [5632/14860 (38%)]\tLoss: 0.016682\n",
      "Train Epoch: 58 [5760/14860 (38%)]\tLoss: 0.023777\n",
      "Train Epoch: 58 [5888/14860 (39%)]\tLoss: 0.017657\n",
      "Train Epoch: 58 [6016/14860 (40%)]\tLoss: 0.024740\n",
      "Train Epoch: 58 [6144/14860 (41%)]\tLoss: 0.025744\n",
      "Train Epoch: 58 [6272/14860 (42%)]\tLoss: 0.027406\n",
      "Train Epoch: 58 [6400/14860 (43%)]\tLoss: 0.025663\n",
      "Train Epoch: 58 [6528/14860 (44%)]\tLoss: 0.019555\n",
      "Train Epoch: 58 [6656/14860 (44%)]\tLoss: 0.020857\n",
      "Train Epoch: 58 [6784/14860 (45%)]\tLoss: 0.022789\n",
      "Train Epoch: 58 [6912/14860 (46%)]\tLoss: 0.016380\n",
      "Train Epoch: 58 [7040/14860 (47%)]\tLoss: 0.012851\n",
      "Train Epoch: 58 [7168/14860 (48%)]\tLoss: 0.019104\n",
      "Train Epoch: 58 [7296/14860 (49%)]\tLoss: 0.013620\n",
      "Train Epoch: 58 [7424/14860 (50%)]\tLoss: 0.021611\n",
      "Train Epoch: 58 [7552/14860 (50%)]\tLoss: 0.014639\n",
      "Train Epoch: 58 [7680/14860 (51%)]\tLoss: 0.016860\n",
      "Train Epoch: 58 [7808/14860 (52%)]\tLoss: 0.018890\n",
      "Train Epoch: 58 [7936/14860 (53%)]\tLoss: 0.019530\n",
      "Train Epoch: 58 [8064/14860 (54%)]\tLoss: 0.018375\n",
      "Train Epoch: 58 [8192/14860 (55%)]\tLoss: 0.018675\n",
      "Train Epoch: 58 [8320/14860 (56%)]\tLoss: 0.019739\n",
      "Train Epoch: 58 [8448/14860 (56%)]\tLoss: 0.018401\n",
      "Train Epoch: 58 [8576/14860 (57%)]\tLoss: 0.019478\n",
      "Train Epoch: 58 [8704/14860 (58%)]\tLoss: 0.018335\n",
      "Train Epoch: 58 [8832/14860 (59%)]\tLoss: 0.016345\n",
      "Train Epoch: 58 [8960/14860 (60%)]\tLoss: 0.022335\n",
      "Train Epoch: 58 [9088/14860 (61%)]\tLoss: 0.023156\n",
      "Train Epoch: 58 [9216/14860 (62%)]\tLoss: 0.018449\n",
      "Train Epoch: 58 [9344/14860 (62%)]\tLoss: 0.025703\n",
      "Train Epoch: 58 [9472/14860 (63%)]\tLoss: 0.023657\n",
      "Train Epoch: 58 [9600/14860 (64%)]\tLoss: 0.028462\n",
      "Train Epoch: 58 [9728/14860 (65%)]\tLoss: 0.015325\n",
      "Train Epoch: 58 [9856/14860 (66%)]\tLoss: 0.017677\n",
      "Train Epoch: 58 [9984/14860 (67%)]\tLoss: 0.016683\n",
      "Train Epoch: 58 [10112/14860 (68%)]\tLoss: 0.016200\n",
      "Train Epoch: 58 [10240/14860 (68%)]\tLoss: 0.022123\n",
      "Train Epoch: 58 [10368/14860 (69%)]\tLoss: 0.025130\n",
      "Train Epoch: 58 [10496/14860 (70%)]\tLoss: 0.023003\n",
      "Train Epoch: 58 [10624/14860 (71%)]\tLoss: 0.015086\n",
      "Train Epoch: 58 [10752/14860 (72%)]\tLoss: 0.018069\n",
      "Train Epoch: 58 [10880/14860 (73%)]\tLoss: 0.029175\n",
      "Train Epoch: 58 [11008/14860 (74%)]\tLoss: 0.025111\n",
      "Train Epoch: 58 [11136/14860 (74%)]\tLoss: 0.027134\n",
      "Train Epoch: 58 [11264/14860 (75%)]\tLoss: 0.026373\n",
      "Train Epoch: 58 [11392/14860 (76%)]\tLoss: 0.027748\n",
      "Train Epoch: 58 [11520/14860 (77%)]\tLoss: 0.016535\n",
      "Train Epoch: 58 [11648/14860 (78%)]\tLoss: 0.027968\n",
      "Train Epoch: 58 [11776/14860 (79%)]\tLoss: 0.027828\n",
      "Train Epoch: 58 [11904/14860 (79%)]\tLoss: 0.013856\n",
      "Train Epoch: 58 [12032/14860 (80%)]\tLoss: 0.025435\n",
      "Train Epoch: 58 [12160/14860 (81%)]\tLoss: 0.023592\n",
      "Train Epoch: 58 [12288/14860 (82%)]\tLoss: 0.023639\n",
      "Train Epoch: 58 [12416/14860 (83%)]\tLoss: 0.020518\n",
      "Train Epoch: 58 [12544/14860 (84%)]\tLoss: 0.020562\n",
      "Train Epoch: 58 [12672/14860 (85%)]\tLoss: 0.032444\n",
      "Train Epoch: 58 [12800/14860 (85%)]\tLoss: 0.018548\n",
      "Train Epoch: 58 [12928/14860 (86%)]\tLoss: 0.024078\n",
      "Train Epoch: 58 [13056/14860 (87%)]\tLoss: 0.025577\n",
      "Train Epoch: 58 [13184/14860 (88%)]\tLoss: 0.016864\n",
      "Train Epoch: 58 [13312/14860 (89%)]\tLoss: 0.021353\n",
      "Train Epoch: 58 [13440/14860 (90%)]\tLoss: 0.018683\n",
      "Train Epoch: 58 [13568/14860 (91%)]\tLoss: 0.024882\n",
      "Train Epoch: 58 [13696/14860 (91%)]\tLoss: 0.022491\n",
      "Train Epoch: 58 [13824/14860 (92%)]\tLoss: 0.020531\n",
      "Train Epoch: 58 [13952/14860 (93%)]\tLoss: 0.017779\n",
      "Train Epoch: 58 [14080/14860 (94%)]\tLoss: 0.020668\n",
      "Train Epoch: 58 [14208/14860 (95%)]\tLoss: 0.021603\n",
      "Train Epoch: 58 [14336/14860 (96%)]\tLoss: 0.022099\n",
      "Train Epoch: 58 [14464/14860 (97%)]\tLoss: 0.027738\n",
      "Train Epoch: 58 [14592/14860 (97%)]\tLoss: 0.014654\n",
      "Train Epoch: 58 [14720/14860 (98%)]\tLoss: 0.023656\n",
      "Train Epoch: 58 [1392/14860 (99%)]\tLoss: 0.006914\n",
      "epoch 58 training loss: 0.020880849920531623\n",
      "epoch 58 validation loss: 0.022591935520310667\n",
      "Train Epoch: 59 [0/14860 (0%)]\tLoss: 0.020727\n",
      "Train Epoch: 59 [128/14860 (1%)]\tLoss: 0.027242\n",
      "Train Epoch: 59 [256/14860 (2%)]\tLoss: 0.019072\n",
      "Train Epoch: 59 [384/14860 (3%)]\tLoss: 0.024135\n",
      "Train Epoch: 59 [512/14860 (3%)]\tLoss: 0.016422\n",
      "Train Epoch: 59 [640/14860 (4%)]\tLoss: 0.024447\n",
      "Train Epoch: 59 [768/14860 (5%)]\tLoss: 0.023485\n",
      "Train Epoch: 59 [896/14860 (6%)]\tLoss: 0.018930\n",
      "Train Epoch: 59 [1024/14860 (7%)]\tLoss: 0.022023\n",
      "Train Epoch: 59 [1152/14860 (8%)]\tLoss: 0.023551\n",
      "Train Epoch: 59 [1280/14860 (9%)]\tLoss: 0.019443\n",
      "Train Epoch: 59 [1408/14860 (9%)]\tLoss: 0.015550\n",
      "Train Epoch: 59 [1536/14860 (10%)]\tLoss: 0.016898\n",
      "Train Epoch: 59 [1664/14860 (11%)]\tLoss: 0.023472\n",
      "Train Epoch: 59 [1792/14860 (12%)]\tLoss: 0.016888\n",
      "Train Epoch: 59 [1920/14860 (13%)]\tLoss: 0.021918\n",
      "Train Epoch: 59 [2048/14860 (14%)]\tLoss: 0.019837\n",
      "Train Epoch: 59 [2176/14860 (15%)]\tLoss: 0.018155\n",
      "Train Epoch: 59 [2304/14860 (15%)]\tLoss: 0.023212\n",
      "Train Epoch: 59 [2432/14860 (16%)]\tLoss: 0.018322\n",
      "Train Epoch: 59 [2560/14860 (17%)]\tLoss: 0.019893\n",
      "Train Epoch: 59 [2688/14860 (18%)]\tLoss: 0.030315\n",
      "Train Epoch: 59 [2816/14860 (19%)]\tLoss: 0.018273\n",
      "Train Epoch: 59 [2944/14860 (20%)]\tLoss: 0.021718\n",
      "Train Epoch: 59 [3072/14860 (21%)]\tLoss: 0.019763\n",
      "Train Epoch: 59 [3200/14860 (21%)]\tLoss: 0.025924\n",
      "Train Epoch: 59 [3328/14860 (22%)]\tLoss: 0.026410\n",
      "Train Epoch: 59 [3456/14860 (23%)]\tLoss: 0.038472\n",
      "Train Epoch: 59 [3584/14860 (24%)]\tLoss: 0.013823\n",
      "Train Epoch: 59 [3712/14860 (25%)]\tLoss: 0.033401\n",
      "Train Epoch: 59 [3840/14860 (26%)]\tLoss: 0.023992\n",
      "Train Epoch: 59 [3968/14860 (26%)]\tLoss: 0.027710\n",
      "Train Epoch: 59 [4096/14860 (27%)]\tLoss: 0.026560\n",
      "Train Epoch: 59 [4224/14860 (28%)]\tLoss: 0.027615\n",
      "Train Epoch: 59 [4352/14860 (29%)]\tLoss: 0.029006\n",
      "Train Epoch: 59 [4480/14860 (30%)]\tLoss: 0.018275\n",
      "Train Epoch: 59 [4608/14860 (31%)]\tLoss: 0.023742\n",
      "Train Epoch: 59 [4736/14860 (32%)]\tLoss: 0.022041\n",
      "Train Epoch: 59 [4864/14860 (32%)]\tLoss: 0.020920\n",
      "Train Epoch: 59 [4992/14860 (33%)]\tLoss: 0.022381\n",
      "Train Epoch: 59 [5120/14860 (34%)]\tLoss: 0.018893\n",
      "Train Epoch: 59 [5248/14860 (35%)]\tLoss: 0.020332\n",
      "Train Epoch: 59 [5376/14860 (36%)]\tLoss: 0.018144\n",
      "Train Epoch: 59 [5504/14860 (37%)]\tLoss: 0.016944\n",
      "Train Epoch: 59 [5632/14860 (38%)]\tLoss: 0.024615\n",
      "Train Epoch: 59 [5760/14860 (38%)]\tLoss: 0.027804\n",
      "Train Epoch: 59 [5888/14860 (39%)]\tLoss: 0.024411\n",
      "Train Epoch: 59 [6016/14860 (40%)]\tLoss: 0.031854\n",
      "Train Epoch: 59 [6144/14860 (41%)]\tLoss: 0.014942\n",
      "Train Epoch: 59 [6272/14860 (42%)]\tLoss: 0.024531\n",
      "Train Epoch: 59 [6400/14860 (43%)]\tLoss: 0.037205\n",
      "Train Epoch: 59 [6528/14860 (44%)]\tLoss: 0.025098\n",
      "Train Epoch: 59 [6656/14860 (44%)]\tLoss: 0.030081\n",
      "Train Epoch: 59 [6784/14860 (45%)]\tLoss: 0.028265\n",
      "Train Epoch: 59 [6912/14860 (46%)]\tLoss: 0.030416\n",
      "Train Epoch: 59 [7040/14860 (47%)]\tLoss: 0.029710\n",
      "Train Epoch: 59 [7168/14860 (48%)]\tLoss: 0.021435\n",
      "Train Epoch: 59 [7296/14860 (49%)]\tLoss: 0.018652\n",
      "Train Epoch: 59 [7424/14860 (50%)]\tLoss: 0.027792\n",
      "Train Epoch: 59 [7552/14860 (50%)]\tLoss: 0.013895\n",
      "Train Epoch: 59 [7680/14860 (51%)]\tLoss: 0.020417\n",
      "Train Epoch: 59 [7808/14860 (52%)]\tLoss: 0.021829\n",
      "Train Epoch: 59 [7936/14860 (53%)]\tLoss: 0.019169\n",
      "Train Epoch: 59 [8064/14860 (54%)]\tLoss: 0.023529\n",
      "Train Epoch: 59 [8192/14860 (55%)]\tLoss: 0.026605\n",
      "Train Epoch: 59 [8320/14860 (56%)]\tLoss: 0.013763\n",
      "Train Epoch: 59 [8448/14860 (56%)]\tLoss: 0.019018\n",
      "Train Epoch: 59 [8576/14860 (57%)]\tLoss: 0.025712\n",
      "Train Epoch: 59 [8704/14860 (58%)]\tLoss: 0.022916\n",
      "Train Epoch: 59 [8832/14860 (59%)]\tLoss: 0.020855\n",
      "Train Epoch: 59 [8960/14860 (60%)]\tLoss: 0.017995\n",
      "Train Epoch: 59 [9088/14860 (61%)]\tLoss: 0.025595\n",
      "Train Epoch: 59 [9216/14860 (62%)]\tLoss: 0.027854\n",
      "Train Epoch: 59 [9344/14860 (62%)]\tLoss: 0.022015\n",
      "Train Epoch: 59 [9472/14860 (63%)]\tLoss: 0.027339\n",
      "Train Epoch: 59 [9600/14860 (64%)]\tLoss: 0.019278\n",
      "Train Epoch: 59 [9728/14860 (65%)]\tLoss: 0.014689\n",
      "Train Epoch: 59 [9856/14860 (66%)]\tLoss: 0.029840\n",
      "Train Epoch: 59 [9984/14860 (67%)]\tLoss: 0.020412\n",
      "Train Epoch: 59 [10112/14860 (68%)]\tLoss: 0.018492\n",
      "Train Epoch: 59 [10240/14860 (68%)]\tLoss: 0.029724\n",
      "Train Epoch: 59 [10368/14860 (69%)]\tLoss: 0.018045\n",
      "Train Epoch: 59 [10496/14860 (70%)]\tLoss: 0.028777\n",
      "Train Epoch: 59 [10624/14860 (71%)]\tLoss: 0.021090\n",
      "Train Epoch: 59 [10752/14860 (72%)]\tLoss: 0.018762\n",
      "Train Epoch: 59 [10880/14860 (73%)]\tLoss: 0.026337\n",
      "Train Epoch: 59 [11008/14860 (74%)]\tLoss: 0.019380\n",
      "Train Epoch: 59 [11136/14860 (74%)]\tLoss: 0.020201\n",
      "Train Epoch: 59 [11264/14860 (75%)]\tLoss: 0.022101\n",
      "Train Epoch: 59 [11392/14860 (76%)]\tLoss: 0.017194\n",
      "Train Epoch: 59 [11520/14860 (77%)]\tLoss: 0.022629\n",
      "Train Epoch: 59 [11648/14860 (78%)]\tLoss: 0.025712\n",
      "Train Epoch: 59 [11776/14860 (79%)]\tLoss: 0.017803\n",
      "Train Epoch: 59 [11904/14860 (79%)]\tLoss: 0.022376\n",
      "Train Epoch: 59 [12032/14860 (80%)]\tLoss: 0.019991\n",
      "Train Epoch: 59 [12160/14860 (81%)]\tLoss: 0.014891\n",
      "Train Epoch: 59 [12288/14860 (82%)]\tLoss: 0.020531\n",
      "Train Epoch: 59 [12416/14860 (83%)]\tLoss: 0.016704\n",
      "Train Epoch: 59 [12544/14860 (84%)]\tLoss: 0.022066\n",
      "Train Epoch: 59 [12672/14860 (85%)]\tLoss: 0.039623\n",
      "Train Epoch: 59 [12800/14860 (85%)]\tLoss: 0.020616\n",
      "Train Epoch: 59 [12928/14860 (86%)]\tLoss: 0.027433\n",
      "Train Epoch: 59 [13056/14860 (87%)]\tLoss: 0.025959\n",
      "Train Epoch: 59 [13184/14860 (88%)]\tLoss: 0.027002\n",
      "Train Epoch: 59 [13312/14860 (89%)]\tLoss: 0.023820\n",
      "Train Epoch: 59 [13440/14860 (90%)]\tLoss: 0.015192\n",
      "Train Epoch: 59 [13568/14860 (91%)]\tLoss: 0.021896\n",
      "Train Epoch: 59 [13696/14860 (91%)]\tLoss: 0.017193\n",
      "Train Epoch: 59 [13824/14860 (92%)]\tLoss: 0.025321\n",
      "Train Epoch: 59 [13952/14860 (93%)]\tLoss: 0.020914\n",
      "Train Epoch: 59 [14080/14860 (94%)]\tLoss: 0.020092\n",
      "Train Epoch: 59 [14208/14860 (95%)]\tLoss: 0.029742\n",
      "Train Epoch: 59 [14336/14860 (96%)]\tLoss: 0.021526\n",
      "Train Epoch: 59 [14464/14860 (97%)]\tLoss: 0.019159\n",
      "Train Epoch: 59 [14592/14860 (97%)]\tLoss: 0.018261\n",
      "Train Epoch: 59 [14720/14860 (98%)]\tLoss: 0.017471\n",
      "Train Epoch: 59 [1392/14860 (99%)]\tLoss: 0.009029\n",
      "epoch 59 training loss: 0.022486048360538278\n",
      "epoch 59 validation loss: 0.02217701142405771\n",
      "Train Epoch: 60 [0/14860 (0%)]\tLoss: 0.021699\n",
      "Train Epoch: 60 [128/14860 (1%)]\tLoss: 0.014470\n",
      "Train Epoch: 60 [256/14860 (2%)]\tLoss: 0.016242\n",
      "Train Epoch: 60 [384/14860 (3%)]\tLoss: 0.021683\n",
      "Train Epoch: 60 [512/14860 (3%)]\tLoss: 0.017989\n",
      "Train Epoch: 60 [640/14860 (4%)]\tLoss: 0.017515\n",
      "Train Epoch: 60 [768/14860 (5%)]\tLoss: 0.021530\n",
      "Train Epoch: 60 [896/14860 (6%)]\tLoss: 0.020039\n",
      "Train Epoch: 60 [1024/14860 (7%)]\tLoss: 0.020820\n",
      "Train Epoch: 60 [1152/14860 (8%)]\tLoss: 0.018575\n",
      "Train Epoch: 60 [1280/14860 (9%)]\tLoss: 0.016179\n",
      "Train Epoch: 60 [1408/14860 (9%)]\tLoss: 0.019462\n",
      "Train Epoch: 60 [1536/14860 (10%)]\tLoss: 0.024516\n",
      "Train Epoch: 60 [1664/14860 (11%)]\tLoss: 0.023549\n",
      "Train Epoch: 60 [1792/14860 (12%)]\tLoss: 0.022691\n",
      "Train Epoch: 60 [1920/14860 (13%)]\tLoss: 0.021238\n",
      "Train Epoch: 60 [2048/14860 (14%)]\tLoss: 0.017738\n",
      "Train Epoch: 60 [2176/14860 (15%)]\tLoss: 0.018442\n",
      "Train Epoch: 60 [2304/14860 (15%)]\tLoss: 0.020017\n",
      "Train Epoch: 60 [2432/14860 (16%)]\tLoss: 0.018050\n",
      "Train Epoch: 60 [2560/14860 (17%)]\tLoss: 0.019303\n",
      "Train Epoch: 60 [2688/14860 (18%)]\tLoss: 0.020510\n",
      "Train Epoch: 60 [2816/14860 (19%)]\tLoss: 0.016251\n",
      "Train Epoch: 60 [2944/14860 (20%)]\tLoss: 0.023241\n",
      "Train Epoch: 60 [3072/14860 (21%)]\tLoss: 0.012512\n",
      "Train Epoch: 60 [3200/14860 (21%)]\tLoss: 0.029439\n",
      "Train Epoch: 60 [3328/14860 (22%)]\tLoss: 0.014683\n",
      "Train Epoch: 60 [3456/14860 (23%)]\tLoss: 0.020612\n",
      "Train Epoch: 60 [3584/14860 (24%)]\tLoss: 0.025476\n",
      "Train Epoch: 60 [3712/14860 (25%)]\tLoss: 0.020934\n",
      "Train Epoch: 60 [3840/14860 (26%)]\tLoss: 0.020309\n",
      "Train Epoch: 60 [3968/14860 (26%)]\tLoss: 0.021583\n",
      "Train Epoch: 60 [4096/14860 (27%)]\tLoss: 0.019853\n",
      "Train Epoch: 60 [4224/14860 (28%)]\tLoss: 0.028147\n",
      "Train Epoch: 60 [4352/14860 (29%)]\tLoss: 0.024476\n",
      "Train Epoch: 60 [4480/14860 (30%)]\tLoss: 0.030562\n",
      "Train Epoch: 60 [4608/14860 (31%)]\tLoss: 0.022677\n",
      "Train Epoch: 60 [4736/14860 (32%)]\tLoss: 0.021195\n",
      "Train Epoch: 60 [4864/14860 (32%)]\tLoss: 0.017218\n",
      "Train Epoch: 60 [4992/14860 (33%)]\tLoss: 0.029133\n",
      "Train Epoch: 60 [5120/14860 (34%)]\tLoss: 0.021360\n",
      "Train Epoch: 60 [5248/14860 (35%)]\tLoss: 0.018391\n",
      "Train Epoch: 60 [5376/14860 (36%)]\tLoss: 0.030286\n",
      "Train Epoch: 60 [5504/14860 (37%)]\tLoss: 0.020566\n",
      "Train Epoch: 60 [5632/14860 (38%)]\tLoss: 0.022466\n",
      "Train Epoch: 60 [5760/14860 (38%)]\tLoss: 0.015394\n",
      "Train Epoch: 60 [5888/14860 (39%)]\tLoss: 0.024582\n",
      "Train Epoch: 60 [6016/14860 (40%)]\tLoss: 0.014984\n",
      "Train Epoch: 60 [6144/14860 (41%)]\tLoss: 0.024935\n",
      "Train Epoch: 60 [6272/14860 (42%)]\tLoss: 0.015084\n",
      "Train Epoch: 60 [6400/14860 (43%)]\tLoss: 0.014990\n",
      "Train Epoch: 60 [6528/14860 (44%)]\tLoss: 0.019673\n",
      "Train Epoch: 60 [6656/14860 (44%)]\tLoss: 0.023803\n",
      "Train Epoch: 60 [6784/14860 (45%)]\tLoss: 0.028000\n",
      "Train Epoch: 60 [6912/14860 (46%)]\tLoss: 0.023604\n",
      "Train Epoch: 60 [7040/14860 (47%)]\tLoss: 0.020669\n",
      "Train Epoch: 60 [7168/14860 (48%)]\tLoss: 0.033617\n",
      "Train Epoch: 60 [7296/14860 (49%)]\tLoss: 0.019815\n",
      "Train Epoch: 60 [7424/14860 (50%)]\tLoss: 0.022336\n",
      "Train Epoch: 60 [7552/14860 (50%)]\tLoss: 0.022241\n",
      "Train Epoch: 60 [7680/14860 (51%)]\tLoss: 0.018194\n",
      "Train Epoch: 60 [7808/14860 (52%)]\tLoss: 0.025080\n",
      "Train Epoch: 60 [7936/14860 (53%)]\tLoss: 0.017551\n",
      "Train Epoch: 60 [8064/14860 (54%)]\tLoss: 0.020254\n",
      "Train Epoch: 60 [8192/14860 (55%)]\tLoss: 0.023613\n",
      "Train Epoch: 60 [8320/14860 (56%)]\tLoss: 0.014786\n",
      "Train Epoch: 60 [8448/14860 (56%)]\tLoss: 0.017489\n",
      "Train Epoch: 60 [8576/14860 (57%)]\tLoss: 0.017041\n",
      "Train Epoch: 60 [8704/14860 (58%)]\tLoss: 0.014875\n",
      "Train Epoch: 60 [8832/14860 (59%)]\tLoss: 0.021310\n",
      "Train Epoch: 60 [8960/14860 (60%)]\tLoss: 0.014236\n",
      "Train Epoch: 60 [9088/14860 (61%)]\tLoss: 0.022360\n",
      "Train Epoch: 60 [9216/14860 (62%)]\tLoss: 0.023310\n",
      "Train Epoch: 60 [9344/14860 (62%)]\tLoss: 0.029036\n",
      "Train Epoch: 60 [9472/14860 (63%)]\tLoss: 0.021028\n",
      "Train Epoch: 60 [9600/14860 (64%)]\tLoss: 0.030494\n",
      "Train Epoch: 60 [9728/14860 (65%)]\tLoss: 0.026535\n",
      "Train Epoch: 60 [9856/14860 (66%)]\tLoss: 0.015136\n",
      "Train Epoch: 60 [9984/14860 (67%)]\tLoss: 0.025450\n",
      "Train Epoch: 60 [10112/14860 (68%)]\tLoss: 0.020519\n",
      "Train Epoch: 60 [10240/14860 (68%)]\tLoss: 0.022628\n",
      "Train Epoch: 60 [10368/14860 (69%)]\tLoss: 0.028224\n",
      "Train Epoch: 60 [10496/14860 (70%)]\tLoss: 0.023178\n",
      "Train Epoch: 60 [10624/14860 (71%)]\tLoss: 0.016814\n",
      "Train Epoch: 60 [10752/14860 (72%)]\tLoss: 0.013908\n",
      "Train Epoch: 60 [10880/14860 (73%)]\tLoss: 0.029957\n",
      "Train Epoch: 60 [11008/14860 (74%)]\tLoss: 0.022127\n",
      "Train Epoch: 60 [11136/14860 (74%)]\tLoss: 0.022891\n",
      "Train Epoch: 60 [11264/14860 (75%)]\tLoss: 0.021882\n",
      "Train Epoch: 60 [11392/14860 (76%)]\tLoss: 0.016000\n",
      "Train Epoch: 60 [11520/14860 (77%)]\tLoss: 0.023221\n",
      "Train Epoch: 60 [11648/14860 (78%)]\tLoss: 0.021235\n",
      "Train Epoch: 60 [11776/14860 (79%)]\tLoss: 0.023078\n",
      "Train Epoch: 60 [11904/14860 (79%)]\tLoss: 0.039309\n",
      "Train Epoch: 60 [12032/14860 (80%)]\tLoss: 0.021833\n",
      "Train Epoch: 60 [12160/14860 (81%)]\tLoss: 0.019613\n",
      "Train Epoch: 60 [12288/14860 (82%)]\tLoss: 0.024522\n",
      "Train Epoch: 60 [12416/14860 (83%)]\tLoss: 0.020677\n",
      "Train Epoch: 60 [12544/14860 (84%)]\tLoss: 0.023244\n",
      "Train Epoch: 60 [12672/14860 (85%)]\tLoss: 0.019591\n",
      "Train Epoch: 60 [12800/14860 (85%)]\tLoss: 0.025502\n",
      "Train Epoch: 60 [12928/14860 (86%)]\tLoss: 0.022659\n",
      "Train Epoch: 60 [13056/14860 (87%)]\tLoss: 0.016915\n",
      "Train Epoch: 60 [13184/14860 (88%)]\tLoss: 0.031226\n",
      "Train Epoch: 60 [13312/14860 (89%)]\tLoss: 0.020180\n",
      "Train Epoch: 60 [13440/14860 (90%)]\tLoss: 0.015377\n",
      "Train Epoch: 60 [13568/14860 (91%)]\tLoss: 0.014253\n",
      "Train Epoch: 60 [13696/14860 (91%)]\tLoss: 0.015978\n",
      "Train Epoch: 60 [13824/14860 (92%)]\tLoss: 0.015214\n",
      "Train Epoch: 60 [13952/14860 (93%)]\tLoss: 0.014946\n",
      "Train Epoch: 60 [14080/14860 (94%)]\tLoss: 0.018321\n",
      "Train Epoch: 60 [14208/14860 (95%)]\tLoss: 0.021274\n",
      "Train Epoch: 60 [14336/14860 (96%)]\tLoss: 0.018392\n",
      "Train Epoch: 60 [14464/14860 (97%)]\tLoss: 0.025700\n",
      "Train Epoch: 60 [14592/14860 (97%)]\tLoss: 0.021764\n",
      "Train Epoch: 60 [14720/14860 (98%)]\tLoss: 0.019715\n",
      "Train Epoch: 60 [1392/14860 (99%)]\tLoss: 0.012713\n",
      "epoch 60 training loss: 0.02110869517056351\n",
      "epoch 60 validation loss: 0.03155944523453424\n",
      "Train Epoch: 61 [0/14860 (0%)]\tLoss: 0.029131\n",
      "Train Epoch: 61 [128/14860 (1%)]\tLoss: 0.025905\n",
      "Train Epoch: 61 [256/14860 (2%)]\tLoss: 0.038571\n",
      "Train Epoch: 61 [384/14860 (3%)]\tLoss: 0.017868\n",
      "Train Epoch: 61 [512/14860 (3%)]\tLoss: 0.033133\n",
      "Train Epoch: 61 [640/14860 (4%)]\tLoss: 0.035858\n",
      "Train Epoch: 61 [768/14860 (5%)]\tLoss: 0.020494\n",
      "Train Epoch: 61 [896/14860 (6%)]\tLoss: 0.040866\n",
      "Train Epoch: 61 [1024/14860 (7%)]\tLoss: 0.017052\n",
      "Train Epoch: 61 [1152/14860 (8%)]\tLoss: 0.023597\n",
      "Train Epoch: 61 [1280/14860 (9%)]\tLoss: 0.023479\n",
      "Train Epoch: 61 [1408/14860 (9%)]\tLoss: 0.024816\n",
      "Train Epoch: 61 [1536/14860 (10%)]\tLoss: 0.024890\n",
      "Train Epoch: 61 [1664/14860 (11%)]\tLoss: 0.031290\n",
      "Train Epoch: 61 [1792/14860 (12%)]\tLoss: 0.022290\n",
      "Train Epoch: 61 [1920/14860 (13%)]\tLoss: 0.013743\n",
      "Train Epoch: 61 [2048/14860 (14%)]\tLoss: 0.027936\n",
      "Train Epoch: 61 [2176/14860 (15%)]\tLoss: 0.017543\n",
      "Train Epoch: 61 [2304/14860 (15%)]\tLoss: 0.018657\n",
      "Train Epoch: 61 [2432/14860 (16%)]\tLoss: 0.026416\n",
      "Train Epoch: 61 [2560/14860 (17%)]\tLoss: 0.017821\n",
      "Train Epoch: 61 [2688/14860 (18%)]\tLoss: 0.019336\n",
      "Train Epoch: 61 [2816/14860 (19%)]\tLoss: 0.022420\n",
      "Train Epoch: 61 [2944/14860 (20%)]\tLoss: 0.012028\n",
      "Train Epoch: 61 [3072/14860 (21%)]\tLoss: 0.013112\n",
      "Train Epoch: 61 [3200/14860 (21%)]\tLoss: 0.013323\n",
      "Train Epoch: 61 [3328/14860 (22%)]\tLoss: 0.027953\n",
      "Train Epoch: 61 [3456/14860 (23%)]\tLoss: 0.017497\n",
      "Train Epoch: 61 [3584/14860 (24%)]\tLoss: 0.018184\n",
      "Train Epoch: 61 [3712/14860 (25%)]\tLoss: 0.020493\n",
      "Train Epoch: 61 [3840/14860 (26%)]\tLoss: 0.019333\n",
      "Train Epoch: 61 [3968/14860 (26%)]\tLoss: 0.020870\n",
      "Train Epoch: 61 [4096/14860 (27%)]\tLoss: 0.010506\n",
      "Train Epoch: 61 [4224/14860 (28%)]\tLoss: 0.023176\n",
      "Train Epoch: 61 [4352/14860 (29%)]\tLoss: 0.029893\n",
      "Train Epoch: 61 [4480/14860 (30%)]\tLoss: 0.024256\n",
      "Train Epoch: 61 [4608/14860 (31%)]\tLoss: 0.027786\n",
      "Train Epoch: 61 [4736/14860 (32%)]\tLoss: 0.016357\n",
      "Train Epoch: 61 [4864/14860 (32%)]\tLoss: 0.024358\n",
      "Train Epoch: 61 [4992/14860 (33%)]\tLoss: 0.016617\n",
      "Train Epoch: 61 [5120/14860 (34%)]\tLoss: 0.020146\n",
      "Train Epoch: 61 [5248/14860 (35%)]\tLoss: 0.022108\n",
      "Train Epoch: 61 [5376/14860 (36%)]\tLoss: 0.024646\n",
      "Train Epoch: 61 [5504/14860 (37%)]\tLoss: 0.032710\n",
      "Train Epoch: 61 [5632/14860 (38%)]\tLoss: 0.018047\n",
      "Train Epoch: 61 [5760/14860 (38%)]\tLoss: 0.016515\n",
      "Train Epoch: 61 [5888/14860 (39%)]\tLoss: 0.020656\n",
      "Train Epoch: 61 [6016/14860 (40%)]\tLoss: 0.019544\n",
      "Train Epoch: 61 [6144/14860 (41%)]\tLoss: 0.016961\n",
      "Train Epoch: 61 [6272/14860 (42%)]\tLoss: 0.018272\n",
      "Train Epoch: 61 [6400/14860 (43%)]\tLoss: 0.021984\n",
      "Train Epoch: 61 [6528/14860 (44%)]\tLoss: 0.018429\n",
      "Train Epoch: 61 [6656/14860 (44%)]\tLoss: 0.016554\n",
      "Train Epoch: 61 [6784/14860 (45%)]\tLoss: 0.026897\n",
      "Train Epoch: 61 [6912/14860 (46%)]\tLoss: 0.022737\n",
      "Train Epoch: 61 [7040/14860 (47%)]\tLoss: 0.019315\n",
      "Train Epoch: 61 [7168/14860 (48%)]\tLoss: 0.016873\n",
      "Train Epoch: 61 [7296/14860 (49%)]\tLoss: 0.020759\n",
      "Train Epoch: 61 [7424/14860 (50%)]\tLoss: 0.017905\n",
      "Train Epoch: 61 [7552/14860 (50%)]\tLoss: 0.020072\n",
      "Train Epoch: 61 [7680/14860 (51%)]\tLoss: 0.022544\n",
      "Train Epoch: 61 [7808/14860 (52%)]\tLoss: 0.014335\n",
      "Train Epoch: 61 [7936/14860 (53%)]\tLoss: 0.020239\n",
      "Train Epoch: 61 [8064/14860 (54%)]\tLoss: 0.016408\n",
      "Train Epoch: 61 [8192/14860 (55%)]\tLoss: 0.022956\n",
      "Train Epoch: 61 [8320/14860 (56%)]\tLoss: 0.024416\n",
      "Train Epoch: 61 [8448/14860 (56%)]\tLoss: 0.023628\n",
      "Train Epoch: 61 [8576/14860 (57%)]\tLoss: 0.018497\n",
      "Train Epoch: 61 [8704/14860 (58%)]\tLoss: 0.019237\n",
      "Train Epoch: 61 [8832/14860 (59%)]\tLoss: 0.021161\n",
      "Train Epoch: 61 [8960/14860 (60%)]\tLoss: 0.028782\n",
      "Train Epoch: 61 [9088/14860 (61%)]\tLoss: 0.023272\n",
      "Train Epoch: 61 [9216/14860 (62%)]\tLoss: 0.015597\n",
      "Train Epoch: 61 [9344/14860 (62%)]\tLoss: 0.013410\n",
      "Train Epoch: 61 [9472/14860 (63%)]\tLoss: 0.018020\n",
      "Train Epoch: 61 [9600/14860 (64%)]\tLoss: 0.010925\n",
      "Train Epoch: 61 [9728/14860 (65%)]\tLoss: 0.013548\n",
      "Train Epoch: 61 [9856/14860 (66%)]\tLoss: 0.022824\n",
      "Train Epoch: 61 [9984/14860 (67%)]\tLoss: 0.038191\n",
      "Train Epoch: 61 [10112/14860 (68%)]\tLoss: 0.019143\n",
      "Train Epoch: 61 [10240/14860 (68%)]\tLoss: 0.017809\n",
      "Train Epoch: 61 [10368/14860 (69%)]\tLoss: 0.017613\n",
      "Train Epoch: 61 [10496/14860 (70%)]\tLoss: 0.030775\n",
      "Train Epoch: 61 [10624/14860 (71%)]\tLoss: 0.012814\n",
      "Train Epoch: 61 [10752/14860 (72%)]\tLoss: 0.023587\n",
      "Train Epoch: 61 [10880/14860 (73%)]\tLoss: 0.017294\n",
      "Train Epoch: 61 [11008/14860 (74%)]\tLoss: 0.034315\n",
      "Train Epoch: 61 [11136/14860 (74%)]\tLoss: 0.022084\n",
      "Train Epoch: 61 [11264/14860 (75%)]\tLoss: 0.025588\n",
      "Train Epoch: 61 [11392/14860 (76%)]\tLoss: 0.018781\n",
      "Train Epoch: 61 [11520/14860 (77%)]\tLoss: 0.024160\n",
      "Train Epoch: 61 [11648/14860 (78%)]\tLoss: 0.026805\n",
      "Train Epoch: 61 [11776/14860 (79%)]\tLoss: 0.018144\n",
      "Train Epoch: 61 [11904/14860 (79%)]\tLoss: 0.020611\n",
      "Train Epoch: 61 [12032/14860 (80%)]\tLoss: 0.015027\n",
      "Train Epoch: 61 [12160/14860 (81%)]\tLoss: 0.019135\n",
      "Train Epoch: 61 [12288/14860 (82%)]\tLoss: 0.028231\n",
      "Train Epoch: 61 [12416/14860 (83%)]\tLoss: 0.018595\n",
      "Train Epoch: 61 [12544/14860 (84%)]\tLoss: 0.026675\n",
      "Train Epoch: 61 [12672/14860 (85%)]\tLoss: 0.024839\n",
      "Train Epoch: 61 [12800/14860 (85%)]\tLoss: 0.021882\n",
      "Train Epoch: 61 [12928/14860 (86%)]\tLoss: 0.017734\n",
      "Train Epoch: 61 [13056/14860 (87%)]\tLoss: 0.017033\n",
      "Train Epoch: 61 [13184/14860 (88%)]\tLoss: 0.018512\n",
      "Train Epoch: 61 [13312/14860 (89%)]\tLoss: 0.016584\n",
      "Train Epoch: 61 [13440/14860 (90%)]\tLoss: 0.020501\n",
      "Train Epoch: 61 [13568/14860 (91%)]\tLoss: 0.025943\n",
      "Train Epoch: 61 [13696/14860 (91%)]\tLoss: 0.020553\n",
      "Train Epoch: 61 [13824/14860 (92%)]\tLoss: 0.027723\n",
      "Train Epoch: 61 [13952/14860 (93%)]\tLoss: 0.022567\n",
      "Train Epoch: 61 [14080/14860 (94%)]\tLoss: 0.025358\n",
      "Train Epoch: 61 [14208/14860 (95%)]\tLoss: 0.029039\n",
      "Train Epoch: 61 [14336/14860 (96%)]\tLoss: 0.025534\n",
      "Train Epoch: 61 [14464/14860 (97%)]\tLoss: 0.024667\n",
      "Train Epoch: 61 [14592/14860 (97%)]\tLoss: 0.012486\n",
      "Train Epoch: 61 [14720/14860 (98%)]\tLoss: 0.023509\n",
      "Train Epoch: 61 [1392/14860 (99%)]\tLoss: 0.024280\n",
      "epoch 61 training loss: 0.0217428318837769\n",
      "epoch 61 validation loss: 0.02105380288047883\n",
      "Train Epoch: 62 [0/14860 (0%)]\tLoss: 0.027240\n",
      "Train Epoch: 62 [128/14860 (1%)]\tLoss: 0.016893\n",
      "Train Epoch: 62 [256/14860 (2%)]\tLoss: 0.017707\n",
      "Train Epoch: 62 [384/14860 (3%)]\tLoss: 0.018223\n",
      "Train Epoch: 62 [512/14860 (3%)]\tLoss: 0.026040\n",
      "Train Epoch: 62 [640/14860 (4%)]\tLoss: 0.017457\n",
      "Train Epoch: 62 [768/14860 (5%)]\tLoss: 0.023839\n",
      "Train Epoch: 62 [896/14860 (6%)]\tLoss: 0.016259\n",
      "Train Epoch: 62 [1024/14860 (7%)]\tLoss: 0.021112\n",
      "Train Epoch: 62 [1152/14860 (8%)]\tLoss: 0.022572\n",
      "Train Epoch: 62 [1280/14860 (9%)]\tLoss: 0.022245\n",
      "Train Epoch: 62 [1408/14860 (9%)]\tLoss: 0.017941\n",
      "Train Epoch: 62 [1536/14860 (10%)]\tLoss: 0.021965\n",
      "Train Epoch: 62 [1664/14860 (11%)]\tLoss: 0.023354\n",
      "Train Epoch: 62 [1792/14860 (12%)]\tLoss: 0.027004\n",
      "Train Epoch: 62 [1920/14860 (13%)]\tLoss: 0.022487\n",
      "Train Epoch: 62 [2048/14860 (14%)]\tLoss: 0.028921\n",
      "Train Epoch: 62 [2176/14860 (15%)]\tLoss: 0.022226\n",
      "Train Epoch: 62 [2304/14860 (15%)]\tLoss: 0.023811\n",
      "Train Epoch: 62 [2432/14860 (16%)]\tLoss: 0.024888\n",
      "Train Epoch: 62 [2560/14860 (17%)]\tLoss: 0.018530\n",
      "Train Epoch: 62 [2688/14860 (18%)]\tLoss: 0.023437\n",
      "Train Epoch: 62 [2816/14860 (19%)]\tLoss: 0.016414\n",
      "Train Epoch: 62 [2944/14860 (20%)]\tLoss: 0.023944\n",
      "Train Epoch: 62 [3072/14860 (21%)]\tLoss: 0.019587\n",
      "Train Epoch: 62 [3200/14860 (21%)]\tLoss: 0.015059\n",
      "Train Epoch: 62 [3328/14860 (22%)]\tLoss: 0.024459\n",
      "Train Epoch: 62 [3456/14860 (23%)]\tLoss: 0.022072\n",
      "Train Epoch: 62 [3584/14860 (24%)]\tLoss: 0.022062\n",
      "Train Epoch: 62 [3712/14860 (25%)]\tLoss: 0.019067\n",
      "Train Epoch: 62 [3840/14860 (26%)]\tLoss: 0.017645\n",
      "Train Epoch: 62 [3968/14860 (26%)]\tLoss: 0.018024\n",
      "Train Epoch: 62 [4096/14860 (27%)]\tLoss: 0.027812\n",
      "Train Epoch: 62 [4224/14860 (28%)]\tLoss: 0.027491\n",
      "Train Epoch: 62 [4352/14860 (29%)]\tLoss: 0.028058\n",
      "Train Epoch: 62 [4480/14860 (30%)]\tLoss: 0.012229\n",
      "Train Epoch: 62 [4608/14860 (31%)]\tLoss: 0.028210\n",
      "Train Epoch: 62 [4736/14860 (32%)]\tLoss: 0.038187\n",
      "Train Epoch: 62 [4864/14860 (32%)]\tLoss: 0.018808\n",
      "Train Epoch: 62 [4992/14860 (33%)]\tLoss: 0.035520\n",
      "Train Epoch: 62 [5120/14860 (34%)]\tLoss: 0.022461\n",
      "Train Epoch: 62 [5248/14860 (35%)]\tLoss: 0.031111\n",
      "Train Epoch: 62 [5376/14860 (36%)]\tLoss: 0.017156\n",
      "Train Epoch: 62 [5504/14860 (37%)]\tLoss: 0.021644\n",
      "Train Epoch: 62 [5632/14860 (38%)]\tLoss: 0.027787\n",
      "Train Epoch: 62 [5760/14860 (38%)]\tLoss: 0.020086\n",
      "Train Epoch: 62 [5888/14860 (39%)]\tLoss: 0.018065\n",
      "Train Epoch: 62 [6016/14860 (40%)]\tLoss: 0.031975\n",
      "Train Epoch: 62 [6144/14860 (41%)]\tLoss: 0.026647\n",
      "Train Epoch: 62 [6272/14860 (42%)]\tLoss: 0.019827\n",
      "Train Epoch: 62 [6400/14860 (43%)]\tLoss: 0.029146\n",
      "Train Epoch: 62 [6528/14860 (44%)]\tLoss: 0.014844\n",
      "Train Epoch: 62 [6656/14860 (44%)]\tLoss: 0.024712\n",
      "Train Epoch: 62 [6784/14860 (45%)]\tLoss: 0.025583\n",
      "Train Epoch: 62 [6912/14860 (46%)]\tLoss: 0.020464\n",
      "Train Epoch: 62 [7040/14860 (47%)]\tLoss: 0.020139\n",
      "Train Epoch: 62 [7168/14860 (48%)]\tLoss: 0.017602\n",
      "Train Epoch: 62 [7296/14860 (49%)]\tLoss: 0.021478\n",
      "Train Epoch: 62 [7424/14860 (50%)]\tLoss: 0.022589\n",
      "Train Epoch: 62 [7552/14860 (50%)]\tLoss: 0.013322\n",
      "Train Epoch: 62 [7680/14860 (51%)]\tLoss: 0.018215\n",
      "Train Epoch: 62 [7808/14860 (52%)]\tLoss: 0.018922\n",
      "Train Epoch: 62 [7936/14860 (53%)]\tLoss: 0.030419\n",
      "Train Epoch: 62 [8064/14860 (54%)]\tLoss: 0.012931\n",
      "Train Epoch: 62 [8192/14860 (55%)]\tLoss: 0.017982\n",
      "Train Epoch: 62 [8320/14860 (56%)]\tLoss: 0.020348\n",
      "Train Epoch: 62 [8448/14860 (56%)]\tLoss: 0.024034\n",
      "Train Epoch: 62 [8576/14860 (57%)]\tLoss: 0.021221\n",
      "Train Epoch: 62 [8704/14860 (58%)]\tLoss: 0.025933\n",
      "Train Epoch: 62 [8832/14860 (59%)]\tLoss: 0.017516\n",
      "Train Epoch: 62 [8960/14860 (60%)]\tLoss: 0.021020\n",
      "Train Epoch: 62 [9088/14860 (61%)]\tLoss: 0.022516\n",
      "Train Epoch: 62 [9216/14860 (62%)]\tLoss: 0.016389\n",
      "Train Epoch: 62 [9344/14860 (62%)]\tLoss: 0.023882\n",
      "Train Epoch: 62 [9472/14860 (63%)]\tLoss: 0.018929\n",
      "Train Epoch: 62 [9600/14860 (64%)]\tLoss: 0.017551\n",
      "Train Epoch: 62 [9728/14860 (65%)]\tLoss: 0.021158\n",
      "Train Epoch: 62 [9856/14860 (66%)]\tLoss: 0.024123\n",
      "Train Epoch: 62 [9984/14860 (67%)]\tLoss: 0.032421\n",
      "Train Epoch: 62 [10112/14860 (68%)]\tLoss: 0.021469\n",
      "Train Epoch: 62 [10240/14860 (68%)]\tLoss: 0.030212\n",
      "Train Epoch: 62 [10368/14860 (69%)]\tLoss: 0.025424\n",
      "Train Epoch: 62 [10496/14860 (70%)]\tLoss: 0.014306\n",
      "Train Epoch: 62 [10624/14860 (71%)]\tLoss: 0.023434\n",
      "Train Epoch: 62 [10752/14860 (72%)]\tLoss: 0.019455\n",
      "Train Epoch: 62 [10880/14860 (73%)]\tLoss: 0.021716\n",
      "Train Epoch: 62 [11008/14860 (74%)]\tLoss: 0.014727\n",
      "Train Epoch: 62 [11136/14860 (74%)]\tLoss: 0.015294\n",
      "Train Epoch: 62 [11264/14860 (75%)]\tLoss: 0.019120\n",
      "Train Epoch: 62 [11392/14860 (76%)]\tLoss: 0.017325\n",
      "Train Epoch: 62 [11520/14860 (77%)]\tLoss: 0.014998\n",
      "Train Epoch: 62 [11648/14860 (78%)]\tLoss: 0.023058\n",
      "Train Epoch: 62 [11776/14860 (79%)]\tLoss: 0.016045\n",
      "Train Epoch: 62 [11904/14860 (79%)]\tLoss: 0.025779\n",
      "Train Epoch: 62 [12032/14860 (80%)]\tLoss: 0.023878\n",
      "Train Epoch: 62 [12160/14860 (81%)]\tLoss: 0.019877\n",
      "Train Epoch: 62 [12288/14860 (82%)]\tLoss: 0.018385\n",
      "Train Epoch: 62 [12416/14860 (83%)]\tLoss: 0.028112\n",
      "Train Epoch: 62 [12544/14860 (84%)]\tLoss: 0.024682\n",
      "Train Epoch: 62 [12672/14860 (85%)]\tLoss: 0.021414\n",
      "Train Epoch: 62 [12800/14860 (85%)]\tLoss: 0.020877\n",
      "Train Epoch: 62 [12928/14860 (86%)]\tLoss: 0.026370\n",
      "Train Epoch: 62 [13056/14860 (87%)]\tLoss: 0.024234\n",
      "Train Epoch: 62 [13184/14860 (88%)]\tLoss: 0.021169\n",
      "Train Epoch: 62 [13312/14860 (89%)]\tLoss: 0.022720\n",
      "Train Epoch: 62 [13440/14860 (90%)]\tLoss: 0.021864\n",
      "Train Epoch: 62 [13568/14860 (91%)]\tLoss: 0.019450\n",
      "Train Epoch: 62 [13696/14860 (91%)]\tLoss: 0.028605\n",
      "Train Epoch: 62 [13824/14860 (92%)]\tLoss: 0.018257\n",
      "Train Epoch: 62 [13952/14860 (93%)]\tLoss: 0.025615\n",
      "Train Epoch: 62 [14080/14860 (94%)]\tLoss: 0.019771\n",
      "Train Epoch: 62 [14208/14860 (95%)]\tLoss: 0.021840\n",
      "Train Epoch: 62 [14336/14860 (96%)]\tLoss: 0.017637\n",
      "Train Epoch: 62 [14464/14860 (97%)]\tLoss: 0.022985\n",
      "Train Epoch: 62 [14592/14860 (97%)]\tLoss: 0.014469\n",
      "Train Epoch: 62 [14720/14860 (98%)]\tLoss: 0.019257\n",
      "Train Epoch: 62 [1392/14860 (99%)]\tLoss: 0.021137\n",
      "epoch 62 training loss: 0.021845377336900968\n",
      "epoch 62 validation loss: 0.02404429245803316\n",
      "Train Epoch: 63 [0/14860 (0%)]\tLoss: 0.015215\n",
      "Train Epoch: 63 [128/14860 (1%)]\tLoss: 0.023966\n",
      "Train Epoch: 63 [256/14860 (2%)]\tLoss: 0.017248\n",
      "Train Epoch: 63 [384/14860 (3%)]\tLoss: 0.015774\n",
      "Train Epoch: 63 [512/14860 (3%)]\tLoss: 0.025842\n",
      "Train Epoch: 63 [640/14860 (4%)]\tLoss: 0.023533\n",
      "Train Epoch: 63 [768/14860 (5%)]\tLoss: 0.015853\n",
      "Train Epoch: 63 [896/14860 (6%)]\tLoss: 0.019780\n",
      "Train Epoch: 63 [1024/14860 (7%)]\tLoss: 0.019944\n",
      "Train Epoch: 63 [1152/14860 (8%)]\tLoss: 0.022499\n",
      "Train Epoch: 63 [1280/14860 (9%)]\tLoss: 0.015306\n",
      "Train Epoch: 63 [1408/14860 (9%)]\tLoss: 0.024517\n",
      "Train Epoch: 63 [1536/14860 (10%)]\tLoss: 0.020024\n",
      "Train Epoch: 63 [1664/14860 (11%)]\tLoss: 0.015053\n",
      "Train Epoch: 63 [1792/14860 (12%)]\tLoss: 0.017546\n",
      "Train Epoch: 63 [1920/14860 (13%)]\tLoss: 0.025934\n",
      "Train Epoch: 63 [2048/14860 (14%)]\tLoss: 0.019546\n",
      "Train Epoch: 63 [2176/14860 (15%)]\tLoss: 0.021145\n",
      "Train Epoch: 63 [2304/14860 (15%)]\tLoss: 0.019093\n",
      "Train Epoch: 63 [2432/14860 (16%)]\tLoss: 0.015159\n",
      "Train Epoch: 63 [2560/14860 (17%)]\tLoss: 0.023956\n",
      "Train Epoch: 63 [2688/14860 (18%)]\tLoss: 0.017658\n",
      "Train Epoch: 63 [2816/14860 (19%)]\tLoss: 0.025405\n",
      "Train Epoch: 63 [2944/14860 (20%)]\tLoss: 0.019297\n",
      "Train Epoch: 63 [3072/14860 (21%)]\tLoss: 0.021098\n",
      "Train Epoch: 63 [3200/14860 (21%)]\tLoss: 0.018912\n",
      "Train Epoch: 63 [3328/14860 (22%)]\tLoss: 0.020085\n",
      "Train Epoch: 63 [3456/14860 (23%)]\tLoss: 0.012032\n",
      "Train Epoch: 63 [3584/14860 (24%)]\tLoss: 0.022097\n",
      "Train Epoch: 63 [3712/14860 (25%)]\tLoss: 0.015432\n",
      "Train Epoch: 63 [3840/14860 (26%)]\tLoss: 0.022961\n",
      "Train Epoch: 63 [3968/14860 (26%)]\tLoss: 0.019780\n",
      "Train Epoch: 63 [4096/14860 (27%)]\tLoss: 0.020921\n",
      "Train Epoch: 63 [4224/14860 (28%)]\tLoss: 0.015683\n",
      "Train Epoch: 63 [4352/14860 (29%)]\tLoss: 0.019886\n",
      "Train Epoch: 63 [4480/14860 (30%)]\tLoss: 0.011618\n",
      "Train Epoch: 63 [4608/14860 (31%)]\tLoss: 0.025960\n",
      "Train Epoch: 63 [4736/14860 (32%)]\tLoss: 0.020861\n",
      "Train Epoch: 63 [4864/14860 (32%)]\tLoss: 0.021376\n",
      "Train Epoch: 63 [4992/14860 (33%)]\tLoss: 0.026342\n",
      "Train Epoch: 63 [5120/14860 (34%)]\tLoss: 0.028074\n",
      "Train Epoch: 63 [5248/14860 (35%)]\tLoss: 0.024427\n",
      "Train Epoch: 63 [5376/14860 (36%)]\tLoss: 0.021922\n",
      "Train Epoch: 63 [5504/14860 (37%)]\tLoss: 0.020999\n",
      "Train Epoch: 63 [5632/14860 (38%)]\tLoss: 0.017595\n",
      "Train Epoch: 63 [5760/14860 (38%)]\tLoss: 0.029307\n",
      "Train Epoch: 63 [5888/14860 (39%)]\tLoss: 0.027455\n",
      "Train Epoch: 63 [6016/14860 (40%)]\tLoss: 0.023041\n",
      "Train Epoch: 63 [6144/14860 (41%)]\tLoss: 0.027902\n",
      "Train Epoch: 63 [6272/14860 (42%)]\tLoss: 0.033122\n",
      "Train Epoch: 63 [6400/14860 (43%)]\tLoss: 0.015333\n",
      "Train Epoch: 63 [6528/14860 (44%)]\tLoss: 0.020308\n",
      "Train Epoch: 63 [6656/14860 (44%)]\tLoss: 0.019818\n",
      "Train Epoch: 63 [6784/14860 (45%)]\tLoss: 0.018406\n",
      "Train Epoch: 63 [6912/14860 (46%)]\tLoss: 0.016622\n",
      "Train Epoch: 63 [7040/14860 (47%)]\tLoss: 0.023116\n",
      "Train Epoch: 63 [7168/14860 (48%)]\tLoss: 0.025145\n",
      "Train Epoch: 63 [7296/14860 (49%)]\tLoss: 0.028465\n",
      "Train Epoch: 63 [7424/14860 (50%)]\tLoss: 0.017781\n",
      "Train Epoch: 63 [7552/14860 (50%)]\tLoss: 0.013042\n",
      "Train Epoch: 63 [7680/14860 (51%)]\tLoss: 0.023962\n",
      "Train Epoch: 63 [7808/14860 (52%)]\tLoss: 0.017122\n",
      "Train Epoch: 63 [7936/14860 (53%)]\tLoss: 0.017832\n",
      "Train Epoch: 63 [8064/14860 (54%)]\tLoss: 0.021872\n",
      "Train Epoch: 63 [8192/14860 (55%)]\tLoss: 0.019313\n",
      "Train Epoch: 63 [8320/14860 (56%)]\tLoss: 0.014185\n",
      "Train Epoch: 63 [8448/14860 (56%)]\tLoss: 0.022248\n",
      "Train Epoch: 63 [8576/14860 (57%)]\tLoss: 0.022422\n",
      "Train Epoch: 63 [8704/14860 (58%)]\tLoss: 0.016823\n",
      "Train Epoch: 63 [8832/14860 (59%)]\tLoss: 0.021801\n",
      "Train Epoch: 63 [8960/14860 (60%)]\tLoss: 0.016538\n",
      "Train Epoch: 63 [9088/14860 (61%)]\tLoss: 0.020025\n",
      "Train Epoch: 63 [9216/14860 (62%)]\tLoss: 0.025560\n",
      "Train Epoch: 63 [9344/14860 (62%)]\tLoss: 0.024625\n",
      "Train Epoch: 63 [9472/14860 (63%)]\tLoss: 0.030233\n",
      "Train Epoch: 63 [9600/14860 (64%)]\tLoss: 0.017103\n",
      "Train Epoch: 63 [9728/14860 (65%)]\tLoss: 0.018940\n",
      "Train Epoch: 63 [9856/14860 (66%)]\tLoss: 0.018769\n",
      "Train Epoch: 63 [9984/14860 (67%)]\tLoss: 0.031393\n",
      "Train Epoch: 63 [10112/14860 (68%)]\tLoss: 0.023539\n",
      "Train Epoch: 63 [10240/14860 (68%)]\tLoss: 0.025181\n",
      "Train Epoch: 63 [10368/14860 (69%)]\tLoss: 0.024929\n",
      "Train Epoch: 63 [10496/14860 (70%)]\tLoss: 0.020733\n",
      "Train Epoch: 63 [10624/14860 (71%)]\tLoss: 0.016199\n",
      "Train Epoch: 63 [10752/14860 (72%)]\tLoss: 0.016639\n",
      "Train Epoch: 63 [10880/14860 (73%)]\tLoss: 0.023856\n",
      "Train Epoch: 63 [11008/14860 (74%)]\tLoss: 0.021087\n",
      "Train Epoch: 63 [11136/14860 (74%)]\tLoss: 0.023091\n",
      "Train Epoch: 63 [11264/14860 (75%)]\tLoss: 0.013786\n",
      "Train Epoch: 63 [11392/14860 (76%)]\tLoss: 0.015998\n",
      "Train Epoch: 63 [11520/14860 (77%)]\tLoss: 0.019318\n",
      "Train Epoch: 63 [11648/14860 (78%)]\tLoss: 0.020705\n",
      "Train Epoch: 63 [11776/14860 (79%)]\tLoss: 0.022629\n",
      "Train Epoch: 63 [11904/14860 (79%)]\tLoss: 0.019112\n",
      "Train Epoch: 63 [12032/14860 (80%)]\tLoss: 0.023774\n",
      "Train Epoch: 63 [12160/14860 (81%)]\tLoss: 0.017656\n",
      "Train Epoch: 63 [12288/14860 (82%)]\tLoss: 0.020501\n",
      "Train Epoch: 63 [12416/14860 (83%)]\tLoss: 0.016833\n",
      "Train Epoch: 63 [12544/14860 (84%)]\tLoss: 0.022679\n",
      "Train Epoch: 63 [12672/14860 (85%)]\tLoss: 0.019533\n",
      "Train Epoch: 63 [12800/14860 (85%)]\tLoss: 0.020927\n",
      "Train Epoch: 63 [12928/14860 (86%)]\tLoss: 0.014441\n",
      "Train Epoch: 63 [13056/14860 (87%)]\tLoss: 0.019192\n",
      "Train Epoch: 63 [13184/14860 (88%)]\tLoss: 0.022233\n",
      "Train Epoch: 63 [13312/14860 (89%)]\tLoss: 0.021292\n",
      "Train Epoch: 63 [13440/14860 (90%)]\tLoss: 0.023765\n",
      "Train Epoch: 63 [13568/14860 (91%)]\tLoss: 0.019163\n",
      "Train Epoch: 63 [13696/14860 (91%)]\tLoss: 0.028144\n",
      "Train Epoch: 63 [13824/14860 (92%)]\tLoss: 0.021579\n",
      "Train Epoch: 63 [13952/14860 (93%)]\tLoss: 0.030618\n",
      "Train Epoch: 63 [14080/14860 (94%)]\tLoss: 0.020481\n",
      "Train Epoch: 63 [14208/14860 (95%)]\tLoss: 0.018915\n",
      "Train Epoch: 63 [14336/14860 (96%)]\tLoss: 0.016607\n",
      "Train Epoch: 63 [14464/14860 (97%)]\tLoss: 0.013460\n",
      "Train Epoch: 63 [14592/14860 (97%)]\tLoss: 0.017722\n",
      "Train Epoch: 63 [14720/14860 (98%)]\tLoss: 0.018091\n",
      "Train Epoch: 63 [1392/14860 (99%)]\tLoss: 0.030178\n",
      "epoch 63 training loss: 0.020782655033354577\n",
      "epoch 63 validation loss: 0.020974700589445543\n",
      "Train Epoch: 64 [0/14860 (0%)]\tLoss: 0.019081\n",
      "Train Epoch: 64 [128/14860 (1%)]\tLoss: 0.022717\n",
      "Train Epoch: 64 [256/14860 (2%)]\tLoss: 0.029563\n",
      "Train Epoch: 64 [384/14860 (3%)]\tLoss: 0.018390\n",
      "Train Epoch: 64 [512/14860 (3%)]\tLoss: 0.024380\n",
      "Train Epoch: 64 [640/14860 (4%)]\tLoss: 0.022114\n",
      "Train Epoch: 64 [768/14860 (5%)]\tLoss: 0.021296\n",
      "Train Epoch: 64 [896/14860 (6%)]\tLoss: 0.018080\n",
      "Train Epoch: 64 [1024/14860 (7%)]\tLoss: 0.012122\n",
      "Train Epoch: 64 [1152/14860 (8%)]\tLoss: 0.025951\n",
      "Train Epoch: 64 [1280/14860 (9%)]\tLoss: 0.019383\n",
      "Train Epoch: 64 [1408/14860 (9%)]\tLoss: 0.014124\n",
      "Train Epoch: 64 [1536/14860 (10%)]\tLoss: 0.015492\n",
      "Train Epoch: 64 [1664/14860 (11%)]\tLoss: 0.015610\n",
      "Train Epoch: 64 [1792/14860 (12%)]\tLoss: 0.016997\n",
      "Train Epoch: 64 [1920/14860 (13%)]\tLoss: 0.023896\n",
      "Train Epoch: 64 [2048/14860 (14%)]\tLoss: 0.016961\n",
      "Train Epoch: 64 [2176/14860 (15%)]\tLoss: 0.013381\n",
      "Train Epoch: 64 [2304/14860 (15%)]\tLoss: 0.021095\n",
      "Train Epoch: 64 [2432/14860 (16%)]\tLoss: 0.017444\n",
      "Train Epoch: 64 [2560/14860 (17%)]\tLoss: 0.024139\n",
      "Train Epoch: 64 [2688/14860 (18%)]\tLoss: 0.022003\n",
      "Train Epoch: 64 [2816/14860 (19%)]\tLoss: 0.019167\n",
      "Train Epoch: 64 [2944/14860 (20%)]\tLoss: 0.017808\n",
      "Train Epoch: 64 [3072/14860 (21%)]\tLoss: 0.012469\n",
      "Train Epoch: 64 [3200/14860 (21%)]\tLoss: 0.016261\n",
      "Train Epoch: 64 [3328/14860 (22%)]\tLoss: 0.016158\n",
      "Train Epoch: 64 [3456/14860 (23%)]\tLoss: 0.029415\n",
      "Train Epoch: 64 [3584/14860 (24%)]\tLoss: 0.015718\n",
      "Train Epoch: 64 [3712/14860 (25%)]\tLoss: 0.014207\n",
      "Train Epoch: 64 [3840/14860 (26%)]\tLoss: 0.030536\n",
      "Train Epoch: 64 [3968/14860 (26%)]\tLoss: 0.025470\n",
      "Train Epoch: 64 [4096/14860 (27%)]\tLoss: 0.022555\n",
      "Train Epoch: 64 [4224/14860 (28%)]\tLoss: 0.016614\n",
      "Train Epoch: 64 [4352/14860 (29%)]\tLoss: 0.023992\n",
      "Train Epoch: 64 [4480/14860 (30%)]\tLoss: 0.023875\n",
      "Train Epoch: 64 [4608/14860 (31%)]\tLoss: 0.022672\n",
      "Train Epoch: 64 [4736/14860 (32%)]\tLoss: 0.019632\n",
      "Train Epoch: 64 [4864/14860 (32%)]\tLoss: 0.031755\n",
      "Train Epoch: 64 [4992/14860 (33%)]\tLoss: 0.024952\n",
      "Train Epoch: 64 [5120/14860 (34%)]\tLoss: 0.032060\n",
      "Train Epoch: 64 [5248/14860 (35%)]\tLoss: 0.022560\n",
      "Train Epoch: 64 [5376/14860 (36%)]\tLoss: 0.021636\n",
      "Train Epoch: 64 [5504/14860 (37%)]\tLoss: 0.014397\n",
      "Train Epoch: 64 [5632/14860 (38%)]\tLoss: 0.019713\n",
      "Train Epoch: 64 [5760/14860 (38%)]\tLoss: 0.017690\n",
      "Train Epoch: 64 [5888/14860 (39%)]\tLoss: 0.016037\n",
      "Train Epoch: 64 [6016/14860 (40%)]\tLoss: 0.019109\n",
      "Train Epoch: 64 [6144/14860 (41%)]\tLoss: 0.019408\n",
      "Train Epoch: 64 [6272/14860 (42%)]\tLoss: 0.023365\n",
      "Train Epoch: 64 [6400/14860 (43%)]\tLoss: 0.020390\n",
      "Train Epoch: 64 [6528/14860 (44%)]\tLoss: 0.018900\n",
      "Train Epoch: 64 [6656/14860 (44%)]\tLoss: 0.023401\n",
      "Train Epoch: 64 [6784/14860 (45%)]\tLoss: 0.022418\n",
      "Train Epoch: 64 [6912/14860 (46%)]\tLoss: 0.022278\n",
      "Train Epoch: 64 [7040/14860 (47%)]\tLoss: 0.023700\n",
      "Train Epoch: 64 [7168/14860 (48%)]\tLoss: 0.019367\n",
      "Train Epoch: 64 [7296/14860 (49%)]\tLoss: 0.018454\n",
      "Train Epoch: 64 [7424/14860 (50%)]\tLoss: 0.012541\n",
      "Train Epoch: 64 [7552/14860 (50%)]\tLoss: 0.015493\n",
      "Train Epoch: 64 [7680/14860 (51%)]\tLoss: 0.021313\n",
      "Train Epoch: 64 [7808/14860 (52%)]\tLoss: 0.018287\n",
      "Train Epoch: 64 [7936/14860 (53%)]\tLoss: 0.023396\n",
      "Train Epoch: 64 [8064/14860 (54%)]\tLoss: 0.035328\n",
      "Train Epoch: 64 [8192/14860 (55%)]\tLoss: 0.021951\n",
      "Train Epoch: 64 [8320/14860 (56%)]\tLoss: 0.015907\n",
      "Train Epoch: 64 [8448/14860 (56%)]\tLoss: 0.016488\n",
      "Train Epoch: 64 [8576/14860 (57%)]\tLoss: 0.025445\n",
      "Train Epoch: 64 [8704/14860 (58%)]\tLoss: 0.018420\n",
      "Train Epoch: 64 [8832/14860 (59%)]\tLoss: 0.021931\n",
      "Train Epoch: 64 [8960/14860 (60%)]\tLoss: 0.020913\n",
      "Train Epoch: 64 [9088/14860 (61%)]\tLoss: 0.020878\n",
      "Train Epoch: 64 [9216/14860 (62%)]\tLoss: 0.019813\n",
      "Train Epoch: 64 [9344/14860 (62%)]\tLoss: 0.019135\n",
      "Train Epoch: 64 [9472/14860 (63%)]\tLoss: 0.018386\n",
      "Train Epoch: 64 [9600/14860 (64%)]\tLoss: 0.017859\n",
      "Train Epoch: 64 [9728/14860 (65%)]\tLoss: 0.013934\n",
      "Train Epoch: 64 [9856/14860 (66%)]\tLoss: 0.018834\n",
      "Train Epoch: 64 [9984/14860 (67%)]\tLoss: 0.018592\n",
      "Train Epoch: 64 [10112/14860 (68%)]\tLoss: 0.017053\n",
      "Train Epoch: 64 [10240/14860 (68%)]\tLoss: 0.017887\n",
      "Train Epoch: 64 [10368/14860 (69%)]\tLoss: 0.025822\n",
      "Train Epoch: 64 [10496/14860 (70%)]\tLoss: 0.024518\n",
      "Train Epoch: 64 [10624/14860 (71%)]\tLoss: 0.022545\n",
      "Train Epoch: 64 [10752/14860 (72%)]\tLoss: 0.022951\n",
      "Train Epoch: 64 [10880/14860 (73%)]\tLoss: 0.019274\n",
      "Train Epoch: 64 [11008/14860 (74%)]\tLoss: 0.028452\n",
      "Train Epoch: 64 [11136/14860 (74%)]\tLoss: 0.024939\n",
      "Train Epoch: 64 [11264/14860 (75%)]\tLoss: 0.036249\n",
      "Train Epoch: 64 [11392/14860 (76%)]\tLoss: 0.015636\n",
      "Train Epoch: 64 [11520/14860 (77%)]\tLoss: 0.021005\n",
      "Train Epoch: 64 [11648/14860 (78%)]\tLoss: 0.018749\n",
      "Train Epoch: 64 [11776/14860 (79%)]\tLoss: 0.027546\n",
      "Train Epoch: 64 [11904/14860 (79%)]\tLoss: 0.026167\n",
      "Train Epoch: 64 [12032/14860 (80%)]\tLoss: 0.021299\n",
      "Train Epoch: 64 [12160/14860 (81%)]\tLoss: 0.027312\n",
      "Train Epoch: 64 [12288/14860 (82%)]\tLoss: 0.018794\n",
      "Train Epoch: 64 [12416/14860 (83%)]\tLoss: 0.037967\n",
      "Train Epoch: 64 [12544/14860 (84%)]\tLoss: 0.025348\n",
      "Train Epoch: 64 [12672/14860 (85%)]\tLoss: 0.024394\n",
      "Train Epoch: 64 [12800/14860 (85%)]\tLoss: 0.024746\n",
      "Train Epoch: 64 [12928/14860 (86%)]\tLoss: 0.025531\n",
      "Train Epoch: 64 [13056/14860 (87%)]\tLoss: 0.036633\n",
      "Train Epoch: 64 [13184/14860 (88%)]\tLoss: 0.016048\n",
      "Train Epoch: 64 [13312/14860 (89%)]\tLoss: 0.018407\n",
      "Train Epoch: 64 [13440/14860 (90%)]\tLoss: 0.019422\n",
      "Train Epoch: 64 [13568/14860 (91%)]\tLoss: 0.020474\n",
      "Train Epoch: 64 [13696/14860 (91%)]\tLoss: 0.020878\n",
      "Train Epoch: 64 [13824/14860 (92%)]\tLoss: 0.020704\n",
      "Train Epoch: 64 [13952/14860 (93%)]\tLoss: 0.020446\n",
      "Train Epoch: 64 [14080/14860 (94%)]\tLoss: 0.013253\n",
      "Train Epoch: 64 [14208/14860 (95%)]\tLoss: 0.023111\n",
      "Train Epoch: 64 [14336/14860 (96%)]\tLoss: 0.030158\n",
      "Train Epoch: 64 [14464/14860 (97%)]\tLoss: 0.017605\n",
      "Train Epoch: 64 [14592/14860 (97%)]\tLoss: 0.023031\n",
      "Train Epoch: 64 [14720/14860 (98%)]\tLoss: 0.015266\n",
      "Train Epoch: 64 [1392/14860 (99%)]\tLoss: 0.016945\n",
      "epoch 64 training loss: 0.021143335188364882\n",
      "epoch 64 validation loss: 0.02239006180451511\n",
      "Train Epoch: 65 [0/14860 (0%)]\tLoss: 0.029546\n",
      "Train Epoch: 65 [128/14860 (1%)]\tLoss: 0.023048\n",
      "Train Epoch: 65 [256/14860 (2%)]\tLoss: 0.019946\n",
      "Train Epoch: 65 [384/14860 (3%)]\tLoss: 0.030469\n",
      "Train Epoch: 65 [512/14860 (3%)]\tLoss: 0.015629\n",
      "Train Epoch: 65 [640/14860 (4%)]\tLoss: 0.017637\n",
      "Train Epoch: 65 [768/14860 (5%)]\tLoss: 0.026200\n",
      "Train Epoch: 65 [896/14860 (6%)]\tLoss: 0.025211\n",
      "Train Epoch: 65 [1024/14860 (7%)]\tLoss: 0.031751\n",
      "Train Epoch: 65 [1152/14860 (8%)]\tLoss: 0.014299\n",
      "Train Epoch: 65 [1280/14860 (9%)]\tLoss: 0.021306\n",
      "Train Epoch: 65 [1408/14860 (9%)]\tLoss: 0.019307\n",
      "Train Epoch: 65 [1536/14860 (10%)]\tLoss: 0.018564\n",
      "Train Epoch: 65 [1664/14860 (11%)]\tLoss: 0.017098\n",
      "Train Epoch: 65 [1792/14860 (12%)]\tLoss: 0.021135\n",
      "Train Epoch: 65 [1920/14860 (13%)]\tLoss: 0.026874\n",
      "Train Epoch: 65 [2048/14860 (14%)]\tLoss: 0.022375\n",
      "Train Epoch: 65 [2176/14860 (15%)]\tLoss: 0.015589\n",
      "Train Epoch: 65 [2304/14860 (15%)]\tLoss: 0.015648\n",
      "Train Epoch: 65 [2432/14860 (16%)]\tLoss: 0.023687\n",
      "Train Epoch: 65 [2560/14860 (17%)]\tLoss: 0.019118\n",
      "Train Epoch: 65 [2688/14860 (18%)]\tLoss: 0.020280\n",
      "Train Epoch: 65 [2816/14860 (19%)]\tLoss: 0.026195\n",
      "Train Epoch: 65 [2944/14860 (20%)]\tLoss: 0.028129\n",
      "Train Epoch: 65 [3072/14860 (21%)]\tLoss: 0.021487\n",
      "Train Epoch: 65 [3200/14860 (21%)]\tLoss: 0.018746\n",
      "Train Epoch: 65 [3328/14860 (22%)]\tLoss: 0.016144\n",
      "Train Epoch: 65 [3456/14860 (23%)]\tLoss: 0.022061\n",
      "Train Epoch: 65 [3584/14860 (24%)]\tLoss: 0.018112\n",
      "Train Epoch: 65 [3712/14860 (25%)]\tLoss: 0.022210\n",
      "Train Epoch: 65 [3840/14860 (26%)]\tLoss: 0.018086\n",
      "Train Epoch: 65 [3968/14860 (26%)]\tLoss: 0.027559\n",
      "Train Epoch: 65 [4096/14860 (27%)]\tLoss: 0.013466\n",
      "Train Epoch: 65 [4224/14860 (28%)]\tLoss: 0.019919\n",
      "Train Epoch: 65 [4352/14860 (29%)]\tLoss: 0.021679\n",
      "Train Epoch: 65 [4480/14860 (30%)]\tLoss: 0.026122\n",
      "Train Epoch: 65 [4608/14860 (31%)]\tLoss: 0.020486\n",
      "Train Epoch: 65 [4736/14860 (32%)]\tLoss: 0.015554\n",
      "Train Epoch: 65 [4864/14860 (32%)]\tLoss: 0.027210\n",
      "Train Epoch: 65 [4992/14860 (33%)]\tLoss: 0.010402\n",
      "Train Epoch: 65 [5120/14860 (34%)]\tLoss: 0.021165\n",
      "Train Epoch: 65 [5248/14860 (35%)]\tLoss: 0.018335\n",
      "Train Epoch: 65 [5376/14860 (36%)]\tLoss: 0.016409\n",
      "Train Epoch: 65 [5504/14860 (37%)]\tLoss: 0.020373\n",
      "Train Epoch: 65 [5632/14860 (38%)]\tLoss: 0.020884\n",
      "Train Epoch: 65 [5760/14860 (38%)]\tLoss: 0.028096\n",
      "Train Epoch: 65 [5888/14860 (39%)]\tLoss: 0.019720\n",
      "Train Epoch: 65 [6016/14860 (40%)]\tLoss: 0.020561\n",
      "Train Epoch: 65 [6144/14860 (41%)]\tLoss: 0.020442\n",
      "Train Epoch: 65 [6272/14860 (42%)]\tLoss: 0.023340\n",
      "Train Epoch: 65 [6400/14860 (43%)]\tLoss: 0.029693\n",
      "Train Epoch: 65 [6528/14860 (44%)]\tLoss: 0.027567\n",
      "Train Epoch: 65 [6656/14860 (44%)]\tLoss: 0.016379\n",
      "Train Epoch: 65 [6784/14860 (45%)]\tLoss: 0.023671\n",
      "Train Epoch: 65 [6912/14860 (46%)]\tLoss: 0.014842\n",
      "Train Epoch: 65 [7040/14860 (47%)]\tLoss: 0.018464\n",
      "Train Epoch: 65 [7168/14860 (48%)]\tLoss: 0.021488\n",
      "Train Epoch: 65 [7296/14860 (49%)]\tLoss: 0.020827\n",
      "Train Epoch: 65 [7424/14860 (50%)]\tLoss: 0.033907\n",
      "Train Epoch: 65 [7552/14860 (50%)]\tLoss: 0.017599\n",
      "Train Epoch: 65 [7680/14860 (51%)]\tLoss: 0.019054\n",
      "Train Epoch: 65 [7808/14860 (52%)]\tLoss: 0.020976\n",
      "Train Epoch: 65 [7936/14860 (53%)]\tLoss: 0.023150\n",
      "Train Epoch: 65 [8064/14860 (54%)]\tLoss: 0.022724\n",
      "Train Epoch: 65 [8192/14860 (55%)]\tLoss: 0.018881\n",
      "Train Epoch: 65 [8320/14860 (56%)]\tLoss: 0.022008\n",
      "Train Epoch: 65 [8448/14860 (56%)]\tLoss: 0.020202\n",
      "Train Epoch: 65 [8576/14860 (57%)]\tLoss: 0.014585\n",
      "Train Epoch: 65 [8704/14860 (58%)]\tLoss: 0.023843\n",
      "Train Epoch: 65 [8832/14860 (59%)]\tLoss: 0.024015\n",
      "Train Epoch: 65 [8960/14860 (60%)]\tLoss: 0.028198\n",
      "Train Epoch: 65 [9088/14860 (61%)]\tLoss: 0.018982\n",
      "Train Epoch: 65 [9216/14860 (62%)]\tLoss: 0.017805\n",
      "Train Epoch: 65 [9344/14860 (62%)]\tLoss: 0.028807\n",
      "Train Epoch: 65 [9472/14860 (63%)]\tLoss: 0.019928\n",
      "Train Epoch: 65 [9600/14860 (64%)]\tLoss: 0.025273\n",
      "Train Epoch: 65 [9728/14860 (65%)]\tLoss: 0.026253\n",
      "Train Epoch: 65 [9856/14860 (66%)]\tLoss: 0.019312\n",
      "Train Epoch: 65 [9984/14860 (67%)]\tLoss: 0.021290\n",
      "Train Epoch: 65 [10112/14860 (68%)]\tLoss: 0.020945\n",
      "Train Epoch: 65 [10240/14860 (68%)]\tLoss: 0.018666\n",
      "Train Epoch: 65 [10368/14860 (69%)]\tLoss: 0.019553\n",
      "Train Epoch: 65 [10496/14860 (70%)]\tLoss: 0.027816\n",
      "Train Epoch: 65 [10624/14860 (71%)]\tLoss: 0.017675\n",
      "Train Epoch: 65 [10752/14860 (72%)]\tLoss: 0.025408\n",
      "Train Epoch: 65 [10880/14860 (73%)]\tLoss: 0.014903\n",
      "Train Epoch: 65 [11008/14860 (74%)]\tLoss: 0.031889\n",
      "Train Epoch: 65 [11136/14860 (74%)]\tLoss: 0.018698\n",
      "Train Epoch: 65 [11264/14860 (75%)]\tLoss: 0.029426\n",
      "Train Epoch: 65 [11392/14860 (76%)]\tLoss: 0.022016\n",
      "Train Epoch: 65 [11520/14860 (77%)]\tLoss: 0.023136\n",
      "Train Epoch: 65 [11648/14860 (78%)]\tLoss: 0.025443\n",
      "Train Epoch: 65 [11776/14860 (79%)]\tLoss: 0.016559\n",
      "Train Epoch: 65 [11904/14860 (79%)]\tLoss: 0.022539\n",
      "Train Epoch: 65 [12032/14860 (80%)]\tLoss: 0.027712\n",
      "Train Epoch: 65 [12160/14860 (81%)]\tLoss: 0.020397\n",
      "Train Epoch: 65 [12288/14860 (82%)]\tLoss: 0.019483\n",
      "Train Epoch: 65 [12416/14860 (83%)]\tLoss: 0.019256\n",
      "Train Epoch: 65 [12544/14860 (84%)]\tLoss: 0.012962\n",
      "Train Epoch: 65 [12672/14860 (85%)]\tLoss: 0.024226\n",
      "Train Epoch: 65 [12800/14860 (85%)]\tLoss: 0.024747\n",
      "Train Epoch: 65 [12928/14860 (86%)]\tLoss: 0.020647\n",
      "Train Epoch: 65 [13056/14860 (87%)]\tLoss: 0.017606\n",
      "Train Epoch: 65 [13184/14860 (88%)]\tLoss: 0.013176\n",
      "Train Epoch: 65 [13312/14860 (89%)]\tLoss: 0.013715\n",
      "Train Epoch: 65 [13440/14860 (90%)]\tLoss: 0.016521\n",
      "Train Epoch: 65 [13568/14860 (91%)]\tLoss: 0.017495\n",
      "Train Epoch: 65 [13696/14860 (91%)]\tLoss: 0.022940\n",
      "Train Epoch: 65 [13824/14860 (92%)]\tLoss: 0.019432\n",
      "Train Epoch: 65 [13952/14860 (93%)]\tLoss: 0.020093\n",
      "Train Epoch: 65 [14080/14860 (94%)]\tLoss: 0.017224\n",
      "Train Epoch: 65 [14208/14860 (95%)]\tLoss: 0.024030\n",
      "Train Epoch: 65 [14336/14860 (96%)]\tLoss: 0.016629\n",
      "Train Epoch: 65 [14464/14860 (97%)]\tLoss: 0.023345\n",
      "Train Epoch: 65 [14592/14860 (97%)]\tLoss: 0.019369\n",
      "Train Epoch: 65 [14720/14860 (98%)]\tLoss: 0.017290\n",
      "Train Epoch: 65 [1392/14860 (99%)]\tLoss: 0.008741\n",
      "epoch 65 training loss: 0.021102907120162606\n",
      "epoch 65 validation loss: 0.021182631609226253\n",
      "Train Epoch: 66 [0/14860 (0%)]\tLoss: 0.027128\n",
      "Train Epoch: 66 [128/14860 (1%)]\tLoss: 0.027317\n",
      "Train Epoch: 66 [256/14860 (2%)]\tLoss: 0.015000\n",
      "Train Epoch: 66 [384/14860 (3%)]\tLoss: 0.031784\n",
      "Train Epoch: 66 [512/14860 (3%)]\tLoss: 0.021696\n",
      "Train Epoch: 66 [640/14860 (4%)]\tLoss: 0.021420\n",
      "Train Epoch: 66 [768/14860 (5%)]\tLoss: 0.018455\n",
      "Train Epoch: 66 [896/14860 (6%)]\tLoss: 0.022711\n",
      "Train Epoch: 66 [1024/14860 (7%)]\tLoss: 0.016739\n",
      "Train Epoch: 66 [1152/14860 (8%)]\tLoss: 0.017194\n",
      "Train Epoch: 66 [1280/14860 (9%)]\tLoss: 0.016944\n",
      "Train Epoch: 66 [1408/14860 (9%)]\tLoss: 0.016665\n",
      "Train Epoch: 66 [1536/14860 (10%)]\tLoss: 0.020598\n",
      "Train Epoch: 66 [1664/14860 (11%)]\tLoss: 0.020185\n",
      "Train Epoch: 66 [1792/14860 (12%)]\tLoss: 0.026819\n",
      "Train Epoch: 66 [1920/14860 (13%)]\tLoss: 0.021062\n",
      "Train Epoch: 66 [2048/14860 (14%)]\tLoss: 0.023703\n",
      "Train Epoch: 66 [2176/14860 (15%)]\tLoss: 0.033141\n",
      "Train Epoch: 66 [2304/14860 (15%)]\tLoss: 0.019038\n",
      "Train Epoch: 66 [2432/14860 (16%)]\tLoss: 0.020914\n",
      "Train Epoch: 66 [2560/14860 (17%)]\tLoss: 0.012816\n",
      "Train Epoch: 66 [2688/14860 (18%)]\tLoss: 0.022200\n",
      "Train Epoch: 66 [2816/14860 (19%)]\tLoss: 0.019364\n",
      "Train Epoch: 66 [2944/14860 (20%)]\tLoss: 0.027820\n",
      "Train Epoch: 66 [3072/14860 (21%)]\tLoss: 0.018943\n",
      "Train Epoch: 66 [3200/14860 (21%)]\tLoss: 0.021902\n",
      "Train Epoch: 66 [3328/14860 (22%)]\tLoss: 0.019616\n",
      "Train Epoch: 66 [3456/14860 (23%)]\tLoss: 0.018731\n",
      "Train Epoch: 66 [3584/14860 (24%)]\tLoss: 0.024928\n",
      "Train Epoch: 66 [3712/14860 (25%)]\tLoss: 0.009884\n",
      "Train Epoch: 66 [3840/14860 (26%)]\tLoss: 0.037155\n",
      "Train Epoch: 66 [3968/14860 (26%)]\tLoss: 0.023961\n",
      "Train Epoch: 66 [4096/14860 (27%)]\tLoss: 0.026485\n",
      "Train Epoch: 66 [4224/14860 (28%)]\tLoss: 0.019700\n",
      "Train Epoch: 66 [4352/14860 (29%)]\tLoss: 0.034444\n",
      "Train Epoch: 66 [4480/14860 (30%)]\tLoss: 0.018965\n",
      "Train Epoch: 66 [4608/14860 (31%)]\tLoss: 0.011838\n",
      "Train Epoch: 66 [4736/14860 (32%)]\tLoss: 0.017882\n",
      "Train Epoch: 66 [4864/14860 (32%)]\tLoss: 0.020102\n",
      "Train Epoch: 66 [4992/14860 (33%)]\tLoss: 0.026793\n",
      "Train Epoch: 66 [5120/14860 (34%)]\tLoss: 0.021901\n",
      "Train Epoch: 66 [5248/14860 (35%)]\tLoss: 0.017086\n",
      "Train Epoch: 66 [5376/14860 (36%)]\tLoss: 0.019567\n",
      "Train Epoch: 66 [5504/14860 (37%)]\tLoss: 0.021754\n",
      "Train Epoch: 66 [5632/14860 (38%)]\tLoss: 0.020868\n",
      "Train Epoch: 66 [5760/14860 (38%)]\tLoss: 0.020817\n",
      "Train Epoch: 66 [5888/14860 (39%)]\tLoss: 0.016459\n",
      "Train Epoch: 66 [6016/14860 (40%)]\tLoss: 0.017148\n",
      "Train Epoch: 66 [6144/14860 (41%)]\tLoss: 0.014377\n",
      "Train Epoch: 66 [6272/14860 (42%)]\tLoss: 0.032394\n",
      "Train Epoch: 66 [6400/14860 (43%)]\tLoss: 0.027926\n",
      "Train Epoch: 66 [6528/14860 (44%)]\tLoss: 0.026091\n",
      "Train Epoch: 66 [6656/14860 (44%)]\tLoss: 0.014232\n",
      "Train Epoch: 66 [6784/14860 (45%)]\tLoss: 0.028167\n",
      "Train Epoch: 66 [6912/14860 (46%)]\tLoss: 0.016778\n",
      "Train Epoch: 66 [7040/14860 (47%)]\tLoss: 0.021223\n",
      "Train Epoch: 66 [7168/14860 (48%)]\tLoss: 0.021675\n",
      "Train Epoch: 66 [7296/14860 (49%)]\tLoss: 0.017726\n",
      "Train Epoch: 66 [7424/14860 (50%)]\tLoss: 0.023096\n",
      "Train Epoch: 66 [7552/14860 (50%)]\tLoss: 0.024056\n",
      "Train Epoch: 66 [7680/14860 (51%)]\tLoss: 0.015808\n",
      "Train Epoch: 66 [7808/14860 (52%)]\tLoss: 0.026841\n",
      "Train Epoch: 66 [7936/14860 (53%)]\tLoss: 0.033248\n",
      "Train Epoch: 66 [8064/14860 (54%)]\tLoss: 0.017886\n",
      "Train Epoch: 66 [8192/14860 (55%)]\tLoss: 0.018151\n",
      "Train Epoch: 66 [8320/14860 (56%)]\tLoss: 0.022315\n",
      "Train Epoch: 66 [8448/14860 (56%)]\tLoss: 0.018693\n",
      "Train Epoch: 66 [8576/14860 (57%)]\tLoss: 0.018480\n",
      "Train Epoch: 66 [8704/14860 (58%)]\tLoss: 0.016643\n",
      "Train Epoch: 66 [8832/14860 (59%)]\tLoss: 0.015312\n",
      "Train Epoch: 66 [8960/14860 (60%)]\tLoss: 0.015867\n",
      "Train Epoch: 66 [9088/14860 (61%)]\tLoss: 0.020515\n",
      "Train Epoch: 66 [9216/14860 (62%)]\tLoss: 0.021283\n",
      "Train Epoch: 66 [9344/14860 (62%)]\tLoss: 0.029253\n",
      "Train Epoch: 66 [9472/14860 (63%)]\tLoss: 0.021291\n",
      "Train Epoch: 66 [9600/14860 (64%)]\tLoss: 0.018389\n",
      "Train Epoch: 66 [9728/14860 (65%)]\tLoss: 0.016944\n",
      "Train Epoch: 66 [9856/14860 (66%)]\tLoss: 0.018343\n",
      "Train Epoch: 66 [9984/14860 (67%)]\tLoss: 0.021321\n",
      "Train Epoch: 66 [10112/14860 (68%)]\tLoss: 0.017369\n",
      "Train Epoch: 66 [10240/14860 (68%)]\tLoss: 0.017132\n",
      "Train Epoch: 66 [10368/14860 (69%)]\tLoss: 0.022484\n",
      "Train Epoch: 66 [10496/14860 (70%)]\tLoss: 0.015547\n",
      "Train Epoch: 66 [10624/14860 (71%)]\tLoss: 0.020209\n",
      "Train Epoch: 66 [10752/14860 (72%)]\tLoss: 0.020231\n",
      "Train Epoch: 66 [10880/14860 (73%)]\tLoss: 0.014616\n",
      "Train Epoch: 66 [11008/14860 (74%)]\tLoss: 0.012131\n",
      "Train Epoch: 66 [11136/14860 (74%)]\tLoss: 0.026097\n",
      "Train Epoch: 66 [11264/14860 (75%)]\tLoss: 0.022986\n",
      "Train Epoch: 66 [11392/14860 (76%)]\tLoss: 0.026577\n",
      "Train Epoch: 66 [11520/14860 (77%)]\tLoss: 0.022136\n",
      "Train Epoch: 66 [11648/14860 (78%)]\tLoss: 0.019950\n",
      "Train Epoch: 66 [11776/14860 (79%)]\tLoss: 0.018306\n",
      "Train Epoch: 66 [11904/14860 (79%)]\tLoss: 0.021219\n",
      "Train Epoch: 66 [12032/14860 (80%)]\tLoss: 0.018874\n",
      "Train Epoch: 66 [12160/14860 (81%)]\tLoss: 0.029820\n",
      "Train Epoch: 66 [12288/14860 (82%)]\tLoss: 0.025402\n",
      "Train Epoch: 66 [12416/14860 (83%)]\tLoss: 0.015393\n",
      "Train Epoch: 66 [12544/14860 (84%)]\tLoss: 0.015591\n",
      "Train Epoch: 66 [12672/14860 (85%)]\tLoss: 0.019488\n",
      "Train Epoch: 66 [12800/14860 (85%)]\tLoss: 0.022148\n",
      "Train Epoch: 66 [12928/14860 (86%)]\tLoss: 0.023520\n",
      "Train Epoch: 66 [13056/14860 (87%)]\tLoss: 0.025448\n",
      "Train Epoch: 66 [13184/14860 (88%)]\tLoss: 0.018011\n",
      "Train Epoch: 66 [13312/14860 (89%)]\tLoss: 0.014954\n",
      "Train Epoch: 66 [13440/14860 (90%)]\tLoss: 0.023940\n",
      "Train Epoch: 66 [13568/14860 (91%)]\tLoss: 0.014708\n",
      "Train Epoch: 66 [13696/14860 (91%)]\tLoss: 0.024141\n",
      "Train Epoch: 66 [13824/14860 (92%)]\tLoss: 0.014375\n",
      "Train Epoch: 66 [13952/14860 (93%)]\tLoss: 0.037174\n",
      "Train Epoch: 66 [14080/14860 (94%)]\tLoss: 0.022409\n",
      "Train Epoch: 66 [14208/14860 (95%)]\tLoss: 0.024726\n",
      "Train Epoch: 66 [14336/14860 (96%)]\tLoss: 0.024511\n",
      "Train Epoch: 66 [14464/14860 (97%)]\tLoss: 0.023918\n",
      "Train Epoch: 66 [14592/14860 (97%)]\tLoss: 0.020958\n",
      "Train Epoch: 66 [14720/14860 (98%)]\tLoss: 0.017823\n",
      "Train Epoch: 66 [1392/14860 (99%)]\tLoss: 0.027100\n",
      "epoch 66 training loss: 0.021225569618499685\n",
      "epoch 66 validation loss: 0.025431745854763373\n",
      "Train Epoch: 67 [0/14860 (0%)]\tLoss: 0.027991\n",
      "Train Epoch: 67 [128/14860 (1%)]\tLoss: 0.018559\n",
      "Train Epoch: 67 [256/14860 (2%)]\tLoss: 0.017870\n",
      "Train Epoch: 67 [384/14860 (3%)]\tLoss: 0.018703\n",
      "Train Epoch: 67 [512/14860 (3%)]\tLoss: 0.024362\n",
      "Train Epoch: 67 [640/14860 (4%)]\tLoss: 0.023011\n",
      "Train Epoch: 67 [768/14860 (5%)]\tLoss: 0.017906\n",
      "Train Epoch: 67 [896/14860 (6%)]\tLoss: 0.018526\n",
      "Train Epoch: 67 [1024/14860 (7%)]\tLoss: 0.022014\n",
      "Train Epoch: 67 [1152/14860 (8%)]\tLoss: 0.024905\n",
      "Train Epoch: 67 [1280/14860 (9%)]\tLoss: 0.014329\n",
      "Train Epoch: 67 [1408/14860 (9%)]\tLoss: 0.021248\n",
      "Train Epoch: 67 [1536/14860 (10%)]\tLoss: 0.021161\n",
      "Train Epoch: 67 [1664/14860 (11%)]\tLoss: 0.018342\n",
      "Train Epoch: 67 [1792/14860 (12%)]\tLoss: 0.017623\n",
      "Train Epoch: 67 [1920/14860 (13%)]\tLoss: 0.021939\n",
      "Train Epoch: 67 [2048/14860 (14%)]\tLoss: 0.017968\n",
      "Train Epoch: 67 [2176/14860 (15%)]\tLoss: 0.020741\n",
      "Train Epoch: 67 [2304/14860 (15%)]\tLoss: 0.022342\n",
      "Train Epoch: 67 [2432/14860 (16%)]\tLoss: 0.023436\n",
      "Train Epoch: 67 [2560/14860 (17%)]\tLoss: 0.022204\n",
      "Train Epoch: 67 [2688/14860 (18%)]\tLoss: 0.023494\n",
      "Train Epoch: 67 [2816/14860 (19%)]\tLoss: 0.023846\n",
      "Train Epoch: 67 [2944/14860 (20%)]\tLoss: 0.028133\n",
      "Train Epoch: 67 [3072/14860 (21%)]\tLoss: 0.016445\n",
      "Train Epoch: 67 [3200/14860 (21%)]\tLoss: 0.017993\n",
      "Train Epoch: 67 [3328/14860 (22%)]\tLoss: 0.021903\n",
      "Train Epoch: 67 [3456/14860 (23%)]\tLoss: 0.014101\n",
      "Train Epoch: 67 [3584/14860 (24%)]\tLoss: 0.019751\n",
      "Train Epoch: 67 [3712/14860 (25%)]\tLoss: 0.022581\n",
      "Train Epoch: 67 [3840/14860 (26%)]\tLoss: 0.022909\n",
      "Train Epoch: 67 [3968/14860 (26%)]\tLoss: 0.016962\n",
      "Train Epoch: 67 [4096/14860 (27%)]\tLoss: 0.019358\n",
      "Train Epoch: 67 [4224/14860 (28%)]\tLoss: 0.026609\n",
      "Train Epoch: 67 [4352/14860 (29%)]\tLoss: 0.020594\n",
      "Train Epoch: 67 [4480/14860 (30%)]\tLoss: 0.024528\n",
      "Train Epoch: 67 [4608/14860 (31%)]\tLoss: 0.018896\n",
      "Train Epoch: 67 [4736/14860 (32%)]\tLoss: 0.022134\n",
      "Train Epoch: 67 [4864/14860 (32%)]\tLoss: 0.025244\n",
      "Train Epoch: 67 [4992/14860 (33%)]\tLoss: 0.012981\n",
      "Train Epoch: 67 [5120/14860 (34%)]\tLoss: 0.015650\n",
      "Train Epoch: 67 [5248/14860 (35%)]\tLoss: 0.016311\n",
      "Train Epoch: 67 [5376/14860 (36%)]\tLoss: 0.019465\n",
      "Train Epoch: 67 [5504/14860 (37%)]\tLoss: 0.025899\n",
      "Train Epoch: 67 [5632/14860 (38%)]\tLoss: 0.024049\n",
      "Train Epoch: 67 [5760/14860 (38%)]\tLoss: 0.032116\n",
      "Train Epoch: 67 [5888/14860 (39%)]\tLoss: 0.023895\n",
      "Train Epoch: 67 [6016/14860 (40%)]\tLoss: 0.029754\n",
      "Train Epoch: 67 [6144/14860 (41%)]\tLoss: 0.016326\n",
      "Train Epoch: 67 [6272/14860 (42%)]\tLoss: 0.039396\n",
      "Train Epoch: 67 [6400/14860 (43%)]\tLoss: 0.023740\n",
      "Train Epoch: 67 [6528/14860 (44%)]\tLoss: 0.031213\n",
      "Train Epoch: 67 [6656/14860 (44%)]\tLoss: 0.027685\n",
      "Train Epoch: 67 [6784/14860 (45%)]\tLoss: 0.022064\n",
      "Train Epoch: 67 [6912/14860 (46%)]\tLoss: 0.010946\n",
      "Train Epoch: 67 [7040/14860 (47%)]\tLoss: 0.017995\n",
      "Train Epoch: 67 [7168/14860 (48%)]\tLoss: 0.021401\n",
      "Train Epoch: 67 [7296/14860 (49%)]\tLoss: 0.016065\n",
      "Train Epoch: 67 [7424/14860 (50%)]\tLoss: 0.020893\n",
      "Train Epoch: 67 [7552/14860 (50%)]\tLoss: 0.019226\n",
      "Train Epoch: 67 [7680/14860 (51%)]\tLoss: 0.023743\n",
      "Train Epoch: 67 [7808/14860 (52%)]\tLoss: 0.020772\n",
      "Train Epoch: 67 [7936/14860 (53%)]\tLoss: 0.015704\n",
      "Train Epoch: 67 [8064/14860 (54%)]\tLoss: 0.015019\n",
      "Train Epoch: 67 [8192/14860 (55%)]\tLoss: 0.028310\n",
      "Train Epoch: 67 [8320/14860 (56%)]\tLoss: 0.014864\n",
      "Train Epoch: 67 [8448/14860 (56%)]\tLoss: 0.021533\n",
      "Train Epoch: 67 [8576/14860 (57%)]\tLoss: 0.028510\n",
      "Train Epoch: 67 [8704/14860 (58%)]\tLoss: 0.014322\n",
      "Train Epoch: 67 [8832/14860 (59%)]\tLoss: 0.032064\n",
      "Train Epoch: 67 [8960/14860 (60%)]\tLoss: 0.022350\n",
      "Train Epoch: 67 [9088/14860 (61%)]\tLoss: 0.023053\n",
      "Train Epoch: 67 [9216/14860 (62%)]\tLoss: 0.025976\n",
      "Train Epoch: 67 [9344/14860 (62%)]\tLoss: 0.018417\n",
      "Train Epoch: 67 [9472/14860 (63%)]\tLoss: 0.022895\n",
      "Train Epoch: 67 [9600/14860 (64%)]\tLoss: 0.017541\n",
      "Train Epoch: 67 [9728/14860 (65%)]\tLoss: 0.019557\n",
      "Train Epoch: 67 [9856/14860 (66%)]\tLoss: 0.019392\n",
      "Train Epoch: 67 [9984/14860 (67%)]\tLoss: 0.018849\n",
      "Train Epoch: 67 [10112/14860 (68%)]\tLoss: 0.028716\n",
      "Train Epoch: 67 [10240/14860 (68%)]\tLoss: 0.018378\n",
      "Train Epoch: 67 [10368/14860 (69%)]\tLoss: 0.025823\n",
      "Train Epoch: 67 [10496/14860 (70%)]\tLoss: 0.018799\n",
      "Train Epoch: 67 [10624/14860 (71%)]\tLoss: 0.015602\n",
      "Train Epoch: 67 [10752/14860 (72%)]\tLoss: 0.013896\n",
      "Train Epoch: 67 [10880/14860 (73%)]\tLoss: 0.013908\n",
      "Train Epoch: 67 [11008/14860 (74%)]\tLoss: 0.019432\n",
      "Train Epoch: 67 [11136/14860 (74%)]\tLoss: 0.018880\n",
      "Train Epoch: 67 [11264/14860 (75%)]\tLoss: 0.019552\n",
      "Train Epoch: 67 [11392/14860 (76%)]\tLoss: 0.017196\n",
      "Train Epoch: 67 [11520/14860 (77%)]\tLoss: 0.023035\n",
      "Train Epoch: 67 [11648/14860 (78%)]\tLoss: 0.014734\n",
      "Train Epoch: 67 [11776/14860 (79%)]\tLoss: 0.020087\n",
      "Train Epoch: 67 [11904/14860 (79%)]\tLoss: 0.026036\n",
      "Train Epoch: 67 [12032/14860 (80%)]\tLoss: 0.023928\n",
      "Train Epoch: 67 [12160/14860 (81%)]\tLoss: 0.015754\n",
      "Train Epoch: 67 [12288/14860 (82%)]\tLoss: 0.019985\n",
      "Train Epoch: 67 [12416/14860 (83%)]\tLoss: 0.020450\n",
      "Train Epoch: 67 [12544/14860 (84%)]\tLoss: 0.019313\n",
      "Train Epoch: 67 [12672/14860 (85%)]\tLoss: 0.020033\n",
      "Train Epoch: 67 [12800/14860 (85%)]\tLoss: 0.027389\n",
      "Train Epoch: 67 [12928/14860 (86%)]\tLoss: 0.023484\n",
      "Train Epoch: 67 [13056/14860 (87%)]\tLoss: 0.021661\n",
      "Train Epoch: 67 [13184/14860 (88%)]\tLoss: 0.019875\n",
      "Train Epoch: 67 [13312/14860 (89%)]\tLoss: 0.015879\n",
      "Train Epoch: 67 [13440/14860 (90%)]\tLoss: 0.020849\n",
      "Train Epoch: 67 [13568/14860 (91%)]\tLoss: 0.027814\n",
      "Train Epoch: 67 [13696/14860 (91%)]\tLoss: 0.016288\n",
      "Train Epoch: 67 [13824/14860 (92%)]\tLoss: 0.020510\n",
      "Train Epoch: 67 [13952/14860 (93%)]\tLoss: 0.010851\n",
      "Train Epoch: 67 [14080/14860 (94%)]\tLoss: 0.012437\n",
      "Train Epoch: 67 [14208/14860 (95%)]\tLoss: 0.018624\n",
      "Train Epoch: 67 [14336/14860 (96%)]\tLoss: 0.014602\n",
      "Train Epoch: 67 [14464/14860 (97%)]\tLoss: 0.016210\n",
      "Train Epoch: 67 [14592/14860 (97%)]\tLoss: 0.031069\n",
      "Train Epoch: 67 [14720/14860 (98%)]\tLoss: 0.019986\n",
      "Train Epoch: 67 [1392/14860 (99%)]\tLoss: 0.015530\n",
      "epoch 67 training loss: 0.020830728981293675\n",
      "epoch 67 validation loss: 0.020908374546803804\n",
      "Train Epoch: 68 [0/14860 (0%)]\tLoss: 0.033190\n",
      "Train Epoch: 68 [128/14860 (1%)]\tLoss: 0.013100\n",
      "Train Epoch: 68 [256/14860 (2%)]\tLoss: 0.017512\n",
      "Train Epoch: 68 [384/14860 (3%)]\tLoss: 0.020222\n",
      "Train Epoch: 68 [512/14860 (3%)]\tLoss: 0.024348\n",
      "Train Epoch: 68 [640/14860 (4%)]\tLoss: 0.020630\n",
      "Train Epoch: 68 [768/14860 (5%)]\tLoss: 0.029264\n",
      "Train Epoch: 68 [896/14860 (6%)]\tLoss: 0.021857\n",
      "Train Epoch: 68 [1024/14860 (7%)]\tLoss: 0.029535\n",
      "Train Epoch: 68 [1152/14860 (8%)]\tLoss: 0.023384\n",
      "Train Epoch: 68 [1280/14860 (9%)]\tLoss: 0.015483\n",
      "Train Epoch: 68 [1408/14860 (9%)]\tLoss: 0.028926\n",
      "Train Epoch: 68 [1536/14860 (10%)]\tLoss: 0.015113\n",
      "Train Epoch: 68 [1664/14860 (11%)]\tLoss: 0.029542\n",
      "Train Epoch: 68 [1792/14860 (12%)]\tLoss: 0.023491\n",
      "Train Epoch: 68 [1920/14860 (13%)]\tLoss: 0.019483\n",
      "Train Epoch: 68 [2048/14860 (14%)]\tLoss: 0.018964\n",
      "Train Epoch: 68 [2176/14860 (15%)]\tLoss: 0.020203\n",
      "Train Epoch: 68 [2304/14860 (15%)]\tLoss: 0.014786\n",
      "Train Epoch: 68 [2432/14860 (16%)]\tLoss: 0.017387\n",
      "Train Epoch: 68 [2560/14860 (17%)]\tLoss: 0.017378\n",
      "Train Epoch: 68 [2688/14860 (18%)]\tLoss: 0.021247\n",
      "Train Epoch: 68 [2816/14860 (19%)]\tLoss: 0.023393\n",
      "Train Epoch: 68 [2944/14860 (20%)]\tLoss: 0.017368\n",
      "Train Epoch: 68 [3072/14860 (21%)]\tLoss: 0.028003\n",
      "Train Epoch: 68 [3200/14860 (21%)]\tLoss: 0.014033\n",
      "Train Epoch: 68 [3328/14860 (22%)]\tLoss: 0.017947\n",
      "Train Epoch: 68 [3456/14860 (23%)]\tLoss: 0.014210\n",
      "Train Epoch: 68 [3584/14860 (24%)]\tLoss: 0.024950\n",
      "Train Epoch: 68 [3712/14860 (25%)]\tLoss: 0.029372\n",
      "Train Epoch: 68 [3840/14860 (26%)]\tLoss: 0.021247\n",
      "Train Epoch: 68 [3968/14860 (26%)]\tLoss: 0.020032\n",
      "Train Epoch: 68 [4096/14860 (27%)]\tLoss: 0.021996\n",
      "Train Epoch: 68 [4224/14860 (28%)]\tLoss: 0.025913\n",
      "Train Epoch: 68 [4352/14860 (29%)]\tLoss: 0.027383\n",
      "Train Epoch: 68 [4480/14860 (30%)]\tLoss: 0.024060\n",
      "Train Epoch: 68 [4608/14860 (31%)]\tLoss: 0.026743\n",
      "Train Epoch: 68 [4736/14860 (32%)]\tLoss: 0.020713\n",
      "Train Epoch: 68 [4864/14860 (32%)]\tLoss: 0.023604\n",
      "Train Epoch: 68 [4992/14860 (33%)]\tLoss: 0.016389\n",
      "Train Epoch: 68 [5120/14860 (34%)]\tLoss: 0.021833\n",
      "Train Epoch: 68 [5248/14860 (35%)]\tLoss: 0.016720\n",
      "Train Epoch: 68 [5376/14860 (36%)]\tLoss: 0.020282\n",
      "Train Epoch: 68 [5504/14860 (37%)]\tLoss: 0.015732\n",
      "Train Epoch: 68 [5632/14860 (38%)]\tLoss: 0.012983\n",
      "Train Epoch: 68 [5760/14860 (38%)]\tLoss: 0.017807\n",
      "Train Epoch: 68 [5888/14860 (39%)]\tLoss: 0.018298\n",
      "Train Epoch: 68 [6016/14860 (40%)]\tLoss: 0.018704\n",
      "Train Epoch: 68 [6144/14860 (41%)]\tLoss: 0.016792\n",
      "Train Epoch: 68 [6272/14860 (42%)]\tLoss: 0.012663\n",
      "Train Epoch: 68 [6400/14860 (43%)]\tLoss: 0.030435\n",
      "Train Epoch: 68 [6528/14860 (44%)]\tLoss: 0.015637\n",
      "Train Epoch: 68 [6656/14860 (44%)]\tLoss: 0.019511\n",
      "Train Epoch: 68 [6784/14860 (45%)]\tLoss: 0.016362\n",
      "Train Epoch: 68 [6912/14860 (46%)]\tLoss: 0.024586\n",
      "Train Epoch: 68 [7040/14860 (47%)]\tLoss: 0.022801\n",
      "Train Epoch: 68 [7168/14860 (48%)]\tLoss: 0.016502\n",
      "Train Epoch: 68 [7296/14860 (49%)]\tLoss: 0.014206\n",
      "Train Epoch: 68 [7424/14860 (50%)]\tLoss: 0.022179\n",
      "Train Epoch: 68 [7552/14860 (50%)]\tLoss: 0.020006\n",
      "Train Epoch: 68 [7680/14860 (51%)]\tLoss: 0.025823\n",
      "Train Epoch: 68 [7808/14860 (52%)]\tLoss: 0.015117\n",
      "Train Epoch: 68 [7936/14860 (53%)]\tLoss: 0.027106\n",
      "Train Epoch: 68 [8064/14860 (54%)]\tLoss: 0.019791\n",
      "Train Epoch: 68 [8192/14860 (55%)]\tLoss: 0.019965\n",
      "Train Epoch: 68 [8320/14860 (56%)]\tLoss: 0.020770\n",
      "Train Epoch: 68 [8448/14860 (56%)]\tLoss: 0.017435\n",
      "Train Epoch: 68 [8576/14860 (57%)]\tLoss: 0.028608\n",
      "Train Epoch: 68 [8704/14860 (58%)]\tLoss: 0.019618\n",
      "Train Epoch: 68 [8832/14860 (59%)]\tLoss: 0.015532\n",
      "Train Epoch: 68 [8960/14860 (60%)]\tLoss: 0.023091\n",
      "Train Epoch: 68 [9088/14860 (61%)]\tLoss: 0.024752\n",
      "Train Epoch: 68 [9216/14860 (62%)]\tLoss: 0.020391\n",
      "Train Epoch: 68 [9344/14860 (62%)]\tLoss: 0.023411\n",
      "Train Epoch: 68 [9472/14860 (63%)]\tLoss: 0.013587\n",
      "Train Epoch: 68 [9600/14860 (64%)]\tLoss: 0.017897\n",
      "Train Epoch: 68 [9728/14860 (65%)]\tLoss: 0.017778\n",
      "Train Epoch: 68 [9856/14860 (66%)]\tLoss: 0.017801\n",
      "Train Epoch: 68 [9984/14860 (67%)]\tLoss: 0.018224\n",
      "Train Epoch: 68 [10112/14860 (68%)]\tLoss: 0.014830\n",
      "Train Epoch: 68 [10240/14860 (68%)]\tLoss: 0.019954\n",
      "Train Epoch: 68 [10368/14860 (69%)]\tLoss: 0.020899\n",
      "Train Epoch: 68 [10496/14860 (70%)]\tLoss: 0.017959\n",
      "Train Epoch: 68 [10624/14860 (71%)]\tLoss: 0.029841\n",
      "Train Epoch: 68 [10752/14860 (72%)]\tLoss: 0.022506\n",
      "Train Epoch: 68 [10880/14860 (73%)]\tLoss: 0.028758\n",
      "Train Epoch: 68 [11008/14860 (74%)]\tLoss: 0.017841\n",
      "Train Epoch: 68 [11136/14860 (74%)]\tLoss: 0.023184\n",
      "Train Epoch: 68 [11264/14860 (75%)]\tLoss: 0.019581\n",
      "Train Epoch: 68 [11392/14860 (76%)]\tLoss: 0.028227\n",
      "Train Epoch: 68 [11520/14860 (77%)]\tLoss: 0.030434\n",
      "Train Epoch: 68 [11648/14860 (78%)]\tLoss: 0.016190\n",
      "Train Epoch: 68 [11776/14860 (79%)]\tLoss: 0.018835\n",
      "Train Epoch: 68 [11904/14860 (79%)]\tLoss: 0.019663\n",
      "Train Epoch: 68 [12032/14860 (80%)]\tLoss: 0.015930\n",
      "Train Epoch: 68 [12160/14860 (81%)]\tLoss: 0.020476\n",
      "Train Epoch: 68 [12288/14860 (82%)]\tLoss: 0.024580\n",
      "Train Epoch: 68 [12416/14860 (83%)]\tLoss: 0.021776\n",
      "Train Epoch: 68 [12544/14860 (84%)]\tLoss: 0.018759\n",
      "Train Epoch: 68 [12672/14860 (85%)]\tLoss: 0.029849\n",
      "Train Epoch: 68 [12800/14860 (85%)]\tLoss: 0.020551\n",
      "Train Epoch: 68 [12928/14860 (86%)]\tLoss: 0.024368\n",
      "Train Epoch: 68 [13056/14860 (87%)]\tLoss: 0.020709\n",
      "Train Epoch: 68 [13184/14860 (88%)]\tLoss: 0.017819\n",
      "Train Epoch: 68 [13312/14860 (89%)]\tLoss: 0.018299\n",
      "Train Epoch: 68 [13440/14860 (90%)]\tLoss: 0.019780\n",
      "Train Epoch: 68 [13568/14860 (91%)]\tLoss: 0.019448\n",
      "Train Epoch: 68 [13696/14860 (91%)]\tLoss: 0.029147\n",
      "Train Epoch: 68 [13824/14860 (92%)]\tLoss: 0.014179\n",
      "Train Epoch: 68 [13952/14860 (93%)]\tLoss: 0.015184\n",
      "Train Epoch: 68 [14080/14860 (94%)]\tLoss: 0.016767\n",
      "Train Epoch: 68 [14208/14860 (95%)]\tLoss: 0.019230\n",
      "Train Epoch: 68 [14336/14860 (96%)]\tLoss: 0.015232\n",
      "Train Epoch: 68 [14464/14860 (97%)]\tLoss: 0.024020\n",
      "Train Epoch: 68 [14592/14860 (97%)]\tLoss: 0.031436\n",
      "Train Epoch: 68 [14720/14860 (98%)]\tLoss: 0.020692\n",
      "Train Epoch: 68 [1392/14860 (99%)]\tLoss: 0.020983\n",
      "epoch 68 training loss: 0.020863723455585986\n",
      "epoch 68 validation loss: 0.022618710850399286\n",
      "Train Epoch: 69 [0/14860 (0%)]\tLoss: 0.022197\n",
      "Train Epoch: 69 [128/14860 (1%)]\tLoss: 0.028671\n",
      "Train Epoch: 69 [256/14860 (2%)]\tLoss: 0.016280\n",
      "Train Epoch: 69 [384/14860 (3%)]\tLoss: 0.030527\n",
      "Train Epoch: 69 [512/14860 (3%)]\tLoss: 0.021693\n",
      "Train Epoch: 69 [640/14860 (4%)]\tLoss: 0.022668\n",
      "Train Epoch: 69 [768/14860 (5%)]\tLoss: 0.018601\n",
      "Train Epoch: 69 [896/14860 (6%)]\tLoss: 0.020207\n",
      "Train Epoch: 69 [1024/14860 (7%)]\tLoss: 0.024135\n",
      "Train Epoch: 69 [1152/14860 (8%)]\tLoss: 0.023135\n",
      "Train Epoch: 69 [1280/14860 (9%)]\tLoss: 0.031643\n",
      "Train Epoch: 69 [1408/14860 (9%)]\tLoss: 0.024878\n",
      "Train Epoch: 69 [1536/14860 (10%)]\tLoss: 0.019567\n",
      "Train Epoch: 69 [1664/14860 (11%)]\tLoss: 0.028971\n",
      "Train Epoch: 69 [1792/14860 (12%)]\tLoss: 0.023540\n",
      "Train Epoch: 69 [1920/14860 (13%)]\tLoss: 0.028943\n",
      "Train Epoch: 69 [2048/14860 (14%)]\tLoss: 0.025794\n",
      "Train Epoch: 69 [2176/14860 (15%)]\tLoss: 0.019826\n",
      "Train Epoch: 69 [2304/14860 (15%)]\tLoss: 0.038113\n",
      "Train Epoch: 69 [2432/14860 (16%)]\tLoss: 0.020055\n",
      "Train Epoch: 69 [2560/14860 (17%)]\tLoss: 0.028914\n",
      "Train Epoch: 69 [2688/14860 (18%)]\tLoss: 0.022598\n",
      "Train Epoch: 69 [2816/14860 (19%)]\tLoss: 0.018850\n",
      "Train Epoch: 69 [2944/14860 (20%)]\tLoss: 0.021103\n",
      "Train Epoch: 69 [3072/14860 (21%)]\tLoss: 0.023234\n",
      "Train Epoch: 69 [3200/14860 (21%)]\tLoss: 0.029277\n",
      "Train Epoch: 69 [3328/14860 (22%)]\tLoss: 0.035378\n",
      "Train Epoch: 69 [3456/14860 (23%)]\tLoss: 0.022480\n",
      "Train Epoch: 69 [3584/14860 (24%)]\tLoss: 0.017748\n",
      "Train Epoch: 69 [3712/14860 (25%)]\tLoss: 0.024434\n",
      "Train Epoch: 69 [3840/14860 (26%)]\tLoss: 0.020496\n",
      "Train Epoch: 69 [3968/14860 (26%)]\tLoss: 0.021455\n",
      "Train Epoch: 69 [4096/14860 (27%)]\tLoss: 0.033245\n",
      "Train Epoch: 69 [4224/14860 (28%)]\tLoss: 0.020377\n",
      "Train Epoch: 69 [4352/14860 (29%)]\tLoss: 0.027822\n",
      "Train Epoch: 69 [4480/14860 (30%)]\tLoss: 0.022747\n",
      "Train Epoch: 69 [4608/14860 (31%)]\tLoss: 0.019806\n",
      "Train Epoch: 69 [4736/14860 (32%)]\tLoss: 0.021609\n",
      "Train Epoch: 69 [4864/14860 (32%)]\tLoss: 0.031382\n",
      "Train Epoch: 69 [4992/14860 (33%)]\tLoss: 0.019557\n",
      "Train Epoch: 69 [5120/14860 (34%)]\tLoss: 0.023851\n",
      "Train Epoch: 69 [5248/14860 (35%)]\tLoss: 0.020958\n",
      "Train Epoch: 69 [5376/14860 (36%)]\tLoss: 0.028526\n",
      "Train Epoch: 69 [5504/14860 (37%)]\tLoss: 0.023168\n",
      "Train Epoch: 69 [5632/14860 (38%)]\tLoss: 0.019626\n",
      "Train Epoch: 69 [5760/14860 (38%)]\tLoss: 0.026993\n",
      "Train Epoch: 69 [5888/14860 (39%)]\tLoss: 0.015082\n",
      "Train Epoch: 69 [6016/14860 (40%)]\tLoss: 0.016657\n",
      "Train Epoch: 69 [6144/14860 (41%)]\tLoss: 0.020454\n",
      "Train Epoch: 69 [6272/14860 (42%)]\tLoss: 0.010679\n",
      "Train Epoch: 69 [6400/14860 (43%)]\tLoss: 0.019797\n",
      "Train Epoch: 69 [6528/14860 (44%)]\tLoss: 0.018226\n",
      "Train Epoch: 69 [6656/14860 (44%)]\tLoss: 0.020409\n",
      "Train Epoch: 69 [6784/14860 (45%)]\tLoss: 0.021156\n",
      "Train Epoch: 69 [6912/14860 (46%)]\tLoss: 0.025777\n",
      "Train Epoch: 69 [7040/14860 (47%)]\tLoss: 0.020298\n",
      "Train Epoch: 69 [7168/14860 (48%)]\tLoss: 0.021444\n",
      "Train Epoch: 69 [7296/14860 (49%)]\tLoss: 0.028105\n",
      "Train Epoch: 69 [7424/14860 (50%)]\tLoss: 0.031333\n",
      "Train Epoch: 69 [7552/14860 (50%)]\tLoss: 0.023054\n",
      "Train Epoch: 69 [7680/14860 (51%)]\tLoss: 0.018735\n",
      "Train Epoch: 69 [7808/14860 (52%)]\tLoss: 0.018926\n",
      "Train Epoch: 69 [7936/14860 (53%)]\tLoss: 0.019869\n",
      "Train Epoch: 69 [8064/14860 (54%)]\tLoss: 0.020311\n",
      "Train Epoch: 69 [8192/14860 (55%)]\tLoss: 0.022814\n",
      "Train Epoch: 69 [8320/14860 (56%)]\tLoss: 0.019439\n",
      "Train Epoch: 69 [8448/14860 (56%)]\tLoss: 0.019439\n",
      "Train Epoch: 69 [8576/14860 (57%)]\tLoss: 0.018307\n",
      "Train Epoch: 69 [8704/14860 (58%)]\tLoss: 0.020894\n",
      "Train Epoch: 69 [8832/14860 (59%)]\tLoss: 0.020966\n",
      "Train Epoch: 69 [8960/14860 (60%)]\tLoss: 0.026164\n",
      "Train Epoch: 69 [9088/14860 (61%)]\tLoss: 0.020793\n",
      "Train Epoch: 69 [9216/14860 (62%)]\tLoss: 0.016865\n",
      "Train Epoch: 69 [9344/14860 (62%)]\tLoss: 0.018090\n",
      "Train Epoch: 69 [9472/14860 (63%)]\tLoss: 0.016211\n",
      "Train Epoch: 69 [9600/14860 (64%)]\tLoss: 0.012432\n",
      "Train Epoch: 69 [9728/14860 (65%)]\tLoss: 0.015575\n",
      "Train Epoch: 69 [9856/14860 (66%)]\tLoss: 0.020260\n",
      "Train Epoch: 69 [9984/14860 (67%)]\tLoss: 0.016978\n",
      "Train Epoch: 69 [10112/14860 (68%)]\tLoss: 0.019430\n",
      "Train Epoch: 69 [10240/14860 (68%)]\tLoss: 0.019332\n",
      "Train Epoch: 69 [10368/14860 (69%)]\tLoss: 0.017946\n",
      "Train Epoch: 69 [10496/14860 (70%)]\tLoss: 0.016202\n",
      "Train Epoch: 69 [10624/14860 (71%)]\tLoss: 0.021334\n",
      "Train Epoch: 69 [10752/14860 (72%)]\tLoss: 0.021655\n",
      "Train Epoch: 69 [10880/14860 (73%)]\tLoss: 0.017757\n",
      "Train Epoch: 69 [11008/14860 (74%)]\tLoss: 0.016817\n",
      "Train Epoch: 69 [11136/14860 (74%)]\tLoss: 0.022848\n",
      "Train Epoch: 69 [11264/14860 (75%)]\tLoss: 0.023875\n",
      "Train Epoch: 69 [11392/14860 (76%)]\tLoss: 0.024135\n",
      "Train Epoch: 69 [11520/14860 (77%)]\tLoss: 0.023348\n",
      "Train Epoch: 69 [11648/14860 (78%)]\tLoss: 0.028203\n",
      "Train Epoch: 69 [11776/14860 (79%)]\tLoss: 0.023167\n",
      "Train Epoch: 69 [11904/14860 (79%)]\tLoss: 0.018071\n",
      "Train Epoch: 69 [12032/14860 (80%)]\tLoss: 0.025871\n",
      "Train Epoch: 69 [12160/14860 (81%)]\tLoss: 0.021785\n",
      "Train Epoch: 69 [12288/14860 (82%)]\tLoss: 0.015711\n",
      "Train Epoch: 69 [12416/14860 (83%)]\tLoss: 0.017452\n",
      "Train Epoch: 69 [12544/14860 (84%)]\tLoss: 0.015701\n",
      "Train Epoch: 69 [12672/14860 (85%)]\tLoss: 0.031720\n",
      "Train Epoch: 69 [12800/14860 (85%)]\tLoss: 0.016181\n",
      "Train Epoch: 69 [12928/14860 (86%)]\tLoss: 0.024968\n",
      "Train Epoch: 69 [13056/14860 (87%)]\tLoss: 0.030113\n",
      "Train Epoch: 69 [13184/14860 (88%)]\tLoss: 0.018709\n",
      "Train Epoch: 69 [13312/14860 (89%)]\tLoss: 0.014413\n",
      "Train Epoch: 69 [13440/14860 (90%)]\tLoss: 0.013241\n",
      "Train Epoch: 69 [13568/14860 (91%)]\tLoss: 0.021547\n",
      "Train Epoch: 69 [13696/14860 (91%)]\tLoss: 0.022630\n",
      "Train Epoch: 69 [13824/14860 (92%)]\tLoss: 0.025414\n",
      "Train Epoch: 69 [13952/14860 (93%)]\tLoss: 0.015987\n",
      "Train Epoch: 69 [14080/14860 (94%)]\tLoss: 0.026845\n",
      "Train Epoch: 69 [14208/14860 (95%)]\tLoss: 0.015930\n",
      "Train Epoch: 69 [14336/14860 (96%)]\tLoss: 0.020955\n",
      "Train Epoch: 69 [14464/14860 (97%)]\tLoss: 0.019404\n",
      "Train Epoch: 69 [14592/14860 (97%)]\tLoss: 0.017205\n",
      "Train Epoch: 69 [14720/14860 (98%)]\tLoss: 0.019290\n",
      "Train Epoch: 69 [1392/14860 (99%)]\tLoss: 0.022058\n",
      "epoch 69 training loss: 0.021862141214884244\n",
      "epoch 69 validation loss: 0.025825867641347373\n",
      "Train Epoch: 70 [0/14860 (0%)]\tLoss: 0.029636\n",
      "Train Epoch: 70 [128/14860 (1%)]\tLoss: 0.020330\n",
      "Train Epoch: 70 [256/14860 (2%)]\tLoss: 0.034184\n",
      "Train Epoch: 70 [384/14860 (3%)]\tLoss: 0.019172\n",
      "Train Epoch: 70 [512/14860 (3%)]\tLoss: 0.034475\n",
      "Train Epoch: 70 [640/14860 (4%)]\tLoss: 0.025484\n",
      "Train Epoch: 70 [768/14860 (5%)]\tLoss: 0.016908\n",
      "Train Epoch: 70 [896/14860 (6%)]\tLoss: 0.028368\n",
      "Train Epoch: 70 [1024/14860 (7%)]\tLoss: 0.020811\n",
      "Train Epoch: 70 [1152/14860 (8%)]\tLoss: 0.018193\n",
      "Train Epoch: 70 [1280/14860 (9%)]\tLoss: 0.033240\n",
      "Train Epoch: 70 [1408/14860 (9%)]\tLoss: 0.029451\n",
      "Train Epoch: 70 [1536/14860 (10%)]\tLoss: 0.026564\n",
      "Train Epoch: 70 [1664/14860 (11%)]\tLoss: 0.015141\n",
      "Train Epoch: 70 [1792/14860 (12%)]\tLoss: 0.029654\n",
      "Train Epoch: 70 [1920/14860 (13%)]\tLoss: 0.015375\n",
      "Train Epoch: 70 [2048/14860 (14%)]\tLoss: 0.014766\n",
      "Train Epoch: 70 [2176/14860 (15%)]\tLoss: 0.015450\n",
      "Train Epoch: 70 [2304/14860 (15%)]\tLoss: 0.022198\n",
      "Train Epoch: 70 [2432/14860 (16%)]\tLoss: 0.016555\n",
      "Train Epoch: 70 [2560/14860 (17%)]\tLoss: 0.015153\n",
      "Train Epoch: 70 [2688/14860 (18%)]\tLoss: 0.016139\n",
      "Train Epoch: 70 [2816/14860 (19%)]\tLoss: 0.024054\n",
      "Train Epoch: 70 [2944/14860 (20%)]\tLoss: 0.017915\n",
      "Train Epoch: 70 [3072/14860 (21%)]\tLoss: 0.020054\n",
      "Train Epoch: 70 [3200/14860 (21%)]\tLoss: 0.020157\n",
      "Train Epoch: 70 [3328/14860 (22%)]\tLoss: 0.033013\n",
      "Train Epoch: 70 [3456/14860 (23%)]\tLoss: 0.032033\n",
      "Train Epoch: 70 [3584/14860 (24%)]\tLoss: 0.021788\n",
      "Train Epoch: 70 [3712/14860 (25%)]\tLoss: 0.017188\n",
      "Train Epoch: 70 [3840/14860 (26%)]\tLoss: 0.026145\n",
      "Train Epoch: 70 [3968/14860 (26%)]\tLoss: 0.020884\n",
      "Train Epoch: 70 [4096/14860 (27%)]\tLoss: 0.028017\n",
      "Train Epoch: 70 [4224/14860 (28%)]\tLoss: 0.018170\n",
      "Train Epoch: 70 [4352/14860 (29%)]\tLoss: 0.020742\n",
      "Train Epoch: 70 [4480/14860 (30%)]\tLoss: 0.023430\n",
      "Train Epoch: 70 [4608/14860 (31%)]\tLoss: 0.013002\n",
      "Train Epoch: 70 [4736/14860 (32%)]\tLoss: 0.017912\n",
      "Train Epoch: 70 [4864/14860 (32%)]\tLoss: 0.013730\n",
      "Train Epoch: 70 [4992/14860 (33%)]\tLoss: 0.027944\n",
      "Train Epoch: 70 [5120/14860 (34%)]\tLoss: 0.018291\n",
      "Train Epoch: 70 [5248/14860 (35%)]\tLoss: 0.029141\n",
      "Train Epoch: 70 [5376/14860 (36%)]\tLoss: 0.027819\n",
      "Train Epoch: 70 [5504/14860 (37%)]\tLoss: 0.027659\n",
      "Train Epoch: 70 [5632/14860 (38%)]\tLoss: 0.025066\n",
      "Train Epoch: 70 [5760/14860 (38%)]\tLoss: 0.017382\n",
      "Train Epoch: 70 [5888/14860 (39%)]\tLoss: 0.015630\n",
      "Train Epoch: 70 [6016/14860 (40%)]\tLoss: 0.027066\n",
      "Train Epoch: 70 [6144/14860 (41%)]\tLoss: 0.018681\n",
      "Train Epoch: 70 [6272/14860 (42%)]\tLoss: 0.017743\n",
      "Train Epoch: 70 [6400/14860 (43%)]\tLoss: 0.013298\n",
      "Train Epoch: 70 [6528/14860 (44%)]\tLoss: 0.022595\n",
      "Train Epoch: 70 [6656/14860 (44%)]\tLoss: 0.022579\n",
      "Train Epoch: 70 [6784/14860 (45%)]\tLoss: 0.022592\n",
      "Train Epoch: 70 [6912/14860 (46%)]\tLoss: 0.019487\n",
      "Train Epoch: 70 [7040/14860 (47%)]\tLoss: 0.023515\n",
      "Train Epoch: 70 [7168/14860 (48%)]\tLoss: 0.023010\n",
      "Train Epoch: 70 [7296/14860 (49%)]\tLoss: 0.020467\n",
      "Train Epoch: 70 [7424/14860 (50%)]\tLoss: 0.020360\n",
      "Train Epoch: 70 [7552/14860 (50%)]\tLoss: 0.018597\n",
      "Train Epoch: 70 [7680/14860 (51%)]\tLoss: 0.015653\n",
      "Train Epoch: 70 [7808/14860 (52%)]\tLoss: 0.021311\n",
      "Train Epoch: 70 [7936/14860 (53%)]\tLoss: 0.019693\n",
      "Train Epoch: 70 [8064/14860 (54%)]\tLoss: 0.017091\n",
      "Train Epoch: 70 [8192/14860 (55%)]\tLoss: 0.022633\n",
      "Train Epoch: 70 [8320/14860 (56%)]\tLoss: 0.018893\n",
      "Train Epoch: 70 [8448/14860 (56%)]\tLoss: 0.018368\n",
      "Train Epoch: 70 [8576/14860 (57%)]\tLoss: 0.016434\n",
      "Train Epoch: 70 [8704/14860 (58%)]\tLoss: 0.017698\n",
      "Train Epoch: 70 [8832/14860 (59%)]\tLoss: 0.023872\n",
      "Train Epoch: 70 [8960/14860 (60%)]\tLoss: 0.019028\n",
      "Train Epoch: 70 [9088/14860 (61%)]\tLoss: 0.015288\n",
      "Train Epoch: 70 [9216/14860 (62%)]\tLoss: 0.023891\n",
      "Train Epoch: 70 [9344/14860 (62%)]\tLoss: 0.019275\n",
      "Train Epoch: 70 [9472/14860 (63%)]\tLoss: 0.019430\n",
      "Train Epoch: 70 [9600/14860 (64%)]\tLoss: 0.017041\n",
      "Train Epoch: 70 [9728/14860 (65%)]\tLoss: 0.022337\n",
      "Train Epoch: 70 [9856/14860 (66%)]\tLoss: 0.020925\n",
      "Train Epoch: 70 [9984/14860 (67%)]\tLoss: 0.019510\n",
      "Train Epoch: 70 [10112/14860 (68%)]\tLoss: 0.027001\n",
      "Train Epoch: 70 [10240/14860 (68%)]\tLoss: 0.016668\n",
      "Train Epoch: 70 [10368/14860 (69%)]\tLoss: 0.022592\n",
      "Train Epoch: 70 [10496/14860 (70%)]\tLoss: 0.025748\n",
      "Train Epoch: 70 [10624/14860 (71%)]\tLoss: 0.029415\n",
      "Train Epoch: 70 [10752/14860 (72%)]\tLoss: 0.021798\n",
      "Train Epoch: 70 [10880/14860 (73%)]\tLoss: 0.020486\n",
      "Train Epoch: 70 [11008/14860 (74%)]\tLoss: 0.020357\n",
      "Train Epoch: 70 [11136/14860 (74%)]\tLoss: 0.022360\n",
      "Train Epoch: 70 [11264/14860 (75%)]\tLoss: 0.018751\n",
      "Train Epoch: 70 [11392/14860 (76%)]\tLoss: 0.028341\n",
      "Train Epoch: 70 [11520/14860 (77%)]\tLoss: 0.017157\n",
      "Train Epoch: 70 [11648/14860 (78%)]\tLoss: 0.023267\n",
      "Train Epoch: 70 [11776/14860 (79%)]\tLoss: 0.015659\n",
      "Train Epoch: 70 [11904/14860 (79%)]\tLoss: 0.014260\n",
      "Train Epoch: 70 [12032/14860 (80%)]\tLoss: 0.014047\n",
      "Train Epoch: 70 [12160/14860 (81%)]\tLoss: 0.019088\n",
      "Train Epoch: 70 [12288/14860 (82%)]\tLoss: 0.021704\n",
      "Train Epoch: 70 [12416/14860 (83%)]\tLoss: 0.013218\n",
      "Train Epoch: 70 [12544/14860 (84%)]\tLoss: 0.024089\n",
      "Train Epoch: 70 [12672/14860 (85%)]\tLoss: 0.014904\n",
      "Train Epoch: 70 [12800/14860 (85%)]\tLoss: 0.030940\n",
      "Train Epoch: 70 [12928/14860 (86%)]\tLoss: 0.014993\n",
      "Train Epoch: 70 [13056/14860 (87%)]\tLoss: 0.020378\n",
      "Train Epoch: 70 [13184/14860 (88%)]\tLoss: 0.029508\n",
      "Train Epoch: 70 [13312/14860 (89%)]\tLoss: 0.019155\n",
      "Train Epoch: 70 [13440/14860 (90%)]\tLoss: 0.019846\n",
      "Train Epoch: 70 [13568/14860 (91%)]\tLoss: 0.024732\n",
      "Train Epoch: 70 [13696/14860 (91%)]\tLoss: 0.020694\n",
      "Train Epoch: 70 [13824/14860 (92%)]\tLoss: 0.019456\n",
      "Train Epoch: 70 [13952/14860 (93%)]\tLoss: 0.017903\n",
      "Train Epoch: 70 [14080/14860 (94%)]\tLoss: 0.023479\n",
      "Train Epoch: 70 [14208/14860 (95%)]\tLoss: 0.027232\n",
      "Train Epoch: 70 [14336/14860 (96%)]\tLoss: 0.014790\n",
      "Train Epoch: 70 [14464/14860 (97%)]\tLoss: 0.037658\n",
      "Train Epoch: 70 [14592/14860 (97%)]\tLoss: 0.016001\n",
      "Train Epoch: 70 [14720/14860 (98%)]\tLoss: 0.033467\n",
      "Train Epoch: 70 [1392/14860 (99%)]\tLoss: 0.007697\n",
      "epoch 70 training loss: 0.021381271322472736\n",
      "epoch 70 validation loss: 0.022122191459156986\n",
      "Train Epoch: 71 [0/14860 (0%)]\tLoss: 0.011214\n",
      "Train Epoch: 71 [128/14860 (1%)]\tLoss: 0.021752\n",
      "Train Epoch: 71 [256/14860 (2%)]\tLoss: 0.028154\n",
      "Train Epoch: 71 [384/14860 (3%)]\tLoss: 0.022404\n",
      "Train Epoch: 71 [512/14860 (3%)]\tLoss: 0.038579\n",
      "Train Epoch: 71 [640/14860 (4%)]\tLoss: 0.015201\n",
      "Train Epoch: 71 [768/14860 (5%)]\tLoss: 0.030324\n",
      "Train Epoch: 71 [896/14860 (6%)]\tLoss: 0.029492\n",
      "Train Epoch: 71 [1024/14860 (7%)]\tLoss: 0.025956\n",
      "Train Epoch: 71 [1152/14860 (8%)]\tLoss: 0.039893\n",
      "Train Epoch: 71 [1280/14860 (9%)]\tLoss: 0.021235\n",
      "Train Epoch: 71 [1408/14860 (9%)]\tLoss: 0.034513\n",
      "Train Epoch: 71 [1536/14860 (10%)]\tLoss: 0.028221\n",
      "Train Epoch: 71 [1664/14860 (11%)]\tLoss: 0.011937\n",
      "Train Epoch: 71 [1792/14860 (12%)]\tLoss: 0.022505\n",
      "Train Epoch: 71 [1920/14860 (13%)]\tLoss: 0.020357\n",
      "Train Epoch: 71 [2048/14860 (14%)]\tLoss: 0.019801\n",
      "Train Epoch: 71 [2176/14860 (15%)]\tLoss: 0.015425\n",
      "Train Epoch: 71 [2304/14860 (15%)]\tLoss: 0.021591\n",
      "Train Epoch: 71 [2432/14860 (16%)]\tLoss: 0.031941\n",
      "Train Epoch: 71 [2560/14860 (17%)]\tLoss: 0.019732\n",
      "Train Epoch: 71 [2688/14860 (18%)]\tLoss: 0.014683\n",
      "Train Epoch: 71 [2816/14860 (19%)]\tLoss: 0.029188\n",
      "Train Epoch: 71 [2944/14860 (20%)]\tLoss: 0.015756\n",
      "Train Epoch: 71 [3072/14860 (21%)]\tLoss: 0.018440\n",
      "Train Epoch: 71 [3200/14860 (21%)]\tLoss: 0.027160\n",
      "Train Epoch: 71 [3328/14860 (22%)]\tLoss: 0.020576\n",
      "Train Epoch: 71 [3456/14860 (23%)]\tLoss: 0.017374\n",
      "Train Epoch: 71 [3584/14860 (24%)]\tLoss: 0.022163\n",
      "Train Epoch: 71 [3712/14860 (25%)]\tLoss: 0.021253\n",
      "Train Epoch: 71 [3840/14860 (26%)]\tLoss: 0.017785\n",
      "Train Epoch: 71 [3968/14860 (26%)]\tLoss: 0.021497\n",
      "Train Epoch: 71 [4096/14860 (27%)]\tLoss: 0.021160\n",
      "Train Epoch: 71 [4224/14860 (28%)]\tLoss: 0.016357\n",
      "Train Epoch: 71 [4352/14860 (29%)]\tLoss: 0.018759\n",
      "Train Epoch: 71 [4480/14860 (30%)]\tLoss: 0.022557\n",
      "Train Epoch: 71 [4608/14860 (31%)]\tLoss: 0.016534\n",
      "Train Epoch: 71 [4736/14860 (32%)]\tLoss: 0.020288\n",
      "Train Epoch: 71 [4864/14860 (32%)]\tLoss: 0.020178\n",
      "Train Epoch: 71 [4992/14860 (33%)]\tLoss: 0.018328\n",
      "Train Epoch: 71 [5120/14860 (34%)]\tLoss: 0.024923\n",
      "Train Epoch: 71 [5248/14860 (35%)]\tLoss: 0.017397\n",
      "Train Epoch: 71 [5376/14860 (36%)]\tLoss: 0.022907\n",
      "Train Epoch: 71 [5504/14860 (37%)]\tLoss: 0.023859\n",
      "Train Epoch: 71 [5632/14860 (38%)]\tLoss: 0.024025\n",
      "Train Epoch: 71 [5760/14860 (38%)]\tLoss: 0.034347\n",
      "Train Epoch: 71 [5888/14860 (39%)]\tLoss: 0.020067\n",
      "Train Epoch: 71 [6016/14860 (40%)]\tLoss: 0.016465\n",
      "Train Epoch: 71 [6144/14860 (41%)]\tLoss: 0.024975\n",
      "Train Epoch: 71 [6272/14860 (42%)]\tLoss: 0.015537\n",
      "Train Epoch: 71 [6400/14860 (43%)]\tLoss: 0.017240\n",
      "Train Epoch: 71 [6528/14860 (44%)]\tLoss: 0.026910\n",
      "Train Epoch: 71 [6656/14860 (44%)]\tLoss: 0.015300\n",
      "Train Epoch: 71 [6784/14860 (45%)]\tLoss: 0.019338\n",
      "Train Epoch: 71 [6912/14860 (46%)]\tLoss: 0.021368\n",
      "Train Epoch: 71 [7040/14860 (47%)]\tLoss: 0.021823\n",
      "Train Epoch: 71 [7168/14860 (48%)]\tLoss: 0.024336\n",
      "Train Epoch: 71 [7296/14860 (49%)]\tLoss: 0.023955\n",
      "Train Epoch: 71 [7424/14860 (50%)]\tLoss: 0.023581\n",
      "Train Epoch: 71 [7552/14860 (50%)]\tLoss: 0.028436\n",
      "Train Epoch: 71 [7680/14860 (51%)]\tLoss: 0.024400\n",
      "Train Epoch: 71 [7808/14860 (52%)]\tLoss: 0.018854\n",
      "Train Epoch: 71 [7936/14860 (53%)]\tLoss: 0.012519\n",
      "Train Epoch: 71 [8064/14860 (54%)]\tLoss: 0.021578\n",
      "Train Epoch: 71 [8192/14860 (55%)]\tLoss: 0.023231\n",
      "Train Epoch: 71 [8320/14860 (56%)]\tLoss: 0.027710\n",
      "Train Epoch: 71 [8448/14860 (56%)]\tLoss: 0.014386\n",
      "Train Epoch: 71 [8576/14860 (57%)]\tLoss: 0.015490\n",
      "Train Epoch: 71 [8704/14860 (58%)]\tLoss: 0.014384\n",
      "Train Epoch: 71 [8832/14860 (59%)]\tLoss: 0.021501\n",
      "Train Epoch: 71 [8960/14860 (60%)]\tLoss: 0.017736\n",
      "Train Epoch: 71 [9088/14860 (61%)]\tLoss: 0.018708\n",
      "Train Epoch: 71 [9216/14860 (62%)]\tLoss: 0.019485\n",
      "Train Epoch: 71 [9344/14860 (62%)]\tLoss: 0.018679\n",
      "Train Epoch: 71 [9472/14860 (63%)]\tLoss: 0.014017\n",
      "Train Epoch: 71 [9600/14860 (64%)]\tLoss: 0.021355\n",
      "Train Epoch: 71 [9728/14860 (65%)]\tLoss: 0.020980\n",
      "Train Epoch: 71 [9856/14860 (66%)]\tLoss: 0.018276\n",
      "Train Epoch: 71 [9984/14860 (67%)]\tLoss: 0.015388\n",
      "Train Epoch: 71 [10112/14860 (68%)]\tLoss: 0.025353\n",
      "Train Epoch: 71 [10240/14860 (68%)]\tLoss: 0.031202\n",
      "Train Epoch: 71 [10368/14860 (69%)]\tLoss: 0.025583\n",
      "Train Epoch: 71 [10496/14860 (70%)]\tLoss: 0.019309\n",
      "Train Epoch: 71 [10624/14860 (71%)]\tLoss: 0.020638\n",
      "Train Epoch: 71 [10752/14860 (72%)]\tLoss: 0.018583\n",
      "Train Epoch: 71 [10880/14860 (73%)]\tLoss: 0.027231\n",
      "Train Epoch: 71 [11008/14860 (74%)]\tLoss: 0.016610\n",
      "Train Epoch: 71 [11136/14860 (74%)]\tLoss: 0.019883\n",
      "Train Epoch: 71 [11264/14860 (75%)]\tLoss: 0.015809\n",
      "Train Epoch: 71 [11392/14860 (76%)]\tLoss: 0.024609\n",
      "Train Epoch: 71 [11520/14860 (77%)]\tLoss: 0.022611\n",
      "Train Epoch: 71 [11648/14860 (78%)]\tLoss: 0.029719\n",
      "Train Epoch: 71 [11776/14860 (79%)]\tLoss: 0.019644\n",
      "Train Epoch: 71 [11904/14860 (79%)]\tLoss: 0.016117\n",
      "Train Epoch: 71 [12032/14860 (80%)]\tLoss: 0.019574\n",
      "Train Epoch: 71 [12160/14860 (81%)]\tLoss: 0.019615\n",
      "Train Epoch: 71 [12288/14860 (82%)]\tLoss: 0.019731\n",
      "Train Epoch: 71 [12416/14860 (83%)]\tLoss: 0.022373\n",
      "Train Epoch: 71 [12544/14860 (84%)]\tLoss: 0.015809\n",
      "Train Epoch: 71 [12672/14860 (85%)]\tLoss: 0.026949\n",
      "Train Epoch: 71 [12800/14860 (85%)]\tLoss: 0.017051\n",
      "Train Epoch: 71 [12928/14860 (86%)]\tLoss: 0.023324\n",
      "Train Epoch: 71 [13056/14860 (87%)]\tLoss: 0.019407\n",
      "Train Epoch: 71 [13184/14860 (88%)]\tLoss: 0.025558\n",
      "Train Epoch: 71 [13312/14860 (89%)]\tLoss: 0.020223\n",
      "Train Epoch: 71 [13440/14860 (90%)]\tLoss: 0.020484\n",
      "Train Epoch: 71 [13568/14860 (91%)]\tLoss: 0.027298\n",
      "Train Epoch: 71 [13696/14860 (91%)]\tLoss: 0.028708\n",
      "Train Epoch: 71 [13824/14860 (92%)]\tLoss: 0.014321\n",
      "Train Epoch: 71 [13952/14860 (93%)]\tLoss: 0.018784\n",
      "Train Epoch: 71 [14080/14860 (94%)]\tLoss: 0.016509\n",
      "Train Epoch: 71 [14208/14860 (95%)]\tLoss: 0.015784\n",
      "Train Epoch: 71 [14336/14860 (96%)]\tLoss: 0.015886\n",
      "Train Epoch: 71 [14464/14860 (97%)]\tLoss: 0.022957\n",
      "Train Epoch: 71 [14592/14860 (97%)]\tLoss: 0.025935\n",
      "Train Epoch: 71 [14720/14860 (98%)]\tLoss: 0.024083\n",
      "Train Epoch: 71 [1392/14860 (99%)]\tLoss: 0.017255\n",
      "epoch 71 training loss: 0.02142089755775837\n",
      "epoch 71 validation loss: 0.02173215006511956\n",
      "Train Epoch: 72 [0/14860 (0%)]\tLoss: 0.020523\n",
      "Train Epoch: 72 [128/14860 (1%)]\tLoss: 0.027800\n",
      "Train Epoch: 72 [256/14860 (2%)]\tLoss: 0.013127\n",
      "Train Epoch: 72 [384/14860 (3%)]\tLoss: 0.029855\n",
      "Train Epoch: 72 [512/14860 (3%)]\tLoss: 0.018598\n",
      "Train Epoch: 72 [640/14860 (4%)]\tLoss: 0.019109\n",
      "Train Epoch: 72 [768/14860 (5%)]\tLoss: 0.024559\n",
      "Train Epoch: 72 [896/14860 (6%)]\tLoss: 0.023591\n",
      "Train Epoch: 72 [1024/14860 (7%)]\tLoss: 0.024547\n",
      "Train Epoch: 72 [1152/14860 (8%)]\tLoss: 0.026068\n",
      "Train Epoch: 72 [1280/14860 (9%)]\tLoss: 0.015551\n",
      "Train Epoch: 72 [1408/14860 (9%)]\tLoss: 0.016944\n",
      "Train Epoch: 72 [1536/14860 (10%)]\tLoss: 0.019045\n",
      "Train Epoch: 72 [1664/14860 (11%)]\tLoss: 0.027597\n",
      "Train Epoch: 72 [1792/14860 (12%)]\tLoss: 0.017497\n",
      "Train Epoch: 72 [1920/14860 (13%)]\tLoss: 0.017591\n",
      "Train Epoch: 72 [2048/14860 (14%)]\tLoss: 0.019244\n",
      "Train Epoch: 72 [2176/14860 (15%)]\tLoss: 0.016972\n",
      "Train Epoch: 72 [2304/14860 (15%)]\tLoss: 0.019413\n",
      "Train Epoch: 72 [2432/14860 (16%)]\tLoss: 0.016862\n",
      "Train Epoch: 72 [2560/14860 (17%)]\tLoss: 0.018025\n",
      "Train Epoch: 72 [2688/14860 (18%)]\tLoss: 0.024107\n",
      "Train Epoch: 72 [2816/14860 (19%)]\tLoss: 0.015190\n",
      "Train Epoch: 72 [2944/14860 (20%)]\tLoss: 0.019849\n",
      "Train Epoch: 72 [3072/14860 (21%)]\tLoss: 0.015609\n",
      "Train Epoch: 72 [3200/14860 (21%)]\tLoss: 0.022317\n",
      "Train Epoch: 72 [3328/14860 (22%)]\tLoss: 0.017624\n",
      "Train Epoch: 72 [3456/14860 (23%)]\tLoss: 0.021345\n",
      "Train Epoch: 72 [3584/14860 (24%)]\tLoss: 0.030572\n",
      "Train Epoch: 72 [3712/14860 (25%)]\tLoss: 0.023814\n",
      "Train Epoch: 72 [3840/14860 (26%)]\tLoss: 0.027241\n",
      "Train Epoch: 72 [3968/14860 (26%)]\tLoss: 0.019685\n",
      "Train Epoch: 72 [4096/14860 (27%)]\tLoss: 0.025731\n",
      "Train Epoch: 72 [4224/14860 (28%)]\tLoss: 0.016942\n",
      "Train Epoch: 72 [4352/14860 (29%)]\tLoss: 0.021054\n",
      "Train Epoch: 72 [4480/14860 (30%)]\tLoss: 0.016117\n",
      "Train Epoch: 72 [4608/14860 (31%)]\tLoss: 0.015849\n",
      "Train Epoch: 72 [4736/14860 (32%)]\tLoss: 0.024380\n",
      "Train Epoch: 72 [4864/14860 (32%)]\tLoss: 0.017689\n",
      "Train Epoch: 72 [4992/14860 (33%)]\tLoss: 0.016531\n",
      "Train Epoch: 72 [5120/14860 (34%)]\tLoss: 0.011659\n",
      "Train Epoch: 72 [5248/14860 (35%)]\tLoss: 0.020941\n",
      "Train Epoch: 72 [5376/14860 (36%)]\tLoss: 0.021595\n",
      "Train Epoch: 72 [5504/14860 (37%)]\tLoss: 0.029266\n",
      "Train Epoch: 72 [5632/14860 (38%)]\tLoss: 0.024960\n",
      "Train Epoch: 72 [5760/14860 (38%)]\tLoss: 0.020482\n",
      "Train Epoch: 72 [5888/14860 (39%)]\tLoss: 0.023798\n",
      "Train Epoch: 72 [6016/14860 (40%)]\tLoss: 0.019592\n",
      "Train Epoch: 72 [6144/14860 (41%)]\tLoss: 0.024166\n",
      "Train Epoch: 72 [6272/14860 (42%)]\tLoss: 0.018789\n",
      "Train Epoch: 72 [6400/14860 (43%)]\tLoss: 0.021440\n",
      "Train Epoch: 72 [6528/14860 (44%)]\tLoss: 0.020676\n",
      "Train Epoch: 72 [6656/14860 (44%)]\tLoss: 0.019063\n",
      "Train Epoch: 72 [6784/14860 (45%)]\tLoss: 0.023979\n",
      "Train Epoch: 72 [6912/14860 (46%)]\tLoss: 0.015624\n",
      "Train Epoch: 72 [7040/14860 (47%)]\tLoss: 0.022581\n",
      "Train Epoch: 72 [7168/14860 (48%)]\tLoss: 0.017587\n",
      "Train Epoch: 72 [7296/14860 (49%)]\tLoss: 0.023397\n",
      "Train Epoch: 72 [7424/14860 (50%)]\tLoss: 0.020293\n",
      "Train Epoch: 72 [7552/14860 (50%)]\tLoss: 0.017502\n",
      "Train Epoch: 72 [7680/14860 (51%)]\tLoss: 0.017417\n",
      "Train Epoch: 72 [7808/14860 (52%)]\tLoss: 0.012773\n",
      "Train Epoch: 72 [7936/14860 (53%)]\tLoss: 0.019825\n",
      "Train Epoch: 72 [8064/14860 (54%)]\tLoss: 0.026058\n",
      "Train Epoch: 72 [8192/14860 (55%)]\tLoss: 0.024814\n",
      "Train Epoch: 72 [8320/14860 (56%)]\tLoss: 0.014383\n",
      "Train Epoch: 72 [8448/14860 (56%)]\tLoss: 0.021033\n",
      "Train Epoch: 72 [8576/14860 (57%)]\tLoss: 0.019575\n",
      "Train Epoch: 72 [8704/14860 (58%)]\tLoss: 0.017845\n",
      "Train Epoch: 72 [8832/14860 (59%)]\tLoss: 0.014480\n",
      "Train Epoch: 72 [8960/14860 (60%)]\tLoss: 0.016073\n",
      "Train Epoch: 72 [9088/14860 (61%)]\tLoss: 0.015537\n",
      "Train Epoch: 72 [9216/14860 (62%)]\tLoss: 0.019236\n",
      "Train Epoch: 72 [9344/14860 (62%)]\tLoss: 0.017491\n",
      "Train Epoch: 72 [9472/14860 (63%)]\tLoss: 0.018504\n",
      "Train Epoch: 72 [9600/14860 (64%)]\tLoss: 0.024342\n",
      "Train Epoch: 72 [9728/14860 (65%)]\tLoss: 0.020015\n",
      "Train Epoch: 72 [9856/14860 (66%)]\tLoss: 0.022947\n",
      "Train Epoch: 72 [9984/14860 (67%)]\tLoss: 0.017602\n",
      "Train Epoch: 72 [10112/14860 (68%)]\tLoss: 0.019712\n",
      "Train Epoch: 72 [10240/14860 (68%)]\tLoss: 0.019410\n",
      "Train Epoch: 72 [10368/14860 (69%)]\tLoss: 0.023555\n",
      "Train Epoch: 72 [10496/14860 (70%)]\tLoss: 0.017629\n",
      "Train Epoch: 72 [10624/14860 (71%)]\tLoss: 0.016197\n",
      "Train Epoch: 72 [10752/14860 (72%)]\tLoss: 0.018971\n",
      "Train Epoch: 72 [10880/14860 (73%)]\tLoss: 0.015155\n",
      "Train Epoch: 72 [11008/14860 (74%)]\tLoss: 0.026221\n",
      "Train Epoch: 72 [11136/14860 (74%)]\tLoss: 0.025537\n",
      "Train Epoch: 72 [11264/14860 (75%)]\tLoss: 0.020049\n",
      "Train Epoch: 72 [11392/14860 (76%)]\tLoss: 0.023098\n",
      "Train Epoch: 72 [11520/14860 (77%)]\tLoss: 0.019937\n",
      "Train Epoch: 72 [11648/14860 (78%)]\tLoss: 0.022097\n",
      "Train Epoch: 72 [11776/14860 (79%)]\tLoss: 0.020311\n",
      "Train Epoch: 72 [11904/14860 (79%)]\tLoss: 0.014094\n",
      "Train Epoch: 72 [12032/14860 (80%)]\tLoss: 0.022500\n",
      "Train Epoch: 72 [12160/14860 (81%)]\tLoss: 0.020976\n",
      "Train Epoch: 72 [12288/14860 (82%)]\tLoss: 0.017998\n",
      "Train Epoch: 72 [12416/14860 (83%)]\tLoss: 0.025846\n",
      "Train Epoch: 72 [12544/14860 (84%)]\tLoss: 0.031987\n",
      "Train Epoch: 72 [12672/14860 (85%)]\tLoss: 0.022168\n",
      "Train Epoch: 72 [12800/14860 (85%)]\tLoss: 0.025400\n",
      "Train Epoch: 72 [12928/14860 (86%)]\tLoss: 0.020451\n",
      "Train Epoch: 72 [13056/14860 (87%)]\tLoss: 0.028121\n",
      "Train Epoch: 72 [13184/14860 (88%)]\tLoss: 0.021250\n",
      "Train Epoch: 72 [13312/14860 (89%)]\tLoss: 0.018389\n",
      "Train Epoch: 72 [13440/14860 (90%)]\tLoss: 0.024744\n",
      "Train Epoch: 72 [13568/14860 (91%)]\tLoss: 0.023011\n",
      "Train Epoch: 72 [13696/14860 (91%)]\tLoss: 0.027435\n",
      "Train Epoch: 72 [13824/14860 (92%)]\tLoss: 0.023599\n",
      "Train Epoch: 72 [13952/14860 (93%)]\tLoss: 0.020144\n",
      "Train Epoch: 72 [14080/14860 (94%)]\tLoss: 0.030091\n",
      "Train Epoch: 72 [14208/14860 (95%)]\tLoss: 0.026781\n",
      "Train Epoch: 72 [14336/14860 (96%)]\tLoss: 0.022741\n",
      "Train Epoch: 72 [14464/14860 (97%)]\tLoss: 0.024995\n",
      "Train Epoch: 72 [14592/14860 (97%)]\tLoss: 0.016612\n",
      "Train Epoch: 72 [14720/14860 (98%)]\tLoss: 0.026086\n",
      "Train Epoch: 72 [1392/14860 (99%)]\tLoss: 0.008568\n",
      "epoch 72 training loss: 0.02079805387900426\n",
      "epoch 72 validation loss: 0.031346350114512964\n",
      "Train Epoch: 73 [0/14860 (0%)]\tLoss: 0.032984\n",
      "Train Epoch: 73 [128/14860 (1%)]\tLoss: 0.014791\n",
      "Train Epoch: 73 [256/14860 (2%)]\tLoss: 0.017427\n",
      "Train Epoch: 73 [384/14860 (3%)]\tLoss: 0.029682\n",
      "Train Epoch: 73 [512/14860 (3%)]\tLoss: 0.019660\n",
      "Train Epoch: 73 [640/14860 (4%)]\tLoss: 0.022333\n",
      "Train Epoch: 73 [768/14860 (5%)]\tLoss: 0.018045\n",
      "Train Epoch: 73 [896/14860 (6%)]\tLoss: 0.012510\n",
      "Train Epoch: 73 [1024/14860 (7%)]\tLoss: 0.017576\n",
      "Train Epoch: 73 [1152/14860 (8%)]\tLoss: 0.022078\n",
      "Train Epoch: 73 [1280/14860 (9%)]\tLoss: 0.022455\n",
      "Train Epoch: 73 [1408/14860 (9%)]\tLoss: 0.023283\n",
      "Train Epoch: 73 [1536/14860 (10%)]\tLoss: 0.016736\n",
      "Train Epoch: 73 [1664/14860 (11%)]\tLoss: 0.018623\n",
      "Train Epoch: 73 [1792/14860 (12%)]\tLoss: 0.018984\n",
      "Train Epoch: 73 [1920/14860 (13%)]\tLoss: 0.015479\n",
      "Train Epoch: 73 [2048/14860 (14%)]\tLoss: 0.017858\n",
      "Train Epoch: 73 [2176/14860 (15%)]\tLoss: 0.016586\n",
      "Train Epoch: 73 [2304/14860 (15%)]\tLoss: 0.018378\n",
      "Train Epoch: 73 [2432/14860 (16%)]\tLoss: 0.019390\n",
      "Train Epoch: 73 [2560/14860 (17%)]\tLoss: 0.021075\n",
      "Train Epoch: 73 [2688/14860 (18%)]\tLoss: 0.020242\n",
      "Train Epoch: 73 [2816/14860 (19%)]\tLoss: 0.023522\n",
      "Train Epoch: 73 [2944/14860 (20%)]\tLoss: 0.016780\n",
      "Train Epoch: 73 [3072/14860 (21%)]\tLoss: 0.021443\n",
      "Train Epoch: 73 [3200/14860 (21%)]\tLoss: 0.018472\n",
      "Train Epoch: 73 [3328/14860 (22%)]\tLoss: 0.026075\n",
      "Train Epoch: 73 [3456/14860 (23%)]\tLoss: 0.018143\n",
      "Train Epoch: 73 [3584/14860 (24%)]\tLoss: 0.021159\n",
      "Train Epoch: 73 [3712/14860 (25%)]\tLoss: 0.019302\n",
      "Train Epoch: 73 [3840/14860 (26%)]\tLoss: 0.020590\n",
      "Train Epoch: 73 [3968/14860 (26%)]\tLoss: 0.022257\n",
      "Train Epoch: 73 [4096/14860 (27%)]\tLoss: 0.012782\n",
      "Train Epoch: 73 [4224/14860 (28%)]\tLoss: 0.016357\n",
      "Train Epoch: 73 [4352/14860 (29%)]\tLoss: 0.016405\n",
      "Train Epoch: 73 [4480/14860 (30%)]\tLoss: 0.020718\n",
      "Train Epoch: 73 [4608/14860 (31%)]\tLoss: 0.013504\n",
      "Train Epoch: 73 [4736/14860 (32%)]\tLoss: 0.028315\n",
      "Train Epoch: 73 [4864/14860 (32%)]\tLoss: 0.025052\n",
      "Train Epoch: 73 [4992/14860 (33%)]\tLoss: 0.017051\n",
      "Train Epoch: 73 [5120/14860 (34%)]\tLoss: 0.011299\n",
      "Train Epoch: 73 [5248/14860 (35%)]\tLoss: 0.026310\n",
      "Train Epoch: 73 [5376/14860 (36%)]\tLoss: 0.022228\n",
      "Train Epoch: 73 [5504/14860 (37%)]\tLoss: 0.024152\n",
      "Train Epoch: 73 [5632/14860 (38%)]\tLoss: 0.013007\n",
      "Train Epoch: 73 [5760/14860 (38%)]\tLoss: 0.031692\n",
      "Train Epoch: 73 [5888/14860 (39%)]\tLoss: 0.019334\n",
      "Train Epoch: 73 [6016/14860 (40%)]\tLoss: 0.026881\n",
      "Train Epoch: 73 [6144/14860 (41%)]\tLoss: 0.020691\n",
      "Train Epoch: 73 [6272/14860 (42%)]\tLoss: 0.022774\n",
      "Train Epoch: 73 [6400/14860 (43%)]\tLoss: 0.029067\n",
      "Train Epoch: 73 [6528/14860 (44%)]\tLoss: 0.022544\n",
      "Train Epoch: 73 [6656/14860 (44%)]\tLoss: 0.027995\n",
      "Train Epoch: 73 [6784/14860 (45%)]\tLoss: 0.024225\n",
      "Train Epoch: 73 [6912/14860 (46%)]\tLoss: 0.023882\n",
      "Train Epoch: 73 [7040/14860 (47%)]\tLoss: 0.016326\n",
      "Train Epoch: 73 [7168/14860 (48%)]\tLoss: 0.025190\n",
      "Train Epoch: 73 [7296/14860 (49%)]\tLoss: 0.026924\n",
      "Train Epoch: 73 [7424/14860 (50%)]\tLoss: 0.024928\n",
      "Train Epoch: 73 [7552/14860 (50%)]\tLoss: 0.021615\n",
      "Train Epoch: 73 [7680/14860 (51%)]\tLoss: 0.023178\n",
      "Train Epoch: 73 [7808/14860 (52%)]\tLoss: 0.027053\n",
      "Train Epoch: 73 [7936/14860 (53%)]\tLoss: 0.018102\n",
      "Train Epoch: 73 [8064/14860 (54%)]\tLoss: 0.022544\n",
      "Train Epoch: 73 [8192/14860 (55%)]\tLoss: 0.017054\n",
      "Train Epoch: 73 [8320/14860 (56%)]\tLoss: 0.015364\n",
      "Train Epoch: 73 [8448/14860 (56%)]\tLoss: 0.023481\n",
      "Train Epoch: 73 [8576/14860 (57%)]\tLoss: 0.020309\n",
      "Train Epoch: 73 [8704/14860 (58%)]\tLoss: 0.022857\n",
      "Train Epoch: 73 [8832/14860 (59%)]\tLoss: 0.026185\n",
      "Train Epoch: 73 [8960/14860 (60%)]\tLoss: 0.027637\n",
      "Train Epoch: 73 [9088/14860 (61%)]\tLoss: 0.020282\n",
      "Train Epoch: 73 [9216/14860 (62%)]\tLoss: 0.028068\n",
      "Train Epoch: 73 [9344/14860 (62%)]\tLoss: 0.018100\n",
      "Train Epoch: 73 [9472/14860 (63%)]\tLoss: 0.020569\n",
      "Train Epoch: 73 [9600/14860 (64%)]\tLoss: 0.023553\n",
      "Train Epoch: 73 [9728/14860 (65%)]\tLoss: 0.020523\n",
      "Train Epoch: 73 [9856/14860 (66%)]\tLoss: 0.019734\n",
      "Train Epoch: 73 [9984/14860 (67%)]\tLoss: 0.017425\n",
      "Train Epoch: 73 [10112/14860 (68%)]\tLoss: 0.019026\n",
      "Train Epoch: 73 [10240/14860 (68%)]\tLoss: 0.018018\n",
      "Train Epoch: 73 [10368/14860 (69%)]\tLoss: 0.023281\n",
      "Train Epoch: 73 [10496/14860 (70%)]\tLoss: 0.017050\n",
      "Train Epoch: 73 [10624/14860 (71%)]\tLoss: 0.023136\n",
      "Train Epoch: 73 [10752/14860 (72%)]\tLoss: 0.021570\n",
      "Train Epoch: 73 [10880/14860 (73%)]\tLoss: 0.031150\n",
      "Train Epoch: 73 [11008/14860 (74%)]\tLoss: 0.024515\n",
      "Train Epoch: 73 [11136/14860 (74%)]\tLoss: 0.030850\n",
      "Train Epoch: 73 [11264/14860 (75%)]\tLoss: 0.017763\n",
      "Train Epoch: 73 [11392/14860 (76%)]\tLoss: 0.018287\n",
      "Train Epoch: 73 [11520/14860 (77%)]\tLoss: 0.019172\n",
      "Train Epoch: 73 [11648/14860 (78%)]\tLoss: 0.026174\n",
      "Train Epoch: 73 [11776/14860 (79%)]\tLoss: 0.016379\n",
      "Train Epoch: 73 [11904/14860 (79%)]\tLoss: 0.015694\n",
      "Train Epoch: 73 [12032/14860 (80%)]\tLoss: 0.022154\n",
      "Train Epoch: 73 [12160/14860 (81%)]\tLoss: 0.015082\n",
      "Train Epoch: 73 [12288/14860 (82%)]\tLoss: 0.021980\n",
      "Train Epoch: 73 [12416/14860 (83%)]\tLoss: 0.020300\n",
      "Train Epoch: 73 [12544/14860 (84%)]\tLoss: 0.026920\n",
      "Train Epoch: 73 [12672/14860 (85%)]\tLoss: 0.020743\n",
      "Train Epoch: 73 [12800/14860 (85%)]\tLoss: 0.016757\n",
      "Train Epoch: 73 [12928/14860 (86%)]\tLoss: 0.022594\n",
      "Train Epoch: 73 [13056/14860 (87%)]\tLoss: 0.016836\n",
      "Train Epoch: 73 [13184/14860 (88%)]\tLoss: 0.025801\n",
      "Train Epoch: 73 [13312/14860 (89%)]\tLoss: 0.014947\n",
      "Train Epoch: 73 [13440/14860 (90%)]\tLoss: 0.023852\n",
      "Train Epoch: 73 [13568/14860 (91%)]\tLoss: 0.020650\n",
      "Train Epoch: 73 [13696/14860 (91%)]\tLoss: 0.021335\n",
      "Train Epoch: 73 [13824/14860 (92%)]\tLoss: 0.022057\n",
      "Train Epoch: 73 [13952/14860 (93%)]\tLoss: 0.019393\n",
      "Train Epoch: 73 [14080/14860 (94%)]\tLoss: 0.011900\n",
      "Train Epoch: 73 [14208/14860 (95%)]\tLoss: 0.030172\n",
      "Train Epoch: 73 [14336/14860 (96%)]\tLoss: 0.020480\n",
      "Train Epoch: 73 [14464/14860 (97%)]\tLoss: 0.023431\n",
      "Train Epoch: 73 [14592/14860 (97%)]\tLoss: 0.022124\n",
      "Train Epoch: 73 [14720/14860 (98%)]\tLoss: 0.020918\n",
      "Train Epoch: 73 [1392/14860 (99%)]\tLoss: 0.041112\n",
      "epoch 73 training loss: 0.02128876783908942\n",
      "epoch 73 validation loss: 0.02611371578950859\n",
      "Train Epoch: 74 [0/14860 (0%)]\tLoss: 0.027472\n",
      "Train Epoch: 74 [128/14860 (1%)]\tLoss: 0.023922\n",
      "Train Epoch: 74 [256/14860 (2%)]\tLoss: 0.019500\n",
      "Train Epoch: 74 [384/14860 (3%)]\tLoss: 0.017535\n",
      "Train Epoch: 74 [512/14860 (3%)]\tLoss: 0.021325\n",
      "Train Epoch: 74 [640/14860 (4%)]\tLoss: 0.022222\n",
      "Train Epoch: 74 [768/14860 (5%)]\tLoss: 0.029045\n",
      "Train Epoch: 74 [896/14860 (6%)]\tLoss: 0.019004\n",
      "Train Epoch: 74 [1024/14860 (7%)]\tLoss: 0.026197\n",
      "Train Epoch: 74 [1152/14860 (8%)]\tLoss: 0.025008\n",
      "Train Epoch: 74 [1280/14860 (9%)]\tLoss: 0.014957\n",
      "Train Epoch: 74 [1408/14860 (9%)]\tLoss: 0.014548\n",
      "Train Epoch: 74 [1536/14860 (10%)]\tLoss: 0.025436\n",
      "Train Epoch: 74 [1664/14860 (11%)]\tLoss: 0.016466\n",
      "Train Epoch: 74 [1792/14860 (12%)]\tLoss: 0.024347\n",
      "Train Epoch: 74 [1920/14860 (13%)]\tLoss: 0.022109\n",
      "Train Epoch: 74 [2048/14860 (14%)]\tLoss: 0.016481\n",
      "Train Epoch: 74 [2176/14860 (15%)]\tLoss: 0.021976\n",
      "Train Epoch: 74 [2304/14860 (15%)]\tLoss: 0.023015\n",
      "Train Epoch: 74 [2432/14860 (16%)]\tLoss: 0.024683\n",
      "Train Epoch: 74 [2560/14860 (17%)]\tLoss: 0.015655\n",
      "Train Epoch: 74 [2688/14860 (18%)]\tLoss: 0.027748\n",
      "Train Epoch: 74 [2816/14860 (19%)]\tLoss: 0.021702\n",
      "Train Epoch: 74 [2944/14860 (20%)]\tLoss: 0.019894\n",
      "Train Epoch: 74 [3072/14860 (21%)]\tLoss: 0.017142\n",
      "Train Epoch: 74 [3200/14860 (21%)]\tLoss: 0.031690\n",
      "Train Epoch: 74 [3328/14860 (22%)]\tLoss: 0.016689\n",
      "Train Epoch: 74 [3456/14860 (23%)]\tLoss: 0.024091\n",
      "Train Epoch: 74 [3584/14860 (24%)]\tLoss: 0.019589\n",
      "Train Epoch: 74 [3712/14860 (25%)]\tLoss: 0.020566\n",
      "Train Epoch: 74 [3840/14860 (26%)]\tLoss: 0.023826\n",
      "Train Epoch: 74 [3968/14860 (26%)]\tLoss: 0.030488\n",
      "Train Epoch: 74 [4096/14860 (27%)]\tLoss: 0.026969\n",
      "Train Epoch: 74 [4224/14860 (28%)]\tLoss: 0.010868\n",
      "Train Epoch: 74 [4352/14860 (29%)]\tLoss: 0.025831\n",
      "Train Epoch: 74 [4480/14860 (30%)]\tLoss: 0.023531\n",
      "Train Epoch: 74 [4608/14860 (31%)]\tLoss: 0.016511\n",
      "Train Epoch: 74 [4736/14860 (32%)]\tLoss: 0.029234\n",
      "Train Epoch: 74 [4864/14860 (32%)]\tLoss: 0.014407\n",
      "Train Epoch: 74 [4992/14860 (33%)]\tLoss: 0.033056\n",
      "Train Epoch: 74 [5120/14860 (34%)]\tLoss: 0.017227\n",
      "Train Epoch: 74 [5248/14860 (35%)]\tLoss: 0.017410\n",
      "Train Epoch: 74 [5376/14860 (36%)]\tLoss: 0.027089\n",
      "Train Epoch: 74 [5504/14860 (37%)]\tLoss: 0.019800\n",
      "Train Epoch: 74 [5632/14860 (38%)]\tLoss: 0.021144\n",
      "Train Epoch: 74 [5760/14860 (38%)]\tLoss: 0.022318\n",
      "Train Epoch: 74 [5888/14860 (39%)]\tLoss: 0.020173\n",
      "Train Epoch: 74 [6016/14860 (40%)]\tLoss: 0.025400\n",
      "Train Epoch: 74 [6144/14860 (41%)]\tLoss: 0.016212\n",
      "Train Epoch: 74 [6272/14860 (42%)]\tLoss: 0.031663\n",
      "Train Epoch: 74 [6400/14860 (43%)]\tLoss: 0.023409\n",
      "Train Epoch: 74 [6528/14860 (44%)]\tLoss: 0.024735\n",
      "Train Epoch: 74 [6656/14860 (44%)]\tLoss: 0.020133\n",
      "Train Epoch: 74 [6784/14860 (45%)]\tLoss: 0.020226\n",
      "Train Epoch: 74 [6912/14860 (46%)]\tLoss: 0.024001\n",
      "Train Epoch: 74 [7040/14860 (47%)]\tLoss: 0.026848\n",
      "Train Epoch: 74 [7168/14860 (48%)]\tLoss: 0.022259\n",
      "Train Epoch: 74 [7296/14860 (49%)]\tLoss: 0.018571\n",
      "Train Epoch: 74 [7424/14860 (50%)]\tLoss: 0.024353\n",
      "Train Epoch: 74 [7552/14860 (50%)]\tLoss: 0.019513\n",
      "Train Epoch: 74 [7680/14860 (51%)]\tLoss: 0.016801\n",
      "Train Epoch: 74 [7808/14860 (52%)]\tLoss: 0.017655\n",
      "Train Epoch: 74 [7936/14860 (53%)]\tLoss: 0.018081\n",
      "Train Epoch: 74 [8064/14860 (54%)]\tLoss: 0.017899\n",
      "Train Epoch: 74 [8192/14860 (55%)]\tLoss: 0.015236\n",
      "Train Epoch: 74 [8320/14860 (56%)]\tLoss: 0.025076\n",
      "Train Epoch: 74 [8448/14860 (56%)]\tLoss: 0.016778\n",
      "Train Epoch: 74 [8576/14860 (57%)]\tLoss: 0.018309\n",
      "Train Epoch: 74 [8704/14860 (58%)]\tLoss: 0.018907\n",
      "Train Epoch: 74 [8832/14860 (59%)]\tLoss: 0.019705\n",
      "Train Epoch: 74 [8960/14860 (60%)]\tLoss: 0.015006\n",
      "Train Epoch: 74 [9088/14860 (61%)]\tLoss: 0.020019\n",
      "Train Epoch: 74 [9216/14860 (62%)]\tLoss: 0.026169\n",
      "Train Epoch: 74 [9344/14860 (62%)]\tLoss: 0.019146\n",
      "Train Epoch: 74 [9472/14860 (63%)]\tLoss: 0.020854\n",
      "Train Epoch: 74 [9600/14860 (64%)]\tLoss: 0.026152\n",
      "Train Epoch: 74 [9728/14860 (65%)]\tLoss: 0.023953\n",
      "Train Epoch: 74 [9856/14860 (66%)]\tLoss: 0.024664\n",
      "Train Epoch: 74 [9984/14860 (67%)]\tLoss: 0.023753\n",
      "Train Epoch: 74 [10112/14860 (68%)]\tLoss: 0.019623\n",
      "Train Epoch: 74 [10240/14860 (68%)]\tLoss: 0.023787\n",
      "Train Epoch: 74 [10368/14860 (69%)]\tLoss: 0.017605\n",
      "Train Epoch: 74 [10496/14860 (70%)]\tLoss: 0.022941\n",
      "Train Epoch: 74 [10624/14860 (71%)]\tLoss: 0.017394\n",
      "Train Epoch: 74 [10752/14860 (72%)]\tLoss: 0.015332\n",
      "Train Epoch: 74 [10880/14860 (73%)]\tLoss: 0.037764\n",
      "Train Epoch: 74 [11008/14860 (74%)]\tLoss: 0.025502\n",
      "Train Epoch: 74 [11136/14860 (74%)]\tLoss: 0.021142\n",
      "Train Epoch: 74 [11264/14860 (75%)]\tLoss: 0.020917\n",
      "Train Epoch: 74 [11392/14860 (76%)]\tLoss: 0.020827\n",
      "Train Epoch: 74 [11520/14860 (77%)]\tLoss: 0.016672\n",
      "Train Epoch: 74 [11648/14860 (78%)]\tLoss: 0.017655\n",
      "Train Epoch: 74 [11776/14860 (79%)]\tLoss: 0.013658\n",
      "Train Epoch: 74 [11904/14860 (79%)]\tLoss: 0.016403\n",
      "Train Epoch: 74 [12032/14860 (80%)]\tLoss: 0.012269\n",
      "Train Epoch: 74 [12160/14860 (81%)]\tLoss: 0.018112\n",
      "Train Epoch: 74 [12288/14860 (82%)]\tLoss: 0.012414\n",
      "Train Epoch: 74 [12416/14860 (83%)]\tLoss: 0.023620\n",
      "Train Epoch: 74 [12544/14860 (84%)]\tLoss: 0.013341\n",
      "Train Epoch: 74 [12672/14860 (85%)]\tLoss: 0.017316\n",
      "Train Epoch: 74 [12800/14860 (85%)]\tLoss: 0.017748\n",
      "Train Epoch: 74 [12928/14860 (86%)]\tLoss: 0.019909\n",
      "Train Epoch: 74 [13056/14860 (87%)]\tLoss: 0.019823\n",
      "Train Epoch: 74 [13184/14860 (88%)]\tLoss: 0.018983\n",
      "Train Epoch: 74 [13312/14860 (89%)]\tLoss: 0.014919\n",
      "Train Epoch: 74 [13440/14860 (90%)]\tLoss: 0.018245\n",
      "Train Epoch: 74 [13568/14860 (91%)]\tLoss: 0.023004\n",
      "Train Epoch: 74 [13696/14860 (91%)]\tLoss: 0.017594\n",
      "Train Epoch: 74 [13824/14860 (92%)]\tLoss: 0.026086\n",
      "Train Epoch: 74 [13952/14860 (93%)]\tLoss: 0.015381\n",
      "Train Epoch: 74 [14080/14860 (94%)]\tLoss: 0.025140\n",
      "Train Epoch: 74 [14208/14860 (95%)]\tLoss: 0.014134\n",
      "Train Epoch: 74 [14336/14860 (96%)]\tLoss: 0.019871\n",
      "Train Epoch: 74 [14464/14860 (97%)]\tLoss: 0.014134\n",
      "Train Epoch: 74 [14592/14860 (97%)]\tLoss: 0.017667\n",
      "Train Epoch: 74 [14720/14860 (98%)]\tLoss: 0.023932\n",
      "Train Epoch: 74 [1392/14860 (99%)]\tLoss: 0.009230\n",
      "epoch 74 training loss: 0.02078186220720283\n",
      "epoch 74 validation loss: 0.024194875438911863\n",
      "Train Epoch: 75 [0/14860 (0%)]\tLoss: 0.025193\n",
      "Train Epoch: 75 [128/14860 (1%)]\tLoss: 0.023137\n",
      "Train Epoch: 75 [256/14860 (2%)]\tLoss: 0.023212\n",
      "Train Epoch: 75 [384/14860 (3%)]\tLoss: 0.020789\n",
      "Train Epoch: 75 [512/14860 (3%)]\tLoss: 0.020459\n",
      "Train Epoch: 75 [640/14860 (4%)]\tLoss: 0.017533\n",
      "Train Epoch: 75 [768/14860 (5%)]\tLoss: 0.019730\n",
      "Train Epoch: 75 [896/14860 (6%)]\tLoss: 0.022182\n",
      "Train Epoch: 75 [1024/14860 (7%)]\tLoss: 0.016228\n",
      "Train Epoch: 75 [1152/14860 (8%)]\tLoss: 0.022470\n",
      "Train Epoch: 75 [1280/14860 (9%)]\tLoss: 0.023211\n",
      "Train Epoch: 75 [1408/14860 (9%)]\tLoss: 0.014748\n",
      "Train Epoch: 75 [1536/14860 (10%)]\tLoss: 0.018902\n",
      "Train Epoch: 75 [1664/14860 (11%)]\tLoss: 0.024957\n",
      "Train Epoch: 75 [1792/14860 (12%)]\tLoss: 0.015814\n",
      "Train Epoch: 75 [1920/14860 (13%)]\tLoss: 0.020883\n",
      "Train Epoch: 75 [2048/14860 (14%)]\tLoss: 0.023742\n",
      "Train Epoch: 75 [2176/14860 (15%)]\tLoss: 0.016403\n",
      "Train Epoch: 75 [2304/14860 (15%)]\tLoss: 0.017351\n",
      "Train Epoch: 75 [2432/14860 (16%)]\tLoss: 0.020461\n",
      "Train Epoch: 75 [2560/14860 (17%)]\tLoss: 0.022346\n",
      "Train Epoch: 75 [2688/14860 (18%)]\tLoss: 0.017165\n",
      "Train Epoch: 75 [2816/14860 (19%)]\tLoss: 0.015932\n",
      "Train Epoch: 75 [2944/14860 (20%)]\tLoss: 0.021299\n",
      "Train Epoch: 75 [3072/14860 (21%)]\tLoss: 0.028485\n",
      "Train Epoch: 75 [3200/14860 (21%)]\tLoss: 0.023674\n",
      "Train Epoch: 75 [3328/14860 (22%)]\tLoss: 0.016597\n",
      "Train Epoch: 75 [3456/14860 (23%)]\tLoss: 0.021373\n",
      "Train Epoch: 75 [3584/14860 (24%)]\tLoss: 0.021301\n",
      "Train Epoch: 75 [3712/14860 (25%)]\tLoss: 0.028281\n",
      "Train Epoch: 75 [3840/14860 (26%)]\tLoss: 0.015761\n",
      "Train Epoch: 75 [3968/14860 (26%)]\tLoss: 0.026577\n",
      "Train Epoch: 75 [4096/14860 (27%)]\tLoss: 0.027862\n",
      "Train Epoch: 75 [4224/14860 (28%)]\tLoss: 0.019924\n",
      "Train Epoch: 75 [4352/14860 (29%)]\tLoss: 0.014302\n",
      "Train Epoch: 75 [4480/14860 (30%)]\tLoss: 0.019273\n",
      "Train Epoch: 75 [4608/14860 (31%)]\tLoss: 0.013401\n",
      "Train Epoch: 75 [4736/14860 (32%)]\tLoss: 0.021776\n",
      "Train Epoch: 75 [4864/14860 (32%)]\tLoss: 0.023195\n",
      "Train Epoch: 75 [4992/14860 (33%)]\tLoss: 0.023674\n",
      "Train Epoch: 75 [5120/14860 (34%)]\tLoss: 0.021273\n",
      "Train Epoch: 75 [5248/14860 (35%)]\tLoss: 0.022926\n",
      "Train Epoch: 75 [5376/14860 (36%)]\tLoss: 0.021754\n",
      "Train Epoch: 75 [5504/14860 (37%)]\tLoss: 0.014528\n",
      "Train Epoch: 75 [5632/14860 (38%)]\tLoss: 0.018798\n",
      "Train Epoch: 75 [5760/14860 (38%)]\tLoss: 0.017113\n",
      "Train Epoch: 75 [5888/14860 (39%)]\tLoss: 0.020635\n",
      "Train Epoch: 75 [6016/14860 (40%)]\tLoss: 0.013817\n",
      "Train Epoch: 75 [6144/14860 (41%)]\tLoss: 0.027705\n",
      "Train Epoch: 75 [6272/14860 (42%)]\tLoss: 0.019744\n",
      "Train Epoch: 75 [6400/14860 (43%)]\tLoss: 0.026475\n",
      "Train Epoch: 75 [6528/14860 (44%)]\tLoss: 0.020717\n",
      "Train Epoch: 75 [6656/14860 (44%)]\tLoss: 0.035002\n",
      "Train Epoch: 75 [6784/14860 (45%)]\tLoss: 0.023073\n",
      "Train Epoch: 75 [6912/14860 (46%)]\tLoss: 0.025496\n",
      "Train Epoch: 75 [7040/14860 (47%)]\tLoss: 0.021200\n",
      "Train Epoch: 75 [7168/14860 (48%)]\tLoss: 0.027371\n",
      "Train Epoch: 75 [7296/14860 (49%)]\tLoss: 0.025138\n",
      "Train Epoch: 75 [7424/14860 (50%)]\tLoss: 0.017550\n",
      "Train Epoch: 75 [7552/14860 (50%)]\tLoss: 0.022812\n",
      "Train Epoch: 75 [7680/14860 (51%)]\tLoss: 0.016987\n",
      "Train Epoch: 75 [7808/14860 (52%)]\tLoss: 0.018560\n",
      "Train Epoch: 75 [7936/14860 (53%)]\tLoss: 0.031811\n",
      "Train Epoch: 75 [8064/14860 (54%)]\tLoss: 0.017384\n",
      "Train Epoch: 75 [8192/14860 (55%)]\tLoss: 0.021659\n",
      "Train Epoch: 75 [8320/14860 (56%)]\tLoss: 0.023444\n",
      "Train Epoch: 75 [8448/14860 (56%)]\tLoss: 0.016714\n",
      "Train Epoch: 75 [8576/14860 (57%)]\tLoss: 0.021975\n",
      "Train Epoch: 75 [8704/14860 (58%)]\tLoss: 0.015770\n",
      "Train Epoch: 75 [8832/14860 (59%)]\tLoss: 0.017190\n",
      "Train Epoch: 75 [8960/14860 (60%)]\tLoss: 0.020250\n",
      "Train Epoch: 75 [9088/14860 (61%)]\tLoss: 0.021417\n",
      "Train Epoch: 75 [9216/14860 (62%)]\tLoss: 0.019080\n",
      "Train Epoch: 75 [9344/14860 (62%)]\tLoss: 0.019435\n",
      "Train Epoch: 75 [9472/14860 (63%)]\tLoss: 0.013818\n",
      "Train Epoch: 75 [9600/14860 (64%)]\tLoss: 0.024791\n",
      "Train Epoch: 75 [9728/14860 (65%)]\tLoss: 0.023306\n",
      "Train Epoch: 75 [9856/14860 (66%)]\tLoss: 0.022541\n",
      "Train Epoch: 75 [9984/14860 (67%)]\tLoss: 0.018316\n",
      "Train Epoch: 75 [10112/14860 (68%)]\tLoss: 0.026913\n",
      "Train Epoch: 75 [10240/14860 (68%)]\tLoss: 0.021762\n",
      "Train Epoch: 75 [10368/14860 (69%)]\tLoss: 0.024493\n",
      "Train Epoch: 75 [10496/14860 (70%)]\tLoss: 0.024458\n",
      "Train Epoch: 75 [10624/14860 (71%)]\tLoss: 0.021147\n",
      "Train Epoch: 75 [10752/14860 (72%)]\tLoss: 0.032848\n",
      "Train Epoch: 75 [10880/14860 (73%)]\tLoss: 0.020999\n",
      "Train Epoch: 75 [11008/14860 (74%)]\tLoss: 0.022029\n",
      "Train Epoch: 75 [11136/14860 (74%)]\tLoss: 0.015671\n",
      "Train Epoch: 75 [11264/14860 (75%)]\tLoss: 0.033742\n",
      "Train Epoch: 75 [11392/14860 (76%)]\tLoss: 0.023319\n",
      "Train Epoch: 75 [11520/14860 (77%)]\tLoss: 0.027530\n",
      "Train Epoch: 75 [11648/14860 (78%)]\tLoss: 0.017785\n",
      "Train Epoch: 75 [11776/14860 (79%)]\tLoss: 0.025907\n",
      "Train Epoch: 75 [11904/14860 (79%)]\tLoss: 0.023571\n",
      "Train Epoch: 75 [12032/14860 (80%)]\tLoss: 0.016981\n",
      "Train Epoch: 75 [12160/14860 (81%)]\tLoss: 0.020881\n",
      "Train Epoch: 75 [12288/14860 (82%)]\tLoss: 0.026104\n",
      "Train Epoch: 75 [12416/14860 (83%)]\tLoss: 0.019138\n",
      "Train Epoch: 75 [12544/14860 (84%)]\tLoss: 0.029031\n",
      "Train Epoch: 75 [12672/14860 (85%)]\tLoss: 0.021320\n",
      "Train Epoch: 75 [12800/14860 (85%)]\tLoss: 0.023855\n",
      "Train Epoch: 75 [12928/14860 (86%)]\tLoss: 0.021140\n",
      "Train Epoch: 75 [13056/14860 (87%)]\tLoss: 0.017666\n",
      "Train Epoch: 75 [13184/14860 (88%)]\tLoss: 0.034538\n",
      "Train Epoch: 75 [13312/14860 (89%)]\tLoss: 0.026229\n",
      "Train Epoch: 75 [13440/14860 (90%)]\tLoss: 0.017282\n",
      "Train Epoch: 75 [13568/14860 (91%)]\tLoss: 0.025352\n",
      "Train Epoch: 75 [13696/14860 (91%)]\tLoss: 0.019902\n",
      "Train Epoch: 75 [13824/14860 (92%)]\tLoss: 0.026846\n",
      "Train Epoch: 75 [13952/14860 (93%)]\tLoss: 0.021436\n",
      "Train Epoch: 75 [14080/14860 (94%)]\tLoss: 0.013337\n",
      "Train Epoch: 75 [14208/14860 (95%)]\tLoss: 0.021574\n",
      "Train Epoch: 75 [14336/14860 (96%)]\tLoss: 0.022416\n",
      "Train Epoch: 75 [14464/14860 (97%)]\tLoss: 0.015351\n",
      "Train Epoch: 75 [14592/14860 (97%)]\tLoss: 0.022104\n",
      "Train Epoch: 75 [14720/14860 (98%)]\tLoss: 0.014315\n",
      "Train Epoch: 75 [1392/14860 (99%)]\tLoss: 0.019128\n",
      "epoch 75 training loss: 0.021498063873722512\n",
      "epoch 75 validation loss: 0.02055215510848648\n",
      "Train Epoch: 76 [0/14860 (0%)]\tLoss: 0.012362\n",
      "Train Epoch: 76 [128/14860 (1%)]\tLoss: 0.017886\n",
      "Train Epoch: 76 [256/14860 (2%)]\tLoss: 0.019988\n",
      "Train Epoch: 76 [384/14860 (3%)]\tLoss: 0.026453\n",
      "Train Epoch: 76 [512/14860 (3%)]\tLoss: 0.021874\n",
      "Train Epoch: 76 [640/14860 (4%)]\tLoss: 0.024747\n",
      "Train Epoch: 76 [768/14860 (5%)]\tLoss: 0.015262\n",
      "Train Epoch: 76 [896/14860 (6%)]\tLoss: 0.019116\n",
      "Train Epoch: 76 [1024/14860 (7%)]\tLoss: 0.019600\n",
      "Train Epoch: 76 [1152/14860 (8%)]\tLoss: 0.025327\n",
      "Train Epoch: 76 [1280/14860 (9%)]\tLoss: 0.018203\n",
      "Train Epoch: 76 [1408/14860 (9%)]\tLoss: 0.018572\n",
      "Train Epoch: 76 [1536/14860 (10%)]\tLoss: 0.020825\n",
      "Train Epoch: 76 [1664/14860 (11%)]\tLoss: 0.021012\n",
      "Train Epoch: 76 [1792/14860 (12%)]\tLoss: 0.010432\n",
      "Train Epoch: 76 [1920/14860 (13%)]\tLoss: 0.017399\n",
      "Train Epoch: 76 [2048/14860 (14%)]\tLoss: 0.030194\n",
      "Train Epoch: 76 [2176/14860 (15%)]\tLoss: 0.027094\n",
      "Train Epoch: 76 [2304/14860 (15%)]\tLoss: 0.018960\n",
      "Train Epoch: 76 [2432/14860 (16%)]\tLoss: 0.016763\n",
      "Train Epoch: 76 [2560/14860 (17%)]\tLoss: 0.019148\n",
      "Train Epoch: 76 [2688/14860 (18%)]\tLoss: 0.012737\n",
      "Train Epoch: 76 [2816/14860 (19%)]\tLoss: 0.014825\n",
      "Train Epoch: 76 [2944/14860 (20%)]\tLoss: 0.027943\n",
      "Train Epoch: 76 [3072/14860 (21%)]\tLoss: 0.013915\n",
      "Train Epoch: 76 [3200/14860 (21%)]\tLoss: 0.021792\n",
      "Train Epoch: 76 [3328/14860 (22%)]\tLoss: 0.020100\n",
      "Train Epoch: 76 [3456/14860 (23%)]\tLoss: 0.015421\n",
      "Train Epoch: 76 [3584/14860 (24%)]\tLoss: 0.016629\n",
      "Train Epoch: 76 [3712/14860 (25%)]\tLoss: 0.019817\n",
      "Train Epoch: 76 [3840/14860 (26%)]\tLoss: 0.021421\n",
      "Train Epoch: 76 [3968/14860 (26%)]\tLoss: 0.016354\n",
      "Train Epoch: 76 [4096/14860 (27%)]\tLoss: 0.013924\n",
      "Train Epoch: 76 [4224/14860 (28%)]\tLoss: 0.021663\n",
      "Train Epoch: 76 [4352/14860 (29%)]\tLoss: 0.033858\n",
      "Train Epoch: 76 [4480/14860 (30%)]\tLoss: 0.019624\n",
      "Train Epoch: 76 [4608/14860 (31%)]\tLoss: 0.024551\n",
      "Train Epoch: 76 [4736/14860 (32%)]\tLoss: 0.018781\n",
      "Train Epoch: 76 [4864/14860 (32%)]\tLoss: 0.018908\n",
      "Train Epoch: 76 [4992/14860 (33%)]\tLoss: 0.021127\n",
      "Train Epoch: 76 [5120/14860 (34%)]\tLoss: 0.015592\n",
      "Train Epoch: 76 [5248/14860 (35%)]\tLoss: 0.024618\n",
      "Train Epoch: 76 [5376/14860 (36%)]\tLoss: 0.018804\n",
      "Train Epoch: 76 [5504/14860 (37%)]\tLoss: 0.018200\n",
      "Train Epoch: 76 [5632/14860 (38%)]\tLoss: 0.017799\n",
      "Train Epoch: 76 [5760/14860 (38%)]\tLoss: 0.015005\n",
      "Train Epoch: 76 [5888/14860 (39%)]\tLoss: 0.022419\n",
      "Train Epoch: 76 [6016/14860 (40%)]\tLoss: 0.013754\n",
      "Train Epoch: 76 [6144/14860 (41%)]\tLoss: 0.021951\n",
      "Train Epoch: 76 [6272/14860 (42%)]\tLoss: 0.016281\n",
      "Train Epoch: 76 [6400/14860 (43%)]\tLoss: 0.018879\n",
      "Train Epoch: 76 [6528/14860 (44%)]\tLoss: 0.019942\n",
      "Train Epoch: 76 [6656/14860 (44%)]\tLoss: 0.012180\n",
      "Train Epoch: 76 [6784/14860 (45%)]\tLoss: 0.029673\n",
      "Train Epoch: 76 [6912/14860 (46%)]\tLoss: 0.022171\n",
      "Train Epoch: 76 [7040/14860 (47%)]\tLoss: 0.024937\n",
      "Train Epoch: 76 [7168/14860 (48%)]\tLoss: 0.016456\n",
      "Train Epoch: 76 [7296/14860 (49%)]\tLoss: 0.026702\n",
      "Train Epoch: 76 [7424/14860 (50%)]\tLoss: 0.016987\n",
      "Train Epoch: 76 [7552/14860 (50%)]\tLoss: 0.020543\n",
      "Train Epoch: 76 [7680/14860 (51%)]\tLoss: 0.015368\n",
      "Train Epoch: 76 [7808/14860 (52%)]\tLoss: 0.026077\n",
      "Train Epoch: 76 [7936/14860 (53%)]\tLoss: 0.020911\n",
      "Train Epoch: 76 [8064/14860 (54%)]\tLoss: 0.019807\n",
      "Train Epoch: 76 [8192/14860 (55%)]\tLoss: 0.019318\n",
      "Train Epoch: 76 [8320/14860 (56%)]\tLoss: 0.013455\n",
      "Train Epoch: 76 [8448/14860 (56%)]\tLoss: 0.018726\n",
      "Train Epoch: 76 [8576/14860 (57%)]\tLoss: 0.032279\n",
      "Train Epoch: 76 [8704/14860 (58%)]\tLoss: 0.011359\n",
      "Train Epoch: 76 [8832/14860 (59%)]\tLoss: 0.019777\n",
      "Train Epoch: 76 [8960/14860 (60%)]\tLoss: 0.014580\n",
      "Train Epoch: 76 [9088/14860 (61%)]\tLoss: 0.018289\n",
      "Train Epoch: 76 [9216/14860 (62%)]\tLoss: 0.026646\n",
      "Train Epoch: 76 [9344/14860 (62%)]\tLoss: 0.025617\n",
      "Train Epoch: 76 [9472/14860 (63%)]\tLoss: 0.020276\n",
      "Train Epoch: 76 [9600/14860 (64%)]\tLoss: 0.022843\n",
      "Train Epoch: 76 [9728/14860 (65%)]\tLoss: 0.018458\n",
      "Train Epoch: 76 [9856/14860 (66%)]\tLoss: 0.019014\n",
      "Train Epoch: 76 [9984/14860 (67%)]\tLoss: 0.027815\n",
      "Train Epoch: 76 [10112/14860 (68%)]\tLoss: 0.026750\n",
      "Train Epoch: 76 [10240/14860 (68%)]\tLoss: 0.032269\n",
      "Train Epoch: 76 [10368/14860 (69%)]\tLoss: 0.021504\n",
      "Train Epoch: 76 [10496/14860 (70%)]\tLoss: 0.029038\n",
      "Train Epoch: 76 [10624/14860 (71%)]\tLoss: 0.022782\n",
      "Train Epoch: 76 [10752/14860 (72%)]\tLoss: 0.028439\n",
      "Train Epoch: 76 [10880/14860 (73%)]\tLoss: 0.022612\n",
      "Train Epoch: 76 [11008/14860 (74%)]\tLoss: 0.023866\n",
      "Train Epoch: 76 [11136/14860 (74%)]\tLoss: 0.019499\n",
      "Train Epoch: 76 [11264/14860 (75%)]\tLoss: 0.025946\n",
      "Train Epoch: 76 [11392/14860 (76%)]\tLoss: 0.016637\n",
      "Train Epoch: 76 [11520/14860 (77%)]\tLoss: 0.016332\n",
      "Train Epoch: 76 [11648/14860 (78%)]\tLoss: 0.012858\n",
      "Train Epoch: 76 [11776/14860 (79%)]\tLoss: 0.027653\n",
      "Train Epoch: 76 [11904/14860 (79%)]\tLoss: 0.019368\n",
      "Train Epoch: 76 [12032/14860 (80%)]\tLoss: 0.021506\n",
      "Train Epoch: 76 [12160/14860 (81%)]\tLoss: 0.027231\n",
      "Train Epoch: 76 [12288/14860 (82%)]\tLoss: 0.023888\n",
      "Train Epoch: 76 [12416/14860 (83%)]\tLoss: 0.021607\n",
      "Train Epoch: 76 [12544/14860 (84%)]\tLoss: 0.033743\n",
      "Train Epoch: 76 [12672/14860 (85%)]\tLoss: 0.018984\n",
      "Train Epoch: 76 [12800/14860 (85%)]\tLoss: 0.023763\n",
      "Train Epoch: 76 [12928/14860 (86%)]\tLoss: 0.022560\n",
      "Train Epoch: 76 [13056/14860 (87%)]\tLoss: 0.022353\n",
      "Train Epoch: 76 [13184/14860 (88%)]\tLoss: 0.016855\n",
      "Train Epoch: 76 [13312/14860 (89%)]\tLoss: 0.024167\n",
      "Train Epoch: 76 [13440/14860 (90%)]\tLoss: 0.019077\n",
      "Train Epoch: 76 [13568/14860 (91%)]\tLoss: 0.018756\n",
      "Train Epoch: 76 [13696/14860 (91%)]\tLoss: 0.028667\n",
      "Train Epoch: 76 [13824/14860 (92%)]\tLoss: 0.010674\n",
      "Train Epoch: 76 [13952/14860 (93%)]\tLoss: 0.027258\n",
      "Train Epoch: 76 [14080/14860 (94%)]\tLoss: 0.020369\n",
      "Train Epoch: 76 [14208/14860 (95%)]\tLoss: 0.025605\n",
      "Train Epoch: 76 [14336/14860 (96%)]\tLoss: 0.009556\n",
      "Train Epoch: 76 [14464/14860 (97%)]\tLoss: 0.019382\n",
      "Train Epoch: 76 [14592/14860 (97%)]\tLoss: 0.020596\n",
      "Train Epoch: 76 [14720/14860 (98%)]\tLoss: 0.023187\n",
      "Train Epoch: 76 [1392/14860 (99%)]\tLoss: 0.014216\n",
      "epoch 76 training loss: 0.020663840035533804\n",
      "epoch 76 validation loss: 0.022519718359515394\n",
      "Train Epoch: 77 [0/14860 (0%)]\tLoss: 0.019874\n",
      "Train Epoch: 77 [128/14860 (1%)]\tLoss: 0.025766\n",
      "Train Epoch: 77 [256/14860 (2%)]\tLoss: 0.018185\n",
      "Train Epoch: 77 [384/14860 (3%)]\tLoss: 0.020502\n",
      "Train Epoch: 77 [512/14860 (3%)]\tLoss: 0.017823\n",
      "Train Epoch: 77 [640/14860 (4%)]\tLoss: 0.019028\n",
      "Train Epoch: 77 [768/14860 (5%)]\tLoss: 0.021864\n",
      "Train Epoch: 77 [896/14860 (6%)]\tLoss: 0.024535\n",
      "Train Epoch: 77 [1024/14860 (7%)]\tLoss: 0.020595\n",
      "Train Epoch: 77 [1152/14860 (8%)]\tLoss: 0.026794\n",
      "Train Epoch: 77 [1280/14860 (9%)]\tLoss: 0.025504\n",
      "Train Epoch: 77 [1408/14860 (9%)]\tLoss: 0.021082\n",
      "Train Epoch: 77 [1536/14860 (10%)]\tLoss: 0.019324\n",
      "Train Epoch: 77 [1664/14860 (11%)]\tLoss: 0.017852\n",
      "Train Epoch: 77 [1792/14860 (12%)]\tLoss: 0.028453\n",
      "Train Epoch: 77 [1920/14860 (13%)]\tLoss: 0.025128\n",
      "Train Epoch: 77 [2048/14860 (14%)]\tLoss: 0.036255\n",
      "Train Epoch: 77 [2176/14860 (15%)]\tLoss: 0.021415\n",
      "Train Epoch: 77 [2304/14860 (15%)]\tLoss: 0.021768\n",
      "Train Epoch: 77 [2432/14860 (16%)]\tLoss: 0.038666\n",
      "Train Epoch: 77 [2560/14860 (17%)]\tLoss: 0.019901\n",
      "Train Epoch: 77 [2688/14860 (18%)]\tLoss: 0.033991\n",
      "Train Epoch: 77 [2816/14860 (19%)]\tLoss: 0.019908\n",
      "Train Epoch: 77 [2944/14860 (20%)]\tLoss: 0.024912\n",
      "Train Epoch: 77 [3072/14860 (21%)]\tLoss: 0.027152\n",
      "Train Epoch: 77 [3200/14860 (21%)]\tLoss: 0.024871\n",
      "Train Epoch: 77 [3328/14860 (22%)]\tLoss: 0.019983\n",
      "Train Epoch: 77 [3456/14860 (23%)]\tLoss: 0.031729\n",
      "Train Epoch: 77 [3584/14860 (24%)]\tLoss: 0.016274\n",
      "Train Epoch: 77 [3712/14860 (25%)]\tLoss: 0.024065\n",
      "Train Epoch: 77 [3840/14860 (26%)]\tLoss: 0.023991\n",
      "Train Epoch: 77 [3968/14860 (26%)]\tLoss: 0.034060\n",
      "Train Epoch: 77 [4096/14860 (27%)]\tLoss: 0.029663\n",
      "Train Epoch: 77 [4224/14860 (28%)]\tLoss: 0.034165\n",
      "Train Epoch: 77 [4352/14860 (29%)]\tLoss: 0.016051\n",
      "Train Epoch: 77 [4480/14860 (30%)]\tLoss: 0.022305\n",
      "Train Epoch: 77 [4608/14860 (31%)]\tLoss: 0.026003\n",
      "Train Epoch: 77 [4736/14860 (32%)]\tLoss: 0.015290\n",
      "Train Epoch: 77 [4864/14860 (32%)]\tLoss: 0.032301\n",
      "Train Epoch: 77 [4992/14860 (33%)]\tLoss: 0.025697\n",
      "Train Epoch: 77 [5120/14860 (34%)]\tLoss: 0.018607\n",
      "Train Epoch: 77 [5248/14860 (35%)]\tLoss: 0.020838\n",
      "Train Epoch: 77 [5376/14860 (36%)]\tLoss: 0.021540\n",
      "Train Epoch: 77 [5504/14860 (37%)]\tLoss: 0.023915\n",
      "Train Epoch: 77 [5632/14860 (38%)]\tLoss: 0.022410\n",
      "Train Epoch: 77 [5760/14860 (38%)]\tLoss: 0.018233\n",
      "Train Epoch: 77 [5888/14860 (39%)]\tLoss: 0.018298\n",
      "Train Epoch: 77 [6016/14860 (40%)]\tLoss: 0.016233\n",
      "Train Epoch: 77 [6144/14860 (41%)]\tLoss: 0.021418\n",
      "Train Epoch: 77 [6272/14860 (42%)]\tLoss: 0.018567\n",
      "Train Epoch: 77 [6400/14860 (43%)]\tLoss: 0.020036\n",
      "Train Epoch: 77 [6528/14860 (44%)]\tLoss: 0.027895\n",
      "Train Epoch: 77 [6656/14860 (44%)]\tLoss: 0.030413\n",
      "Train Epoch: 77 [6784/14860 (45%)]\tLoss: 0.020473\n",
      "Train Epoch: 77 [6912/14860 (46%)]\tLoss: 0.013641\n",
      "Train Epoch: 77 [7040/14860 (47%)]\tLoss: 0.018021\n",
      "Train Epoch: 77 [7168/14860 (48%)]\tLoss: 0.019999\n",
      "Train Epoch: 77 [7296/14860 (49%)]\tLoss: 0.020796\n",
      "Train Epoch: 77 [7424/14860 (50%)]\tLoss: 0.019543\n",
      "Train Epoch: 77 [7552/14860 (50%)]\tLoss: 0.022232\n",
      "Train Epoch: 77 [7680/14860 (51%)]\tLoss: 0.018928\n",
      "Train Epoch: 77 [7808/14860 (52%)]\tLoss: 0.019635\n",
      "Train Epoch: 77 [7936/14860 (53%)]\tLoss: 0.016725\n",
      "Train Epoch: 77 [8064/14860 (54%)]\tLoss: 0.018711\n",
      "Train Epoch: 77 [8192/14860 (55%)]\tLoss: 0.030945\n",
      "Train Epoch: 77 [8320/14860 (56%)]\tLoss: 0.016824\n",
      "Train Epoch: 77 [8448/14860 (56%)]\tLoss: 0.022995\n",
      "Train Epoch: 77 [8576/14860 (57%)]\tLoss: 0.016879\n",
      "Train Epoch: 77 [8704/14860 (58%)]\tLoss: 0.028570\n",
      "Train Epoch: 77 [8832/14860 (59%)]\tLoss: 0.015842\n",
      "Train Epoch: 77 [8960/14860 (60%)]\tLoss: 0.019737\n",
      "Train Epoch: 77 [9088/14860 (61%)]\tLoss: 0.018083\n",
      "Train Epoch: 77 [9216/14860 (62%)]\tLoss: 0.016170\n",
      "Train Epoch: 77 [9344/14860 (62%)]\tLoss: 0.016709\n",
      "Train Epoch: 77 [9472/14860 (63%)]\tLoss: 0.020133\n",
      "Train Epoch: 77 [9600/14860 (64%)]\tLoss: 0.015798\n",
      "Train Epoch: 77 [9728/14860 (65%)]\tLoss: 0.014960\n",
      "Train Epoch: 77 [9856/14860 (66%)]\tLoss: 0.018938\n",
      "Train Epoch: 77 [9984/14860 (67%)]\tLoss: 0.017327\n",
      "Train Epoch: 77 [10112/14860 (68%)]\tLoss: 0.017693\n",
      "Train Epoch: 77 [10240/14860 (68%)]\tLoss: 0.019746\n",
      "Train Epoch: 77 [10368/14860 (69%)]\tLoss: 0.023555\n",
      "Train Epoch: 77 [10496/14860 (70%)]\tLoss: 0.023642\n",
      "Train Epoch: 77 [10624/14860 (71%)]\tLoss: 0.016646\n",
      "Train Epoch: 77 [10752/14860 (72%)]\tLoss: 0.014130\n",
      "Train Epoch: 77 [10880/14860 (73%)]\tLoss: 0.014358\n",
      "Train Epoch: 77 [11008/14860 (74%)]\tLoss: 0.019808\n",
      "Train Epoch: 77 [11136/14860 (74%)]\tLoss: 0.019754\n",
      "Train Epoch: 77 [11264/14860 (75%)]\tLoss: 0.021845\n",
      "Train Epoch: 77 [11392/14860 (76%)]\tLoss: 0.019291\n",
      "Train Epoch: 77 [11520/14860 (77%)]\tLoss: 0.018565\n",
      "Train Epoch: 77 [11648/14860 (78%)]\tLoss: 0.021585\n",
      "Train Epoch: 77 [11776/14860 (79%)]\tLoss: 0.019218\n",
      "Train Epoch: 77 [11904/14860 (79%)]\tLoss: 0.014649\n",
      "Train Epoch: 77 [12032/14860 (80%)]\tLoss: 0.022064\n",
      "Train Epoch: 77 [12160/14860 (81%)]\tLoss: 0.017135\n",
      "Train Epoch: 77 [12288/14860 (82%)]\tLoss: 0.014507\n",
      "Train Epoch: 77 [12416/14860 (83%)]\tLoss: 0.015420\n",
      "Train Epoch: 77 [12544/14860 (84%)]\tLoss: 0.016166\n",
      "Train Epoch: 77 [12672/14860 (85%)]\tLoss: 0.019406\n",
      "Train Epoch: 77 [12800/14860 (85%)]\tLoss: 0.016186\n",
      "Train Epoch: 77 [12928/14860 (86%)]\tLoss: 0.018932\n",
      "Train Epoch: 77 [13056/14860 (87%)]\tLoss: 0.020258\n",
      "Train Epoch: 77 [13184/14860 (88%)]\tLoss: 0.031628\n",
      "Train Epoch: 77 [13312/14860 (89%)]\tLoss: 0.019535\n",
      "Train Epoch: 77 [13440/14860 (90%)]\tLoss: 0.016930\n",
      "Train Epoch: 77 [13568/14860 (91%)]\tLoss: 0.023691\n",
      "Train Epoch: 77 [13696/14860 (91%)]\tLoss: 0.015070\n",
      "Train Epoch: 77 [13824/14860 (92%)]\tLoss: 0.024228\n",
      "Train Epoch: 77 [13952/14860 (93%)]\tLoss: 0.019814\n",
      "Train Epoch: 77 [14080/14860 (94%)]\tLoss: 0.024056\n",
      "Train Epoch: 77 [14208/14860 (95%)]\tLoss: 0.026287\n",
      "Train Epoch: 77 [14336/14860 (96%)]\tLoss: 0.014425\n",
      "Train Epoch: 77 [14464/14860 (97%)]\tLoss: 0.019961\n",
      "Train Epoch: 77 [14592/14860 (97%)]\tLoss: 0.015315\n",
      "Train Epoch: 77 [14720/14860 (98%)]\tLoss: 0.013835\n",
      "Train Epoch: 77 [1392/14860 (99%)]\tLoss: 0.047637\n",
      "epoch 77 training loss: 0.021424921961803723\n",
      "epoch 77 validation loss: 0.04086297505127027\n",
      "Train Epoch: 78 [0/14860 (0%)]\tLoss: 0.038837\n",
      "Train Epoch: 78 [128/14860 (1%)]\tLoss: 0.013576\n",
      "Train Epoch: 78 [256/14860 (2%)]\tLoss: 0.028670\n",
      "Train Epoch: 78 [384/14860 (3%)]\tLoss: 0.027533\n",
      "Train Epoch: 78 [512/14860 (3%)]\tLoss: 0.019271\n",
      "Train Epoch: 78 [640/14860 (4%)]\tLoss: 0.034810\n",
      "Train Epoch: 78 [768/14860 (5%)]\tLoss: 0.022474\n",
      "Train Epoch: 78 [896/14860 (6%)]\tLoss: 0.029266\n",
      "Train Epoch: 78 [1024/14860 (7%)]\tLoss: 0.031188\n",
      "Train Epoch: 78 [1152/14860 (8%)]\tLoss: 0.018636\n",
      "Train Epoch: 78 [1280/14860 (9%)]\tLoss: 0.021739\n",
      "Train Epoch: 78 [1408/14860 (9%)]\tLoss: 0.020576\n",
      "Train Epoch: 78 [1536/14860 (10%)]\tLoss: 0.017510\n",
      "Train Epoch: 78 [1664/14860 (11%)]\tLoss: 0.031246\n",
      "Train Epoch: 78 [1792/14860 (12%)]\tLoss: 0.033255\n",
      "Train Epoch: 78 [1920/14860 (13%)]\tLoss: 0.031264\n",
      "Train Epoch: 78 [2048/14860 (14%)]\tLoss: 0.027293\n",
      "Train Epoch: 78 [2176/14860 (15%)]\tLoss: 0.023784\n",
      "Train Epoch: 78 [2304/14860 (15%)]\tLoss: 0.023361\n",
      "Train Epoch: 78 [2432/14860 (16%)]\tLoss: 0.026893\n",
      "Train Epoch: 78 [2560/14860 (17%)]\tLoss: 0.027408\n",
      "Train Epoch: 78 [2688/14860 (18%)]\tLoss: 0.026737\n",
      "Train Epoch: 78 [2816/14860 (19%)]\tLoss: 0.025379\n",
      "Train Epoch: 78 [2944/14860 (20%)]\tLoss: 0.013290\n",
      "Train Epoch: 78 [3072/14860 (21%)]\tLoss: 0.040721\n",
      "Train Epoch: 78 [3200/14860 (21%)]\tLoss: 0.021455\n",
      "Train Epoch: 78 [3328/14860 (22%)]\tLoss: 0.015707\n",
      "Train Epoch: 78 [3456/14860 (23%)]\tLoss: 0.021204\n",
      "Train Epoch: 78 [3584/14860 (24%)]\tLoss: 0.015396\n",
      "Train Epoch: 78 [3712/14860 (25%)]\tLoss: 0.021639\n",
      "Train Epoch: 78 [3840/14860 (26%)]\tLoss: 0.028034\n",
      "Train Epoch: 78 [3968/14860 (26%)]\tLoss: 0.027673\n",
      "Train Epoch: 78 [4096/14860 (27%)]\tLoss: 0.027930\n",
      "Train Epoch: 78 [4224/14860 (28%)]\tLoss: 0.024414\n",
      "Train Epoch: 78 [4352/14860 (29%)]\tLoss: 0.018424\n",
      "Train Epoch: 78 [4480/14860 (30%)]\tLoss: 0.033065\n",
      "Train Epoch: 78 [4608/14860 (31%)]\tLoss: 0.020954\n",
      "Train Epoch: 78 [4736/14860 (32%)]\tLoss: 0.027169\n",
      "Train Epoch: 78 [4864/14860 (32%)]\tLoss: 0.016736\n",
      "Train Epoch: 78 [4992/14860 (33%)]\tLoss: 0.020097\n",
      "Train Epoch: 78 [5120/14860 (34%)]\tLoss: 0.021566\n",
      "Train Epoch: 78 [5248/14860 (35%)]\tLoss: 0.014813\n",
      "Train Epoch: 78 [5376/14860 (36%)]\tLoss: 0.020644\n",
      "Train Epoch: 78 [5504/14860 (37%)]\tLoss: 0.017359\n",
      "Train Epoch: 78 [5632/14860 (38%)]\tLoss: 0.012623\n",
      "Train Epoch: 78 [5760/14860 (38%)]\tLoss: 0.029614\n",
      "Train Epoch: 78 [5888/14860 (39%)]\tLoss: 0.016960\n",
      "Train Epoch: 78 [6016/14860 (40%)]\tLoss: 0.017503\n",
      "Train Epoch: 78 [6144/14860 (41%)]\tLoss: 0.024421\n",
      "Train Epoch: 78 [6272/14860 (42%)]\tLoss: 0.019948\n",
      "Train Epoch: 78 [6400/14860 (43%)]\tLoss: 0.025443\n",
      "Train Epoch: 78 [6528/14860 (44%)]\tLoss: 0.014895\n",
      "Train Epoch: 78 [6656/14860 (44%)]\tLoss: 0.020521\n",
      "Train Epoch: 78 [6784/14860 (45%)]\tLoss: 0.022268\n",
      "Train Epoch: 78 [6912/14860 (46%)]\tLoss: 0.023804\n",
      "Train Epoch: 78 [7040/14860 (47%)]\tLoss: 0.023515\n",
      "Train Epoch: 78 [7168/14860 (48%)]\tLoss: 0.020009\n",
      "Train Epoch: 78 [7296/14860 (49%)]\tLoss: 0.022071\n",
      "Train Epoch: 78 [7424/14860 (50%)]\tLoss: 0.017454\n",
      "Train Epoch: 78 [7552/14860 (50%)]\tLoss: 0.020912\n",
      "Train Epoch: 78 [7680/14860 (51%)]\tLoss: 0.020940\n",
      "Train Epoch: 78 [7808/14860 (52%)]\tLoss: 0.020578\n",
      "Train Epoch: 78 [7936/14860 (53%)]\tLoss: 0.020523\n",
      "Train Epoch: 78 [8064/14860 (54%)]\tLoss: 0.013613\n",
      "Train Epoch: 78 [8192/14860 (55%)]\tLoss: 0.017935\n",
      "Train Epoch: 78 [8320/14860 (56%)]\tLoss: 0.017268\n",
      "Train Epoch: 78 [8448/14860 (56%)]\tLoss: 0.024141\n",
      "Train Epoch: 78 [8576/14860 (57%)]\tLoss: 0.024407\n",
      "Train Epoch: 78 [8704/14860 (58%)]\tLoss: 0.021593\n",
      "Train Epoch: 78 [8832/14860 (59%)]\tLoss: 0.015989\n",
      "Train Epoch: 78 [8960/14860 (60%)]\tLoss: 0.017990\n",
      "Train Epoch: 78 [9088/14860 (61%)]\tLoss: 0.017137\n",
      "Train Epoch: 78 [9216/14860 (62%)]\tLoss: 0.021306\n",
      "Train Epoch: 78 [9344/14860 (62%)]\tLoss: 0.017840\n",
      "Train Epoch: 78 [9472/14860 (63%)]\tLoss: 0.013529\n",
      "Train Epoch: 78 [9600/14860 (64%)]\tLoss: 0.022785\n",
      "Train Epoch: 78 [9728/14860 (65%)]\tLoss: 0.027029\n",
      "Train Epoch: 78 [9856/14860 (66%)]\tLoss: 0.022053\n",
      "Train Epoch: 78 [9984/14860 (67%)]\tLoss: 0.024308\n",
      "Train Epoch: 78 [10112/14860 (68%)]\tLoss: 0.022702\n",
      "Train Epoch: 78 [10240/14860 (68%)]\tLoss: 0.014700\n",
      "Train Epoch: 78 [10368/14860 (69%)]\tLoss: 0.018086\n",
      "Train Epoch: 78 [10496/14860 (70%)]\tLoss: 0.015741\n",
      "Train Epoch: 78 [10624/14860 (71%)]\tLoss: 0.017674\n",
      "Train Epoch: 78 [10752/14860 (72%)]\tLoss: 0.019714\n",
      "Train Epoch: 78 [10880/14860 (73%)]\tLoss: 0.021489\n",
      "Train Epoch: 78 [11008/14860 (74%)]\tLoss: 0.022471\n",
      "Train Epoch: 78 [11136/14860 (74%)]\tLoss: 0.018311\n",
      "Train Epoch: 78 [11264/14860 (75%)]\tLoss: 0.016433\n",
      "Train Epoch: 78 [11392/14860 (76%)]\tLoss: 0.027577\n",
      "Train Epoch: 78 [11520/14860 (77%)]\tLoss: 0.028820\n",
      "Train Epoch: 78 [11648/14860 (78%)]\tLoss: 0.023731\n",
      "Train Epoch: 78 [11776/14860 (79%)]\tLoss: 0.019283\n",
      "Train Epoch: 78 [11904/14860 (79%)]\tLoss: 0.022470\n",
      "Train Epoch: 78 [12032/14860 (80%)]\tLoss: 0.018266\n",
      "Train Epoch: 78 [12160/14860 (81%)]\tLoss: 0.020316\n",
      "Train Epoch: 78 [12288/14860 (82%)]\tLoss: 0.023205\n",
      "Train Epoch: 78 [12416/14860 (83%)]\tLoss: 0.019293\n",
      "Train Epoch: 78 [12544/14860 (84%)]\tLoss: 0.025148\n",
      "Train Epoch: 78 [12672/14860 (85%)]\tLoss: 0.016311\n",
      "Train Epoch: 78 [12800/14860 (85%)]\tLoss: 0.018463\n",
      "Train Epoch: 78 [12928/14860 (86%)]\tLoss: 0.017175\n",
      "Train Epoch: 78 [13056/14860 (87%)]\tLoss: 0.028310\n",
      "Train Epoch: 78 [13184/14860 (88%)]\tLoss: 0.019013\n",
      "Train Epoch: 78 [13312/14860 (89%)]\tLoss: 0.020097\n",
      "Train Epoch: 78 [13440/14860 (90%)]\tLoss: 0.019547\n",
      "Train Epoch: 78 [13568/14860 (91%)]\tLoss: 0.018190\n",
      "Train Epoch: 78 [13696/14860 (91%)]\tLoss: 0.024380\n",
      "Train Epoch: 78 [13824/14860 (92%)]\tLoss: 0.017359\n",
      "Train Epoch: 78 [13952/14860 (93%)]\tLoss: 0.021088\n",
      "Train Epoch: 78 [14080/14860 (94%)]\tLoss: 0.027647\n",
      "Train Epoch: 78 [14208/14860 (95%)]\tLoss: 0.019128\n",
      "Train Epoch: 78 [14336/14860 (96%)]\tLoss: 0.023864\n",
      "Train Epoch: 78 [14464/14860 (97%)]\tLoss: 0.021428\n",
      "Train Epoch: 78 [14592/14860 (97%)]\tLoss: 0.027251\n",
      "Train Epoch: 78 [14720/14860 (98%)]\tLoss: 0.016364\n",
      "Train Epoch: 78 [1392/14860 (99%)]\tLoss: 0.007992\n",
      "epoch 78 training loss: 0.02188851744828061\n",
      "epoch 78 validation loss: 0.03570931110774634\n",
      "Train Epoch: 79 [0/14860 (0%)]\tLoss: 0.032258\n",
      "Train Epoch: 79 [128/14860 (1%)]\tLoss: 0.026764\n",
      "Train Epoch: 79 [256/14860 (2%)]\tLoss: 0.019470\n",
      "Train Epoch: 79 [384/14860 (3%)]\tLoss: 0.024215\n",
      "Train Epoch: 79 [512/14860 (3%)]\tLoss: 0.013372\n",
      "Train Epoch: 79 [640/14860 (4%)]\tLoss: 0.032103\n",
      "Train Epoch: 79 [768/14860 (5%)]\tLoss: 0.026061\n",
      "Train Epoch: 79 [896/14860 (6%)]\tLoss: 0.020753\n",
      "Train Epoch: 79 [1024/14860 (7%)]\tLoss: 0.026081\n",
      "Train Epoch: 79 [1152/14860 (8%)]\tLoss: 0.023595\n",
      "Train Epoch: 79 [1280/14860 (9%)]\tLoss: 0.027728\n",
      "Train Epoch: 79 [1408/14860 (9%)]\tLoss: 0.019115\n",
      "Train Epoch: 79 [1536/14860 (10%)]\tLoss: 0.014463\n",
      "Train Epoch: 79 [1664/14860 (11%)]\tLoss: 0.026171\n",
      "Train Epoch: 79 [1792/14860 (12%)]\tLoss: 0.018620\n",
      "Train Epoch: 79 [1920/14860 (13%)]\tLoss: 0.024360\n",
      "Train Epoch: 79 [2048/14860 (14%)]\tLoss: 0.022802\n",
      "Train Epoch: 79 [2176/14860 (15%)]\tLoss: 0.016351\n",
      "Train Epoch: 79 [2304/14860 (15%)]\tLoss: 0.025860\n",
      "Train Epoch: 79 [2432/14860 (16%)]\tLoss: 0.018565\n",
      "Train Epoch: 79 [2560/14860 (17%)]\tLoss: 0.018211\n",
      "Train Epoch: 79 [2688/14860 (18%)]\tLoss: 0.016036\n",
      "Train Epoch: 79 [2816/14860 (19%)]\tLoss: 0.011647\n",
      "Train Epoch: 79 [2944/14860 (20%)]\tLoss: 0.015733\n",
      "Train Epoch: 79 [3072/14860 (21%)]\tLoss: 0.019303\n",
      "Train Epoch: 79 [3200/14860 (21%)]\tLoss: 0.019931\n",
      "Train Epoch: 79 [3328/14860 (22%)]\tLoss: 0.015546\n",
      "Train Epoch: 79 [3456/14860 (23%)]\tLoss: 0.018331\n",
      "Train Epoch: 79 [3584/14860 (24%)]\tLoss: 0.014294\n",
      "Train Epoch: 79 [3712/14860 (25%)]\tLoss: 0.019746\n",
      "Train Epoch: 79 [3840/14860 (26%)]\tLoss: 0.022556\n",
      "Train Epoch: 79 [3968/14860 (26%)]\tLoss: 0.017847\n",
      "Train Epoch: 79 [4096/14860 (27%)]\tLoss: 0.018771\n",
      "Train Epoch: 79 [4224/14860 (28%)]\tLoss: 0.017316\n",
      "Train Epoch: 79 [4352/14860 (29%)]\tLoss: 0.027732\n",
      "Train Epoch: 79 [4480/14860 (30%)]\tLoss: 0.028648\n",
      "Train Epoch: 79 [4608/14860 (31%)]\tLoss: 0.018555\n",
      "Train Epoch: 79 [4736/14860 (32%)]\tLoss: 0.017600\n",
      "Train Epoch: 79 [4864/14860 (32%)]\tLoss: 0.022232\n",
      "Train Epoch: 79 [4992/14860 (33%)]\tLoss: 0.015064\n",
      "Train Epoch: 79 [5120/14860 (34%)]\tLoss: 0.025646\n",
      "Train Epoch: 79 [5248/14860 (35%)]\tLoss: 0.020709\n",
      "Train Epoch: 79 [5376/14860 (36%)]\tLoss: 0.020373\n",
      "Train Epoch: 79 [5504/14860 (37%)]\tLoss: 0.015590\n",
      "Train Epoch: 79 [5632/14860 (38%)]\tLoss: 0.012533\n",
      "Train Epoch: 79 [5760/14860 (38%)]\tLoss: 0.013555\n",
      "Train Epoch: 79 [5888/14860 (39%)]\tLoss: 0.016731\n",
      "Train Epoch: 79 [6016/14860 (40%)]\tLoss: 0.021911\n",
      "Train Epoch: 79 [6144/14860 (41%)]\tLoss: 0.021691\n",
      "Train Epoch: 79 [6272/14860 (42%)]\tLoss: 0.018225\n",
      "Train Epoch: 79 [6400/14860 (43%)]\tLoss: 0.025260\n",
      "Train Epoch: 79 [6528/14860 (44%)]\tLoss: 0.018725\n",
      "Train Epoch: 79 [6656/14860 (44%)]\tLoss: 0.034299\n",
      "Train Epoch: 79 [6784/14860 (45%)]\tLoss: 0.014236\n",
      "Train Epoch: 79 [6912/14860 (46%)]\tLoss: 0.019572\n",
      "Train Epoch: 79 [7040/14860 (47%)]\tLoss: 0.021661\n",
      "Train Epoch: 79 [7168/14860 (48%)]\tLoss: 0.021588\n",
      "Train Epoch: 79 [7296/14860 (49%)]\tLoss: 0.015923\n",
      "Train Epoch: 79 [7424/14860 (50%)]\tLoss: 0.032447\n",
      "Train Epoch: 79 [7552/14860 (50%)]\tLoss: 0.016882\n",
      "Train Epoch: 79 [7680/14860 (51%)]\tLoss: 0.019459\n",
      "Train Epoch: 79 [7808/14860 (52%)]\tLoss: 0.023518\n",
      "Train Epoch: 79 [7936/14860 (53%)]\tLoss: 0.020551\n",
      "Train Epoch: 79 [8064/14860 (54%)]\tLoss: 0.022249\n",
      "Train Epoch: 79 [8192/14860 (55%)]\tLoss: 0.020142\n",
      "Train Epoch: 79 [8320/14860 (56%)]\tLoss: 0.024240\n",
      "Train Epoch: 79 [8448/14860 (56%)]\tLoss: 0.021091\n",
      "Train Epoch: 79 [8576/14860 (57%)]\tLoss: 0.016881\n",
      "Train Epoch: 79 [8704/14860 (58%)]\tLoss: 0.023290\n",
      "Train Epoch: 79 [8832/14860 (59%)]\tLoss: 0.026036\n",
      "Train Epoch: 79 [8960/14860 (60%)]\tLoss: 0.025093\n",
      "Train Epoch: 79 [9088/14860 (61%)]\tLoss: 0.017135\n",
      "Train Epoch: 79 [9216/14860 (62%)]\tLoss: 0.013579\n",
      "Train Epoch: 79 [9344/14860 (62%)]\tLoss: 0.032265\n",
      "Train Epoch: 79 [9472/14860 (63%)]\tLoss: 0.016629\n",
      "Train Epoch: 79 [9600/14860 (64%)]\tLoss: 0.022448\n",
      "Train Epoch: 79 [9728/14860 (65%)]\tLoss: 0.024129\n",
      "Train Epoch: 79 [9856/14860 (66%)]\tLoss: 0.015317\n",
      "Train Epoch: 79 [9984/14860 (67%)]\tLoss: 0.017527\n",
      "Train Epoch: 79 [10112/14860 (68%)]\tLoss: 0.025121\n",
      "Train Epoch: 79 [10240/14860 (68%)]\tLoss: 0.026476\n",
      "Train Epoch: 79 [10368/14860 (69%)]\tLoss: 0.021390\n",
      "Train Epoch: 79 [10496/14860 (70%)]\tLoss: 0.029275\n",
      "Train Epoch: 79 [10624/14860 (71%)]\tLoss: 0.024177\n",
      "Train Epoch: 79 [10752/14860 (72%)]\tLoss: 0.016302\n",
      "Train Epoch: 79 [10880/14860 (73%)]\tLoss: 0.022832\n",
      "Train Epoch: 79 [11008/14860 (74%)]\tLoss: 0.019992\n",
      "Train Epoch: 79 [11136/14860 (74%)]\tLoss: 0.012998\n",
      "Train Epoch: 79 [11264/14860 (75%)]\tLoss: 0.025138\n",
      "Train Epoch: 79 [11392/14860 (76%)]\tLoss: 0.018446\n",
      "Train Epoch: 79 [11520/14860 (77%)]\tLoss: 0.021842\n",
      "Train Epoch: 79 [11648/14860 (78%)]\tLoss: 0.017800\n",
      "Train Epoch: 79 [11776/14860 (79%)]\tLoss: 0.019419\n",
      "Train Epoch: 79 [11904/14860 (79%)]\tLoss: 0.018336\n",
      "Train Epoch: 79 [12032/14860 (80%)]\tLoss: 0.023274\n",
      "Train Epoch: 79 [12160/14860 (81%)]\tLoss: 0.019256\n",
      "Train Epoch: 79 [12288/14860 (82%)]\tLoss: 0.021925\n",
      "Train Epoch: 79 [12416/14860 (83%)]\tLoss: 0.022403\n",
      "Train Epoch: 79 [12544/14860 (84%)]\tLoss: 0.016564\n",
      "Train Epoch: 79 [12672/14860 (85%)]\tLoss: 0.027242\n",
      "Train Epoch: 79 [12800/14860 (85%)]\tLoss: 0.015621\n",
      "Train Epoch: 79 [12928/14860 (86%)]\tLoss: 0.015791\n",
      "Train Epoch: 79 [13056/14860 (87%)]\tLoss: 0.020805\n",
      "Train Epoch: 79 [13184/14860 (88%)]\tLoss: 0.016569\n",
      "Train Epoch: 79 [13312/14860 (89%)]\tLoss: 0.020144\n",
      "Train Epoch: 79 [13440/14860 (90%)]\tLoss: 0.018830\n",
      "Train Epoch: 79 [13568/14860 (91%)]\tLoss: 0.028157\n",
      "Train Epoch: 79 [13696/14860 (91%)]\tLoss: 0.022021\n",
      "Train Epoch: 79 [13824/14860 (92%)]\tLoss: 0.018031\n",
      "Train Epoch: 79 [13952/14860 (93%)]\tLoss: 0.023357\n",
      "Train Epoch: 79 [14080/14860 (94%)]\tLoss: 0.019283\n",
      "Train Epoch: 79 [14208/14860 (95%)]\tLoss: 0.023079\n",
      "Train Epoch: 79 [14336/14860 (96%)]\tLoss: 0.029024\n",
      "Train Epoch: 79 [14464/14860 (97%)]\tLoss: 0.024492\n",
      "Train Epoch: 79 [14592/14860 (97%)]\tLoss: 0.019163\n",
      "Train Epoch: 79 [14720/14860 (98%)]\tLoss: 0.026284\n",
      "Train Epoch: 79 [1392/14860 (99%)]\tLoss: 0.010681\n",
      "epoch 79 training loss: 0.020892987688446146\n",
      "epoch 79 validation loss: 0.02833211017867266\n",
      "Train Epoch: 80 [0/14860 (0%)]\tLoss: 0.024909\n",
      "Train Epoch: 80 [128/14860 (1%)]\tLoss: 0.026148\n",
      "Train Epoch: 80 [256/14860 (2%)]\tLoss: 0.019670\n",
      "Train Epoch: 80 [384/14860 (3%)]\tLoss: 0.022915\n",
      "Train Epoch: 80 [512/14860 (3%)]\tLoss: 0.019895\n",
      "Train Epoch: 80 [640/14860 (4%)]\tLoss: 0.018124\n",
      "Train Epoch: 80 [768/14860 (5%)]\tLoss: 0.020552\n",
      "Train Epoch: 80 [896/14860 (6%)]\tLoss: 0.029684\n",
      "Train Epoch: 80 [1024/14860 (7%)]\tLoss: 0.018164\n",
      "Train Epoch: 80 [1152/14860 (8%)]\tLoss: 0.026438\n",
      "Train Epoch: 80 [1280/14860 (9%)]\tLoss: 0.017824\n",
      "Train Epoch: 80 [1408/14860 (9%)]\tLoss: 0.021671\n",
      "Train Epoch: 80 [1536/14860 (10%)]\tLoss: 0.032810\n",
      "Train Epoch: 80 [1664/14860 (11%)]\tLoss: 0.020274\n",
      "Train Epoch: 80 [1792/14860 (12%)]\tLoss: 0.024479\n",
      "Train Epoch: 80 [1920/14860 (13%)]\tLoss: 0.019241\n",
      "Train Epoch: 80 [2048/14860 (14%)]\tLoss: 0.024008\n",
      "Train Epoch: 80 [2176/14860 (15%)]\tLoss: 0.028340\n",
      "Train Epoch: 80 [2304/14860 (15%)]\tLoss: 0.023992\n",
      "Train Epoch: 80 [2432/14860 (16%)]\tLoss: 0.026503\n",
      "Train Epoch: 80 [2560/14860 (17%)]\tLoss: 0.017538\n",
      "Train Epoch: 80 [2688/14860 (18%)]\tLoss: 0.019417\n",
      "Train Epoch: 80 [2816/14860 (19%)]\tLoss: 0.020751\n",
      "Train Epoch: 80 [2944/14860 (20%)]\tLoss: 0.014126\n",
      "Train Epoch: 80 [3072/14860 (21%)]\tLoss: 0.019660\n",
      "Train Epoch: 80 [3200/14860 (21%)]\tLoss: 0.016170\n",
      "Train Epoch: 80 [3328/14860 (22%)]\tLoss: 0.016353\n",
      "Train Epoch: 80 [3456/14860 (23%)]\tLoss: 0.017439\n",
      "Train Epoch: 80 [3584/14860 (24%)]\tLoss: 0.024292\n",
      "Train Epoch: 80 [3712/14860 (25%)]\tLoss: 0.014866\n",
      "Train Epoch: 80 [3840/14860 (26%)]\tLoss: 0.022837\n",
      "Train Epoch: 80 [3968/14860 (26%)]\tLoss: 0.021335\n",
      "Train Epoch: 80 [4096/14860 (27%)]\tLoss: 0.017590\n",
      "Train Epoch: 80 [4224/14860 (28%)]\tLoss: 0.019387\n",
      "Train Epoch: 80 [4352/14860 (29%)]\tLoss: 0.027287\n",
      "Train Epoch: 80 [4480/14860 (30%)]\tLoss: 0.024430\n",
      "Train Epoch: 80 [4608/14860 (31%)]\tLoss: 0.015621\n",
      "Train Epoch: 80 [4736/14860 (32%)]\tLoss: 0.021225\n",
      "Train Epoch: 80 [4864/14860 (32%)]\tLoss: 0.015196\n",
      "Train Epoch: 80 [4992/14860 (33%)]\tLoss: 0.025520\n",
      "Train Epoch: 80 [5120/14860 (34%)]\tLoss: 0.023331\n",
      "Train Epoch: 80 [5248/14860 (35%)]\tLoss: 0.016411\n",
      "Train Epoch: 80 [5376/14860 (36%)]\tLoss: 0.024509\n",
      "Train Epoch: 80 [5504/14860 (37%)]\tLoss: 0.023788\n",
      "Train Epoch: 80 [5632/14860 (38%)]\tLoss: 0.022254\n",
      "Train Epoch: 80 [5760/14860 (38%)]\tLoss: 0.016137\n",
      "Train Epoch: 80 [5888/14860 (39%)]\tLoss: 0.024275\n",
      "Train Epoch: 80 [6016/14860 (40%)]\tLoss: 0.022837\n",
      "Train Epoch: 80 [6144/14860 (41%)]\tLoss: 0.029790\n",
      "Train Epoch: 80 [6272/14860 (42%)]\tLoss: 0.023343\n",
      "Train Epoch: 80 [6400/14860 (43%)]\tLoss: 0.017138\n",
      "Train Epoch: 80 [6528/14860 (44%)]\tLoss: 0.022427\n",
      "Train Epoch: 80 [6656/14860 (44%)]\tLoss: 0.021597\n",
      "Train Epoch: 80 [6784/14860 (45%)]\tLoss: 0.027393\n",
      "Train Epoch: 80 [6912/14860 (46%)]\tLoss: 0.021530\n",
      "Train Epoch: 80 [7040/14860 (47%)]\tLoss: 0.019619\n",
      "Train Epoch: 80 [7168/14860 (48%)]\tLoss: 0.017754\n",
      "Train Epoch: 80 [7296/14860 (49%)]\tLoss: 0.014765\n",
      "Train Epoch: 80 [7424/14860 (50%)]\tLoss: 0.021583\n",
      "Train Epoch: 80 [7552/14860 (50%)]\tLoss: 0.023743\n",
      "Train Epoch: 80 [7680/14860 (51%)]\tLoss: 0.023060\n",
      "Train Epoch: 80 [7808/14860 (52%)]\tLoss: 0.016890\n",
      "Train Epoch: 80 [7936/14860 (53%)]\tLoss: 0.017237\n",
      "Train Epoch: 80 [8064/14860 (54%)]\tLoss: 0.020247\n",
      "Train Epoch: 80 [8192/14860 (55%)]\tLoss: 0.025042\n",
      "Train Epoch: 80 [8320/14860 (56%)]\tLoss: 0.016543\n",
      "Train Epoch: 80 [8448/14860 (56%)]\tLoss: 0.016954\n",
      "Train Epoch: 80 [8576/14860 (57%)]\tLoss: 0.026943\n",
      "Train Epoch: 80 [8704/14860 (58%)]\tLoss: 0.017637\n",
      "Train Epoch: 80 [8832/14860 (59%)]\tLoss: 0.030436\n",
      "Train Epoch: 80 [8960/14860 (60%)]\tLoss: 0.019192\n",
      "Train Epoch: 80 [9088/14860 (61%)]\tLoss: 0.021233\n",
      "Train Epoch: 80 [9216/14860 (62%)]\tLoss: 0.027225\n",
      "Train Epoch: 80 [9344/14860 (62%)]\tLoss: 0.018840\n",
      "Train Epoch: 80 [9472/14860 (63%)]\tLoss: 0.019326\n",
      "Train Epoch: 80 [9600/14860 (64%)]\tLoss: 0.019639\n",
      "Train Epoch: 80 [9728/14860 (65%)]\tLoss: 0.018759\n",
      "Train Epoch: 80 [9856/14860 (66%)]\tLoss: 0.024824\n",
      "Train Epoch: 80 [9984/14860 (67%)]\tLoss: 0.022458\n",
      "Train Epoch: 80 [10112/14860 (68%)]\tLoss: 0.024729\n",
      "Train Epoch: 80 [10240/14860 (68%)]\tLoss: 0.023297\n",
      "Train Epoch: 80 [10368/14860 (69%)]\tLoss: 0.016078\n",
      "Train Epoch: 80 [10496/14860 (70%)]\tLoss: 0.011680\n",
      "Train Epoch: 80 [10624/14860 (71%)]\tLoss: 0.014090\n",
      "Train Epoch: 80 [10752/14860 (72%)]\tLoss: 0.021929\n",
      "Train Epoch: 80 [10880/14860 (73%)]\tLoss: 0.020444\n",
      "Train Epoch: 80 [11008/14860 (74%)]\tLoss: 0.019106\n",
      "Train Epoch: 80 [11136/14860 (74%)]\tLoss: 0.013690\n",
      "Train Epoch: 80 [11264/14860 (75%)]\tLoss: 0.025907\n",
      "Train Epoch: 80 [11392/14860 (76%)]\tLoss: 0.017701\n",
      "Train Epoch: 80 [11520/14860 (77%)]\tLoss: 0.018900\n",
      "Train Epoch: 80 [11648/14860 (78%)]\tLoss: 0.019068\n",
      "Train Epoch: 80 [11776/14860 (79%)]\tLoss: 0.015000\n",
      "Train Epoch: 80 [11904/14860 (79%)]\tLoss: 0.015120\n",
      "Train Epoch: 80 [12032/14860 (80%)]\tLoss: 0.020660\n",
      "Train Epoch: 80 [12160/14860 (81%)]\tLoss: 0.025025\n",
      "Train Epoch: 80 [12288/14860 (82%)]\tLoss: 0.017138\n",
      "Train Epoch: 80 [12416/14860 (83%)]\tLoss: 0.022598\n",
      "Train Epoch: 80 [12544/14860 (84%)]\tLoss: 0.016807\n",
      "Train Epoch: 80 [12672/14860 (85%)]\tLoss: 0.018913\n",
      "Train Epoch: 80 [12800/14860 (85%)]\tLoss: 0.022521\n",
      "Train Epoch: 80 [12928/14860 (86%)]\tLoss: 0.020485\n",
      "Train Epoch: 80 [13056/14860 (87%)]\tLoss: 0.014707\n",
      "Train Epoch: 80 [13184/14860 (88%)]\tLoss: 0.023528\n",
      "Train Epoch: 80 [13312/14860 (89%)]\tLoss: 0.018127\n",
      "Train Epoch: 80 [13440/14860 (90%)]\tLoss: 0.020106\n",
      "Train Epoch: 80 [13568/14860 (91%)]\tLoss: 0.011105\n",
      "Train Epoch: 80 [13696/14860 (91%)]\tLoss: 0.014049\n",
      "Train Epoch: 80 [13824/14860 (92%)]\tLoss: 0.019548\n",
      "Train Epoch: 80 [13952/14860 (93%)]\tLoss: 0.018972\n",
      "Train Epoch: 80 [14080/14860 (94%)]\tLoss: 0.021423\n",
      "Train Epoch: 80 [14208/14860 (95%)]\tLoss: 0.014930\n",
      "Train Epoch: 80 [14336/14860 (96%)]\tLoss: 0.020809\n",
      "Train Epoch: 80 [14464/14860 (97%)]\tLoss: 0.019282\n",
      "Train Epoch: 80 [14592/14860 (97%)]\tLoss: 0.026143\n",
      "Train Epoch: 80 [14720/14860 (98%)]\tLoss: 0.020282\n",
      "Train Epoch: 80 [1392/14860 (99%)]\tLoss: 0.041375\n",
      "epoch 80 training loss: 0.020843256631086014\n",
      "epoch 80 validation loss: 0.030903704518556018\n",
      "Train Epoch: 81 [0/14860 (0%)]\tLoss: 0.030541\n",
      "Train Epoch: 81 [128/14860 (1%)]\tLoss: 0.022067\n",
      "Train Epoch: 81 [256/14860 (2%)]\tLoss: 0.026487\n",
      "Train Epoch: 81 [384/14860 (3%)]\tLoss: 0.020724\n",
      "Train Epoch: 81 [512/14860 (3%)]\tLoss: 0.021894\n",
      "Train Epoch: 81 [640/14860 (4%)]\tLoss: 0.029715\n",
      "Train Epoch: 81 [768/14860 (5%)]\tLoss: 0.023199\n",
      "Train Epoch: 81 [896/14860 (6%)]\tLoss: 0.029866\n",
      "Train Epoch: 81 [1024/14860 (7%)]\tLoss: 0.014449\n",
      "Train Epoch: 81 [1152/14860 (8%)]\tLoss: 0.018505\n",
      "Train Epoch: 81 [1280/14860 (9%)]\tLoss: 0.026791\n",
      "Train Epoch: 81 [1408/14860 (9%)]\tLoss: 0.026433\n",
      "Train Epoch: 81 [1536/14860 (10%)]\tLoss: 0.023460\n",
      "Train Epoch: 81 [1664/14860 (11%)]\tLoss: 0.026195\n",
      "Train Epoch: 81 [1792/14860 (12%)]\tLoss: 0.020598\n",
      "Train Epoch: 81 [1920/14860 (13%)]\tLoss: 0.026226\n",
      "Train Epoch: 81 [2048/14860 (14%)]\tLoss: 0.019716\n",
      "Train Epoch: 81 [2176/14860 (15%)]\tLoss: 0.022160\n",
      "Train Epoch: 81 [2304/14860 (15%)]\tLoss: 0.023258\n",
      "Train Epoch: 81 [2432/14860 (16%)]\tLoss: 0.013130\n",
      "Train Epoch: 81 [2560/14860 (17%)]\tLoss: 0.017734\n",
      "Train Epoch: 81 [2688/14860 (18%)]\tLoss: 0.028911\n",
      "Train Epoch: 81 [2816/14860 (19%)]\tLoss: 0.018306\n",
      "Train Epoch: 81 [2944/14860 (20%)]\tLoss: 0.021431\n",
      "Train Epoch: 81 [3072/14860 (21%)]\tLoss: 0.019035\n",
      "Train Epoch: 81 [3200/14860 (21%)]\tLoss: 0.018622\n",
      "Train Epoch: 81 [3328/14860 (22%)]\tLoss: 0.019950\n",
      "Train Epoch: 81 [3456/14860 (23%)]\tLoss: 0.011772\n",
      "Train Epoch: 81 [3584/14860 (24%)]\tLoss: 0.026253\n",
      "Train Epoch: 81 [3712/14860 (25%)]\tLoss: 0.020399\n",
      "Train Epoch: 81 [3840/14860 (26%)]\tLoss: 0.012496\n",
      "Train Epoch: 81 [3968/14860 (26%)]\tLoss: 0.029076\n",
      "Train Epoch: 81 [4096/14860 (27%)]\tLoss: 0.015125\n",
      "Train Epoch: 81 [4224/14860 (28%)]\tLoss: 0.024896\n",
      "Train Epoch: 81 [4352/14860 (29%)]\tLoss: 0.023207\n",
      "Train Epoch: 81 [4480/14860 (30%)]\tLoss: 0.016814\n",
      "Train Epoch: 81 [4608/14860 (31%)]\tLoss: 0.025459\n",
      "Train Epoch: 81 [4736/14860 (32%)]\tLoss: 0.018625\n",
      "Train Epoch: 81 [4864/14860 (32%)]\tLoss: 0.018406\n",
      "Train Epoch: 81 [4992/14860 (33%)]\tLoss: 0.016145\n",
      "Train Epoch: 81 [5120/14860 (34%)]\tLoss: 0.017612\n",
      "Train Epoch: 81 [5248/14860 (35%)]\tLoss: 0.032093\n",
      "Train Epoch: 81 [5376/14860 (36%)]\tLoss: 0.020577\n",
      "Train Epoch: 81 [5504/14860 (37%)]\tLoss: 0.016754\n",
      "Train Epoch: 81 [5632/14860 (38%)]\tLoss: 0.016790\n",
      "Train Epoch: 81 [5760/14860 (38%)]\tLoss: 0.017658\n",
      "Train Epoch: 81 [5888/14860 (39%)]\tLoss: 0.020729\n",
      "Train Epoch: 81 [6016/14860 (40%)]\tLoss: 0.023072\n",
      "Train Epoch: 81 [6144/14860 (41%)]\tLoss: 0.014834\n",
      "Train Epoch: 81 [6272/14860 (42%)]\tLoss: 0.022818\n",
      "Train Epoch: 81 [6400/14860 (43%)]\tLoss: 0.017220\n",
      "Train Epoch: 81 [6528/14860 (44%)]\tLoss: 0.016134\n",
      "Train Epoch: 81 [6656/14860 (44%)]\tLoss: 0.023496\n",
      "Train Epoch: 81 [6784/14860 (45%)]\tLoss: 0.013100\n",
      "Train Epoch: 81 [6912/14860 (46%)]\tLoss: 0.020228\n",
      "Train Epoch: 81 [7040/14860 (47%)]\tLoss: 0.014108\n",
      "Train Epoch: 81 [7168/14860 (48%)]\tLoss: 0.020607\n",
      "Train Epoch: 81 [7296/14860 (49%)]\tLoss: 0.019619\n",
      "Train Epoch: 81 [7424/14860 (50%)]\tLoss: 0.025548\n",
      "Train Epoch: 81 [7552/14860 (50%)]\tLoss: 0.013696\n",
      "Train Epoch: 81 [7680/14860 (51%)]\tLoss: 0.031090\n",
      "Train Epoch: 81 [7808/14860 (52%)]\tLoss: 0.018146\n",
      "Train Epoch: 81 [7936/14860 (53%)]\tLoss: 0.019373\n",
      "Train Epoch: 81 [8064/14860 (54%)]\tLoss: 0.017849\n",
      "Train Epoch: 81 [8192/14860 (55%)]\tLoss: 0.025203\n",
      "Train Epoch: 81 [8320/14860 (56%)]\tLoss: 0.018252\n",
      "Train Epoch: 81 [8448/14860 (56%)]\tLoss: 0.024446\n",
      "Train Epoch: 81 [8576/14860 (57%)]\tLoss: 0.017976\n",
      "Train Epoch: 81 [8704/14860 (58%)]\tLoss: 0.022551\n",
      "Train Epoch: 81 [8832/14860 (59%)]\tLoss: 0.016863\n",
      "Train Epoch: 81 [8960/14860 (60%)]\tLoss: 0.019277\n",
      "Train Epoch: 81 [9088/14860 (61%)]\tLoss: 0.013816\n",
      "Train Epoch: 81 [9216/14860 (62%)]\tLoss: 0.021591\n",
      "Train Epoch: 81 [9344/14860 (62%)]\tLoss: 0.014292\n",
      "Train Epoch: 81 [9472/14860 (63%)]\tLoss: 0.018696\n",
      "Train Epoch: 81 [9600/14860 (64%)]\tLoss: 0.020411\n",
      "Train Epoch: 81 [9728/14860 (65%)]\tLoss: 0.030203\n",
      "Train Epoch: 81 [9856/14860 (66%)]\tLoss: 0.023334\n",
      "Train Epoch: 81 [9984/14860 (67%)]\tLoss: 0.016596\n",
      "Train Epoch: 81 [10112/14860 (68%)]\tLoss: 0.020638\n",
      "Train Epoch: 81 [10240/14860 (68%)]\tLoss: 0.022230\n",
      "Train Epoch: 81 [10368/14860 (69%)]\tLoss: 0.022483\n",
      "Train Epoch: 81 [10496/14860 (70%)]\tLoss: 0.022364\n",
      "Train Epoch: 81 [10624/14860 (71%)]\tLoss: 0.017338\n",
      "Train Epoch: 81 [10752/14860 (72%)]\tLoss: 0.010655\n",
      "Train Epoch: 81 [10880/14860 (73%)]\tLoss: 0.017627\n",
      "Train Epoch: 81 [11008/14860 (74%)]\tLoss: 0.013798\n",
      "Train Epoch: 81 [11136/14860 (74%)]\tLoss: 0.016427\n",
      "Train Epoch: 81 [11264/14860 (75%)]\tLoss: 0.019029\n",
      "Train Epoch: 81 [11392/14860 (76%)]\tLoss: 0.031977\n",
      "Train Epoch: 81 [11520/14860 (77%)]\tLoss: 0.028992\n",
      "Train Epoch: 81 [11648/14860 (78%)]\tLoss: 0.033484\n",
      "Train Epoch: 81 [11776/14860 (79%)]\tLoss: 0.043895\n",
      "Train Epoch: 81 [11904/14860 (79%)]\tLoss: 0.028557\n",
      "Train Epoch: 81 [12032/14860 (80%)]\tLoss: 0.018438\n",
      "Train Epoch: 81 [12160/14860 (81%)]\tLoss: 0.020575\n",
      "Train Epoch: 81 [12288/14860 (82%)]\tLoss: 0.023239\n",
      "Train Epoch: 81 [12416/14860 (83%)]\tLoss: 0.025614\n",
      "Train Epoch: 81 [12544/14860 (84%)]\tLoss: 0.026278\n",
      "Train Epoch: 81 [12672/14860 (85%)]\tLoss: 0.019837\n",
      "Train Epoch: 81 [12800/14860 (85%)]\tLoss: 0.024202\n",
      "Train Epoch: 81 [12928/14860 (86%)]\tLoss: 0.024276\n",
      "Train Epoch: 81 [13056/14860 (87%)]\tLoss: 0.026985\n",
      "Train Epoch: 81 [13184/14860 (88%)]\tLoss: 0.014436\n",
      "Train Epoch: 81 [13312/14860 (89%)]\tLoss: 0.028451\n",
      "Train Epoch: 81 [13440/14860 (90%)]\tLoss: 0.019806\n",
      "Train Epoch: 81 [13568/14860 (91%)]\tLoss: 0.016726\n",
      "Train Epoch: 81 [13696/14860 (91%)]\tLoss: 0.016658\n",
      "Train Epoch: 81 [13824/14860 (92%)]\tLoss: 0.019431\n",
      "Train Epoch: 81 [13952/14860 (93%)]\tLoss: 0.026100\n",
      "Train Epoch: 81 [14080/14860 (94%)]\tLoss: 0.019125\n",
      "Train Epoch: 81 [14208/14860 (95%)]\tLoss: 0.019177\n",
      "Train Epoch: 81 [14336/14860 (96%)]\tLoss: 0.017558\n",
      "Train Epoch: 81 [14464/14860 (97%)]\tLoss: 0.026563\n",
      "Train Epoch: 81 [14592/14860 (97%)]\tLoss: 0.022760\n",
      "Train Epoch: 81 [14720/14860 (98%)]\tLoss: 0.022681\n",
      "Train Epoch: 81 [1392/14860 (99%)]\tLoss: 0.009113\n",
      "epoch 81 training loss: 0.02121590372397859\n",
      "epoch 81 validation loss: 0.021917257701513555\n",
      "Train Epoch: 82 [0/14860 (0%)]\tLoss: 0.016953\n",
      "Train Epoch: 82 [128/14860 (1%)]\tLoss: 0.027168\n",
      "Train Epoch: 82 [256/14860 (2%)]\tLoss: 0.016527\n",
      "Train Epoch: 82 [384/14860 (3%)]\tLoss: 0.028488\n",
      "Train Epoch: 82 [512/14860 (3%)]\tLoss: 0.020041\n",
      "Train Epoch: 82 [640/14860 (4%)]\tLoss: 0.021037\n",
      "Train Epoch: 82 [768/14860 (5%)]\tLoss: 0.025878\n",
      "Train Epoch: 82 [896/14860 (6%)]\tLoss: 0.024123\n",
      "Train Epoch: 82 [1024/14860 (7%)]\tLoss: 0.016404\n",
      "Train Epoch: 82 [1152/14860 (8%)]\tLoss: 0.025363\n",
      "Train Epoch: 82 [1280/14860 (9%)]\tLoss: 0.027239\n",
      "Train Epoch: 82 [1408/14860 (9%)]\tLoss: 0.015536\n",
      "Train Epoch: 82 [1536/14860 (10%)]\tLoss: 0.027914\n",
      "Train Epoch: 82 [1664/14860 (11%)]\tLoss: 0.022303\n",
      "Train Epoch: 82 [1792/14860 (12%)]\tLoss: 0.021481\n",
      "Train Epoch: 82 [1920/14860 (13%)]\tLoss: 0.020310\n",
      "Train Epoch: 82 [2048/14860 (14%)]\tLoss: 0.019985\n",
      "Train Epoch: 82 [2176/14860 (15%)]\tLoss: 0.020341\n",
      "Train Epoch: 82 [2304/14860 (15%)]\tLoss: 0.020602\n",
      "Train Epoch: 82 [2432/14860 (16%)]\tLoss: 0.018693\n",
      "Train Epoch: 82 [2560/14860 (17%)]\tLoss: 0.014957\n",
      "Train Epoch: 82 [2688/14860 (18%)]\tLoss: 0.017195\n",
      "Train Epoch: 82 [2816/14860 (19%)]\tLoss: 0.019698\n",
      "Train Epoch: 82 [2944/14860 (20%)]\tLoss: 0.016370\n",
      "Train Epoch: 82 [3072/14860 (21%)]\tLoss: 0.016115\n",
      "Train Epoch: 82 [3200/14860 (21%)]\tLoss: 0.020077\n",
      "Train Epoch: 82 [3328/14860 (22%)]\tLoss: 0.014837\n",
      "Train Epoch: 82 [3456/14860 (23%)]\tLoss: 0.021495\n",
      "Train Epoch: 82 [3584/14860 (24%)]\tLoss: 0.023188\n",
      "Train Epoch: 82 [3712/14860 (25%)]\tLoss: 0.023184\n",
      "Train Epoch: 82 [3840/14860 (26%)]\tLoss: 0.024160\n",
      "Train Epoch: 82 [3968/14860 (26%)]\tLoss: 0.017435\n",
      "Train Epoch: 82 [4096/14860 (27%)]\tLoss: 0.030866\n",
      "Train Epoch: 82 [4224/14860 (28%)]\tLoss: 0.021983\n",
      "Train Epoch: 82 [4352/14860 (29%)]\tLoss: 0.022200\n",
      "Train Epoch: 82 [4480/14860 (30%)]\tLoss: 0.019550\n",
      "Train Epoch: 82 [4608/14860 (31%)]\tLoss: 0.017775\n",
      "Train Epoch: 82 [4736/14860 (32%)]\tLoss: 0.025921\n",
      "Train Epoch: 82 [4864/14860 (32%)]\tLoss: 0.013017\n",
      "Train Epoch: 82 [4992/14860 (33%)]\tLoss: 0.021830\n",
      "Train Epoch: 82 [5120/14860 (34%)]\tLoss: 0.022963\n",
      "Train Epoch: 82 [5248/14860 (35%)]\tLoss: 0.022686\n",
      "Train Epoch: 82 [5376/14860 (36%)]\tLoss: 0.016960\n",
      "Train Epoch: 82 [5504/14860 (37%)]\tLoss: 0.023017\n",
      "Train Epoch: 82 [5632/14860 (38%)]\tLoss: 0.019244\n",
      "Train Epoch: 82 [5760/14860 (38%)]\tLoss: 0.023697\n",
      "Train Epoch: 82 [5888/14860 (39%)]\tLoss: 0.017881\n",
      "Train Epoch: 82 [6016/14860 (40%)]\tLoss: 0.019888\n",
      "Train Epoch: 82 [6144/14860 (41%)]\tLoss: 0.021997\n",
      "Train Epoch: 82 [6272/14860 (42%)]\tLoss: 0.017557\n",
      "Train Epoch: 82 [6400/14860 (43%)]\tLoss: 0.015325\n",
      "Train Epoch: 82 [6528/14860 (44%)]\tLoss: 0.021474\n",
      "Train Epoch: 82 [6656/14860 (44%)]\tLoss: 0.018281\n",
      "Train Epoch: 82 [6784/14860 (45%)]\tLoss: 0.028038\n",
      "Train Epoch: 82 [6912/14860 (46%)]\tLoss: 0.021286\n",
      "Train Epoch: 82 [7040/14860 (47%)]\tLoss: 0.019440\n",
      "Train Epoch: 82 [7168/14860 (48%)]\tLoss: 0.020874\n",
      "Train Epoch: 82 [7296/14860 (49%)]\tLoss: 0.019725\n",
      "Train Epoch: 82 [7424/14860 (50%)]\tLoss: 0.016863\n",
      "Train Epoch: 82 [7552/14860 (50%)]\tLoss: 0.025676\n",
      "Train Epoch: 82 [7680/14860 (51%)]\tLoss: 0.018988\n",
      "Train Epoch: 82 [7808/14860 (52%)]\tLoss: 0.034577\n",
      "Train Epoch: 82 [7936/14860 (53%)]\tLoss: 0.019573\n",
      "Train Epoch: 82 [8064/14860 (54%)]\tLoss: 0.017584\n",
      "Train Epoch: 82 [8192/14860 (55%)]\tLoss: 0.024674\n",
      "Train Epoch: 82 [8320/14860 (56%)]\tLoss: 0.020816\n",
      "Train Epoch: 82 [8448/14860 (56%)]\tLoss: 0.029009\n",
      "Train Epoch: 82 [8576/14860 (57%)]\tLoss: 0.014497\n",
      "Train Epoch: 82 [8704/14860 (58%)]\tLoss: 0.021873\n",
      "Train Epoch: 82 [8832/14860 (59%)]\tLoss: 0.021553\n",
      "Train Epoch: 82 [8960/14860 (60%)]\tLoss: 0.026382\n",
      "Train Epoch: 82 [9088/14860 (61%)]\tLoss: 0.017856\n",
      "Train Epoch: 82 [9216/14860 (62%)]\tLoss: 0.026044\n",
      "Train Epoch: 82 [9344/14860 (62%)]\tLoss: 0.018362\n",
      "Train Epoch: 82 [9472/14860 (63%)]\tLoss: 0.021949\n",
      "Train Epoch: 82 [9600/14860 (64%)]\tLoss: 0.022295\n",
      "Train Epoch: 82 [9728/14860 (65%)]\tLoss: 0.022818\n",
      "Train Epoch: 82 [9856/14860 (66%)]\tLoss: 0.022251\n",
      "Train Epoch: 82 [9984/14860 (67%)]\tLoss: 0.015707\n",
      "Train Epoch: 82 [10112/14860 (68%)]\tLoss: 0.023992\n",
      "Train Epoch: 82 [10240/14860 (68%)]\tLoss: 0.016675\n",
      "Train Epoch: 82 [10368/14860 (69%)]\tLoss: 0.021718\n",
      "Train Epoch: 82 [10496/14860 (70%)]\tLoss: 0.016465\n",
      "Train Epoch: 82 [10624/14860 (71%)]\tLoss: 0.021539\n",
      "Train Epoch: 82 [10752/14860 (72%)]\tLoss: 0.024895\n",
      "Train Epoch: 82 [10880/14860 (73%)]\tLoss: 0.020169\n",
      "Train Epoch: 82 [11008/14860 (74%)]\tLoss: 0.026889\n",
      "Train Epoch: 82 [11136/14860 (74%)]\tLoss: 0.024255\n",
      "Train Epoch: 82 [11264/14860 (75%)]\tLoss: 0.022840\n",
      "Train Epoch: 82 [11392/14860 (76%)]\tLoss: 0.013697\n",
      "Train Epoch: 82 [11520/14860 (77%)]\tLoss: 0.019455\n",
      "Train Epoch: 82 [11648/14860 (78%)]\tLoss: 0.020126\n",
      "Train Epoch: 82 [11776/14860 (79%)]\tLoss: 0.026591\n",
      "Train Epoch: 82 [11904/14860 (79%)]\tLoss: 0.020511\n",
      "Train Epoch: 82 [12032/14860 (80%)]\tLoss: 0.020443\n",
      "Train Epoch: 82 [12160/14860 (81%)]\tLoss: 0.020173\n",
      "Train Epoch: 82 [12288/14860 (82%)]\tLoss: 0.020527\n",
      "Train Epoch: 82 [12416/14860 (83%)]\tLoss: 0.019843\n",
      "Train Epoch: 82 [12544/14860 (84%)]\tLoss: 0.016659\n",
      "Train Epoch: 82 [12672/14860 (85%)]\tLoss: 0.018138\n",
      "Train Epoch: 82 [12800/14860 (85%)]\tLoss: 0.020437\n",
      "Train Epoch: 82 [12928/14860 (86%)]\tLoss: 0.013290\n",
      "Train Epoch: 82 [13056/14860 (87%)]\tLoss: 0.011260\n",
      "Train Epoch: 82 [13184/14860 (88%)]\tLoss: 0.023463\n",
      "Train Epoch: 82 [13312/14860 (89%)]\tLoss: 0.022565\n",
      "Train Epoch: 82 [13440/14860 (90%)]\tLoss: 0.023863\n",
      "Train Epoch: 82 [13568/14860 (91%)]\tLoss: 0.017252\n",
      "Train Epoch: 82 [13696/14860 (91%)]\tLoss: 0.018660\n",
      "Train Epoch: 82 [13824/14860 (92%)]\tLoss: 0.016445\n",
      "Train Epoch: 82 [13952/14860 (93%)]\tLoss: 0.030303\n",
      "Train Epoch: 82 [14080/14860 (94%)]\tLoss: 0.025695\n",
      "Train Epoch: 82 [14208/14860 (95%)]\tLoss: 0.023270\n",
      "Train Epoch: 82 [14336/14860 (96%)]\tLoss: 0.018956\n",
      "Train Epoch: 82 [14464/14860 (97%)]\tLoss: 0.021054\n",
      "Train Epoch: 82 [14592/14860 (97%)]\tLoss: 0.023796\n",
      "Train Epoch: 82 [14720/14860 (98%)]\tLoss: 0.023518\n",
      "Train Epoch: 82 [1392/14860 (99%)]\tLoss: 0.017411\n",
      "epoch 82 training loss: 0.020980794595665913\n",
      "epoch 82 validation loss: 0.024924225004764215\n",
      "Train Epoch: 83 [0/14860 (0%)]\tLoss: 0.030053\n",
      "Train Epoch: 83 [128/14860 (1%)]\tLoss: 0.013674\n",
      "Train Epoch: 83 [256/14860 (2%)]\tLoss: 0.022699\n",
      "Train Epoch: 83 [384/14860 (3%)]\tLoss: 0.016459\n",
      "Train Epoch: 83 [512/14860 (3%)]\tLoss: 0.014328\n",
      "Train Epoch: 83 [640/14860 (4%)]\tLoss: 0.017492\n",
      "Train Epoch: 83 [768/14860 (5%)]\tLoss: 0.025404\n",
      "Train Epoch: 83 [896/14860 (6%)]\tLoss: 0.019161\n",
      "Train Epoch: 83 [1024/14860 (7%)]\tLoss: 0.017658\n",
      "Train Epoch: 83 [1152/14860 (8%)]\tLoss: 0.020435\n",
      "Train Epoch: 83 [1280/14860 (9%)]\tLoss: 0.017853\n",
      "Train Epoch: 83 [1408/14860 (9%)]\tLoss: 0.027141\n",
      "Train Epoch: 83 [1536/14860 (10%)]\tLoss: 0.026322\n",
      "Train Epoch: 83 [1664/14860 (11%)]\tLoss: 0.022151\n",
      "Train Epoch: 83 [1792/14860 (12%)]\tLoss: 0.024944\n",
      "Train Epoch: 83 [1920/14860 (13%)]\tLoss: 0.025179\n",
      "Train Epoch: 83 [2048/14860 (14%)]\tLoss: 0.017295\n",
      "Train Epoch: 83 [2176/14860 (15%)]\tLoss: 0.026779\n",
      "Train Epoch: 83 [2304/14860 (15%)]\tLoss: 0.020691\n",
      "Train Epoch: 83 [2432/14860 (16%)]\tLoss: 0.019902\n",
      "Train Epoch: 83 [2560/14860 (17%)]\tLoss: 0.019016\n",
      "Train Epoch: 83 [2688/14860 (18%)]\tLoss: 0.014444\n",
      "Train Epoch: 83 [2816/14860 (19%)]\tLoss: 0.026001\n",
      "Train Epoch: 83 [2944/14860 (20%)]\tLoss: 0.022163\n",
      "Train Epoch: 83 [3072/14860 (21%)]\tLoss: 0.025339\n",
      "Train Epoch: 83 [3200/14860 (21%)]\tLoss: 0.019704\n",
      "Train Epoch: 83 [3328/14860 (22%)]\tLoss: 0.023377\n",
      "Train Epoch: 83 [3456/14860 (23%)]\tLoss: 0.034029\n",
      "Train Epoch: 83 [3584/14860 (24%)]\tLoss: 0.020012\n",
      "Train Epoch: 83 [3712/14860 (25%)]\tLoss: 0.044136\n",
      "Train Epoch: 83 [3840/14860 (26%)]\tLoss: 0.023284\n",
      "Train Epoch: 83 [3968/14860 (26%)]\tLoss: 0.021399\n",
      "Train Epoch: 83 [4096/14860 (27%)]\tLoss: 0.031210\n",
      "Train Epoch: 83 [4224/14860 (28%)]\tLoss: 0.024269\n",
      "Train Epoch: 83 [4352/14860 (29%)]\tLoss: 0.025463\n",
      "Train Epoch: 83 [4480/14860 (30%)]\tLoss: 0.017722\n",
      "Train Epoch: 83 [4608/14860 (31%)]\tLoss: 0.021479\n",
      "Train Epoch: 83 [4736/14860 (32%)]\tLoss: 0.020926\n",
      "Train Epoch: 83 [4864/14860 (32%)]\tLoss: 0.023865\n",
      "Train Epoch: 83 [4992/14860 (33%)]\tLoss: 0.014695\n",
      "Train Epoch: 83 [5120/14860 (34%)]\tLoss: 0.021281\n",
      "Train Epoch: 83 [5248/14860 (35%)]\tLoss: 0.019006\n",
      "Train Epoch: 83 [5376/14860 (36%)]\tLoss: 0.029099\n",
      "Train Epoch: 83 [5504/14860 (37%)]\tLoss: 0.026776\n",
      "Train Epoch: 83 [5632/14860 (38%)]\tLoss: 0.020282\n",
      "Train Epoch: 83 [5760/14860 (38%)]\tLoss: 0.018389\n",
      "Train Epoch: 83 [5888/14860 (39%)]\tLoss: 0.028679\n",
      "Train Epoch: 83 [6016/14860 (40%)]\tLoss: 0.016993\n",
      "Train Epoch: 83 [6144/14860 (41%)]\tLoss: 0.019341\n",
      "Train Epoch: 83 [6272/14860 (42%)]\tLoss: 0.024390\n",
      "Train Epoch: 83 [6400/14860 (43%)]\tLoss: 0.019096\n",
      "Train Epoch: 83 [6528/14860 (44%)]\tLoss: 0.025699\n",
      "Train Epoch: 83 [6656/14860 (44%)]\tLoss: 0.032826\n",
      "Train Epoch: 83 [6784/14860 (45%)]\tLoss: 0.019914\n",
      "Train Epoch: 83 [6912/14860 (46%)]\tLoss: 0.033273\n",
      "Train Epoch: 83 [7040/14860 (47%)]\tLoss: 0.028736\n",
      "Train Epoch: 83 [7168/14860 (48%)]\tLoss: 0.019968\n",
      "Train Epoch: 83 [7296/14860 (49%)]\tLoss: 0.023122\n",
      "Train Epoch: 83 [7424/14860 (50%)]\tLoss: 0.022776\n",
      "Train Epoch: 83 [7552/14860 (50%)]\tLoss: 0.016022\n",
      "Train Epoch: 83 [7680/14860 (51%)]\tLoss: 0.027872\n",
      "Train Epoch: 83 [7808/14860 (52%)]\tLoss: 0.021741\n",
      "Train Epoch: 83 [7936/14860 (53%)]\tLoss: 0.024584\n",
      "Train Epoch: 83 [8064/14860 (54%)]\tLoss: 0.018635\n",
      "Train Epoch: 83 [8192/14860 (55%)]\tLoss: 0.017477\n",
      "Train Epoch: 83 [8320/14860 (56%)]\tLoss: 0.016788\n",
      "Train Epoch: 83 [8448/14860 (56%)]\tLoss: 0.019450\n",
      "Train Epoch: 83 [8576/14860 (57%)]\tLoss: 0.019977\n",
      "Train Epoch: 83 [8704/14860 (58%)]\tLoss: 0.025021\n",
      "Train Epoch: 83 [8832/14860 (59%)]\tLoss: 0.018753\n",
      "Train Epoch: 83 [8960/14860 (60%)]\tLoss: 0.016674\n",
      "Train Epoch: 83 [9088/14860 (61%)]\tLoss: 0.028099\n",
      "Train Epoch: 83 [9216/14860 (62%)]\tLoss: 0.023248\n",
      "Train Epoch: 83 [9344/14860 (62%)]\tLoss: 0.020643\n",
      "Train Epoch: 83 [9472/14860 (63%)]\tLoss: 0.015221\n",
      "Train Epoch: 83 [9600/14860 (64%)]\tLoss: 0.025922\n",
      "Train Epoch: 83 [9728/14860 (65%)]\tLoss: 0.016233\n",
      "Train Epoch: 83 [9856/14860 (66%)]\tLoss: 0.018620\n",
      "Train Epoch: 83 [9984/14860 (67%)]\tLoss: 0.020127\n",
      "Train Epoch: 83 [10112/14860 (68%)]\tLoss: 0.029707\n",
      "Train Epoch: 83 [10240/14860 (68%)]\tLoss: 0.027648\n",
      "Train Epoch: 83 [10368/14860 (69%)]\tLoss: 0.020715\n",
      "Train Epoch: 83 [10496/14860 (70%)]\tLoss: 0.021013\n",
      "Train Epoch: 83 [10624/14860 (71%)]\tLoss: 0.018286\n",
      "Train Epoch: 83 [10752/14860 (72%)]\tLoss: 0.024751\n",
      "Train Epoch: 83 [10880/14860 (73%)]\tLoss: 0.019517\n",
      "Train Epoch: 83 [11008/14860 (74%)]\tLoss: 0.024317\n",
      "Train Epoch: 83 [11136/14860 (74%)]\tLoss: 0.020411\n",
      "Train Epoch: 83 [11264/14860 (75%)]\tLoss: 0.027612\n",
      "Train Epoch: 83 [11392/14860 (76%)]\tLoss: 0.016893\n",
      "Train Epoch: 83 [11520/14860 (77%)]\tLoss: 0.017103\n",
      "Train Epoch: 83 [11648/14860 (78%)]\tLoss: 0.016496\n",
      "Train Epoch: 83 [11776/14860 (79%)]\tLoss: 0.017491\n",
      "Train Epoch: 83 [11904/14860 (79%)]\tLoss: 0.026147\n",
      "Train Epoch: 83 [12032/14860 (80%)]\tLoss: 0.018530\n",
      "Train Epoch: 83 [12160/14860 (81%)]\tLoss: 0.024860\n",
      "Train Epoch: 83 [12288/14860 (82%)]\tLoss: 0.020948\n",
      "Train Epoch: 83 [12416/14860 (83%)]\tLoss: 0.024192\n",
      "Train Epoch: 83 [12544/14860 (84%)]\tLoss: 0.020876\n",
      "Train Epoch: 83 [12672/14860 (85%)]\tLoss: 0.019392\n",
      "Train Epoch: 83 [12800/14860 (85%)]\tLoss: 0.017539\n",
      "Train Epoch: 83 [12928/14860 (86%)]\tLoss: 0.024272\n",
      "Train Epoch: 83 [13056/14860 (87%)]\tLoss: 0.016662\n",
      "Train Epoch: 83 [13184/14860 (88%)]\tLoss: 0.017357\n",
      "Train Epoch: 83 [13312/14860 (89%)]\tLoss: 0.016726\n",
      "Train Epoch: 83 [13440/14860 (90%)]\tLoss: 0.016638\n",
      "Train Epoch: 83 [13568/14860 (91%)]\tLoss: 0.012574\n",
      "Train Epoch: 83 [13696/14860 (91%)]\tLoss: 0.018808\n",
      "Train Epoch: 83 [13824/14860 (92%)]\tLoss: 0.024385\n",
      "Train Epoch: 83 [13952/14860 (93%)]\tLoss: 0.021880\n",
      "Train Epoch: 83 [14080/14860 (94%)]\tLoss: 0.022772\n",
      "Train Epoch: 83 [14208/14860 (95%)]\tLoss: 0.016281\n",
      "Train Epoch: 83 [14336/14860 (96%)]\tLoss: 0.019759\n",
      "Train Epoch: 83 [14464/14860 (97%)]\tLoss: 0.019610\n",
      "Train Epoch: 83 [14592/14860 (97%)]\tLoss: 0.017304\n",
      "Train Epoch: 83 [14720/14860 (98%)]\tLoss: 0.014752\n",
      "Train Epoch: 83 [1392/14860 (99%)]\tLoss: 0.008578\n",
      "epoch 83 training loss: 0.02155306976702478\n",
      "epoch 83 validation loss: 0.02067351095901563\n",
      "Train Epoch: 84 [0/14860 (0%)]\tLoss: 0.022251\n",
      "Train Epoch: 84 [128/14860 (1%)]\tLoss: 0.022176\n",
      "Train Epoch: 84 [256/14860 (2%)]\tLoss: 0.022053\n",
      "Train Epoch: 84 [384/14860 (3%)]\tLoss: 0.022898\n",
      "Train Epoch: 84 [512/14860 (3%)]\tLoss: 0.016057\n",
      "Train Epoch: 84 [640/14860 (4%)]\tLoss: 0.022894\n",
      "Train Epoch: 84 [768/14860 (5%)]\tLoss: 0.021943\n",
      "Train Epoch: 84 [896/14860 (6%)]\tLoss: 0.019364\n",
      "Train Epoch: 84 [1024/14860 (7%)]\tLoss: 0.016502\n",
      "Train Epoch: 84 [1152/14860 (8%)]\tLoss: 0.015924\n",
      "Train Epoch: 84 [1280/14860 (9%)]\tLoss: 0.020787\n",
      "Train Epoch: 84 [1408/14860 (9%)]\tLoss: 0.016792\n",
      "Train Epoch: 84 [1536/14860 (10%)]\tLoss: 0.020388\n",
      "Train Epoch: 84 [1664/14860 (11%)]\tLoss: 0.014806\n",
      "Train Epoch: 84 [1792/14860 (12%)]\tLoss: 0.020346\n",
      "Train Epoch: 84 [1920/14860 (13%)]\tLoss: 0.029416\n",
      "Train Epoch: 84 [2048/14860 (14%)]\tLoss: 0.028406\n",
      "Train Epoch: 84 [2176/14860 (15%)]\tLoss: 0.023112\n",
      "Train Epoch: 84 [2304/14860 (15%)]\tLoss: 0.018225\n",
      "Train Epoch: 84 [2432/14860 (16%)]\tLoss: 0.021715\n",
      "Train Epoch: 84 [2560/14860 (17%)]\tLoss: 0.027052\n",
      "Train Epoch: 84 [2688/14860 (18%)]\tLoss: 0.029710\n",
      "Train Epoch: 84 [2816/14860 (19%)]\tLoss: 0.019780\n",
      "Train Epoch: 84 [2944/14860 (20%)]\tLoss: 0.028625\n",
      "Train Epoch: 84 [3072/14860 (21%)]\tLoss: 0.026793\n",
      "Train Epoch: 84 [3200/14860 (21%)]\tLoss: 0.021670\n",
      "Train Epoch: 84 [3328/14860 (22%)]\tLoss: 0.021709\n",
      "Train Epoch: 84 [3456/14860 (23%)]\tLoss: 0.027266\n",
      "Train Epoch: 84 [3584/14860 (24%)]\tLoss: 0.022480\n",
      "Train Epoch: 84 [3712/14860 (25%)]\tLoss: 0.021025\n",
      "Train Epoch: 84 [3840/14860 (26%)]\tLoss: 0.024880\n",
      "Train Epoch: 84 [3968/14860 (26%)]\tLoss: 0.025930\n",
      "Train Epoch: 84 [4096/14860 (27%)]\tLoss: 0.029255\n",
      "Train Epoch: 84 [4224/14860 (28%)]\tLoss: 0.018270\n",
      "Train Epoch: 84 [4352/14860 (29%)]\tLoss: 0.017280\n",
      "Train Epoch: 84 [4480/14860 (30%)]\tLoss: 0.015064\n",
      "Train Epoch: 84 [4608/14860 (31%)]\tLoss: 0.020003\n",
      "Train Epoch: 84 [4736/14860 (32%)]\tLoss: 0.016588\n",
      "Train Epoch: 84 [4864/14860 (32%)]\tLoss: 0.016727\n",
      "Train Epoch: 84 [4992/14860 (33%)]\tLoss: 0.021437\n",
      "Train Epoch: 84 [5120/14860 (34%)]\tLoss: 0.015706\n",
      "Train Epoch: 84 [5248/14860 (35%)]\tLoss: 0.011456\n",
      "Train Epoch: 84 [5376/14860 (36%)]\tLoss: 0.021198\n",
      "Train Epoch: 84 [5504/14860 (37%)]\tLoss: 0.016995\n",
      "Train Epoch: 84 [5632/14860 (38%)]\tLoss: 0.017011\n",
      "Train Epoch: 84 [5760/14860 (38%)]\tLoss: 0.029147\n",
      "Train Epoch: 84 [5888/14860 (39%)]\tLoss: 0.019208\n",
      "Train Epoch: 84 [6016/14860 (40%)]\tLoss: 0.022685\n",
      "Train Epoch: 84 [6144/14860 (41%)]\tLoss: 0.020612\n",
      "Train Epoch: 84 [6272/14860 (42%)]\tLoss: 0.020950\n",
      "Train Epoch: 84 [6400/14860 (43%)]\tLoss: 0.023414\n",
      "Train Epoch: 84 [6528/14860 (44%)]\tLoss: 0.019622\n",
      "Train Epoch: 84 [6656/14860 (44%)]\tLoss: 0.020490\n",
      "Train Epoch: 84 [6784/14860 (45%)]\tLoss: 0.021549\n",
      "Train Epoch: 84 [6912/14860 (46%)]\tLoss: 0.020537\n",
      "Train Epoch: 84 [7040/14860 (47%)]\tLoss: 0.016291\n",
      "Train Epoch: 84 [7168/14860 (48%)]\tLoss: 0.022607\n",
      "Train Epoch: 84 [7296/14860 (49%)]\tLoss: 0.024232\n",
      "Train Epoch: 84 [7424/14860 (50%)]\tLoss: 0.021094\n",
      "Train Epoch: 84 [7552/14860 (50%)]\tLoss: 0.018822\n",
      "Train Epoch: 84 [7680/14860 (51%)]\tLoss: 0.018946\n",
      "Train Epoch: 84 [7808/14860 (52%)]\tLoss: 0.013269\n",
      "Train Epoch: 84 [7936/14860 (53%)]\tLoss: 0.018884\n",
      "Train Epoch: 84 [8064/14860 (54%)]\tLoss: 0.019941\n",
      "Train Epoch: 84 [8192/14860 (55%)]\tLoss: 0.021119\n",
      "Train Epoch: 84 [8320/14860 (56%)]\tLoss: 0.015564\n",
      "Train Epoch: 84 [8448/14860 (56%)]\tLoss: 0.023023\n",
      "Train Epoch: 84 [8576/14860 (57%)]\tLoss: 0.016410\n",
      "Train Epoch: 84 [8704/14860 (58%)]\tLoss: 0.022351\n",
      "Train Epoch: 84 [8832/14860 (59%)]\tLoss: 0.017715\n",
      "Train Epoch: 84 [8960/14860 (60%)]\tLoss: 0.019076\n",
      "Train Epoch: 84 [9088/14860 (61%)]\tLoss: 0.019295\n",
      "Train Epoch: 84 [9216/14860 (62%)]\tLoss: 0.022912\n",
      "Train Epoch: 84 [9344/14860 (62%)]\tLoss: 0.016934\n",
      "Train Epoch: 84 [9472/14860 (63%)]\tLoss: 0.025239\n",
      "Train Epoch: 84 [9600/14860 (64%)]\tLoss: 0.015970\n",
      "Train Epoch: 84 [9728/14860 (65%)]\tLoss: 0.017545\n",
      "Train Epoch: 84 [9856/14860 (66%)]\tLoss: 0.014737\n",
      "Train Epoch: 84 [9984/14860 (67%)]\tLoss: 0.017061\n",
      "Train Epoch: 84 [10112/14860 (68%)]\tLoss: 0.020510\n",
      "Train Epoch: 84 [10240/14860 (68%)]\tLoss: 0.025548\n",
      "Train Epoch: 84 [10368/14860 (69%)]\tLoss: 0.022801\n",
      "Train Epoch: 84 [10496/14860 (70%)]\tLoss: 0.018765\n",
      "Train Epoch: 84 [10624/14860 (71%)]\tLoss: 0.025647\n",
      "Train Epoch: 84 [10752/14860 (72%)]\tLoss: 0.025242\n",
      "Train Epoch: 84 [10880/14860 (73%)]\tLoss: 0.019296\n",
      "Train Epoch: 84 [11008/14860 (74%)]\tLoss: 0.023700\n",
      "Train Epoch: 84 [11136/14860 (74%)]\tLoss: 0.018845\n",
      "Train Epoch: 84 [11264/14860 (75%)]\tLoss: 0.016583\n",
      "Train Epoch: 84 [11392/14860 (76%)]\tLoss: 0.016028\n",
      "Train Epoch: 84 [11520/14860 (77%)]\tLoss: 0.012529\n",
      "Train Epoch: 84 [11648/14860 (78%)]\tLoss: 0.014211\n",
      "Train Epoch: 84 [11776/14860 (79%)]\tLoss: 0.017355\n",
      "Train Epoch: 84 [11904/14860 (79%)]\tLoss: 0.027608\n",
      "Train Epoch: 84 [12032/14860 (80%)]\tLoss: 0.022798\n",
      "Train Epoch: 84 [12160/14860 (81%)]\tLoss: 0.021762\n",
      "Train Epoch: 84 [12288/14860 (82%)]\tLoss: 0.013941\n",
      "Train Epoch: 84 [12416/14860 (83%)]\tLoss: 0.023941\n",
      "Train Epoch: 84 [12544/14860 (84%)]\tLoss: 0.017265\n",
      "Train Epoch: 84 [12672/14860 (85%)]\tLoss: 0.019748\n",
      "Train Epoch: 84 [12800/14860 (85%)]\tLoss: 0.018086\n",
      "Train Epoch: 84 [12928/14860 (86%)]\tLoss: 0.017731\n",
      "Train Epoch: 84 [13056/14860 (87%)]\tLoss: 0.023189\n",
      "Train Epoch: 84 [13184/14860 (88%)]\tLoss: 0.020152\n",
      "Train Epoch: 84 [13312/14860 (89%)]\tLoss: 0.016689\n",
      "Train Epoch: 84 [13440/14860 (90%)]\tLoss: 0.026399\n",
      "Train Epoch: 84 [13568/14860 (91%)]\tLoss: 0.013106\n",
      "Train Epoch: 84 [13696/14860 (91%)]\tLoss: 0.023188\n",
      "Train Epoch: 84 [13824/14860 (92%)]\tLoss: 0.018167\n",
      "Train Epoch: 84 [13952/14860 (93%)]\tLoss: 0.019143\n",
      "Train Epoch: 84 [14080/14860 (94%)]\tLoss: 0.019830\n",
      "Train Epoch: 84 [14208/14860 (95%)]\tLoss: 0.013757\n",
      "Train Epoch: 84 [14336/14860 (96%)]\tLoss: 0.019074\n",
      "Train Epoch: 84 [14464/14860 (97%)]\tLoss: 0.014949\n",
      "Train Epoch: 84 [14592/14860 (97%)]\tLoss: 0.017927\n",
      "Train Epoch: 84 [14720/14860 (98%)]\tLoss: 0.025267\n",
      "Train Epoch: 84 [1392/14860 (99%)]\tLoss: 0.030755\n",
      "epoch 84 training loss: 0.020416653635473844\n",
      "epoch 84 validation loss: 0.026372762482622346\n",
      "Train Epoch: 85 [0/14860 (0%)]\tLoss: 0.035644\n",
      "Train Epoch: 85 [128/14860 (1%)]\tLoss: 0.021648\n",
      "Train Epoch: 85 [256/14860 (2%)]\tLoss: 0.019959\n",
      "Train Epoch: 85 [384/14860 (3%)]\tLoss: 0.026983\n",
      "Train Epoch: 85 [512/14860 (3%)]\tLoss: 0.021355\n",
      "Train Epoch: 85 [640/14860 (4%)]\tLoss: 0.025985\n",
      "Train Epoch: 85 [768/14860 (5%)]\tLoss: 0.016989\n",
      "Train Epoch: 85 [896/14860 (6%)]\tLoss: 0.021096\n",
      "Train Epoch: 85 [1024/14860 (7%)]\tLoss: 0.020714\n",
      "Train Epoch: 85 [1152/14860 (8%)]\tLoss: 0.022209\n",
      "Train Epoch: 85 [1280/14860 (9%)]\tLoss: 0.029060\n",
      "Train Epoch: 85 [1408/14860 (9%)]\tLoss: 0.020131\n",
      "Train Epoch: 85 [1536/14860 (10%)]\tLoss: 0.020543\n",
      "Train Epoch: 85 [1664/14860 (11%)]\tLoss: 0.020924\n",
      "Train Epoch: 85 [1792/14860 (12%)]\tLoss: 0.020606\n",
      "Train Epoch: 85 [1920/14860 (13%)]\tLoss: 0.024787\n",
      "Train Epoch: 85 [2048/14860 (14%)]\tLoss: 0.015857\n",
      "Train Epoch: 85 [2176/14860 (15%)]\tLoss: 0.015626\n",
      "Train Epoch: 85 [2304/14860 (15%)]\tLoss: 0.023119\n",
      "Train Epoch: 85 [2432/14860 (16%)]\tLoss: 0.014515\n",
      "Train Epoch: 85 [2560/14860 (17%)]\tLoss: 0.023800\n",
      "Train Epoch: 85 [2688/14860 (18%)]\tLoss: 0.024630\n",
      "Train Epoch: 85 [2816/14860 (19%)]\tLoss: 0.023365\n",
      "Train Epoch: 85 [2944/14860 (20%)]\tLoss: 0.015282\n",
      "Train Epoch: 85 [3072/14860 (21%)]\tLoss: 0.025610\n",
      "Train Epoch: 85 [3200/14860 (21%)]\tLoss: 0.024923\n",
      "Train Epoch: 85 [3328/14860 (22%)]\tLoss: 0.017198\n",
      "Train Epoch: 85 [3456/14860 (23%)]\tLoss: 0.021703\n",
      "Train Epoch: 85 [3584/14860 (24%)]\tLoss: 0.016234\n",
      "Train Epoch: 85 [3712/14860 (25%)]\tLoss: 0.022036\n",
      "Train Epoch: 85 [3840/14860 (26%)]\tLoss: 0.020191\n",
      "Train Epoch: 85 [3968/14860 (26%)]\tLoss: 0.017295\n",
      "Train Epoch: 85 [4096/14860 (27%)]\tLoss: 0.028462\n",
      "Train Epoch: 85 [4224/14860 (28%)]\tLoss: 0.016723\n",
      "Train Epoch: 85 [4352/14860 (29%)]\tLoss: 0.019100\n",
      "Train Epoch: 85 [4480/14860 (30%)]\tLoss: 0.018109\n",
      "Train Epoch: 85 [4608/14860 (31%)]\tLoss: 0.018826\n",
      "Train Epoch: 85 [4736/14860 (32%)]\tLoss: 0.020456\n",
      "Train Epoch: 85 [4864/14860 (32%)]\tLoss: 0.019490\n",
      "Train Epoch: 85 [4992/14860 (33%)]\tLoss: 0.023300\n",
      "Train Epoch: 85 [5120/14860 (34%)]\tLoss: 0.019549\n",
      "Train Epoch: 85 [5248/14860 (35%)]\tLoss: 0.032651\n",
      "Train Epoch: 85 [5376/14860 (36%)]\tLoss: 0.014386\n",
      "Train Epoch: 85 [5504/14860 (37%)]\tLoss: 0.025579\n",
      "Train Epoch: 85 [5632/14860 (38%)]\tLoss: 0.019908\n",
      "Train Epoch: 85 [5760/14860 (38%)]\tLoss: 0.022262\n",
      "Train Epoch: 85 [5888/14860 (39%)]\tLoss: 0.022262\n",
      "Train Epoch: 85 [6016/14860 (40%)]\tLoss: 0.017026\n",
      "Train Epoch: 85 [6144/14860 (41%)]\tLoss: 0.023550\n",
      "Train Epoch: 85 [6272/14860 (42%)]\tLoss: 0.020086\n",
      "Train Epoch: 85 [6400/14860 (43%)]\tLoss: 0.022479\n",
      "Train Epoch: 85 [6528/14860 (44%)]\tLoss: 0.018371\n",
      "Train Epoch: 85 [6656/14860 (44%)]\tLoss: 0.016916\n",
      "Train Epoch: 85 [6784/14860 (45%)]\tLoss: 0.017651\n",
      "Train Epoch: 85 [6912/14860 (46%)]\tLoss: 0.018262\n",
      "Train Epoch: 85 [7040/14860 (47%)]\tLoss: 0.015135\n",
      "Train Epoch: 85 [7168/14860 (48%)]\tLoss: 0.020539\n",
      "Train Epoch: 85 [7296/14860 (49%)]\tLoss: 0.024607\n",
      "Train Epoch: 85 [7424/14860 (50%)]\tLoss: 0.014205\n",
      "Train Epoch: 85 [7552/14860 (50%)]\tLoss: 0.015940\n",
      "Train Epoch: 85 [7680/14860 (51%)]\tLoss: 0.016373\n",
      "Train Epoch: 85 [7808/14860 (52%)]\tLoss: 0.022352\n",
      "Train Epoch: 85 [7936/14860 (53%)]\tLoss: 0.017889\n",
      "Train Epoch: 85 [8064/14860 (54%)]\tLoss: 0.016932\n",
      "Train Epoch: 85 [8192/14860 (55%)]\tLoss: 0.014839\n",
      "Train Epoch: 85 [8320/14860 (56%)]\tLoss: 0.020021\n",
      "Train Epoch: 85 [8448/14860 (56%)]\tLoss: 0.017645\n",
      "Train Epoch: 85 [8576/14860 (57%)]\tLoss: 0.019231\n",
      "Train Epoch: 85 [8704/14860 (58%)]\tLoss: 0.029857\n",
      "Train Epoch: 85 [8832/14860 (59%)]\tLoss: 0.021099\n",
      "Train Epoch: 85 [8960/14860 (60%)]\tLoss: 0.017514\n",
      "Train Epoch: 85 [9088/14860 (61%)]\tLoss: 0.018427\n",
      "Train Epoch: 85 [9216/14860 (62%)]\tLoss: 0.026184\n",
      "Train Epoch: 85 [9344/14860 (62%)]\tLoss: 0.020718\n",
      "Train Epoch: 85 [9472/14860 (63%)]\tLoss: 0.022628\n",
      "Train Epoch: 85 [9600/14860 (64%)]\tLoss: 0.027441\n",
      "Train Epoch: 85 [9728/14860 (65%)]\tLoss: 0.022563\n",
      "Train Epoch: 85 [9856/14860 (66%)]\tLoss: 0.029245\n",
      "Train Epoch: 85 [9984/14860 (67%)]\tLoss: 0.021600\n",
      "Train Epoch: 85 [10112/14860 (68%)]\tLoss: 0.019244\n",
      "Train Epoch: 85 [10240/14860 (68%)]\tLoss: 0.025174\n",
      "Train Epoch: 85 [10368/14860 (69%)]\tLoss: 0.030660\n",
      "Train Epoch: 85 [10496/14860 (70%)]\tLoss: 0.027823\n",
      "Train Epoch: 85 [10624/14860 (71%)]\tLoss: 0.022642\n",
      "Train Epoch: 85 [10752/14860 (72%)]\tLoss: 0.018234\n",
      "Train Epoch: 85 [10880/14860 (73%)]\tLoss: 0.021145\n",
      "Train Epoch: 85 [11008/14860 (74%)]\tLoss: 0.022161\n",
      "Train Epoch: 85 [11136/14860 (74%)]\tLoss: 0.027311\n",
      "Train Epoch: 85 [11264/14860 (75%)]\tLoss: 0.017444\n",
      "Train Epoch: 85 [11392/14860 (76%)]\tLoss: 0.016658\n",
      "Train Epoch: 85 [11520/14860 (77%)]\tLoss: 0.021765\n",
      "Train Epoch: 85 [11648/14860 (78%)]\tLoss: 0.020733\n",
      "Train Epoch: 85 [11776/14860 (79%)]\tLoss: 0.020936\n",
      "Train Epoch: 85 [11904/14860 (79%)]\tLoss: 0.019897\n",
      "Train Epoch: 85 [12032/14860 (80%)]\tLoss: 0.020667\n",
      "Train Epoch: 85 [12160/14860 (81%)]\tLoss: 0.023519\n",
      "Train Epoch: 85 [12288/14860 (82%)]\tLoss: 0.022677\n",
      "Train Epoch: 85 [12416/14860 (83%)]\tLoss: 0.023789\n",
      "Train Epoch: 85 [12544/14860 (84%)]\tLoss: 0.025073\n",
      "Train Epoch: 85 [12672/14860 (85%)]\tLoss: 0.023903\n",
      "Train Epoch: 85 [12800/14860 (85%)]\tLoss: 0.020554\n",
      "Train Epoch: 85 [12928/14860 (86%)]\tLoss: 0.027983\n",
      "Train Epoch: 85 [13056/14860 (87%)]\tLoss: 0.015279\n",
      "Train Epoch: 85 [13184/14860 (88%)]\tLoss: 0.019809\n",
      "Train Epoch: 85 [13312/14860 (89%)]\tLoss: 0.019022\n",
      "Train Epoch: 85 [13440/14860 (90%)]\tLoss: 0.016383\n",
      "Train Epoch: 85 [13568/14860 (91%)]\tLoss: 0.024116\n",
      "Train Epoch: 85 [13696/14860 (91%)]\tLoss: 0.015299\n",
      "Train Epoch: 85 [13824/14860 (92%)]\tLoss: 0.022064\n",
      "Train Epoch: 85 [13952/14860 (93%)]\tLoss: 0.019837\n",
      "Train Epoch: 85 [14080/14860 (94%)]\tLoss: 0.021816\n",
      "Train Epoch: 85 [14208/14860 (95%)]\tLoss: 0.029565\n",
      "Train Epoch: 85 [14336/14860 (96%)]\tLoss: 0.022039\n",
      "Train Epoch: 85 [14464/14860 (97%)]\tLoss: 0.017201\n",
      "Train Epoch: 85 [14592/14860 (97%)]\tLoss: 0.020123\n",
      "Train Epoch: 85 [14720/14860 (98%)]\tLoss: 0.020751\n",
      "Train Epoch: 85 [1392/14860 (99%)]\tLoss: 0.029350\n",
      "epoch 85 training loss: 0.021291026702293984\n",
      "epoch 85 validation loss: 0.04257329569601839\n",
      "Train Epoch: 86 [0/14860 (0%)]\tLoss: 0.039941\n",
      "Train Epoch: 86 [128/14860 (1%)]\tLoss: 0.034764\n",
      "Train Epoch: 86 [256/14860 (2%)]\tLoss: 0.022351\n",
      "Train Epoch: 86 [384/14860 (3%)]\tLoss: 0.030688\n",
      "Train Epoch: 86 [512/14860 (3%)]\tLoss: 0.030425\n",
      "Train Epoch: 86 [640/14860 (4%)]\tLoss: 0.018313\n",
      "Train Epoch: 86 [768/14860 (5%)]\tLoss: 0.026901\n",
      "Train Epoch: 86 [896/14860 (6%)]\tLoss: 0.016841\n",
      "Train Epoch: 86 [1024/14860 (7%)]\tLoss: 0.017970\n",
      "Train Epoch: 86 [1152/14860 (8%)]\tLoss: 0.023126\n",
      "Train Epoch: 86 [1280/14860 (9%)]\tLoss: 0.030650\n",
      "Train Epoch: 86 [1408/14860 (9%)]\tLoss: 0.040320\n",
      "Train Epoch: 86 [1536/14860 (10%)]\tLoss: 0.023129\n",
      "Train Epoch: 86 [1664/14860 (11%)]\tLoss: 0.033459\n",
      "Train Epoch: 86 [1792/14860 (12%)]\tLoss: 0.010734\n",
      "Train Epoch: 86 [1920/14860 (13%)]\tLoss: 0.027185\n",
      "Train Epoch: 86 [2048/14860 (14%)]\tLoss: 0.024335\n",
      "Train Epoch: 86 [2176/14860 (15%)]\tLoss: 0.015460\n",
      "Train Epoch: 86 [2304/14860 (15%)]\tLoss: 0.029798\n",
      "Train Epoch: 86 [2432/14860 (16%)]\tLoss: 0.018278\n",
      "Train Epoch: 86 [2560/14860 (17%)]\tLoss: 0.027353\n",
      "Train Epoch: 86 [2688/14860 (18%)]\tLoss: 0.018918\n",
      "Train Epoch: 86 [2816/14860 (19%)]\tLoss: 0.022131\n",
      "Train Epoch: 86 [2944/14860 (20%)]\tLoss: 0.024579\n",
      "Train Epoch: 86 [3072/14860 (21%)]\tLoss: 0.024805\n",
      "Train Epoch: 86 [3200/14860 (21%)]\tLoss: 0.021855\n",
      "Train Epoch: 86 [3328/14860 (22%)]\tLoss: 0.029271\n",
      "Train Epoch: 86 [3456/14860 (23%)]\tLoss: 0.018998\n",
      "Train Epoch: 86 [3584/14860 (24%)]\tLoss: 0.018443\n",
      "Train Epoch: 86 [3712/14860 (25%)]\tLoss: 0.021248\n",
      "Train Epoch: 86 [3840/14860 (26%)]\tLoss: 0.017877\n",
      "Train Epoch: 86 [3968/14860 (26%)]\tLoss: 0.022850\n",
      "Train Epoch: 86 [4096/14860 (27%)]\tLoss: 0.020163\n",
      "Train Epoch: 86 [4224/14860 (28%)]\tLoss: 0.019202\n",
      "Train Epoch: 86 [4352/14860 (29%)]\tLoss: 0.027792\n",
      "Train Epoch: 86 [4480/14860 (30%)]\tLoss: 0.020283\n",
      "Train Epoch: 86 [4608/14860 (31%)]\tLoss: 0.018088\n",
      "Train Epoch: 86 [4736/14860 (32%)]\tLoss: 0.018379\n",
      "Train Epoch: 86 [4864/14860 (32%)]\tLoss: 0.029073\n",
      "Train Epoch: 86 [4992/14860 (33%)]\tLoss: 0.017575\n",
      "Train Epoch: 86 [5120/14860 (34%)]\tLoss: 0.024079\n",
      "Train Epoch: 86 [5248/14860 (35%)]\tLoss: 0.009775\n",
      "Train Epoch: 86 [5376/14860 (36%)]\tLoss: 0.020213\n",
      "Train Epoch: 86 [5504/14860 (37%)]\tLoss: 0.017869\n",
      "Train Epoch: 86 [5632/14860 (38%)]\tLoss: 0.023685\n",
      "Train Epoch: 86 [5760/14860 (38%)]\tLoss: 0.027490\n",
      "Train Epoch: 86 [5888/14860 (39%)]\tLoss: 0.019546\n",
      "Train Epoch: 86 [6016/14860 (40%)]\tLoss: 0.014781\n",
      "Train Epoch: 86 [6144/14860 (41%)]\tLoss: 0.031836\n",
      "Train Epoch: 86 [6272/14860 (42%)]\tLoss: 0.020007\n",
      "Train Epoch: 86 [6400/14860 (43%)]\tLoss: 0.026939\n",
      "Train Epoch: 86 [6528/14860 (44%)]\tLoss: 0.015047\n",
      "Train Epoch: 86 [6656/14860 (44%)]\tLoss: 0.017572\n",
      "Train Epoch: 86 [6784/14860 (45%)]\tLoss: 0.021368\n",
      "Train Epoch: 86 [6912/14860 (46%)]\tLoss: 0.020494\n",
      "Train Epoch: 86 [7040/14860 (47%)]\tLoss: 0.029267\n",
      "Train Epoch: 86 [7168/14860 (48%)]\tLoss: 0.022736\n",
      "Train Epoch: 86 [7296/14860 (49%)]\tLoss: 0.023547\n",
      "Train Epoch: 86 [7424/14860 (50%)]\tLoss: 0.017017\n",
      "Train Epoch: 86 [7552/14860 (50%)]\tLoss: 0.020271\n",
      "Train Epoch: 86 [7680/14860 (51%)]\tLoss: 0.017003\n",
      "Train Epoch: 86 [7808/14860 (52%)]\tLoss: 0.021229\n",
      "Train Epoch: 86 [7936/14860 (53%)]\tLoss: 0.019773\n",
      "Train Epoch: 86 [8064/14860 (54%)]\tLoss: 0.022469\n",
      "Train Epoch: 86 [8192/14860 (55%)]\tLoss: 0.013134\n",
      "Train Epoch: 86 [8320/14860 (56%)]\tLoss: 0.017114\n",
      "Train Epoch: 86 [8448/14860 (56%)]\tLoss: 0.017451\n",
      "Train Epoch: 86 [8576/14860 (57%)]\tLoss: 0.017716\n",
      "Train Epoch: 86 [8704/14860 (58%)]\tLoss: 0.020138\n",
      "Train Epoch: 86 [8832/14860 (59%)]\tLoss: 0.025366\n",
      "Train Epoch: 86 [8960/14860 (60%)]\tLoss: 0.022383\n",
      "Train Epoch: 86 [9088/14860 (61%)]\tLoss: 0.017559\n",
      "Train Epoch: 86 [9216/14860 (62%)]\tLoss: 0.018355\n",
      "Train Epoch: 86 [9344/14860 (62%)]\tLoss: 0.014302\n",
      "Train Epoch: 86 [9472/14860 (63%)]\tLoss: 0.016501\n",
      "Train Epoch: 86 [9600/14860 (64%)]\tLoss: 0.015727\n",
      "Train Epoch: 86 [9728/14860 (65%)]\tLoss: 0.032885\n",
      "Train Epoch: 86 [9856/14860 (66%)]\tLoss: 0.020464\n",
      "Train Epoch: 86 [9984/14860 (67%)]\tLoss: 0.018747\n",
      "Train Epoch: 86 [10112/14860 (68%)]\tLoss: 0.015702\n",
      "Train Epoch: 86 [10240/14860 (68%)]\tLoss: 0.026071\n",
      "Train Epoch: 86 [10368/14860 (69%)]\tLoss: 0.015980\n",
      "Train Epoch: 86 [10496/14860 (70%)]\tLoss: 0.028282\n",
      "Train Epoch: 86 [10624/14860 (71%)]\tLoss: 0.017329\n",
      "Train Epoch: 86 [10752/14860 (72%)]\tLoss: 0.017901\n",
      "Train Epoch: 86 [10880/14860 (73%)]\tLoss: 0.027743\n",
      "Train Epoch: 86 [11008/14860 (74%)]\tLoss: 0.024555\n",
      "Train Epoch: 86 [11136/14860 (74%)]\tLoss: 0.024612\n",
      "Train Epoch: 86 [11264/14860 (75%)]\tLoss: 0.017596\n",
      "Train Epoch: 86 [11392/14860 (76%)]\tLoss: 0.025218\n",
      "Train Epoch: 86 [11520/14860 (77%)]\tLoss: 0.019457\n",
      "Train Epoch: 86 [11648/14860 (78%)]\tLoss: 0.023336\n",
      "Train Epoch: 86 [11776/14860 (79%)]\tLoss: 0.016807\n",
      "Train Epoch: 86 [11904/14860 (79%)]\tLoss: 0.018118\n",
      "Train Epoch: 86 [12032/14860 (80%)]\tLoss: 0.025023\n",
      "Train Epoch: 86 [12160/14860 (81%)]\tLoss: 0.024517\n",
      "Train Epoch: 86 [12288/14860 (82%)]\tLoss: 0.026830\n",
      "Train Epoch: 86 [12416/14860 (83%)]\tLoss: 0.012629\n",
      "Train Epoch: 86 [12544/14860 (84%)]\tLoss: 0.020309\n",
      "Train Epoch: 86 [12672/14860 (85%)]\tLoss: 0.017004\n",
      "Train Epoch: 86 [12800/14860 (85%)]\tLoss: 0.016230\n",
      "Train Epoch: 86 [12928/14860 (86%)]\tLoss: 0.022005\n",
      "Train Epoch: 86 [13056/14860 (87%)]\tLoss: 0.015519\n",
      "Train Epoch: 86 [13184/14860 (88%)]\tLoss: 0.016413\n",
      "Train Epoch: 86 [13312/14860 (89%)]\tLoss: 0.018702\n",
      "Train Epoch: 86 [13440/14860 (90%)]\tLoss: 0.025067\n",
      "Train Epoch: 86 [13568/14860 (91%)]\tLoss: 0.016218\n",
      "Train Epoch: 86 [13696/14860 (91%)]\tLoss: 0.018535\n",
      "Train Epoch: 86 [13824/14860 (92%)]\tLoss: 0.021899\n",
      "Train Epoch: 86 [13952/14860 (93%)]\tLoss: 0.022476\n",
      "Train Epoch: 86 [14080/14860 (94%)]\tLoss: 0.021670\n",
      "Train Epoch: 86 [14208/14860 (95%)]\tLoss: 0.023643\n",
      "Train Epoch: 86 [14336/14860 (96%)]\tLoss: 0.018348\n",
      "Train Epoch: 86 [14464/14860 (97%)]\tLoss: 0.032161\n",
      "Train Epoch: 86 [14592/14860 (97%)]\tLoss: 0.020667\n",
      "Train Epoch: 86 [14720/14860 (98%)]\tLoss: 0.019181\n",
      "Train Epoch: 86 [1392/14860 (99%)]\tLoss: 0.010264\n",
      "epoch 86 training loss: 0.02161896153170074\n",
      "epoch 86 validation loss: 0.02207777445310542\n",
      "Train Epoch: 87 [0/14860 (0%)]\tLoss: 0.021616\n",
      "Train Epoch: 87 [128/14860 (1%)]\tLoss: 0.022501\n",
      "Train Epoch: 87 [256/14860 (2%)]\tLoss: 0.022987\n",
      "Train Epoch: 87 [384/14860 (3%)]\tLoss: 0.020490\n",
      "Train Epoch: 87 [512/14860 (3%)]\tLoss: 0.022583\n",
      "Train Epoch: 87 [640/14860 (4%)]\tLoss: 0.012330\n",
      "Train Epoch: 87 [768/14860 (5%)]\tLoss: 0.033452\n",
      "Train Epoch: 87 [896/14860 (6%)]\tLoss: 0.026632\n",
      "Train Epoch: 87 [1024/14860 (7%)]\tLoss: 0.030445\n",
      "Train Epoch: 87 [1152/14860 (8%)]\tLoss: 0.020591\n",
      "Train Epoch: 87 [1280/14860 (9%)]\tLoss: 0.015762\n",
      "Train Epoch: 87 [1408/14860 (9%)]\tLoss: 0.029850\n",
      "Train Epoch: 87 [1536/14860 (10%)]\tLoss: 0.019318\n",
      "Train Epoch: 87 [1664/14860 (11%)]\tLoss: 0.014456\n",
      "Train Epoch: 87 [1792/14860 (12%)]\tLoss: 0.028169\n",
      "Train Epoch: 87 [1920/14860 (13%)]\tLoss: 0.017724\n",
      "Train Epoch: 87 [2048/14860 (14%)]\tLoss: 0.023707\n",
      "Train Epoch: 87 [2176/14860 (15%)]\tLoss: 0.015418\n",
      "Train Epoch: 87 [2304/14860 (15%)]\tLoss: 0.022027\n",
      "Train Epoch: 87 [2432/14860 (16%)]\tLoss: 0.022680\n",
      "Train Epoch: 87 [2560/14860 (17%)]\tLoss: 0.025282\n",
      "Train Epoch: 87 [2688/14860 (18%)]\tLoss: 0.021654\n",
      "Train Epoch: 87 [2816/14860 (19%)]\tLoss: 0.026178\n",
      "Train Epoch: 87 [2944/14860 (20%)]\tLoss: 0.025993\n",
      "Train Epoch: 87 [3072/14860 (21%)]\tLoss: 0.023638\n",
      "Train Epoch: 87 [3200/14860 (21%)]\tLoss: 0.030787\n",
      "Train Epoch: 87 [3328/14860 (22%)]\tLoss: 0.020753\n",
      "Train Epoch: 87 [3456/14860 (23%)]\tLoss: 0.024987\n",
      "Train Epoch: 87 [3584/14860 (24%)]\tLoss: 0.017209\n",
      "Train Epoch: 87 [3712/14860 (25%)]\tLoss: 0.024238\n",
      "Train Epoch: 87 [3840/14860 (26%)]\tLoss: 0.019735\n",
      "Train Epoch: 87 [3968/14860 (26%)]\tLoss: 0.012351\n",
      "Train Epoch: 87 [4096/14860 (27%)]\tLoss: 0.015036\n",
      "Train Epoch: 87 [4224/14860 (28%)]\tLoss: 0.021537\n",
      "Train Epoch: 87 [4352/14860 (29%)]\tLoss: 0.020140\n",
      "Train Epoch: 87 [4480/14860 (30%)]\tLoss: 0.017841\n",
      "Train Epoch: 87 [4608/14860 (31%)]\tLoss: 0.022816\n",
      "Train Epoch: 87 [4736/14860 (32%)]\tLoss: 0.028367\n",
      "Train Epoch: 87 [4864/14860 (32%)]\tLoss: 0.014043\n",
      "Train Epoch: 87 [4992/14860 (33%)]\tLoss: 0.022338\n",
      "Train Epoch: 87 [5120/14860 (34%)]\tLoss: 0.025785\n",
      "Train Epoch: 87 [5248/14860 (35%)]\tLoss: 0.022755\n",
      "Train Epoch: 87 [5376/14860 (36%)]\tLoss: 0.028630\n",
      "Train Epoch: 87 [5504/14860 (37%)]\tLoss: 0.019081\n",
      "Train Epoch: 87 [5632/14860 (38%)]\tLoss: 0.020756\n",
      "Train Epoch: 87 [5760/14860 (38%)]\tLoss: 0.022172\n",
      "Train Epoch: 87 [5888/14860 (39%)]\tLoss: 0.024449\n",
      "Train Epoch: 87 [6016/14860 (40%)]\tLoss: 0.012020\n",
      "Train Epoch: 87 [6144/14860 (41%)]\tLoss: 0.021284\n",
      "Train Epoch: 87 [6272/14860 (42%)]\tLoss: 0.016799\n",
      "Train Epoch: 87 [6400/14860 (43%)]\tLoss: 0.016781\n",
      "Train Epoch: 87 [6528/14860 (44%)]\tLoss: 0.025684\n",
      "Train Epoch: 87 [6656/14860 (44%)]\tLoss: 0.019026\n",
      "Train Epoch: 87 [6784/14860 (45%)]\tLoss: 0.023824\n",
      "Train Epoch: 87 [6912/14860 (46%)]\tLoss: 0.021069\n",
      "Train Epoch: 87 [7040/14860 (47%)]\tLoss: 0.017042\n",
      "Train Epoch: 87 [7168/14860 (48%)]\tLoss: 0.017126\n",
      "Train Epoch: 87 [7296/14860 (49%)]\tLoss: 0.025761\n",
      "Train Epoch: 87 [7424/14860 (50%)]\tLoss: 0.017072\n",
      "Train Epoch: 87 [7552/14860 (50%)]\tLoss: 0.016799\n",
      "Train Epoch: 87 [7680/14860 (51%)]\tLoss: 0.012490\n",
      "Train Epoch: 87 [7808/14860 (52%)]\tLoss: 0.024351\n",
      "Train Epoch: 87 [7936/14860 (53%)]\tLoss: 0.027699\n",
      "Train Epoch: 87 [8064/14860 (54%)]\tLoss: 0.021449\n",
      "Train Epoch: 87 [8192/14860 (55%)]\tLoss: 0.017695\n",
      "Train Epoch: 87 [8320/14860 (56%)]\tLoss: 0.015253\n",
      "Train Epoch: 87 [8448/14860 (56%)]\tLoss: 0.028545\n",
      "Train Epoch: 87 [8576/14860 (57%)]\tLoss: 0.016698\n",
      "Train Epoch: 87 [8704/14860 (58%)]\tLoss: 0.023861\n",
      "Train Epoch: 87 [8832/14860 (59%)]\tLoss: 0.021043\n",
      "Train Epoch: 87 [8960/14860 (60%)]\tLoss: 0.034223\n",
      "Train Epoch: 87 [9088/14860 (61%)]\tLoss: 0.021182\n",
      "Train Epoch: 87 [9216/14860 (62%)]\tLoss: 0.023370\n",
      "Train Epoch: 87 [9344/14860 (62%)]\tLoss: 0.021228\n",
      "Train Epoch: 87 [9472/14860 (63%)]\tLoss: 0.020271\n",
      "Train Epoch: 87 [9600/14860 (64%)]\tLoss: 0.026605\n",
      "Train Epoch: 87 [9728/14860 (65%)]\tLoss: 0.020565\n",
      "Train Epoch: 87 [9856/14860 (66%)]\tLoss: 0.021079\n",
      "Train Epoch: 87 [9984/14860 (67%)]\tLoss: 0.017318\n",
      "Train Epoch: 87 [10112/14860 (68%)]\tLoss: 0.020531\n",
      "Train Epoch: 87 [10240/14860 (68%)]\tLoss: 0.021376\n",
      "Train Epoch: 87 [10368/14860 (69%)]\tLoss: 0.021791\n",
      "Train Epoch: 87 [10496/14860 (70%)]\tLoss: 0.011055\n",
      "Train Epoch: 87 [10624/14860 (71%)]\tLoss: 0.023149\n",
      "Train Epoch: 87 [10752/14860 (72%)]\tLoss: 0.016705\n",
      "Train Epoch: 87 [10880/14860 (73%)]\tLoss: 0.017177\n",
      "Train Epoch: 87 [11008/14860 (74%)]\tLoss: 0.021064\n",
      "Train Epoch: 87 [11136/14860 (74%)]\tLoss: 0.022405\n",
      "Train Epoch: 87 [11264/14860 (75%)]\tLoss: 0.019513\n",
      "Train Epoch: 87 [11392/14860 (76%)]\tLoss: 0.021233\n",
      "Train Epoch: 87 [11520/14860 (77%)]\tLoss: 0.017817\n",
      "Train Epoch: 87 [11648/14860 (78%)]\tLoss: 0.022637\n",
      "Train Epoch: 87 [11776/14860 (79%)]\tLoss: 0.022646\n",
      "Train Epoch: 87 [11904/14860 (79%)]\tLoss: 0.020733\n",
      "Train Epoch: 87 [12032/14860 (80%)]\tLoss: 0.023084\n",
      "Train Epoch: 87 [12160/14860 (81%)]\tLoss: 0.019917\n",
      "Train Epoch: 87 [12288/14860 (82%)]\tLoss: 0.016784\n",
      "Train Epoch: 87 [12416/14860 (83%)]\tLoss: 0.025911\n",
      "Train Epoch: 87 [12544/14860 (84%)]\tLoss: 0.018832\n",
      "Train Epoch: 87 [12672/14860 (85%)]\tLoss: 0.019025\n",
      "Train Epoch: 87 [12800/14860 (85%)]\tLoss: 0.013614\n",
      "Train Epoch: 87 [12928/14860 (86%)]\tLoss: 0.019754\n",
      "Train Epoch: 87 [13056/14860 (87%)]\tLoss: 0.020149\n",
      "Train Epoch: 87 [13184/14860 (88%)]\tLoss: 0.018934\n",
      "Train Epoch: 87 [13312/14860 (89%)]\tLoss: 0.024550\n",
      "Train Epoch: 87 [13440/14860 (90%)]\tLoss: 0.021901\n",
      "Train Epoch: 87 [13568/14860 (91%)]\tLoss: 0.019485\n",
      "Train Epoch: 87 [13696/14860 (91%)]\tLoss: 0.015014\n",
      "Train Epoch: 87 [13824/14860 (92%)]\tLoss: 0.024162\n",
      "Train Epoch: 87 [13952/14860 (93%)]\tLoss: 0.020422\n",
      "Train Epoch: 87 [14080/14860 (94%)]\tLoss: 0.014205\n",
      "Train Epoch: 87 [14208/14860 (95%)]\tLoss: 0.024646\n",
      "Train Epoch: 87 [14336/14860 (96%)]\tLoss: 0.017456\n",
      "Train Epoch: 87 [14464/14860 (97%)]\tLoss: 0.022186\n",
      "Train Epoch: 87 [14592/14860 (97%)]\tLoss: 0.019349\n",
      "Train Epoch: 87 [14720/14860 (98%)]\tLoss: 0.022307\n",
      "Train Epoch: 87 [1392/14860 (99%)]\tLoss: 0.021921\n",
      "epoch 87 training loss: 0.02111061718951688\n",
      "epoch 87 validation loss: 0.020921949757213454\n",
      "Train Epoch: 88 [0/14860 (0%)]\tLoss: 0.019702\n",
      "Train Epoch: 88 [128/14860 (1%)]\tLoss: 0.027993\n",
      "Train Epoch: 88 [256/14860 (2%)]\tLoss: 0.021703\n",
      "Train Epoch: 88 [384/14860 (3%)]\tLoss: 0.019731\n",
      "Train Epoch: 88 [512/14860 (3%)]\tLoss: 0.019913\n",
      "Train Epoch: 88 [640/14860 (4%)]\tLoss: 0.017428\n",
      "Train Epoch: 88 [768/14860 (5%)]\tLoss: 0.027249\n",
      "Train Epoch: 88 [896/14860 (6%)]\tLoss: 0.023400\n",
      "Train Epoch: 88 [1024/14860 (7%)]\tLoss: 0.034100\n",
      "Train Epoch: 88 [1152/14860 (8%)]\tLoss: 0.019821\n",
      "Train Epoch: 88 [1280/14860 (9%)]\tLoss: 0.018950\n",
      "Train Epoch: 88 [1408/14860 (9%)]\tLoss: 0.017848\n",
      "Train Epoch: 88 [1536/14860 (10%)]\tLoss: 0.015677\n",
      "Train Epoch: 88 [1664/14860 (11%)]\tLoss: 0.014384\n",
      "Train Epoch: 88 [1792/14860 (12%)]\tLoss: 0.019169\n",
      "Train Epoch: 88 [1920/14860 (13%)]\tLoss: 0.021728\n",
      "Train Epoch: 88 [2048/14860 (14%)]\tLoss: 0.025750\n",
      "Train Epoch: 88 [2176/14860 (15%)]\tLoss: 0.016192\n",
      "Train Epoch: 88 [2304/14860 (15%)]\tLoss: 0.029733\n",
      "Train Epoch: 88 [2432/14860 (16%)]\tLoss: 0.017895\n",
      "Train Epoch: 88 [2560/14860 (17%)]\tLoss: 0.018873\n",
      "Train Epoch: 88 [2688/14860 (18%)]\tLoss: 0.019995\n",
      "Train Epoch: 88 [2816/14860 (19%)]\tLoss: 0.015918\n",
      "Train Epoch: 88 [2944/14860 (20%)]\tLoss: 0.024091\n",
      "Train Epoch: 88 [3072/14860 (21%)]\tLoss: 0.020527\n",
      "Train Epoch: 88 [3200/14860 (21%)]\tLoss: 0.022467\n",
      "Train Epoch: 88 [3328/14860 (22%)]\tLoss: 0.021520\n",
      "Train Epoch: 88 [3456/14860 (23%)]\tLoss: 0.031693\n",
      "Train Epoch: 88 [3584/14860 (24%)]\tLoss: 0.019398\n",
      "Train Epoch: 88 [3712/14860 (25%)]\tLoss: 0.014887\n",
      "Train Epoch: 88 [3840/14860 (26%)]\tLoss: 0.018838\n",
      "Train Epoch: 88 [3968/14860 (26%)]\tLoss: 0.020818\n",
      "Train Epoch: 88 [4096/14860 (27%)]\tLoss: 0.016282\n",
      "Train Epoch: 88 [4224/14860 (28%)]\tLoss: 0.028968\n",
      "Train Epoch: 88 [4352/14860 (29%)]\tLoss: 0.020796\n",
      "Train Epoch: 88 [4480/14860 (30%)]\tLoss: 0.017328\n",
      "Train Epoch: 88 [4608/14860 (31%)]\tLoss: 0.021761\n",
      "Train Epoch: 88 [4736/14860 (32%)]\tLoss: 0.017221\n",
      "Train Epoch: 88 [4864/14860 (32%)]\tLoss: 0.016778\n",
      "Train Epoch: 88 [4992/14860 (33%)]\tLoss: 0.022735\n",
      "Train Epoch: 88 [5120/14860 (34%)]\tLoss: 0.019386\n",
      "Train Epoch: 88 [5248/14860 (35%)]\tLoss: 0.021512\n",
      "Train Epoch: 88 [5376/14860 (36%)]\tLoss: 0.023163\n",
      "Train Epoch: 88 [5504/14860 (37%)]\tLoss: 0.020743\n",
      "Train Epoch: 88 [5632/14860 (38%)]\tLoss: 0.022670\n",
      "Train Epoch: 88 [5760/14860 (38%)]\tLoss: 0.019656\n",
      "Train Epoch: 88 [5888/14860 (39%)]\tLoss: 0.021308\n",
      "Train Epoch: 88 [6016/14860 (40%)]\tLoss: 0.019506\n",
      "Train Epoch: 88 [6144/14860 (41%)]\tLoss: 0.021915\n",
      "Train Epoch: 88 [6272/14860 (42%)]\tLoss: 0.019549\n",
      "Train Epoch: 88 [6400/14860 (43%)]\tLoss: 0.017509\n",
      "Train Epoch: 88 [6528/14860 (44%)]\tLoss: 0.016290\n",
      "Train Epoch: 88 [6656/14860 (44%)]\tLoss: 0.019166\n",
      "Train Epoch: 88 [6784/14860 (45%)]\tLoss: 0.015077\n",
      "Train Epoch: 88 [6912/14860 (46%)]\tLoss: 0.020434\n",
      "Train Epoch: 88 [7040/14860 (47%)]\tLoss: 0.021703\n",
      "Train Epoch: 88 [7168/14860 (48%)]\tLoss: 0.015565\n",
      "Train Epoch: 88 [7296/14860 (49%)]\tLoss: 0.017232\n",
      "Train Epoch: 88 [7424/14860 (50%)]\tLoss: 0.020877\n",
      "Train Epoch: 88 [7552/14860 (50%)]\tLoss: 0.022077\n",
      "Train Epoch: 88 [7680/14860 (51%)]\tLoss: 0.022225\n",
      "Train Epoch: 88 [7808/14860 (52%)]\tLoss: 0.020591\n",
      "Train Epoch: 88 [7936/14860 (53%)]\tLoss: 0.020612\n",
      "Train Epoch: 88 [8064/14860 (54%)]\tLoss: 0.013923\n",
      "Train Epoch: 88 [8192/14860 (55%)]\tLoss: 0.023522\n",
      "Train Epoch: 88 [8320/14860 (56%)]\tLoss: 0.016729\n",
      "Train Epoch: 88 [8448/14860 (56%)]\tLoss: 0.018825\n",
      "Train Epoch: 88 [8576/14860 (57%)]\tLoss: 0.014590\n",
      "Train Epoch: 88 [8704/14860 (58%)]\tLoss: 0.016317\n",
      "Train Epoch: 88 [8832/14860 (59%)]\tLoss: 0.018319\n",
      "Train Epoch: 88 [8960/14860 (60%)]\tLoss: 0.032524\n",
      "Train Epoch: 88 [9088/14860 (61%)]\tLoss: 0.020073\n",
      "Train Epoch: 88 [9216/14860 (62%)]\tLoss: 0.027212\n",
      "Train Epoch: 88 [9344/14860 (62%)]\tLoss: 0.022307\n",
      "Train Epoch: 88 [9472/14860 (63%)]\tLoss: 0.018314\n",
      "Train Epoch: 88 [9600/14860 (64%)]\tLoss: 0.020751\n",
      "Train Epoch: 88 [9728/14860 (65%)]\tLoss: 0.019818\n",
      "Train Epoch: 88 [9856/14860 (66%)]\tLoss: 0.022141\n",
      "Train Epoch: 88 [9984/14860 (67%)]\tLoss: 0.016922\n",
      "Train Epoch: 88 [10112/14860 (68%)]\tLoss: 0.015952\n",
      "Train Epoch: 88 [10240/14860 (68%)]\tLoss: 0.021815\n",
      "Train Epoch: 88 [10368/14860 (69%)]\tLoss: 0.018779\n",
      "Train Epoch: 88 [10496/14860 (70%)]\tLoss: 0.022671\n",
      "Train Epoch: 88 [10624/14860 (71%)]\tLoss: 0.023585\n",
      "Train Epoch: 88 [10752/14860 (72%)]\tLoss: 0.014541\n",
      "Train Epoch: 88 [10880/14860 (73%)]\tLoss: 0.023928\n",
      "Train Epoch: 88 [11008/14860 (74%)]\tLoss: 0.017766\n",
      "Train Epoch: 88 [11136/14860 (74%)]\tLoss: 0.015422\n",
      "Train Epoch: 88 [11264/14860 (75%)]\tLoss: 0.018890\n",
      "Train Epoch: 88 [11392/14860 (76%)]\tLoss: 0.016325\n",
      "Train Epoch: 88 [11520/14860 (77%)]\tLoss: 0.024961\n",
      "Train Epoch: 88 [11648/14860 (78%)]\tLoss: 0.020386\n",
      "Train Epoch: 88 [11776/14860 (79%)]\tLoss: 0.014944\n",
      "Train Epoch: 88 [11904/14860 (79%)]\tLoss: 0.020996\n",
      "Train Epoch: 88 [12032/14860 (80%)]\tLoss: 0.014258\n",
      "Train Epoch: 88 [12160/14860 (81%)]\tLoss: 0.017848\n",
      "Train Epoch: 88 [12288/14860 (82%)]\tLoss: 0.017621\n",
      "Train Epoch: 88 [12416/14860 (83%)]\tLoss: 0.021904\n",
      "Train Epoch: 88 [12544/14860 (84%)]\tLoss: 0.020095\n",
      "Train Epoch: 88 [12672/14860 (85%)]\tLoss: 0.020299\n",
      "Train Epoch: 88 [12800/14860 (85%)]\tLoss: 0.036552\n",
      "Train Epoch: 88 [12928/14860 (86%)]\tLoss: 0.024129\n",
      "Train Epoch: 88 [13056/14860 (87%)]\tLoss: 0.020463\n",
      "Train Epoch: 88 [13184/14860 (88%)]\tLoss: 0.021563\n",
      "Train Epoch: 88 [13312/14860 (89%)]\tLoss: 0.032011\n",
      "Train Epoch: 88 [13440/14860 (90%)]\tLoss: 0.019410\n",
      "Train Epoch: 88 [13568/14860 (91%)]\tLoss: 0.030062\n",
      "Train Epoch: 88 [13696/14860 (91%)]\tLoss: 0.013277\n",
      "Train Epoch: 88 [13824/14860 (92%)]\tLoss: 0.027283\n",
      "Train Epoch: 88 [13952/14860 (93%)]\tLoss: 0.020419\n",
      "Train Epoch: 88 [14080/14860 (94%)]\tLoss: 0.020104\n",
      "Train Epoch: 88 [14208/14860 (95%)]\tLoss: 0.031923\n",
      "Train Epoch: 88 [14336/14860 (96%)]\tLoss: 0.019395\n",
      "Train Epoch: 88 [14464/14860 (97%)]\tLoss: 0.018598\n",
      "Train Epoch: 88 [14592/14860 (97%)]\tLoss: 0.017031\n",
      "Train Epoch: 88 [14720/14860 (98%)]\tLoss: 0.021174\n",
      "Train Epoch: 88 [1392/14860 (99%)]\tLoss: 0.011158\n",
      "epoch 88 training loss: 0.02057992834916227\n",
      "epoch 88 validation loss: 0.02050610337649939\n",
      "Train Epoch: 89 [0/14860 (0%)]\tLoss: 0.015251\n",
      "Train Epoch: 89 [128/14860 (1%)]\tLoss: 0.014425\n",
      "Train Epoch: 89 [256/14860 (2%)]\tLoss: 0.022854\n",
      "Train Epoch: 89 [384/14860 (3%)]\tLoss: 0.017548\n",
      "Train Epoch: 89 [512/14860 (3%)]\tLoss: 0.024443\n",
      "Train Epoch: 89 [640/14860 (4%)]\tLoss: 0.019933\n",
      "Train Epoch: 89 [768/14860 (5%)]\tLoss: 0.017812\n",
      "Train Epoch: 89 [896/14860 (6%)]\tLoss: 0.027064\n",
      "Train Epoch: 89 [1024/14860 (7%)]\tLoss: 0.024796\n",
      "Train Epoch: 89 [1152/14860 (8%)]\tLoss: 0.036840\n",
      "Train Epoch: 89 [1280/14860 (9%)]\tLoss: 0.019490\n",
      "Train Epoch: 89 [1408/14860 (9%)]\tLoss: 0.018216\n",
      "Train Epoch: 89 [1536/14860 (10%)]\tLoss: 0.023723\n",
      "Train Epoch: 89 [1664/14860 (11%)]\tLoss: 0.014517\n",
      "Train Epoch: 89 [1792/14860 (12%)]\tLoss: 0.020005\n",
      "Train Epoch: 89 [1920/14860 (13%)]\tLoss: 0.023255\n",
      "Train Epoch: 89 [2048/14860 (14%)]\tLoss: 0.019126\n",
      "Train Epoch: 89 [2176/14860 (15%)]\tLoss: 0.012154\n",
      "Train Epoch: 89 [2304/14860 (15%)]\tLoss: 0.041297\n",
      "Train Epoch: 89 [2432/14860 (16%)]\tLoss: 0.012976\n",
      "Train Epoch: 89 [2560/14860 (17%)]\tLoss: 0.019316\n",
      "Train Epoch: 89 [2688/14860 (18%)]\tLoss: 0.012472\n",
      "Train Epoch: 89 [2816/14860 (19%)]\tLoss: 0.028867\n",
      "Train Epoch: 89 [2944/14860 (20%)]\tLoss: 0.017661\n",
      "Train Epoch: 89 [3072/14860 (21%)]\tLoss: 0.020775\n",
      "Train Epoch: 89 [3200/14860 (21%)]\tLoss: 0.017413\n",
      "Train Epoch: 89 [3328/14860 (22%)]\tLoss: 0.013659\n",
      "Train Epoch: 89 [3456/14860 (23%)]\tLoss: 0.013367\n",
      "Train Epoch: 89 [3584/14860 (24%)]\tLoss: 0.020249\n",
      "Train Epoch: 89 [3712/14860 (25%)]\tLoss: 0.021429\n",
      "Train Epoch: 89 [3840/14860 (26%)]\tLoss: 0.025204\n",
      "Train Epoch: 89 [3968/14860 (26%)]\tLoss: 0.023545\n",
      "Train Epoch: 89 [4096/14860 (27%)]\tLoss: 0.015125\n",
      "Train Epoch: 89 [4224/14860 (28%)]\tLoss: 0.018211\n",
      "Train Epoch: 89 [4352/14860 (29%)]\tLoss: 0.015378\n",
      "Train Epoch: 89 [4480/14860 (30%)]\tLoss: 0.015307\n",
      "Train Epoch: 89 [4608/14860 (31%)]\tLoss: 0.017918\n",
      "Train Epoch: 89 [4736/14860 (32%)]\tLoss: 0.020689\n",
      "Train Epoch: 89 [4864/14860 (32%)]\tLoss: 0.025428\n",
      "Train Epoch: 89 [4992/14860 (33%)]\tLoss: 0.023072\n",
      "Train Epoch: 89 [5120/14860 (34%)]\tLoss: 0.014370\n",
      "Train Epoch: 89 [5248/14860 (35%)]\tLoss: 0.019496\n",
      "Train Epoch: 89 [5376/14860 (36%)]\tLoss: 0.024982\n",
      "Train Epoch: 89 [5504/14860 (37%)]\tLoss: 0.022323\n",
      "Train Epoch: 89 [5632/14860 (38%)]\tLoss: 0.023268\n",
      "Train Epoch: 89 [5760/14860 (38%)]\tLoss: 0.025295\n",
      "Train Epoch: 89 [5888/14860 (39%)]\tLoss: 0.021640\n",
      "Train Epoch: 89 [6016/14860 (40%)]\tLoss: 0.019078\n",
      "Train Epoch: 89 [6144/14860 (41%)]\tLoss: 0.029626\n",
      "Train Epoch: 89 [6272/14860 (42%)]\tLoss: 0.017090\n",
      "Train Epoch: 89 [6400/14860 (43%)]\tLoss: 0.019138\n",
      "Train Epoch: 89 [6528/14860 (44%)]\tLoss: 0.021951\n",
      "Train Epoch: 89 [6656/14860 (44%)]\tLoss: 0.018566\n",
      "Train Epoch: 89 [6784/14860 (45%)]\tLoss: 0.017408\n",
      "Train Epoch: 89 [6912/14860 (46%)]\tLoss: 0.016300\n",
      "Train Epoch: 89 [7040/14860 (47%)]\tLoss: 0.026202\n",
      "Train Epoch: 89 [7168/14860 (48%)]\tLoss: 0.021805\n",
      "Train Epoch: 89 [7296/14860 (49%)]\tLoss: 0.018456\n",
      "Train Epoch: 89 [7424/14860 (50%)]\tLoss: 0.017401\n",
      "Train Epoch: 89 [7552/14860 (50%)]\tLoss: 0.028277\n",
      "Train Epoch: 89 [7680/14860 (51%)]\tLoss: 0.028080\n",
      "Train Epoch: 89 [7808/14860 (52%)]\tLoss: 0.021520\n",
      "Train Epoch: 89 [7936/14860 (53%)]\tLoss: 0.015839\n",
      "Train Epoch: 89 [8064/14860 (54%)]\tLoss: 0.019295\n",
      "Train Epoch: 89 [8192/14860 (55%)]\tLoss: 0.015981\n",
      "Train Epoch: 89 [8320/14860 (56%)]\tLoss: 0.015285\n",
      "Train Epoch: 89 [8448/14860 (56%)]\tLoss: 0.014544\n",
      "Train Epoch: 89 [8576/14860 (57%)]\tLoss: 0.023871\n",
      "Train Epoch: 89 [8704/14860 (58%)]\tLoss: 0.021249\n",
      "Train Epoch: 89 [8832/14860 (59%)]\tLoss: 0.015654\n",
      "Train Epoch: 89 [8960/14860 (60%)]\tLoss: 0.020014\n",
      "Train Epoch: 89 [9088/14860 (61%)]\tLoss: 0.019278\n",
      "Train Epoch: 89 [9216/14860 (62%)]\tLoss: 0.015959\n",
      "Train Epoch: 89 [9344/14860 (62%)]\tLoss: 0.019151\n",
      "Train Epoch: 89 [9472/14860 (63%)]\tLoss: 0.026322\n",
      "Train Epoch: 89 [9600/14860 (64%)]\tLoss: 0.028602\n",
      "Train Epoch: 89 [9728/14860 (65%)]\tLoss: 0.018446\n",
      "Train Epoch: 89 [9856/14860 (66%)]\tLoss: 0.020673\n",
      "Train Epoch: 89 [9984/14860 (67%)]\tLoss: 0.020065\n",
      "Train Epoch: 89 [10112/14860 (68%)]\tLoss: 0.020645\n",
      "Train Epoch: 89 [10240/14860 (68%)]\tLoss: 0.020689\n",
      "Train Epoch: 89 [10368/14860 (69%)]\tLoss: 0.029970\n",
      "Train Epoch: 89 [10496/14860 (70%)]\tLoss: 0.015930\n",
      "Train Epoch: 89 [10624/14860 (71%)]\tLoss: 0.014449\n",
      "Train Epoch: 89 [10752/14860 (72%)]\tLoss: 0.021962\n",
      "Train Epoch: 89 [10880/14860 (73%)]\tLoss: 0.025486\n",
      "Train Epoch: 89 [11008/14860 (74%)]\tLoss: 0.022243\n",
      "Train Epoch: 89 [11136/14860 (74%)]\tLoss: 0.019166\n",
      "Train Epoch: 89 [11264/14860 (75%)]\tLoss: 0.025592\n",
      "Train Epoch: 89 [11392/14860 (76%)]\tLoss: 0.013776\n",
      "Train Epoch: 89 [11520/14860 (77%)]\tLoss: 0.014545\n",
      "Train Epoch: 89 [11648/14860 (78%)]\tLoss: 0.017664\n",
      "Train Epoch: 89 [11776/14860 (79%)]\tLoss: 0.030016\n",
      "Train Epoch: 89 [11904/14860 (79%)]\tLoss: 0.021468\n",
      "Train Epoch: 89 [12032/14860 (80%)]\tLoss: 0.020054\n",
      "Train Epoch: 89 [12160/14860 (81%)]\tLoss: 0.020310\n",
      "Train Epoch: 89 [12288/14860 (82%)]\tLoss: 0.020099\n",
      "Train Epoch: 89 [12416/14860 (83%)]\tLoss: 0.021571\n",
      "Train Epoch: 89 [12544/14860 (84%)]\tLoss: 0.021890\n",
      "Train Epoch: 89 [12672/14860 (85%)]\tLoss: 0.017762\n",
      "Train Epoch: 89 [12800/14860 (85%)]\tLoss: 0.026134\n",
      "Train Epoch: 89 [12928/14860 (86%)]\tLoss: 0.018009\n",
      "Train Epoch: 89 [13056/14860 (87%)]\tLoss: 0.022405\n",
      "Train Epoch: 89 [13184/14860 (88%)]\tLoss: 0.017206\n",
      "Train Epoch: 89 [13312/14860 (89%)]\tLoss: 0.028062\n",
      "Train Epoch: 89 [13440/14860 (90%)]\tLoss: 0.024347\n",
      "Train Epoch: 89 [13568/14860 (91%)]\tLoss: 0.019197\n",
      "Train Epoch: 89 [13696/14860 (91%)]\tLoss: 0.029409\n",
      "Train Epoch: 89 [13824/14860 (92%)]\tLoss: 0.014566\n",
      "Train Epoch: 89 [13952/14860 (93%)]\tLoss: 0.027547\n",
      "Train Epoch: 89 [14080/14860 (94%)]\tLoss: 0.029287\n",
      "Train Epoch: 89 [14208/14860 (95%)]\tLoss: 0.020548\n",
      "Train Epoch: 89 [14336/14860 (96%)]\tLoss: 0.031576\n",
      "Train Epoch: 89 [14464/14860 (97%)]\tLoss: 0.020330\n",
      "Train Epoch: 89 [14592/14860 (97%)]\tLoss: 0.018843\n",
      "Train Epoch: 89 [14720/14860 (98%)]\tLoss: 0.038748\n",
      "Train Epoch: 89 [1392/14860 (99%)]\tLoss: 0.021340\n",
      "epoch 89 training loss: 0.02099274593190505\n",
      "epoch 89 validation loss: 0.022276599384104655\n",
      "Train Epoch: 90 [0/14860 (0%)]\tLoss: 0.027636\n",
      "Train Epoch: 90 [128/14860 (1%)]\tLoss: 0.035468\n",
      "Train Epoch: 90 [256/14860 (2%)]\tLoss: 0.024577\n",
      "Train Epoch: 90 [384/14860 (3%)]\tLoss: 0.021582\n",
      "Train Epoch: 90 [512/14860 (3%)]\tLoss: 0.025321\n",
      "Train Epoch: 90 [640/14860 (4%)]\tLoss: 0.016803\n",
      "Train Epoch: 90 [768/14860 (5%)]\tLoss: 0.025812\n",
      "Train Epoch: 90 [896/14860 (6%)]\tLoss: 0.025429\n",
      "Train Epoch: 90 [1024/14860 (7%)]\tLoss: 0.021760\n",
      "Train Epoch: 90 [1152/14860 (8%)]\tLoss: 0.024260\n",
      "Train Epoch: 90 [1280/14860 (9%)]\tLoss: 0.021385\n",
      "Train Epoch: 90 [1408/14860 (9%)]\tLoss: 0.019840\n",
      "Train Epoch: 90 [1536/14860 (10%)]\tLoss: 0.017826\n",
      "Train Epoch: 90 [1664/14860 (11%)]\tLoss: 0.024036\n",
      "Train Epoch: 90 [1792/14860 (12%)]\tLoss: 0.021288\n",
      "Train Epoch: 90 [1920/14860 (13%)]\tLoss: 0.021641\n",
      "Train Epoch: 90 [2048/14860 (14%)]\tLoss: 0.016373\n",
      "Train Epoch: 90 [2176/14860 (15%)]\tLoss: 0.033198\n",
      "Train Epoch: 90 [2304/14860 (15%)]\tLoss: 0.017994\n",
      "Train Epoch: 90 [2432/14860 (16%)]\tLoss: 0.021983\n",
      "Train Epoch: 90 [2560/14860 (17%)]\tLoss: 0.020233\n",
      "Train Epoch: 90 [2688/14860 (18%)]\tLoss: 0.015341\n",
      "Train Epoch: 90 [2816/14860 (19%)]\tLoss: 0.020883\n",
      "Train Epoch: 90 [2944/14860 (20%)]\tLoss: 0.017841\n",
      "Train Epoch: 90 [3072/14860 (21%)]\tLoss: 0.013886\n",
      "Train Epoch: 90 [3200/14860 (21%)]\tLoss: 0.017468\n",
      "Train Epoch: 90 [3328/14860 (22%)]\tLoss: 0.020560\n",
      "Train Epoch: 90 [3456/14860 (23%)]\tLoss: 0.022350\n",
      "Train Epoch: 90 [3584/14860 (24%)]\tLoss: 0.017338\n",
      "Train Epoch: 90 [3712/14860 (25%)]\tLoss: 0.024871\n",
      "Train Epoch: 90 [3840/14860 (26%)]\tLoss: 0.023402\n",
      "Train Epoch: 90 [3968/14860 (26%)]\tLoss: 0.019593\n",
      "Train Epoch: 90 [4096/14860 (27%)]\tLoss: 0.016597\n",
      "Train Epoch: 90 [4224/14860 (28%)]\tLoss: 0.020118\n",
      "Train Epoch: 90 [4352/14860 (29%)]\tLoss: 0.028711\n",
      "Train Epoch: 90 [4480/14860 (30%)]\tLoss: 0.022660\n",
      "Train Epoch: 90 [4608/14860 (31%)]\tLoss: 0.020140\n",
      "Train Epoch: 90 [4736/14860 (32%)]\tLoss: 0.022721\n",
      "Train Epoch: 90 [4864/14860 (32%)]\tLoss: 0.020578\n",
      "Train Epoch: 90 [4992/14860 (33%)]\tLoss: 0.021100\n",
      "Train Epoch: 90 [5120/14860 (34%)]\tLoss: 0.017841\n",
      "Train Epoch: 90 [5248/14860 (35%)]\tLoss: 0.026461\n",
      "Train Epoch: 90 [5376/14860 (36%)]\tLoss: 0.024708\n",
      "Train Epoch: 90 [5504/14860 (37%)]\tLoss: 0.022021\n",
      "Train Epoch: 90 [5632/14860 (38%)]\tLoss: 0.011478\n",
      "Train Epoch: 90 [5760/14860 (38%)]\tLoss: 0.022146\n",
      "Train Epoch: 90 [5888/14860 (39%)]\tLoss: 0.014975\n",
      "Train Epoch: 90 [6016/14860 (40%)]\tLoss: 0.020145\n",
      "Train Epoch: 90 [6144/14860 (41%)]\tLoss: 0.020159\n",
      "Train Epoch: 90 [6272/14860 (42%)]\tLoss: 0.020232\n",
      "Train Epoch: 90 [6400/14860 (43%)]\tLoss: 0.014407\n",
      "Train Epoch: 90 [6528/14860 (44%)]\tLoss: 0.020250\n",
      "Train Epoch: 90 [6656/14860 (44%)]\tLoss: 0.015934\n",
      "Train Epoch: 90 [6784/14860 (45%)]\tLoss: 0.016728\n",
      "Train Epoch: 90 [6912/14860 (46%)]\tLoss: 0.016263\n",
      "Train Epoch: 90 [7040/14860 (47%)]\tLoss: 0.018383\n",
      "Train Epoch: 90 [7168/14860 (48%)]\tLoss: 0.016651\n",
      "Train Epoch: 90 [7296/14860 (49%)]\tLoss: 0.018099\n",
      "Train Epoch: 90 [7424/14860 (50%)]\tLoss: 0.018238\n",
      "Train Epoch: 90 [7552/14860 (50%)]\tLoss: 0.019704\n",
      "Train Epoch: 90 [7680/14860 (51%)]\tLoss: 0.018726\n",
      "Train Epoch: 90 [7808/14860 (52%)]\tLoss: 0.017930\n",
      "Train Epoch: 90 [7936/14860 (53%)]\tLoss: 0.026725\n",
      "Train Epoch: 90 [8064/14860 (54%)]\tLoss: 0.024457\n",
      "Train Epoch: 90 [8192/14860 (55%)]\tLoss: 0.018599\n",
      "Train Epoch: 90 [8320/14860 (56%)]\tLoss: 0.017493\n",
      "Train Epoch: 90 [8448/14860 (56%)]\tLoss: 0.025310\n",
      "Train Epoch: 90 [8576/14860 (57%)]\tLoss: 0.017246\n",
      "Train Epoch: 90 [8704/14860 (58%)]\tLoss: 0.028184\n",
      "Train Epoch: 90 [8832/14860 (59%)]\tLoss: 0.023909\n",
      "Train Epoch: 90 [8960/14860 (60%)]\tLoss: 0.027115\n",
      "Train Epoch: 90 [9088/14860 (61%)]\tLoss: 0.018924\n",
      "Train Epoch: 90 [9216/14860 (62%)]\tLoss: 0.019202\n",
      "Train Epoch: 90 [9344/14860 (62%)]\tLoss: 0.021529\n",
      "Train Epoch: 90 [9472/14860 (63%)]\tLoss: 0.013536\n",
      "Train Epoch: 90 [9600/14860 (64%)]\tLoss: 0.029198\n",
      "Train Epoch: 90 [9728/14860 (65%)]\tLoss: 0.022725\n",
      "Train Epoch: 90 [9856/14860 (66%)]\tLoss: 0.019095\n",
      "Train Epoch: 90 [9984/14860 (67%)]\tLoss: 0.027793\n",
      "Train Epoch: 90 [10112/14860 (68%)]\tLoss: 0.027374\n",
      "Train Epoch: 90 [10240/14860 (68%)]\tLoss: 0.016488\n",
      "Train Epoch: 90 [10368/14860 (69%)]\tLoss: 0.035739\n",
      "Train Epoch: 90 [10496/14860 (70%)]\tLoss: 0.017233\n",
      "Train Epoch: 90 [10624/14860 (71%)]\tLoss: 0.021882\n",
      "Train Epoch: 90 [10752/14860 (72%)]\tLoss: 0.020902\n",
      "Train Epoch: 90 [10880/14860 (73%)]\tLoss: 0.019686\n",
      "Train Epoch: 90 [11008/14860 (74%)]\tLoss: 0.022890\n",
      "Train Epoch: 90 [11136/14860 (74%)]\tLoss: 0.024203\n",
      "Train Epoch: 90 [11264/14860 (75%)]\tLoss: 0.021066\n",
      "Train Epoch: 90 [11392/14860 (76%)]\tLoss: 0.026329\n",
      "Train Epoch: 90 [11520/14860 (77%)]\tLoss: 0.021531\n",
      "Train Epoch: 90 [11648/14860 (78%)]\tLoss: 0.031558\n",
      "Train Epoch: 90 [11776/14860 (79%)]\tLoss: 0.019561\n",
      "Train Epoch: 90 [11904/14860 (79%)]\tLoss: 0.021559\n",
      "Train Epoch: 90 [12032/14860 (80%)]\tLoss: 0.013844\n",
      "Train Epoch: 90 [12160/14860 (81%)]\tLoss: 0.022047\n",
      "Train Epoch: 90 [12288/14860 (82%)]\tLoss: 0.013688\n",
      "Train Epoch: 90 [12416/14860 (83%)]\tLoss: 0.019154\n",
      "Train Epoch: 90 [12544/14860 (84%)]\tLoss: 0.017923\n",
      "Train Epoch: 90 [12672/14860 (85%)]\tLoss: 0.014856\n",
      "Train Epoch: 90 [12800/14860 (85%)]\tLoss: 0.018207\n",
      "Train Epoch: 90 [12928/14860 (86%)]\tLoss: 0.023881\n",
      "Train Epoch: 90 [13056/14860 (87%)]\tLoss: 0.013180\n",
      "Train Epoch: 90 [13184/14860 (88%)]\tLoss: 0.022924\n",
      "Train Epoch: 90 [13312/14860 (89%)]\tLoss: 0.013862\n",
      "Train Epoch: 90 [13440/14860 (90%)]\tLoss: 0.017636\n",
      "Train Epoch: 90 [13568/14860 (91%)]\tLoss: 0.026134\n",
      "Train Epoch: 90 [13696/14860 (91%)]\tLoss: 0.015575\n",
      "Train Epoch: 90 [13824/14860 (92%)]\tLoss: 0.014914\n",
      "Train Epoch: 90 [13952/14860 (93%)]\tLoss: 0.022425\n",
      "Train Epoch: 90 [14080/14860 (94%)]\tLoss: 0.027576\n",
      "Train Epoch: 90 [14208/14860 (95%)]\tLoss: 0.026372\n",
      "Train Epoch: 90 [14336/14860 (96%)]\tLoss: 0.019730\n",
      "Train Epoch: 90 [14464/14860 (97%)]\tLoss: 0.013698\n",
      "Train Epoch: 90 [14592/14860 (97%)]\tLoss: 0.018560\n",
      "Train Epoch: 90 [14720/14860 (98%)]\tLoss: 0.022094\n",
      "Train Epoch: 90 [1392/14860 (99%)]\tLoss: 0.051144\n",
      "epoch 90 training loss: 0.021201234334745467\n",
      "epoch 90 validation loss: 0.03635033395042142\n",
      "Train Epoch: 91 [0/14860 (0%)]\tLoss: 0.038066\n",
      "Train Epoch: 91 [128/14860 (1%)]\tLoss: 0.013184\n",
      "Train Epoch: 91 [256/14860 (2%)]\tLoss: 0.021697\n",
      "Train Epoch: 91 [384/14860 (3%)]\tLoss: 0.029139\n",
      "Train Epoch: 91 [512/14860 (3%)]\tLoss: 0.013505\n",
      "Train Epoch: 91 [640/14860 (4%)]\tLoss: 0.020038\n",
      "Train Epoch: 91 [768/14860 (5%)]\tLoss: 0.020781\n",
      "Train Epoch: 91 [896/14860 (6%)]\tLoss: 0.020154\n",
      "Train Epoch: 91 [1024/14860 (7%)]\tLoss: 0.022448\n",
      "Train Epoch: 91 [1152/14860 (8%)]\tLoss: 0.016615\n",
      "Train Epoch: 91 [1280/14860 (9%)]\tLoss: 0.019575\n",
      "Train Epoch: 91 [1408/14860 (9%)]\tLoss: 0.022296\n",
      "Train Epoch: 91 [1536/14860 (10%)]\tLoss: 0.020184\n",
      "Train Epoch: 91 [1664/14860 (11%)]\tLoss: 0.017602\n",
      "Train Epoch: 91 [1792/14860 (12%)]\tLoss: 0.028111\n",
      "Train Epoch: 91 [1920/14860 (13%)]\tLoss: 0.020150\n",
      "Train Epoch: 91 [2048/14860 (14%)]\tLoss: 0.016625\n",
      "Train Epoch: 91 [2176/14860 (15%)]\tLoss: 0.021673\n",
      "Train Epoch: 91 [2304/14860 (15%)]\tLoss: 0.018372\n",
      "Train Epoch: 91 [2432/14860 (16%)]\tLoss: 0.018473\n",
      "Train Epoch: 91 [2560/14860 (17%)]\tLoss: 0.019520\n",
      "Train Epoch: 91 [2688/14860 (18%)]\tLoss: 0.022060\n",
      "Train Epoch: 91 [2816/14860 (19%)]\tLoss: 0.021045\n",
      "Train Epoch: 91 [2944/14860 (20%)]\tLoss: 0.022884\n",
      "Train Epoch: 91 [3072/14860 (21%)]\tLoss: 0.018198\n",
      "Train Epoch: 91 [3200/14860 (21%)]\tLoss: 0.012701\n",
      "Train Epoch: 91 [3328/14860 (22%)]\tLoss: 0.026016\n",
      "Train Epoch: 91 [3456/14860 (23%)]\tLoss: 0.027928\n",
      "Train Epoch: 91 [3584/14860 (24%)]\tLoss: 0.029037\n",
      "Train Epoch: 91 [3712/14860 (25%)]\tLoss: 0.022674\n",
      "Train Epoch: 91 [3840/14860 (26%)]\tLoss: 0.018204\n",
      "Train Epoch: 91 [3968/14860 (26%)]\tLoss: 0.019288\n",
      "Train Epoch: 91 [4096/14860 (27%)]\tLoss: 0.016838\n",
      "Train Epoch: 91 [4224/14860 (28%)]\tLoss: 0.028019\n",
      "Train Epoch: 91 [4352/14860 (29%)]\tLoss: 0.019350\n",
      "Train Epoch: 91 [4480/14860 (30%)]\tLoss: 0.028941\n",
      "Train Epoch: 91 [4608/14860 (31%)]\tLoss: 0.026682\n",
      "Train Epoch: 91 [4736/14860 (32%)]\tLoss: 0.022196\n",
      "Train Epoch: 91 [4864/14860 (32%)]\tLoss: 0.035566\n",
      "Train Epoch: 91 [4992/14860 (33%)]\tLoss: 0.023773\n",
      "Train Epoch: 91 [5120/14860 (34%)]\tLoss: 0.021840\n",
      "Train Epoch: 91 [5248/14860 (35%)]\tLoss: 0.020012\n",
      "Train Epoch: 91 [5376/14860 (36%)]\tLoss: 0.020521\n",
      "Train Epoch: 91 [5504/14860 (37%)]\tLoss: 0.019984\n",
      "Train Epoch: 91 [5632/14860 (38%)]\tLoss: 0.027289\n",
      "Train Epoch: 91 [5760/14860 (38%)]\tLoss: 0.020777\n",
      "Train Epoch: 91 [5888/14860 (39%)]\tLoss: 0.023567\n",
      "Train Epoch: 91 [6016/14860 (40%)]\tLoss: 0.017200\n",
      "Train Epoch: 91 [6144/14860 (41%)]\tLoss: 0.011355\n",
      "Train Epoch: 91 [6272/14860 (42%)]\tLoss: 0.017552\n",
      "Train Epoch: 91 [6400/14860 (43%)]\tLoss: 0.022268\n",
      "Train Epoch: 91 [6528/14860 (44%)]\tLoss: 0.013668\n",
      "Train Epoch: 91 [6656/14860 (44%)]\tLoss: 0.024884\n",
      "Train Epoch: 91 [6784/14860 (45%)]\tLoss: 0.018925\n",
      "Train Epoch: 91 [6912/14860 (46%)]\tLoss: 0.022480\n",
      "Train Epoch: 91 [7040/14860 (47%)]\tLoss: 0.020418\n",
      "Train Epoch: 91 [7168/14860 (48%)]\tLoss: 0.026177\n",
      "Train Epoch: 91 [7296/14860 (49%)]\tLoss: 0.017653\n",
      "Train Epoch: 91 [7424/14860 (50%)]\tLoss: 0.017689\n",
      "Train Epoch: 91 [7552/14860 (50%)]\tLoss: 0.018975\n",
      "Train Epoch: 91 [7680/14860 (51%)]\tLoss: 0.026703\n",
      "Train Epoch: 91 [7808/14860 (52%)]\tLoss: 0.021084\n",
      "Train Epoch: 91 [7936/14860 (53%)]\tLoss: 0.022215\n",
      "Train Epoch: 91 [8064/14860 (54%)]\tLoss: 0.023714\n",
      "Train Epoch: 91 [8192/14860 (55%)]\tLoss: 0.028321\n",
      "Train Epoch: 91 [8320/14860 (56%)]\tLoss: 0.014902\n",
      "Train Epoch: 91 [8448/14860 (56%)]\tLoss: 0.019357\n",
      "Train Epoch: 91 [8576/14860 (57%)]\tLoss: 0.018369\n",
      "Train Epoch: 91 [8704/14860 (58%)]\tLoss: 0.020629\n",
      "Train Epoch: 91 [8832/14860 (59%)]\tLoss: 0.022270\n",
      "Train Epoch: 91 [8960/14860 (60%)]\tLoss: 0.019452\n",
      "Train Epoch: 91 [9088/14860 (61%)]\tLoss: 0.025189\n",
      "Train Epoch: 91 [9216/14860 (62%)]\tLoss: 0.019543\n",
      "Train Epoch: 91 [9344/14860 (62%)]\tLoss: 0.017076\n",
      "Train Epoch: 91 [9472/14860 (63%)]\tLoss: 0.016486\n",
      "Train Epoch: 91 [9600/14860 (64%)]\tLoss: 0.016361\n",
      "Train Epoch: 91 [9728/14860 (65%)]\tLoss: 0.022361\n",
      "Train Epoch: 91 [9856/14860 (66%)]\tLoss: 0.016393\n",
      "Train Epoch: 91 [9984/14860 (67%)]\tLoss: 0.022282\n",
      "Train Epoch: 91 [10112/14860 (68%)]\tLoss: 0.015338\n",
      "Train Epoch: 91 [10240/14860 (68%)]\tLoss: 0.019072\n",
      "Train Epoch: 91 [10368/14860 (69%)]\tLoss: 0.015297\n",
      "Train Epoch: 91 [10496/14860 (70%)]\tLoss: 0.016083\n",
      "Train Epoch: 91 [10624/14860 (71%)]\tLoss: 0.022342\n",
      "Train Epoch: 91 [10752/14860 (72%)]\tLoss: 0.023226\n",
      "Train Epoch: 91 [10880/14860 (73%)]\tLoss: 0.022006\n",
      "Train Epoch: 91 [11008/14860 (74%)]\tLoss: 0.017132\n",
      "Train Epoch: 91 [11136/14860 (74%)]\tLoss: 0.015396\n",
      "Train Epoch: 91 [11264/14860 (75%)]\tLoss: 0.024404\n",
      "Train Epoch: 91 [11392/14860 (76%)]\tLoss: 0.020775\n",
      "Train Epoch: 91 [11520/14860 (77%)]\tLoss: 0.015463\n",
      "Train Epoch: 91 [11648/14860 (78%)]\tLoss: 0.024298\n",
      "Train Epoch: 91 [11776/14860 (79%)]\tLoss: 0.023823\n",
      "Train Epoch: 91 [11904/14860 (79%)]\tLoss: 0.018316\n",
      "Train Epoch: 91 [12032/14860 (80%)]\tLoss: 0.018079\n",
      "Train Epoch: 91 [12160/14860 (81%)]\tLoss: 0.014440\n",
      "Train Epoch: 91 [12288/14860 (82%)]\tLoss: 0.021235\n",
      "Train Epoch: 91 [12416/14860 (83%)]\tLoss: 0.014701\n",
      "Train Epoch: 91 [12544/14860 (84%)]\tLoss: 0.022849\n",
      "Train Epoch: 91 [12672/14860 (85%)]\tLoss: 0.012065\n",
      "Train Epoch: 91 [12800/14860 (85%)]\tLoss: 0.021470\n",
      "Train Epoch: 91 [12928/14860 (86%)]\tLoss: 0.013370\n",
      "Train Epoch: 91 [13056/14860 (87%)]\tLoss: 0.022336\n",
      "Train Epoch: 91 [13184/14860 (88%)]\tLoss: 0.021303\n",
      "Train Epoch: 91 [13312/14860 (89%)]\tLoss: 0.016137\n",
      "Train Epoch: 91 [13440/14860 (90%)]\tLoss: 0.015444\n",
      "Train Epoch: 91 [13568/14860 (91%)]\tLoss: 0.024044\n",
      "Train Epoch: 91 [13696/14860 (91%)]\tLoss: 0.023449\n",
      "Train Epoch: 91 [13824/14860 (92%)]\tLoss: 0.018053\n",
      "Train Epoch: 91 [13952/14860 (93%)]\tLoss: 0.019994\n",
      "Train Epoch: 91 [14080/14860 (94%)]\tLoss: 0.019091\n",
      "Train Epoch: 91 [14208/14860 (95%)]\tLoss: 0.017538\n",
      "Train Epoch: 91 [14336/14860 (96%)]\tLoss: 0.018168\n",
      "Train Epoch: 91 [14464/14860 (97%)]\tLoss: 0.019304\n",
      "Train Epoch: 91 [14592/14860 (97%)]\tLoss: 0.037131\n",
      "Train Epoch: 91 [14720/14860 (98%)]\tLoss: 0.019593\n",
      "Train Epoch: 91 [1392/14860 (99%)]\tLoss: 0.022494\n",
      "epoch 91 training loss: 0.020690704950601116\n",
      "epoch 91 validation loss: 0.020482649959028487\n",
      "Train Epoch: 92 [0/14860 (0%)]\tLoss: 0.030995\n",
      "Train Epoch: 92 [128/14860 (1%)]\tLoss: 0.024288\n",
      "Train Epoch: 92 [256/14860 (2%)]\tLoss: 0.027077\n",
      "Train Epoch: 92 [384/14860 (3%)]\tLoss: 0.018232\n",
      "Train Epoch: 92 [512/14860 (3%)]\tLoss: 0.030180\n",
      "Train Epoch: 92 [640/14860 (4%)]\tLoss: 0.017483\n",
      "Train Epoch: 92 [768/14860 (5%)]\tLoss: 0.023598\n",
      "Train Epoch: 92 [896/14860 (6%)]\tLoss: 0.017084\n",
      "Train Epoch: 92 [1024/14860 (7%)]\tLoss: 0.029050\n",
      "Train Epoch: 92 [1152/14860 (8%)]\tLoss: 0.022263\n",
      "Train Epoch: 92 [1280/14860 (9%)]\tLoss: 0.021803\n",
      "Train Epoch: 92 [1408/14860 (9%)]\tLoss: 0.026442\n",
      "Train Epoch: 92 [1536/14860 (10%)]\tLoss: 0.025805\n",
      "Train Epoch: 92 [1664/14860 (11%)]\tLoss: 0.021802\n",
      "Train Epoch: 92 [1792/14860 (12%)]\tLoss: 0.015892\n",
      "Train Epoch: 92 [1920/14860 (13%)]\tLoss: 0.022161\n",
      "Train Epoch: 92 [2048/14860 (14%)]\tLoss: 0.022353\n",
      "Train Epoch: 92 [2176/14860 (15%)]\tLoss: 0.014689\n",
      "Train Epoch: 92 [2304/14860 (15%)]\tLoss: 0.019028\n",
      "Train Epoch: 92 [2432/14860 (16%)]\tLoss: 0.024401\n",
      "Train Epoch: 92 [2560/14860 (17%)]\tLoss: 0.020901\n",
      "Train Epoch: 92 [2688/14860 (18%)]\tLoss: 0.023092\n",
      "Train Epoch: 92 [2816/14860 (19%)]\tLoss: 0.021546\n",
      "Train Epoch: 92 [2944/14860 (20%)]\tLoss: 0.032017\n",
      "Train Epoch: 92 [3072/14860 (21%)]\tLoss: 0.026177\n",
      "Train Epoch: 92 [3200/14860 (21%)]\tLoss: 0.015530\n",
      "Train Epoch: 92 [3328/14860 (22%)]\tLoss: 0.020809\n",
      "Train Epoch: 92 [3456/14860 (23%)]\tLoss: 0.020819\n",
      "Train Epoch: 92 [3584/14860 (24%)]\tLoss: 0.017356\n",
      "Train Epoch: 92 [3712/14860 (25%)]\tLoss: 0.021084\n",
      "Train Epoch: 92 [3840/14860 (26%)]\tLoss: 0.021208\n",
      "Train Epoch: 92 [3968/14860 (26%)]\tLoss: 0.017858\n",
      "Train Epoch: 92 [4096/14860 (27%)]\tLoss: 0.018893\n",
      "Train Epoch: 92 [4224/14860 (28%)]\tLoss: 0.022737\n",
      "Train Epoch: 92 [4352/14860 (29%)]\tLoss: 0.024807\n",
      "Train Epoch: 92 [4480/14860 (30%)]\tLoss: 0.014796\n",
      "Train Epoch: 92 [4608/14860 (31%)]\tLoss: 0.014951\n",
      "Train Epoch: 92 [4736/14860 (32%)]\tLoss: 0.014386\n",
      "Train Epoch: 92 [4864/14860 (32%)]\tLoss: 0.019609\n",
      "Train Epoch: 92 [4992/14860 (33%)]\tLoss: 0.015761\n",
      "Train Epoch: 92 [5120/14860 (34%)]\tLoss: 0.019374\n",
      "Train Epoch: 92 [5248/14860 (35%)]\tLoss: 0.019720\n",
      "Train Epoch: 92 [5376/14860 (36%)]\tLoss: 0.025943\n",
      "Train Epoch: 92 [5504/14860 (37%)]\tLoss: 0.025215\n",
      "Train Epoch: 92 [5632/14860 (38%)]\tLoss: 0.020264\n",
      "Train Epoch: 92 [5760/14860 (38%)]\tLoss: 0.020772\n",
      "Train Epoch: 92 [5888/14860 (39%)]\tLoss: 0.014723\n",
      "Train Epoch: 92 [6016/14860 (40%)]\tLoss: 0.012923\n",
      "Train Epoch: 92 [6144/14860 (41%)]\tLoss: 0.013187\n",
      "Train Epoch: 92 [6272/14860 (42%)]\tLoss: 0.014755\n",
      "Train Epoch: 92 [6400/14860 (43%)]\tLoss: 0.025404\n",
      "Train Epoch: 92 [6528/14860 (44%)]\tLoss: 0.026550\n",
      "Train Epoch: 92 [6656/14860 (44%)]\tLoss: 0.029181\n",
      "Train Epoch: 92 [6784/14860 (45%)]\tLoss: 0.017249\n",
      "Train Epoch: 92 [6912/14860 (46%)]\tLoss: 0.024555\n",
      "Train Epoch: 92 [7040/14860 (47%)]\tLoss: 0.020619\n",
      "Train Epoch: 92 [7168/14860 (48%)]\tLoss: 0.017491\n",
      "Train Epoch: 92 [7296/14860 (49%)]\tLoss: 0.022262\n",
      "Train Epoch: 92 [7424/14860 (50%)]\tLoss: 0.018174\n",
      "Train Epoch: 92 [7552/14860 (50%)]\tLoss: 0.033937\n",
      "Train Epoch: 92 [7680/14860 (51%)]\tLoss: 0.018864\n",
      "Train Epoch: 92 [7808/14860 (52%)]\tLoss: 0.018060\n",
      "Train Epoch: 92 [7936/14860 (53%)]\tLoss: 0.019433\n",
      "Train Epoch: 92 [8064/14860 (54%)]\tLoss: 0.018690\n",
      "Train Epoch: 92 [8192/14860 (55%)]\tLoss: 0.023266\n",
      "Train Epoch: 92 [8320/14860 (56%)]\tLoss: 0.016263\n",
      "Train Epoch: 92 [8448/14860 (56%)]\tLoss: 0.020544\n",
      "Train Epoch: 92 [8576/14860 (57%)]\tLoss: 0.013992\n",
      "Train Epoch: 92 [8704/14860 (58%)]\tLoss: 0.019341\n",
      "Train Epoch: 92 [8832/14860 (59%)]\tLoss: 0.018997\n",
      "Train Epoch: 92 [8960/14860 (60%)]\tLoss: 0.034904\n",
      "Train Epoch: 92 [9088/14860 (61%)]\tLoss: 0.018376\n",
      "Train Epoch: 92 [9216/14860 (62%)]\tLoss: 0.023215\n",
      "Train Epoch: 92 [9344/14860 (62%)]\tLoss: 0.025812\n",
      "Train Epoch: 92 [9472/14860 (63%)]\tLoss: 0.022644\n",
      "Train Epoch: 92 [9600/14860 (64%)]\tLoss: 0.018890\n",
      "Train Epoch: 92 [9728/14860 (65%)]\tLoss: 0.019085\n",
      "Train Epoch: 92 [9856/14860 (66%)]\tLoss: 0.016252\n",
      "Train Epoch: 92 [9984/14860 (67%)]\tLoss: 0.014037\n",
      "Train Epoch: 92 [10112/14860 (68%)]\tLoss: 0.016846\n",
      "Train Epoch: 92 [10240/14860 (68%)]\tLoss: 0.022095\n",
      "Train Epoch: 92 [10368/14860 (69%)]\tLoss: 0.018462\n",
      "Train Epoch: 92 [10496/14860 (70%)]\tLoss: 0.020200\n",
      "Train Epoch: 92 [10624/14860 (71%)]\tLoss: 0.019600\n",
      "Train Epoch: 92 [10752/14860 (72%)]\tLoss: 0.016204\n",
      "Train Epoch: 92 [10880/14860 (73%)]\tLoss: 0.016108\n",
      "Train Epoch: 92 [11008/14860 (74%)]\tLoss: 0.016935\n",
      "Train Epoch: 92 [11136/14860 (74%)]\tLoss: 0.016031\n",
      "Train Epoch: 92 [11264/14860 (75%)]\tLoss: 0.023679\n",
      "Train Epoch: 92 [11392/14860 (76%)]\tLoss: 0.031019\n",
      "Train Epoch: 92 [11520/14860 (77%)]\tLoss: 0.024621\n",
      "Train Epoch: 92 [11648/14860 (78%)]\tLoss: 0.022084\n",
      "Train Epoch: 92 [11776/14860 (79%)]\tLoss: 0.014695\n",
      "Train Epoch: 92 [11904/14860 (79%)]\tLoss: 0.022595\n",
      "Train Epoch: 92 [12032/14860 (80%)]\tLoss: 0.017403\n",
      "Train Epoch: 92 [12160/14860 (81%)]\tLoss: 0.018965\n",
      "Train Epoch: 92 [12288/14860 (82%)]\tLoss: 0.013797\n",
      "Train Epoch: 92 [12416/14860 (83%)]\tLoss: 0.015652\n",
      "Train Epoch: 92 [12544/14860 (84%)]\tLoss: 0.020705\n",
      "Train Epoch: 92 [12672/14860 (85%)]\tLoss: 0.020689\n",
      "Train Epoch: 92 [12800/14860 (85%)]\tLoss: 0.019180\n",
      "Train Epoch: 92 [12928/14860 (86%)]\tLoss: 0.020501\n",
      "Train Epoch: 92 [13056/14860 (87%)]\tLoss: 0.021804\n",
      "Train Epoch: 92 [13184/14860 (88%)]\tLoss: 0.015602\n",
      "Train Epoch: 92 [13312/14860 (89%)]\tLoss: 0.028012\n",
      "Train Epoch: 92 [13440/14860 (90%)]\tLoss: 0.021675\n",
      "Train Epoch: 92 [13568/14860 (91%)]\tLoss: 0.018891\n",
      "Train Epoch: 92 [13696/14860 (91%)]\tLoss: 0.024944\n",
      "Train Epoch: 92 [13824/14860 (92%)]\tLoss: 0.015005\n",
      "Train Epoch: 92 [13952/14860 (93%)]\tLoss: 0.016705\n",
      "Train Epoch: 92 [14080/14860 (94%)]\tLoss: 0.012380\n",
      "Train Epoch: 92 [14208/14860 (95%)]\tLoss: 0.015603\n",
      "Train Epoch: 92 [14336/14860 (96%)]\tLoss: 0.020358\n",
      "Train Epoch: 92 [14464/14860 (97%)]\tLoss: 0.022343\n",
      "Train Epoch: 92 [14592/14860 (97%)]\tLoss: 0.026264\n",
      "Train Epoch: 92 [14720/14860 (98%)]\tLoss: 0.022487\n",
      "Train Epoch: 92 [1392/14860 (99%)]\tLoss: 0.024544\n",
      "epoch 92 training loss: 0.020654789339273404\n",
      "epoch 92 validation loss: 0.022656306804814005\n",
      "Train Epoch: 93 [0/14860 (0%)]\tLoss: 0.019736\n",
      "Train Epoch: 93 [128/14860 (1%)]\tLoss: 0.015186\n",
      "Train Epoch: 93 [256/14860 (2%)]\tLoss: 0.032707\n",
      "Train Epoch: 93 [384/14860 (3%)]\tLoss: 0.018564\n",
      "Train Epoch: 93 [512/14860 (3%)]\tLoss: 0.031381\n",
      "Train Epoch: 93 [640/14860 (4%)]\tLoss: 0.014659\n",
      "Train Epoch: 93 [768/14860 (5%)]\tLoss: 0.030490\n",
      "Train Epoch: 93 [896/14860 (6%)]\tLoss: 0.019741\n",
      "Train Epoch: 93 [1024/14860 (7%)]\tLoss: 0.021572\n",
      "Train Epoch: 93 [1152/14860 (8%)]\tLoss: 0.022080\n",
      "Train Epoch: 93 [1280/14860 (9%)]\tLoss: 0.024964\n",
      "Train Epoch: 93 [1408/14860 (9%)]\tLoss: 0.017676\n",
      "Train Epoch: 93 [1536/14860 (10%)]\tLoss: 0.016126\n",
      "Train Epoch: 93 [1664/14860 (11%)]\tLoss: 0.023878\n",
      "Train Epoch: 93 [1792/14860 (12%)]\tLoss: 0.020061\n",
      "Train Epoch: 93 [1920/14860 (13%)]\tLoss: 0.024516\n",
      "Train Epoch: 93 [2048/14860 (14%)]\tLoss: 0.022802\n",
      "Train Epoch: 93 [2176/14860 (15%)]\tLoss: 0.026528\n",
      "Train Epoch: 93 [2304/14860 (15%)]\tLoss: 0.017296\n",
      "Train Epoch: 93 [2432/14860 (16%)]\tLoss: 0.013793\n",
      "Train Epoch: 93 [2560/14860 (17%)]\tLoss: 0.028729\n",
      "Train Epoch: 93 [2688/14860 (18%)]\tLoss: 0.021531\n",
      "Train Epoch: 93 [2816/14860 (19%)]\tLoss: 0.022290\n",
      "Train Epoch: 93 [2944/14860 (20%)]\tLoss: 0.013408\n",
      "Train Epoch: 93 [3072/14860 (21%)]\tLoss: 0.031707\n",
      "Train Epoch: 93 [3200/14860 (21%)]\tLoss: 0.025281\n",
      "Train Epoch: 93 [3328/14860 (22%)]\tLoss: 0.022414\n",
      "Train Epoch: 93 [3456/14860 (23%)]\tLoss: 0.025549\n",
      "Train Epoch: 93 [3584/14860 (24%)]\tLoss: 0.020393\n",
      "Train Epoch: 93 [3712/14860 (25%)]\tLoss: 0.037253\n",
      "Train Epoch: 93 [3840/14860 (26%)]\tLoss: 0.022352\n",
      "Train Epoch: 93 [3968/14860 (26%)]\tLoss: 0.034631\n",
      "Train Epoch: 93 [4096/14860 (27%)]\tLoss: 0.025796\n",
      "Train Epoch: 93 [4224/14860 (28%)]\tLoss: 0.021427\n",
      "Train Epoch: 93 [4352/14860 (29%)]\tLoss: 0.025506\n",
      "Train Epoch: 93 [4480/14860 (30%)]\tLoss: 0.018351\n",
      "Train Epoch: 93 [4608/14860 (31%)]\tLoss: 0.017615\n",
      "Train Epoch: 93 [4736/14860 (32%)]\tLoss: 0.023350\n",
      "Train Epoch: 93 [4864/14860 (32%)]\tLoss: 0.014732\n",
      "Train Epoch: 93 [4992/14860 (33%)]\tLoss: 0.013313\n",
      "Train Epoch: 93 [5120/14860 (34%)]\tLoss: 0.019148\n",
      "Train Epoch: 93 [5248/14860 (35%)]\tLoss: 0.024844\n",
      "Train Epoch: 93 [5376/14860 (36%)]\tLoss: 0.019219\n",
      "Train Epoch: 93 [5504/14860 (37%)]\tLoss: 0.022716\n",
      "Train Epoch: 93 [5632/14860 (38%)]\tLoss: 0.017084\n",
      "Train Epoch: 93 [5760/14860 (38%)]\tLoss: 0.016224\n",
      "Train Epoch: 93 [5888/14860 (39%)]\tLoss: 0.024376\n",
      "Train Epoch: 93 [6016/14860 (40%)]\tLoss: 0.014507\n",
      "Train Epoch: 93 [6144/14860 (41%)]\tLoss: 0.027139\n",
      "Train Epoch: 93 [6272/14860 (42%)]\tLoss: 0.018189\n",
      "Train Epoch: 93 [6400/14860 (43%)]\tLoss: 0.022298\n",
      "Train Epoch: 93 [6528/14860 (44%)]\tLoss: 0.018579\n",
      "Train Epoch: 93 [6656/14860 (44%)]\tLoss: 0.025366\n",
      "Train Epoch: 93 [6784/14860 (45%)]\tLoss: 0.030760\n",
      "Train Epoch: 93 [6912/14860 (46%)]\tLoss: 0.029915\n",
      "Train Epoch: 93 [7040/14860 (47%)]\tLoss: 0.023488\n",
      "Train Epoch: 93 [7168/14860 (48%)]\tLoss: 0.015432\n",
      "Train Epoch: 93 [7296/14860 (49%)]\tLoss: 0.016636\n",
      "Train Epoch: 93 [7424/14860 (50%)]\tLoss: 0.018962\n",
      "Train Epoch: 93 [7552/14860 (50%)]\tLoss: 0.016867\n",
      "Train Epoch: 93 [7680/14860 (51%)]\tLoss: 0.018953\n",
      "Train Epoch: 93 [7808/14860 (52%)]\tLoss: 0.020568\n",
      "Train Epoch: 93 [7936/14860 (53%)]\tLoss: 0.016099\n",
      "Train Epoch: 93 [8064/14860 (54%)]\tLoss: 0.013790\n",
      "Train Epoch: 93 [8192/14860 (55%)]\tLoss: 0.022201\n",
      "Train Epoch: 93 [8320/14860 (56%)]\tLoss: 0.020514\n",
      "Train Epoch: 93 [8448/14860 (56%)]\tLoss: 0.014888\n",
      "Train Epoch: 93 [8576/14860 (57%)]\tLoss: 0.019013\n",
      "Train Epoch: 93 [8704/14860 (58%)]\tLoss: 0.025970\n",
      "Train Epoch: 93 [8832/14860 (59%)]\tLoss: 0.009516\n",
      "Train Epoch: 93 [8960/14860 (60%)]\tLoss: 0.037801\n",
      "Train Epoch: 93 [9088/14860 (61%)]\tLoss: 0.021595\n",
      "Train Epoch: 93 [9216/14860 (62%)]\tLoss: 0.033820\n",
      "Train Epoch: 93 [9344/14860 (62%)]\tLoss: 0.024367\n",
      "Train Epoch: 93 [9472/14860 (63%)]\tLoss: 0.025900\n",
      "Train Epoch: 93 [9600/14860 (64%)]\tLoss: 0.020286\n",
      "Train Epoch: 93 [9728/14860 (65%)]\tLoss: 0.016005\n",
      "Train Epoch: 93 [9856/14860 (66%)]\tLoss: 0.018736\n",
      "Train Epoch: 93 [9984/14860 (67%)]\tLoss: 0.022789\n",
      "Train Epoch: 93 [10112/14860 (68%)]\tLoss: 0.015526\n",
      "Train Epoch: 93 [10240/14860 (68%)]\tLoss: 0.023810\n",
      "Train Epoch: 93 [10368/14860 (69%)]\tLoss: 0.021280\n",
      "Train Epoch: 93 [10496/14860 (70%)]\tLoss: 0.016200\n",
      "Train Epoch: 93 [10624/14860 (71%)]\tLoss: 0.019797\n",
      "Train Epoch: 93 [10752/14860 (72%)]\tLoss: 0.025050\n",
      "Train Epoch: 93 [10880/14860 (73%)]\tLoss: 0.016524\n",
      "Train Epoch: 93 [11008/14860 (74%)]\tLoss: 0.023827\n",
      "Train Epoch: 93 [11136/14860 (74%)]\tLoss: 0.022553\n",
      "Train Epoch: 93 [11264/14860 (75%)]\tLoss: 0.025457\n",
      "Train Epoch: 93 [11392/14860 (76%)]\tLoss: 0.019093\n",
      "Train Epoch: 93 [11520/14860 (77%)]\tLoss: 0.028541\n",
      "Train Epoch: 93 [11648/14860 (78%)]\tLoss: 0.022205\n",
      "Train Epoch: 93 [11776/14860 (79%)]\tLoss: 0.022465\n",
      "Train Epoch: 93 [11904/14860 (79%)]\tLoss: 0.020666\n",
      "Train Epoch: 93 [12032/14860 (80%)]\tLoss: 0.019035\n",
      "Train Epoch: 93 [12160/14860 (81%)]\tLoss: 0.022886\n",
      "Train Epoch: 93 [12288/14860 (82%)]\tLoss: 0.017500\n",
      "Train Epoch: 93 [12416/14860 (83%)]\tLoss: 0.018948\n",
      "Train Epoch: 93 [12544/14860 (84%)]\tLoss: 0.027019\n",
      "Train Epoch: 93 [12672/14860 (85%)]\tLoss: 0.017199\n",
      "Train Epoch: 93 [12800/14860 (85%)]\tLoss: 0.027707\n",
      "Train Epoch: 93 [12928/14860 (86%)]\tLoss: 0.020835\n",
      "Train Epoch: 93 [13056/14860 (87%)]\tLoss: 0.025005\n",
      "Train Epoch: 93 [13184/14860 (88%)]\tLoss: 0.030273\n",
      "Train Epoch: 93 [13312/14860 (89%)]\tLoss: 0.022191\n",
      "Train Epoch: 93 [13440/14860 (90%)]\tLoss: 0.018525\n",
      "Train Epoch: 93 [13568/14860 (91%)]\tLoss: 0.020092\n",
      "Train Epoch: 93 [13696/14860 (91%)]\tLoss: 0.014223\n",
      "Train Epoch: 93 [13824/14860 (92%)]\tLoss: 0.017807\n",
      "Train Epoch: 93 [13952/14860 (93%)]\tLoss: 0.017365\n",
      "Train Epoch: 93 [14080/14860 (94%)]\tLoss: 0.023342\n",
      "Train Epoch: 93 [14208/14860 (95%)]\tLoss: 0.015195\n",
      "Train Epoch: 93 [14336/14860 (96%)]\tLoss: 0.012808\n",
      "Train Epoch: 93 [14464/14860 (97%)]\tLoss: 0.020744\n",
      "Train Epoch: 93 [14592/14860 (97%)]\tLoss: 0.023118\n",
      "Train Epoch: 93 [14720/14860 (98%)]\tLoss: 0.019480\n",
      "Train Epoch: 93 [1392/14860 (99%)]\tLoss: 0.018461\n",
      "epoch 93 training loss: 0.021510259272196353\n",
      "epoch 93 validation loss: 0.025414840072465576\n",
      "Train Epoch: 94 [0/14860 (0%)]\tLoss: 0.016385\n",
      "Train Epoch: 94 [128/14860 (1%)]\tLoss: 0.021626\n",
      "Train Epoch: 94 [256/14860 (2%)]\tLoss: 0.016382\n",
      "Train Epoch: 94 [384/14860 (3%)]\tLoss: 0.022648\n",
      "Train Epoch: 94 [512/14860 (3%)]\tLoss: 0.025581\n",
      "Train Epoch: 94 [640/14860 (4%)]\tLoss: 0.020064\n",
      "Train Epoch: 94 [768/14860 (5%)]\tLoss: 0.015223\n",
      "Train Epoch: 94 [896/14860 (6%)]\tLoss: 0.019036\n",
      "Train Epoch: 94 [1024/14860 (7%)]\tLoss: 0.019980\n",
      "Train Epoch: 94 [1152/14860 (8%)]\tLoss: 0.017959\n",
      "Train Epoch: 94 [1280/14860 (9%)]\tLoss: 0.016709\n",
      "Train Epoch: 94 [1408/14860 (9%)]\tLoss: 0.024337\n",
      "Train Epoch: 94 [1536/14860 (10%)]\tLoss: 0.012779\n",
      "Train Epoch: 94 [1664/14860 (11%)]\tLoss: 0.027403\n",
      "Train Epoch: 94 [1792/14860 (12%)]\tLoss: 0.014336\n",
      "Train Epoch: 94 [1920/14860 (13%)]\tLoss: 0.013887\n",
      "Train Epoch: 94 [2048/14860 (14%)]\tLoss: 0.023193\n",
      "Train Epoch: 94 [2176/14860 (15%)]\tLoss: 0.016943\n",
      "Train Epoch: 94 [2304/14860 (15%)]\tLoss: 0.019797\n",
      "Train Epoch: 94 [2432/14860 (16%)]\tLoss: 0.022435\n",
      "Train Epoch: 94 [2560/14860 (17%)]\tLoss: 0.026910\n",
      "Train Epoch: 94 [2688/14860 (18%)]\tLoss: 0.022978\n",
      "Train Epoch: 94 [2816/14860 (19%)]\tLoss: 0.012798\n",
      "Train Epoch: 94 [2944/14860 (20%)]\tLoss: 0.014975\n",
      "Train Epoch: 94 [3072/14860 (21%)]\tLoss: 0.014017\n",
      "Train Epoch: 94 [3200/14860 (21%)]\tLoss: 0.017153\n",
      "Train Epoch: 94 [3328/14860 (22%)]\tLoss: 0.022551\n",
      "Train Epoch: 94 [3456/14860 (23%)]\tLoss: 0.023306\n",
      "Train Epoch: 94 [3584/14860 (24%)]\tLoss: 0.019326\n",
      "Train Epoch: 94 [3712/14860 (25%)]\tLoss: 0.013169\n",
      "Train Epoch: 94 [3840/14860 (26%)]\tLoss: 0.023913\n",
      "Train Epoch: 94 [3968/14860 (26%)]\tLoss: 0.017315\n",
      "Train Epoch: 94 [4096/14860 (27%)]\tLoss: 0.025739\n",
      "Train Epoch: 94 [4224/14860 (28%)]\tLoss: 0.017312\n",
      "Train Epoch: 94 [4352/14860 (29%)]\tLoss: 0.022996\n",
      "Train Epoch: 94 [4480/14860 (30%)]\tLoss: 0.018283\n",
      "Train Epoch: 94 [4608/14860 (31%)]\tLoss: 0.024291\n",
      "Train Epoch: 94 [4736/14860 (32%)]\tLoss: 0.014672\n",
      "Train Epoch: 94 [4864/14860 (32%)]\tLoss: 0.023413\n",
      "Train Epoch: 94 [4992/14860 (33%)]\tLoss: 0.016577\n",
      "Train Epoch: 94 [5120/14860 (34%)]\tLoss: 0.021335\n",
      "Train Epoch: 94 [5248/14860 (35%)]\tLoss: 0.021934\n",
      "Train Epoch: 94 [5376/14860 (36%)]\tLoss: 0.013015\n",
      "Train Epoch: 94 [5504/14860 (37%)]\tLoss: 0.027837\n",
      "Train Epoch: 94 [5632/14860 (38%)]\tLoss: 0.026110\n",
      "Train Epoch: 94 [5760/14860 (38%)]\tLoss: 0.025549\n",
      "Train Epoch: 94 [5888/14860 (39%)]\tLoss: 0.012855\n",
      "Train Epoch: 94 [6016/14860 (40%)]\tLoss: 0.016320\n",
      "Train Epoch: 94 [6144/14860 (41%)]\tLoss: 0.028403\n",
      "Train Epoch: 94 [6272/14860 (42%)]\tLoss: 0.025707\n",
      "Train Epoch: 94 [6400/14860 (43%)]\tLoss: 0.026379\n",
      "Train Epoch: 94 [6528/14860 (44%)]\tLoss: 0.018928\n",
      "Train Epoch: 94 [6656/14860 (44%)]\tLoss: 0.014832\n",
      "Train Epoch: 94 [6784/14860 (45%)]\tLoss: 0.022364\n",
      "Train Epoch: 94 [6912/14860 (46%)]\tLoss: 0.013394\n",
      "Train Epoch: 94 [7040/14860 (47%)]\tLoss: 0.034542\n",
      "Train Epoch: 94 [7168/14860 (48%)]\tLoss: 0.023422\n",
      "Train Epoch: 94 [7296/14860 (49%)]\tLoss: 0.018090\n",
      "Train Epoch: 94 [7424/14860 (50%)]\tLoss: 0.029154\n",
      "Train Epoch: 94 [7552/14860 (50%)]\tLoss: 0.016467\n",
      "Train Epoch: 94 [7680/14860 (51%)]\tLoss: 0.024128\n",
      "Train Epoch: 94 [7808/14860 (52%)]\tLoss: 0.018815\n",
      "Train Epoch: 94 [7936/14860 (53%)]\tLoss: 0.016293\n",
      "Train Epoch: 94 [8064/14860 (54%)]\tLoss: 0.012196\n",
      "Train Epoch: 94 [8192/14860 (55%)]\tLoss: 0.009421\n",
      "Train Epoch: 94 [8320/14860 (56%)]\tLoss: 0.023020\n",
      "Train Epoch: 94 [8448/14860 (56%)]\tLoss: 0.020622\n",
      "Train Epoch: 94 [8576/14860 (57%)]\tLoss: 0.020843\n",
      "Train Epoch: 94 [8704/14860 (58%)]\tLoss: 0.017653\n",
      "Train Epoch: 94 [8832/14860 (59%)]\tLoss: 0.019719\n",
      "Train Epoch: 94 [8960/14860 (60%)]\tLoss: 0.023569\n",
      "Train Epoch: 94 [9088/14860 (61%)]\tLoss: 0.021069\n",
      "Train Epoch: 94 [9216/14860 (62%)]\tLoss: 0.014671\n",
      "Train Epoch: 94 [9344/14860 (62%)]\tLoss: 0.019100\n",
      "Train Epoch: 94 [9472/14860 (63%)]\tLoss: 0.021352\n",
      "Train Epoch: 94 [9600/14860 (64%)]\tLoss: 0.014743\n",
      "Train Epoch: 94 [9728/14860 (65%)]\tLoss: 0.021532\n",
      "Train Epoch: 94 [9856/14860 (66%)]\tLoss: 0.026418\n",
      "Train Epoch: 94 [9984/14860 (67%)]\tLoss: 0.026233\n",
      "Train Epoch: 94 [10112/14860 (68%)]\tLoss: 0.071352\n",
      "Train Epoch: 94 [10240/14860 (68%)]\tLoss: 0.051116\n",
      "Train Epoch: 94 [10368/14860 (69%)]\tLoss: 0.023556\n",
      "Train Epoch: 94 [10496/14860 (70%)]\tLoss: 0.032708\n",
      "Train Epoch: 94 [10624/14860 (71%)]\tLoss: 0.030353\n",
      "Train Epoch: 94 [10752/14860 (72%)]\tLoss: 0.022610\n",
      "Train Epoch: 94 [10880/14860 (73%)]\tLoss: 0.025092\n",
      "Train Epoch: 94 [11008/14860 (74%)]\tLoss: 0.027603\n",
      "Train Epoch: 94 [11136/14860 (74%)]\tLoss: 0.024439\n",
      "Train Epoch: 94 [11264/14860 (75%)]\tLoss: 0.028251\n",
      "Train Epoch: 94 [11392/14860 (76%)]\tLoss: 0.018620\n",
      "Train Epoch: 94 [11520/14860 (77%)]\tLoss: 0.018315\n",
      "Train Epoch: 94 [11648/14860 (78%)]\tLoss: 0.029070\n",
      "Train Epoch: 94 [11776/14860 (79%)]\tLoss: 0.013970\n",
      "Train Epoch: 94 [11904/14860 (79%)]\tLoss: 0.011017\n",
      "Train Epoch: 94 [12032/14860 (80%)]\tLoss: 0.016293\n",
      "Train Epoch: 94 [12160/14860 (81%)]\tLoss: 0.022294\n",
      "Train Epoch: 94 [12288/14860 (82%)]\tLoss: 0.017918\n",
      "Train Epoch: 94 [12416/14860 (83%)]\tLoss: 0.016874\n",
      "Train Epoch: 94 [12544/14860 (84%)]\tLoss: 0.018355\n",
      "Train Epoch: 94 [12672/14860 (85%)]\tLoss: 0.021422\n",
      "Train Epoch: 94 [12800/14860 (85%)]\tLoss: 0.030302\n",
      "Train Epoch: 94 [12928/14860 (86%)]\tLoss: 0.012079\n",
      "Train Epoch: 94 [13056/14860 (87%)]\tLoss: 0.017524\n",
      "Train Epoch: 94 [13184/14860 (88%)]\tLoss: 0.025701\n",
      "Train Epoch: 94 [13312/14860 (89%)]\tLoss: 0.017454\n",
      "Train Epoch: 94 [13440/14860 (90%)]\tLoss: 0.018156\n",
      "Train Epoch: 94 [13568/14860 (91%)]\tLoss: 0.015908\n",
      "Train Epoch: 94 [13696/14860 (91%)]\tLoss: 0.023388\n",
      "Train Epoch: 94 [13824/14860 (92%)]\tLoss: 0.020581\n",
      "Train Epoch: 94 [13952/14860 (93%)]\tLoss: 0.021936\n",
      "Train Epoch: 94 [14080/14860 (94%)]\tLoss: 0.020921\n",
      "Train Epoch: 94 [14208/14860 (95%)]\tLoss: 0.023925\n",
      "Train Epoch: 94 [14336/14860 (96%)]\tLoss: 0.034444\n",
      "Train Epoch: 94 [14464/14860 (97%)]\tLoss: 0.018410\n",
      "Train Epoch: 94 [14592/14860 (97%)]\tLoss: 0.019695\n",
      "Train Epoch: 94 [14720/14860 (98%)]\tLoss: 0.019053\n",
      "Train Epoch: 94 [1392/14860 (99%)]\tLoss: 0.007472\n",
      "epoch 94 training loss: 0.02115048447018887\n",
      "epoch 94 validation loss: 0.022014048428570097\n",
      "Train Epoch: 95 [0/14860 (0%)]\tLoss: 0.017851\n",
      "Train Epoch: 95 [128/14860 (1%)]\tLoss: 0.022908\n",
      "Train Epoch: 95 [256/14860 (2%)]\tLoss: 0.020486\n",
      "Train Epoch: 95 [384/14860 (3%)]\tLoss: 0.016193\n",
      "Train Epoch: 95 [512/14860 (3%)]\tLoss: 0.026470\n",
      "Train Epoch: 95 [640/14860 (4%)]\tLoss: 0.017261\n",
      "Train Epoch: 95 [768/14860 (5%)]\tLoss: 0.026051\n",
      "Train Epoch: 95 [896/14860 (6%)]\tLoss: 0.012473\n",
      "Train Epoch: 95 [1024/14860 (7%)]\tLoss: 0.043565\n",
      "Train Epoch: 95 [1152/14860 (8%)]\tLoss: 0.017608\n",
      "Train Epoch: 95 [1280/14860 (9%)]\tLoss: 0.024292\n",
      "Train Epoch: 95 [1408/14860 (9%)]\tLoss: 0.022273\n",
      "Train Epoch: 95 [1536/14860 (10%)]\tLoss: 0.026673\n",
      "Train Epoch: 95 [1664/14860 (11%)]\tLoss: 0.013647\n",
      "Train Epoch: 95 [1792/14860 (12%)]\tLoss: 0.019975\n",
      "Train Epoch: 95 [1920/14860 (13%)]\tLoss: 0.021829\n",
      "Train Epoch: 95 [2048/14860 (14%)]\tLoss: 0.024480\n",
      "Train Epoch: 95 [2176/14860 (15%)]\tLoss: 0.016305\n",
      "Train Epoch: 95 [2304/14860 (15%)]\tLoss: 0.014089\n",
      "Train Epoch: 95 [2432/14860 (16%)]\tLoss: 0.017010\n",
      "Train Epoch: 95 [2560/14860 (17%)]\tLoss: 0.019815\n",
      "Train Epoch: 95 [2688/14860 (18%)]\tLoss: 0.018028\n",
      "Train Epoch: 95 [2816/14860 (19%)]\tLoss: 0.024441\n",
      "Train Epoch: 95 [2944/14860 (20%)]\tLoss: 0.020618\n",
      "Train Epoch: 95 [3072/14860 (21%)]\tLoss: 0.015794\n",
      "Train Epoch: 95 [3200/14860 (21%)]\tLoss: 0.022034\n",
      "Train Epoch: 95 [3328/14860 (22%)]\tLoss: 0.022620\n",
      "Train Epoch: 95 [3456/14860 (23%)]\tLoss: 0.032460\n",
      "Train Epoch: 95 [3584/14860 (24%)]\tLoss: 0.015462\n",
      "Train Epoch: 95 [3712/14860 (25%)]\tLoss: 0.016874\n",
      "Train Epoch: 95 [3840/14860 (26%)]\tLoss: 0.035070\n",
      "Train Epoch: 95 [3968/14860 (26%)]\tLoss: 0.014150\n",
      "Train Epoch: 95 [4096/14860 (27%)]\tLoss: 0.027474\n",
      "Train Epoch: 95 [4224/14860 (28%)]\tLoss: 0.018864\n",
      "Train Epoch: 95 [4352/14860 (29%)]\tLoss: 0.034579\n",
      "Train Epoch: 95 [4480/14860 (30%)]\tLoss: 0.022466\n",
      "Train Epoch: 95 [4608/14860 (31%)]\tLoss: 0.022982\n",
      "Train Epoch: 95 [4736/14860 (32%)]\tLoss: 0.025977\n",
      "Train Epoch: 95 [4864/14860 (32%)]\tLoss: 0.012101\n",
      "Train Epoch: 95 [4992/14860 (33%)]\tLoss: 0.019175\n",
      "Train Epoch: 95 [5120/14860 (34%)]\tLoss: 0.017978\n",
      "Train Epoch: 95 [5248/14860 (35%)]\tLoss: 0.015346\n",
      "Train Epoch: 95 [5376/14860 (36%)]\tLoss: 0.027430\n",
      "Train Epoch: 95 [5504/14860 (37%)]\tLoss: 0.021283\n",
      "Train Epoch: 95 [5632/14860 (38%)]\tLoss: 0.025289\n",
      "Train Epoch: 95 [5760/14860 (38%)]\tLoss: 0.017789\n",
      "Train Epoch: 95 [5888/14860 (39%)]\tLoss: 0.024568\n",
      "Train Epoch: 95 [6016/14860 (40%)]\tLoss: 0.022203\n",
      "Train Epoch: 95 [6144/14860 (41%)]\tLoss: 0.016513\n",
      "Train Epoch: 95 [6272/14860 (42%)]\tLoss: 0.019503\n",
      "Train Epoch: 95 [6400/14860 (43%)]\tLoss: 0.021278\n",
      "Train Epoch: 95 [6528/14860 (44%)]\tLoss: 0.025144\n",
      "Train Epoch: 95 [6656/14860 (44%)]\tLoss: 0.021700\n",
      "Train Epoch: 95 [6784/14860 (45%)]\tLoss: 0.019252\n",
      "Train Epoch: 95 [6912/14860 (46%)]\tLoss: 0.018849\n",
      "Train Epoch: 95 [7040/14860 (47%)]\tLoss: 0.016199\n",
      "Train Epoch: 95 [7168/14860 (48%)]\tLoss: 0.023682\n",
      "Train Epoch: 95 [7296/14860 (49%)]\tLoss: 0.016021\n",
      "Train Epoch: 95 [7424/14860 (50%)]\tLoss: 0.016433\n",
      "Train Epoch: 95 [7552/14860 (50%)]\tLoss: 0.015873\n",
      "Train Epoch: 95 [7680/14860 (51%)]\tLoss: 0.028392\n",
      "Train Epoch: 95 [7808/14860 (52%)]\tLoss: 0.017372\n",
      "Train Epoch: 95 [7936/14860 (53%)]\tLoss: 0.032714\n",
      "Train Epoch: 95 [8064/14860 (54%)]\tLoss: 0.030829\n",
      "Train Epoch: 95 [8192/14860 (55%)]\tLoss: 0.030653\n",
      "Train Epoch: 95 [8320/14860 (56%)]\tLoss: 0.019536\n",
      "Train Epoch: 95 [8448/14860 (56%)]\tLoss: 0.031359\n",
      "Train Epoch: 95 [8576/14860 (57%)]\tLoss: 0.024240\n",
      "Train Epoch: 95 [8704/14860 (58%)]\tLoss: 0.031072\n",
      "Train Epoch: 95 [8832/14860 (59%)]\tLoss: 0.018488\n",
      "Train Epoch: 95 [8960/14860 (60%)]\tLoss: 0.026640\n",
      "Train Epoch: 95 [9088/14860 (61%)]\tLoss: 0.028616\n",
      "Train Epoch: 95 [9216/14860 (62%)]\tLoss: 0.023038\n",
      "Train Epoch: 95 [9344/14860 (62%)]\tLoss: 0.022481\n",
      "Train Epoch: 95 [9472/14860 (63%)]\tLoss: 0.014060\n",
      "Train Epoch: 95 [9600/14860 (64%)]\tLoss: 0.029929\n",
      "Train Epoch: 95 [9728/14860 (65%)]\tLoss: 0.024204\n",
      "Train Epoch: 95 [9856/14860 (66%)]\tLoss: 0.018352\n",
      "Train Epoch: 95 [9984/14860 (67%)]\tLoss: 0.020071\n",
      "Train Epoch: 95 [10112/14860 (68%)]\tLoss: 0.019031\n",
      "Train Epoch: 95 [10240/14860 (68%)]\tLoss: 0.017499\n",
      "Train Epoch: 95 [10368/14860 (69%)]\tLoss: 0.023899\n",
      "Train Epoch: 95 [10496/14860 (70%)]\tLoss: 0.016432\n",
      "Train Epoch: 95 [10624/14860 (71%)]\tLoss: 0.020740\n",
      "Train Epoch: 95 [10752/14860 (72%)]\tLoss: 0.013941\n",
      "Train Epoch: 95 [10880/14860 (73%)]\tLoss: 0.018813\n",
      "Train Epoch: 95 [11008/14860 (74%)]\tLoss: 0.019106\n",
      "Train Epoch: 95 [11136/14860 (74%)]\tLoss: 0.027134\n",
      "Train Epoch: 95 [11264/14860 (75%)]\tLoss: 0.027884\n",
      "Train Epoch: 95 [11392/14860 (76%)]\tLoss: 0.012729\n",
      "Train Epoch: 95 [11520/14860 (77%)]\tLoss: 0.019273\n",
      "Train Epoch: 95 [11648/14860 (78%)]\tLoss: 0.022752\n",
      "Train Epoch: 95 [11776/14860 (79%)]\tLoss: 0.015088\n",
      "Train Epoch: 95 [11904/14860 (79%)]\tLoss: 0.013500\n",
      "Train Epoch: 95 [12032/14860 (80%)]\tLoss: 0.024494\n",
      "Train Epoch: 95 [12160/14860 (81%)]\tLoss: 0.019440\n",
      "Train Epoch: 95 [12288/14860 (82%)]\tLoss: 0.014022\n",
      "Train Epoch: 95 [12416/14860 (83%)]\tLoss: 0.016209\n",
      "Train Epoch: 95 [12544/14860 (84%)]\tLoss: 0.017427\n",
      "Train Epoch: 95 [12672/14860 (85%)]\tLoss: 0.018912\n",
      "Train Epoch: 95 [12800/14860 (85%)]\tLoss: 0.019615\n",
      "Train Epoch: 95 [12928/14860 (86%)]\tLoss: 0.023615\n",
      "Train Epoch: 95 [13056/14860 (87%)]\tLoss: 0.024494\n",
      "Train Epoch: 95 [13184/14860 (88%)]\tLoss: 0.022784\n",
      "Train Epoch: 95 [13312/14860 (89%)]\tLoss: 0.018349\n",
      "Train Epoch: 95 [13440/14860 (90%)]\tLoss: 0.020896\n",
      "Train Epoch: 95 [13568/14860 (91%)]\tLoss: 0.013620\n",
      "Train Epoch: 95 [13696/14860 (91%)]\tLoss: 0.022779\n",
      "Train Epoch: 95 [13824/14860 (92%)]\tLoss: 0.017717\n",
      "Train Epoch: 95 [13952/14860 (93%)]\tLoss: 0.020373\n",
      "Train Epoch: 95 [14080/14860 (94%)]\tLoss: 0.028469\n",
      "Train Epoch: 95 [14208/14860 (95%)]\tLoss: 0.022174\n",
      "Train Epoch: 95 [14336/14860 (96%)]\tLoss: 0.024825\n",
      "Train Epoch: 95 [14464/14860 (97%)]\tLoss: 0.015113\n",
      "Train Epoch: 95 [14592/14860 (97%)]\tLoss: 0.012692\n",
      "Train Epoch: 95 [14720/14860 (98%)]\tLoss: 0.030530\n",
      "Train Epoch: 95 [1392/14860 (99%)]\tLoss: 0.017088\n",
      "epoch 95 training loss: 0.021284259004024867\n",
      "epoch 95 validation loss: 0.021507102265484974\n",
      "Train Epoch: 96 [0/14860 (0%)]\tLoss: 0.016925\n",
      "Train Epoch: 96 [128/14860 (1%)]\tLoss: 0.020854\n",
      "Train Epoch: 96 [256/14860 (2%)]\tLoss: 0.015318\n",
      "Train Epoch: 96 [384/14860 (3%)]\tLoss: 0.021794\n",
      "Train Epoch: 96 [512/14860 (3%)]\tLoss: 0.021647\n",
      "Train Epoch: 96 [640/14860 (4%)]\tLoss: 0.017909\n",
      "Train Epoch: 96 [768/14860 (5%)]\tLoss: 0.014966\n",
      "Train Epoch: 96 [896/14860 (6%)]\tLoss: 0.018672\n",
      "Train Epoch: 96 [1024/14860 (7%)]\tLoss: 0.019602\n",
      "Train Epoch: 96 [1152/14860 (8%)]\tLoss: 0.020187\n",
      "Train Epoch: 96 [1280/14860 (9%)]\tLoss: 0.024537\n",
      "Train Epoch: 96 [1408/14860 (9%)]\tLoss: 0.016691\n",
      "Train Epoch: 96 [1536/14860 (10%)]\tLoss: 0.032263\n",
      "Train Epoch: 96 [1664/14860 (11%)]\tLoss: 0.017591\n",
      "Train Epoch: 96 [1792/14860 (12%)]\tLoss: 0.025139\n",
      "Train Epoch: 96 [1920/14860 (13%)]\tLoss: 0.020389\n",
      "Train Epoch: 96 [2048/14860 (14%)]\tLoss: 0.022031\n",
      "Train Epoch: 96 [2176/14860 (15%)]\tLoss: 0.017295\n",
      "Train Epoch: 96 [2304/14860 (15%)]\tLoss: 0.015458\n",
      "Train Epoch: 96 [2432/14860 (16%)]\tLoss: 0.020857\n",
      "Train Epoch: 96 [2560/14860 (17%)]\tLoss: 0.021755\n",
      "Train Epoch: 96 [2688/14860 (18%)]\tLoss: 0.013704\n",
      "Train Epoch: 96 [2816/14860 (19%)]\tLoss: 0.020474\n",
      "Train Epoch: 96 [2944/14860 (20%)]\tLoss: 0.019853\n",
      "Train Epoch: 96 [3072/14860 (21%)]\tLoss: 0.020911\n",
      "Train Epoch: 96 [3200/14860 (21%)]\tLoss: 0.018267\n",
      "Train Epoch: 96 [3328/14860 (22%)]\tLoss: 0.023141\n",
      "Train Epoch: 96 [3456/14860 (23%)]\tLoss: 0.019758\n",
      "Train Epoch: 96 [3584/14860 (24%)]\tLoss: 0.015875\n",
      "Train Epoch: 96 [3712/14860 (25%)]\tLoss: 0.016107\n",
      "Train Epoch: 96 [3840/14860 (26%)]\tLoss: 0.014297\n",
      "Train Epoch: 96 [3968/14860 (26%)]\tLoss: 0.017654\n",
      "Train Epoch: 96 [4096/14860 (27%)]\tLoss: 0.025892\n",
      "Train Epoch: 96 [4224/14860 (28%)]\tLoss: 0.016647\n",
      "Train Epoch: 96 [4352/14860 (29%)]\tLoss: 0.012818\n",
      "Train Epoch: 96 [4480/14860 (30%)]\tLoss: 0.028564\n",
      "Train Epoch: 96 [4608/14860 (31%)]\tLoss: 0.019156\n",
      "Train Epoch: 96 [4736/14860 (32%)]\tLoss: 0.017994\n",
      "Train Epoch: 96 [4864/14860 (32%)]\tLoss: 0.017418\n",
      "Train Epoch: 96 [4992/14860 (33%)]\tLoss: 0.029878\n",
      "Train Epoch: 96 [5120/14860 (34%)]\tLoss: 0.016889\n",
      "Train Epoch: 96 [5248/14860 (35%)]\tLoss: 0.019927\n",
      "Train Epoch: 96 [5376/14860 (36%)]\tLoss: 0.013045\n",
      "Train Epoch: 96 [5504/14860 (37%)]\tLoss: 0.020319\n",
      "Train Epoch: 96 [5632/14860 (38%)]\tLoss: 0.018355\n",
      "Train Epoch: 96 [5760/14860 (38%)]\tLoss: 0.022049\n",
      "Train Epoch: 96 [5888/14860 (39%)]\tLoss: 0.014690\n",
      "Train Epoch: 96 [6016/14860 (40%)]\tLoss: 0.018662\n",
      "Train Epoch: 96 [6144/14860 (41%)]\tLoss: 0.019777\n",
      "Train Epoch: 96 [6272/14860 (42%)]\tLoss: 0.028088\n",
      "Train Epoch: 96 [6400/14860 (43%)]\tLoss: 0.027631\n",
      "Train Epoch: 96 [6528/14860 (44%)]\tLoss: 0.026535\n",
      "Train Epoch: 96 [6656/14860 (44%)]\tLoss: 0.027484\n",
      "Train Epoch: 96 [6784/14860 (45%)]\tLoss: 0.020719\n",
      "Train Epoch: 96 [6912/14860 (46%)]\tLoss: 0.024519\n",
      "Train Epoch: 96 [7040/14860 (47%)]\tLoss: 0.026346\n",
      "Train Epoch: 96 [7168/14860 (48%)]\tLoss: 0.020313\n",
      "Train Epoch: 96 [7296/14860 (49%)]\tLoss: 0.020911\n",
      "Train Epoch: 96 [7424/14860 (50%)]\tLoss: 0.017941\n",
      "Train Epoch: 96 [7552/14860 (50%)]\tLoss: 0.018319\n",
      "Train Epoch: 96 [7680/14860 (51%)]\tLoss: 0.024429\n",
      "Train Epoch: 96 [7808/14860 (52%)]\tLoss: 0.013613\n",
      "Train Epoch: 96 [7936/14860 (53%)]\tLoss: 0.020469\n",
      "Train Epoch: 96 [8064/14860 (54%)]\tLoss: 0.021691\n",
      "Train Epoch: 96 [8192/14860 (55%)]\tLoss: 0.018649\n",
      "Train Epoch: 96 [8320/14860 (56%)]\tLoss: 0.026341\n",
      "Train Epoch: 96 [8448/14860 (56%)]\tLoss: 0.019078\n",
      "Train Epoch: 96 [8576/14860 (57%)]\tLoss: 0.025285\n",
      "Train Epoch: 96 [8704/14860 (58%)]\tLoss: 0.017501\n",
      "Train Epoch: 96 [8832/14860 (59%)]\tLoss: 0.020651\n",
      "Train Epoch: 96 [8960/14860 (60%)]\tLoss: 0.016320\n",
      "Train Epoch: 96 [9088/14860 (61%)]\tLoss: 0.017493\n",
      "Train Epoch: 96 [9216/14860 (62%)]\tLoss: 0.019814\n",
      "Train Epoch: 96 [9344/14860 (62%)]\tLoss: 0.014509\n",
      "Train Epoch: 96 [9472/14860 (63%)]\tLoss: 0.021448\n",
      "Train Epoch: 96 [9600/14860 (64%)]\tLoss: 0.019322\n",
      "Train Epoch: 96 [9728/14860 (65%)]\tLoss: 0.018284\n",
      "Train Epoch: 96 [9856/14860 (66%)]\tLoss: 0.026233\n",
      "Train Epoch: 96 [9984/14860 (67%)]\tLoss: 0.019838\n",
      "Train Epoch: 96 [10112/14860 (68%)]\tLoss: 0.023208\n",
      "Train Epoch: 96 [10240/14860 (68%)]\tLoss: 0.020561\n",
      "Train Epoch: 96 [10368/14860 (69%)]\tLoss: 0.023293\n",
      "Train Epoch: 96 [10496/14860 (70%)]\tLoss: 0.017562\n",
      "Train Epoch: 96 [10624/14860 (71%)]\tLoss: 0.021468\n",
      "Train Epoch: 96 [10752/14860 (72%)]\tLoss: 0.020125\n",
      "Train Epoch: 96 [10880/14860 (73%)]\tLoss: 0.014881\n",
      "Train Epoch: 96 [11008/14860 (74%)]\tLoss: 0.013462\n",
      "Train Epoch: 96 [11136/14860 (74%)]\tLoss: 0.021425\n",
      "Train Epoch: 96 [11264/14860 (75%)]\tLoss: 0.010930\n",
      "Train Epoch: 96 [11392/14860 (76%)]\tLoss: 0.018962\n",
      "Train Epoch: 96 [11520/14860 (77%)]\tLoss: 0.015708\n",
      "Train Epoch: 96 [11648/14860 (78%)]\tLoss: 0.017862\n",
      "Train Epoch: 96 [11776/14860 (79%)]\tLoss: 0.021181\n",
      "Train Epoch: 96 [11904/14860 (79%)]\tLoss: 0.021337\n",
      "Train Epoch: 96 [12032/14860 (80%)]\tLoss: 0.025501\n",
      "Train Epoch: 96 [12160/14860 (81%)]\tLoss: 0.025824\n",
      "Train Epoch: 96 [12288/14860 (82%)]\tLoss: 0.021561\n",
      "Train Epoch: 96 [12416/14860 (83%)]\tLoss: 0.029839\n",
      "Train Epoch: 96 [12544/14860 (84%)]\tLoss: 0.020555\n",
      "Train Epoch: 96 [12672/14860 (85%)]\tLoss: 0.026172\n",
      "Train Epoch: 96 [12800/14860 (85%)]\tLoss: 0.016820\n",
      "Train Epoch: 96 [12928/14860 (86%)]\tLoss: 0.033287\n",
      "Train Epoch: 96 [13056/14860 (87%)]\tLoss: 0.021391\n",
      "Train Epoch: 96 [13184/14860 (88%)]\tLoss: 0.019617\n",
      "Train Epoch: 96 [13312/14860 (89%)]\tLoss: 0.026009\n",
      "Train Epoch: 96 [13440/14860 (90%)]\tLoss: 0.014643\n",
      "Train Epoch: 96 [13568/14860 (91%)]\tLoss: 0.035305\n",
      "Train Epoch: 96 [13696/14860 (91%)]\tLoss: 0.021103\n",
      "Train Epoch: 96 [13824/14860 (92%)]\tLoss: 0.021929\n",
      "Train Epoch: 96 [13952/14860 (93%)]\tLoss: 0.029912\n",
      "Train Epoch: 96 [14080/14860 (94%)]\tLoss: 0.017678\n",
      "Train Epoch: 96 [14208/14860 (95%)]\tLoss: 0.026319\n",
      "Train Epoch: 96 [14336/14860 (96%)]\tLoss: 0.018794\n",
      "Train Epoch: 96 [14464/14860 (97%)]\tLoss: 0.013518\n",
      "Train Epoch: 96 [14592/14860 (97%)]\tLoss: 0.015501\n",
      "Train Epoch: 96 [14720/14860 (98%)]\tLoss: 0.027091\n",
      "Train Epoch: 96 [1392/14860 (99%)]\tLoss: 0.013062\n",
      "epoch 96 training loss: 0.02048867718022094\n",
      "epoch 96 validation loss: 0.020836223773748476\n",
      "Train Epoch: 97 [0/14860 (0%)]\tLoss: 0.017827\n",
      "Train Epoch: 97 [128/14860 (1%)]\tLoss: 0.035858\n",
      "Train Epoch: 97 [256/14860 (2%)]\tLoss: 0.022475\n",
      "Train Epoch: 97 [384/14860 (3%)]\tLoss: 0.019839\n",
      "Train Epoch: 97 [512/14860 (3%)]\tLoss: 0.014151\n",
      "Train Epoch: 97 [640/14860 (4%)]\tLoss: 0.021009\n",
      "Train Epoch: 97 [768/14860 (5%)]\tLoss: 0.019402\n",
      "Train Epoch: 97 [896/14860 (6%)]\tLoss: 0.020346\n",
      "Train Epoch: 97 [1024/14860 (7%)]\tLoss: 0.023493\n",
      "Train Epoch: 97 [1152/14860 (8%)]\tLoss: 0.015504\n",
      "Train Epoch: 97 [1280/14860 (9%)]\tLoss: 0.023213\n",
      "Train Epoch: 97 [1408/14860 (9%)]\tLoss: 0.020440\n",
      "Train Epoch: 97 [1536/14860 (10%)]\tLoss: 0.016063\n",
      "Train Epoch: 97 [1664/14860 (11%)]\tLoss: 0.033256\n",
      "Train Epoch: 97 [1792/14860 (12%)]\tLoss: 0.014695\n",
      "Train Epoch: 97 [1920/14860 (13%)]\tLoss: 0.019590\n",
      "Train Epoch: 97 [2048/14860 (14%)]\tLoss: 0.023953\n",
      "Train Epoch: 97 [2176/14860 (15%)]\tLoss: 0.018458\n",
      "Train Epoch: 97 [2304/14860 (15%)]\tLoss: 0.026931\n",
      "Train Epoch: 97 [2432/14860 (16%)]\tLoss: 0.015200\n",
      "Train Epoch: 97 [2560/14860 (17%)]\tLoss: 0.024405\n",
      "Train Epoch: 97 [2688/14860 (18%)]\tLoss: 0.026073\n",
      "Train Epoch: 97 [2816/14860 (19%)]\tLoss: 0.026957\n",
      "Train Epoch: 97 [2944/14860 (20%)]\tLoss: 0.020230\n",
      "Train Epoch: 97 [3072/14860 (21%)]\tLoss: 0.010919\n",
      "Train Epoch: 97 [3200/14860 (21%)]\tLoss: 0.027360\n",
      "Train Epoch: 97 [3328/14860 (22%)]\tLoss: 0.011895\n",
      "Train Epoch: 97 [3456/14860 (23%)]\tLoss: 0.025248\n",
      "Train Epoch: 97 [3584/14860 (24%)]\tLoss: 0.031048\n",
      "Train Epoch: 97 [3712/14860 (25%)]\tLoss: 0.021751\n",
      "Train Epoch: 97 [3840/14860 (26%)]\tLoss: 0.028837\n",
      "Train Epoch: 97 [3968/14860 (26%)]\tLoss: 0.017718\n",
      "Train Epoch: 97 [4096/14860 (27%)]\tLoss: 0.014607\n",
      "Train Epoch: 97 [4224/14860 (28%)]\tLoss: 0.023413\n",
      "Train Epoch: 97 [4352/14860 (29%)]\tLoss: 0.027064\n",
      "Train Epoch: 97 [4480/14860 (30%)]\tLoss: 0.021515\n",
      "Train Epoch: 97 [4608/14860 (31%)]\tLoss: 0.019047\n",
      "Train Epoch: 97 [4736/14860 (32%)]\tLoss: 0.017045\n",
      "Train Epoch: 97 [4864/14860 (32%)]\tLoss: 0.024429\n",
      "Train Epoch: 97 [4992/14860 (33%)]\tLoss: 0.023870\n",
      "Train Epoch: 97 [5120/14860 (34%)]\tLoss: 0.023881\n",
      "Train Epoch: 97 [5248/14860 (35%)]\tLoss: 0.026702\n",
      "Train Epoch: 97 [5376/14860 (36%)]\tLoss: 0.021574\n",
      "Train Epoch: 97 [5504/14860 (37%)]\tLoss: 0.018196\n",
      "Train Epoch: 97 [5632/14860 (38%)]\tLoss: 0.018391\n",
      "Train Epoch: 97 [5760/14860 (38%)]\tLoss: 0.024447\n",
      "Train Epoch: 97 [5888/14860 (39%)]\tLoss: 0.011308\n",
      "Train Epoch: 97 [6016/14860 (40%)]\tLoss: 0.016509\n",
      "Train Epoch: 97 [6144/14860 (41%)]\tLoss: 0.019826\n",
      "Train Epoch: 97 [6272/14860 (42%)]\tLoss: 0.016699\n",
      "Train Epoch: 97 [6400/14860 (43%)]\tLoss: 0.021978\n",
      "Train Epoch: 97 [6528/14860 (44%)]\tLoss: 0.019606\n",
      "Train Epoch: 97 [6656/14860 (44%)]\tLoss: 0.016097\n",
      "Train Epoch: 97 [6784/14860 (45%)]\tLoss: 0.019166\n",
      "Train Epoch: 97 [6912/14860 (46%)]\tLoss: 0.020484\n",
      "Train Epoch: 97 [7040/14860 (47%)]\tLoss: 0.020182\n",
      "Train Epoch: 97 [7168/14860 (48%)]\tLoss: 0.014295\n",
      "Train Epoch: 97 [7296/14860 (49%)]\tLoss: 0.022384\n",
      "Train Epoch: 97 [7424/14860 (50%)]\tLoss: 0.020191\n",
      "Train Epoch: 97 [7552/14860 (50%)]\tLoss: 0.028348\n",
      "Train Epoch: 97 [7680/14860 (51%)]\tLoss: 0.013615\n",
      "Train Epoch: 97 [7808/14860 (52%)]\tLoss: 0.023671\n",
      "Train Epoch: 97 [7936/14860 (53%)]\tLoss: 0.024932\n",
      "Train Epoch: 97 [8064/14860 (54%)]\tLoss: 0.032254\n",
      "Train Epoch: 97 [8192/14860 (55%)]\tLoss: 0.019870\n",
      "Train Epoch: 97 [8320/14860 (56%)]\tLoss: 0.034980\n",
      "Train Epoch: 97 [8448/14860 (56%)]\tLoss: 0.027426\n",
      "Train Epoch: 97 [8576/14860 (57%)]\tLoss: 0.014938\n",
      "Train Epoch: 97 [8704/14860 (58%)]\tLoss: 0.026769\n",
      "Train Epoch: 97 [8832/14860 (59%)]\tLoss: 0.015217\n",
      "Train Epoch: 97 [8960/14860 (60%)]\tLoss: 0.014015\n",
      "Train Epoch: 97 [9088/14860 (61%)]\tLoss: 0.033810\n",
      "Train Epoch: 97 [9216/14860 (62%)]\tLoss: 0.025349\n",
      "Train Epoch: 97 [9344/14860 (62%)]\tLoss: 0.022269\n",
      "Train Epoch: 97 [9472/14860 (63%)]\tLoss: 0.024154\n",
      "Train Epoch: 97 [9600/14860 (64%)]\tLoss: 0.021606\n",
      "Train Epoch: 97 [9728/14860 (65%)]\tLoss: 0.016843\n",
      "Train Epoch: 97 [9856/14860 (66%)]\tLoss: 0.024965\n",
      "Train Epoch: 97 [9984/14860 (67%)]\tLoss: 0.018201\n",
      "Train Epoch: 97 [10112/14860 (68%)]\tLoss: 0.023409\n",
      "Train Epoch: 97 [10240/14860 (68%)]\tLoss: 0.019122\n",
      "Train Epoch: 97 [10368/14860 (69%)]\tLoss: 0.011241\n",
      "Train Epoch: 97 [10496/14860 (70%)]\tLoss: 0.026397\n",
      "Train Epoch: 97 [10624/14860 (71%)]\tLoss: 0.016684\n",
      "Train Epoch: 97 [10752/14860 (72%)]\tLoss: 0.015065\n",
      "Train Epoch: 97 [10880/14860 (73%)]\tLoss: 0.026578\n",
      "Train Epoch: 97 [11008/14860 (74%)]\tLoss: 0.027229\n",
      "Train Epoch: 97 [11136/14860 (74%)]\tLoss: 0.015634\n",
      "Train Epoch: 97 [11264/14860 (75%)]\tLoss: 0.022932\n",
      "Train Epoch: 97 [11392/14860 (76%)]\tLoss: 0.013925\n",
      "Train Epoch: 97 [11520/14860 (77%)]\tLoss: 0.038296\n",
      "Train Epoch: 97 [11648/14860 (78%)]\tLoss: 0.022116\n",
      "Train Epoch: 97 [11776/14860 (79%)]\tLoss: 0.021092\n",
      "Train Epoch: 97 [11904/14860 (79%)]\tLoss: 0.022970\n",
      "Train Epoch: 97 [12032/14860 (80%)]\tLoss: 0.027036\n",
      "Train Epoch: 97 [12160/14860 (81%)]\tLoss: 0.014261\n",
      "Train Epoch: 97 [12288/14860 (82%)]\tLoss: 0.023286\n",
      "Train Epoch: 97 [12416/14860 (83%)]\tLoss: 0.018678\n",
      "Train Epoch: 97 [12544/14860 (84%)]\tLoss: 0.021625\n",
      "Train Epoch: 97 [12672/14860 (85%)]\tLoss: 0.015591\n",
      "Train Epoch: 97 [12800/14860 (85%)]\tLoss: 0.018100\n",
      "Train Epoch: 97 [12928/14860 (86%)]\tLoss: 0.018784\n",
      "Train Epoch: 97 [13056/14860 (87%)]\tLoss: 0.020276\n",
      "Train Epoch: 97 [13184/14860 (88%)]\tLoss: 0.022702\n",
      "Train Epoch: 97 [13312/14860 (89%)]\tLoss: 0.017911\n",
      "Train Epoch: 97 [13440/14860 (90%)]\tLoss: 0.019079\n",
      "Train Epoch: 97 [13568/14860 (91%)]\tLoss: 0.017785\n",
      "Train Epoch: 97 [13696/14860 (91%)]\tLoss: 0.021559\n",
      "Train Epoch: 97 [13824/14860 (92%)]\tLoss: 0.016045\n",
      "Train Epoch: 97 [13952/14860 (93%)]\tLoss: 0.021034\n",
      "Train Epoch: 97 [14080/14860 (94%)]\tLoss: 0.013522\n",
      "Train Epoch: 97 [14208/14860 (95%)]\tLoss: 0.024744\n",
      "Train Epoch: 97 [14336/14860 (96%)]\tLoss: 0.018126\n",
      "Train Epoch: 97 [14464/14860 (97%)]\tLoss: 0.030997\n",
      "Train Epoch: 97 [14592/14860 (97%)]\tLoss: 0.020055\n",
      "Train Epoch: 97 [14720/14860 (98%)]\tLoss: 0.016611\n",
      "Train Epoch: 97 [1392/14860 (99%)]\tLoss: 0.038565\n",
      "epoch 97 training loss: 0.021361911406692784\n",
      "epoch 97 validation loss: 0.02043822393290356\n",
      "Train Epoch: 98 [0/14860 (0%)]\tLoss: 0.020452\n",
      "Train Epoch: 98 [128/14860 (1%)]\tLoss: 0.029427\n",
      "Train Epoch: 98 [256/14860 (2%)]\tLoss: 0.022162\n",
      "Train Epoch: 98 [384/14860 (3%)]\tLoss: 0.029461\n",
      "Train Epoch: 98 [512/14860 (3%)]\tLoss: 0.022188\n",
      "Train Epoch: 98 [640/14860 (4%)]\tLoss: 0.025570\n",
      "Train Epoch: 98 [768/14860 (5%)]\tLoss: 0.022431\n",
      "Train Epoch: 98 [896/14860 (6%)]\tLoss: 0.028490\n",
      "Train Epoch: 98 [1024/14860 (7%)]\tLoss: 0.020976\n",
      "Train Epoch: 98 [1152/14860 (8%)]\tLoss: 0.017826\n",
      "Train Epoch: 98 [1280/14860 (9%)]\tLoss: 0.038206\n",
      "Train Epoch: 98 [1408/14860 (9%)]\tLoss: 0.022637\n",
      "Train Epoch: 98 [1536/14860 (10%)]\tLoss: 0.026929\n",
      "Train Epoch: 98 [1664/14860 (11%)]\tLoss: 0.027621\n",
      "Train Epoch: 98 [1792/14860 (12%)]\tLoss: 0.028344\n",
      "Train Epoch: 98 [1920/14860 (13%)]\tLoss: 0.020192\n",
      "Train Epoch: 98 [2048/14860 (14%)]\tLoss: 0.020612\n",
      "Train Epoch: 98 [2176/14860 (15%)]\tLoss: 0.023514\n",
      "Train Epoch: 98 [2304/14860 (15%)]\tLoss: 0.020753\n",
      "Train Epoch: 98 [2432/14860 (16%)]\tLoss: 0.016039\n",
      "Train Epoch: 98 [2560/14860 (17%)]\tLoss: 0.016554\n",
      "Train Epoch: 98 [2688/14860 (18%)]\tLoss: 0.018612\n",
      "Train Epoch: 98 [2816/14860 (19%)]\tLoss: 0.013688\n",
      "Train Epoch: 98 [2944/14860 (20%)]\tLoss: 0.015665\n",
      "Train Epoch: 98 [3072/14860 (21%)]\tLoss: 0.017037\n",
      "Train Epoch: 98 [3200/14860 (21%)]\tLoss: 0.021559\n",
      "Train Epoch: 98 [3328/14860 (22%)]\tLoss: 0.020893\n",
      "Train Epoch: 98 [3456/14860 (23%)]\tLoss: 0.018161\n",
      "Train Epoch: 98 [3584/14860 (24%)]\tLoss: 0.011136\n",
      "Train Epoch: 98 [3712/14860 (25%)]\tLoss: 0.021181\n",
      "Train Epoch: 98 [3840/14860 (26%)]\tLoss: 0.014635\n",
      "Train Epoch: 98 [3968/14860 (26%)]\tLoss: 0.025684\n",
      "Train Epoch: 98 [4096/14860 (27%)]\tLoss: 0.015947\n",
      "Train Epoch: 98 [4224/14860 (28%)]\tLoss: 0.015979\n",
      "Train Epoch: 98 [4352/14860 (29%)]\tLoss: 0.022024\n",
      "Train Epoch: 98 [4480/14860 (30%)]\tLoss: 0.022874\n",
      "Train Epoch: 98 [4608/14860 (31%)]\tLoss: 0.020427\n",
      "Train Epoch: 98 [4736/14860 (32%)]\tLoss: 0.022998\n",
      "Train Epoch: 98 [4864/14860 (32%)]\tLoss: 0.021954\n",
      "Train Epoch: 98 [4992/14860 (33%)]\tLoss: 0.021658\n",
      "Train Epoch: 98 [5120/14860 (34%)]\tLoss: 0.020474\n",
      "Train Epoch: 98 [5248/14860 (35%)]\tLoss: 0.020130\n",
      "Train Epoch: 98 [5376/14860 (36%)]\tLoss: 0.019634\n",
      "Train Epoch: 98 [5504/14860 (37%)]\tLoss: 0.027722\n",
      "Train Epoch: 98 [5632/14860 (38%)]\tLoss: 0.018522\n",
      "Train Epoch: 98 [5760/14860 (38%)]\tLoss: 0.018236\n",
      "Train Epoch: 98 [5888/14860 (39%)]\tLoss: 0.020644\n",
      "Train Epoch: 98 [6016/14860 (40%)]\tLoss: 0.019295\n",
      "Train Epoch: 98 [6144/14860 (41%)]\tLoss: 0.016458\n",
      "Train Epoch: 98 [6272/14860 (42%)]\tLoss: 0.022570\n",
      "Train Epoch: 98 [6400/14860 (43%)]\tLoss: 0.019725\n",
      "Train Epoch: 98 [6528/14860 (44%)]\tLoss: 0.018075\n",
      "Train Epoch: 98 [6656/14860 (44%)]\tLoss: 0.015465\n",
      "Train Epoch: 98 [6784/14860 (45%)]\tLoss: 0.019330\n",
      "Train Epoch: 98 [6912/14860 (46%)]\tLoss: 0.018647\n",
      "Train Epoch: 98 [7040/14860 (47%)]\tLoss: 0.023097\n",
      "Train Epoch: 98 [7168/14860 (48%)]\tLoss: 0.015299\n",
      "Train Epoch: 98 [7296/14860 (49%)]\tLoss: 0.019890\n",
      "Train Epoch: 98 [7424/14860 (50%)]\tLoss: 0.019637\n",
      "Train Epoch: 98 [7552/14860 (50%)]\tLoss: 0.020533\n",
      "Train Epoch: 98 [7680/14860 (51%)]\tLoss: 0.028508\n",
      "Train Epoch: 98 [7808/14860 (52%)]\tLoss: 0.027022\n",
      "Train Epoch: 98 [7936/14860 (53%)]\tLoss: 0.015509\n",
      "Train Epoch: 98 [8064/14860 (54%)]\tLoss: 0.013305\n",
      "Train Epoch: 98 [8192/14860 (55%)]\tLoss: 0.015901\n",
      "Train Epoch: 98 [8320/14860 (56%)]\tLoss: 0.027599\n",
      "Train Epoch: 98 [8448/14860 (56%)]\tLoss: 0.019018\n",
      "Train Epoch: 98 [8576/14860 (57%)]\tLoss: 0.022818\n",
      "Train Epoch: 98 [8704/14860 (58%)]\tLoss: 0.019615\n",
      "Train Epoch: 98 [8832/14860 (59%)]\tLoss: 0.014730\n",
      "Train Epoch: 98 [8960/14860 (60%)]\tLoss: 0.017887\n",
      "Train Epoch: 98 [9088/14860 (61%)]\tLoss: 0.014080\n",
      "Train Epoch: 98 [9216/14860 (62%)]\tLoss: 0.018569\n",
      "Train Epoch: 98 [9344/14860 (62%)]\tLoss: 0.021176\n",
      "Train Epoch: 98 [9472/14860 (63%)]\tLoss: 0.021999\n",
      "Train Epoch: 98 [9600/14860 (64%)]\tLoss: 0.021801\n",
      "Train Epoch: 98 [9728/14860 (65%)]\tLoss: 0.020870\n",
      "Train Epoch: 98 [9856/14860 (66%)]\tLoss: 0.019442\n",
      "Train Epoch: 98 [9984/14860 (67%)]\tLoss: 0.022017\n",
      "Train Epoch: 98 [10112/14860 (68%)]\tLoss: 0.017769\n",
      "Train Epoch: 98 [10240/14860 (68%)]\tLoss: 0.020570\n",
      "Train Epoch: 98 [10368/14860 (69%)]\tLoss: 0.018843\n",
      "Train Epoch: 98 [10496/14860 (70%)]\tLoss: 0.032094\n",
      "Train Epoch: 98 [10624/14860 (71%)]\tLoss: 0.014495\n",
      "Train Epoch: 98 [10752/14860 (72%)]\tLoss: 0.016205\n",
      "Train Epoch: 98 [10880/14860 (73%)]\tLoss: 0.018126\n",
      "Train Epoch: 98 [11008/14860 (74%)]\tLoss: 0.020127\n",
      "Train Epoch: 98 [11136/14860 (74%)]\tLoss: 0.015370\n",
      "Train Epoch: 98 [11264/14860 (75%)]\tLoss: 0.016507\n",
      "Train Epoch: 98 [11392/14860 (76%)]\tLoss: 0.026475\n",
      "Train Epoch: 98 [11520/14860 (77%)]\tLoss: 0.018016\n",
      "Train Epoch: 98 [11648/14860 (78%)]\tLoss: 0.019983\n",
      "Train Epoch: 98 [11776/14860 (79%)]\tLoss: 0.025934\n",
      "Train Epoch: 98 [11904/14860 (79%)]\tLoss: 0.016294\n",
      "Train Epoch: 98 [12032/14860 (80%)]\tLoss: 0.022349\n",
      "Train Epoch: 98 [12160/14860 (81%)]\tLoss: 0.022979\n",
      "Train Epoch: 98 [12288/14860 (82%)]\tLoss: 0.022014\n",
      "Train Epoch: 98 [12416/14860 (83%)]\tLoss: 0.024440\n",
      "Train Epoch: 98 [12544/14860 (84%)]\tLoss: 0.019603\n",
      "Train Epoch: 98 [12672/14860 (85%)]\tLoss: 0.021905\n",
      "Train Epoch: 98 [12800/14860 (85%)]\tLoss: 0.027010\n",
      "Train Epoch: 98 [12928/14860 (86%)]\tLoss: 0.022906\n",
      "Train Epoch: 98 [13056/14860 (87%)]\tLoss: 0.020278\n",
      "Train Epoch: 98 [13184/14860 (88%)]\tLoss: 0.022289\n",
      "Train Epoch: 98 [13312/14860 (89%)]\tLoss: 0.023759\n",
      "Train Epoch: 98 [13440/14860 (90%)]\tLoss: 0.023810\n",
      "Train Epoch: 98 [13568/14860 (91%)]\tLoss: 0.024171\n",
      "Train Epoch: 98 [13696/14860 (91%)]\tLoss: 0.027313\n",
      "Train Epoch: 98 [13824/14860 (92%)]\tLoss: 0.018647\n",
      "Train Epoch: 98 [13952/14860 (93%)]\tLoss: 0.034065\n",
      "Train Epoch: 98 [14080/14860 (94%)]\tLoss: 0.025461\n",
      "Train Epoch: 98 [14208/14860 (95%)]\tLoss: 0.031682\n",
      "Train Epoch: 98 [14336/14860 (96%)]\tLoss: 0.018839\n",
      "Train Epoch: 98 [14464/14860 (97%)]\tLoss: 0.015553\n",
      "Train Epoch: 98 [14592/14860 (97%)]\tLoss: 0.032824\n",
      "Train Epoch: 98 [14720/14860 (98%)]\tLoss: 0.020356\n",
      "Train Epoch: 98 [1392/14860 (99%)]\tLoss: 0.020858\n",
      "epoch 98 training loss: 0.02117660907534962\n",
      "epoch 98 validation loss: 0.022979703711539724\n",
      "Train Epoch: 99 [0/14860 (0%)]\tLoss: 0.025856\n",
      "Train Epoch: 99 [128/14860 (1%)]\tLoss: 0.021416\n",
      "Train Epoch: 99 [256/14860 (2%)]\tLoss: 0.026219\n",
      "Train Epoch: 99 [384/14860 (3%)]\tLoss: 0.020272\n",
      "Train Epoch: 99 [512/14860 (3%)]\tLoss: 0.020392\n",
      "Train Epoch: 99 [640/14860 (4%)]\tLoss: 0.022897\n",
      "Train Epoch: 99 [768/14860 (5%)]\tLoss: 0.026610\n",
      "Train Epoch: 99 [896/14860 (6%)]\tLoss: 0.016443\n",
      "Train Epoch: 99 [1024/14860 (7%)]\tLoss: 0.026890\n",
      "Train Epoch: 99 [1152/14860 (8%)]\tLoss: 0.029700\n",
      "Train Epoch: 99 [1280/14860 (9%)]\tLoss: 0.028816\n",
      "Train Epoch: 99 [1408/14860 (9%)]\tLoss: 0.021000\n",
      "Train Epoch: 99 [1536/14860 (10%)]\tLoss: 0.027114\n",
      "Train Epoch: 99 [1664/14860 (11%)]\tLoss: 0.027812\n",
      "Train Epoch: 99 [1792/14860 (12%)]\tLoss: 0.013811\n",
      "Train Epoch: 99 [1920/14860 (13%)]\tLoss: 0.024233\n",
      "Train Epoch: 99 [2048/14860 (14%)]\tLoss: 0.017382\n",
      "Train Epoch: 99 [2176/14860 (15%)]\tLoss: 0.012926\n",
      "Train Epoch: 99 [2304/14860 (15%)]\tLoss: 0.019651\n",
      "Train Epoch: 99 [2432/14860 (16%)]\tLoss: 0.017180\n",
      "Train Epoch: 99 [2560/14860 (17%)]\tLoss: 0.021149\n",
      "Train Epoch: 99 [2688/14860 (18%)]\tLoss: 0.025101\n",
      "Train Epoch: 99 [2816/14860 (19%)]\tLoss: 0.023308\n",
      "Train Epoch: 99 [2944/14860 (20%)]\tLoss: 0.016996\n",
      "Train Epoch: 99 [3072/14860 (21%)]\tLoss: 0.022394\n",
      "Train Epoch: 99 [3200/14860 (21%)]\tLoss: 0.011067\n",
      "Train Epoch: 99 [3328/14860 (22%)]\tLoss: 0.025820\n",
      "Train Epoch: 99 [3456/14860 (23%)]\tLoss: 0.021943\n",
      "Train Epoch: 99 [3584/14860 (24%)]\tLoss: 0.022826\n",
      "Train Epoch: 99 [3712/14860 (25%)]\tLoss: 0.016655\n",
      "Train Epoch: 99 [3840/14860 (26%)]\tLoss: 0.016162\n",
      "Train Epoch: 99 [3968/14860 (26%)]\tLoss: 0.015726\n",
      "Train Epoch: 99 [4096/14860 (27%)]\tLoss: 0.020546\n",
      "Train Epoch: 99 [4224/14860 (28%)]\tLoss: 0.015104\n",
      "Train Epoch: 99 [4352/14860 (29%)]\tLoss: 0.026825\n",
      "Train Epoch: 99 [4480/14860 (30%)]\tLoss: 0.014077\n",
      "Train Epoch: 99 [4608/14860 (31%)]\tLoss: 0.022242\n",
      "Train Epoch: 99 [4736/14860 (32%)]\tLoss: 0.015723\n",
      "Train Epoch: 99 [4864/14860 (32%)]\tLoss: 0.017427\n",
      "Train Epoch: 99 [4992/14860 (33%)]\tLoss: 0.016991\n",
      "Train Epoch: 99 [5120/14860 (34%)]\tLoss: 0.016134\n",
      "Train Epoch: 99 [5248/14860 (35%)]\tLoss: 0.023586\n",
      "Train Epoch: 99 [5376/14860 (36%)]\tLoss: 0.017332\n",
      "Train Epoch: 99 [5504/14860 (37%)]\tLoss: 0.021249\n",
      "Train Epoch: 99 [5632/14860 (38%)]\tLoss: 0.013218\n",
      "Train Epoch: 99 [5760/14860 (38%)]\tLoss: 0.018656\n",
      "Train Epoch: 99 [5888/14860 (39%)]\tLoss: 0.029893\n",
      "Train Epoch: 99 [6016/14860 (40%)]\tLoss: 0.023393\n",
      "Train Epoch: 99 [6144/14860 (41%)]\tLoss: 0.032908\n",
      "Train Epoch: 99 [6272/14860 (42%)]\tLoss: 0.024798\n",
      "Train Epoch: 99 [6400/14860 (43%)]\tLoss: 0.028777\n",
      "Train Epoch: 99 [6528/14860 (44%)]\tLoss: 0.018993\n",
      "Train Epoch: 99 [6656/14860 (44%)]\tLoss: 0.021051\n",
      "Train Epoch: 99 [6784/14860 (45%)]\tLoss: 0.021239\n",
      "Train Epoch: 99 [6912/14860 (46%)]\tLoss: 0.018385\n",
      "Train Epoch: 99 [7040/14860 (47%)]\tLoss: 0.025940\n",
      "Train Epoch: 99 [7168/14860 (48%)]\tLoss: 0.026459\n",
      "Train Epoch: 99 [7296/14860 (49%)]\tLoss: 0.023285\n",
      "Train Epoch: 99 [7424/14860 (50%)]\tLoss: 0.026244\n",
      "Train Epoch: 99 [7552/14860 (50%)]\tLoss: 0.027974\n",
      "Train Epoch: 99 [7680/14860 (51%)]\tLoss: 0.023683\n",
      "Train Epoch: 99 [7808/14860 (52%)]\tLoss: 0.029521\n",
      "Train Epoch: 99 [7936/14860 (53%)]\tLoss: 0.028206\n",
      "Train Epoch: 99 [8064/14860 (54%)]\tLoss: 0.017871\n",
      "Train Epoch: 99 [8192/14860 (55%)]\tLoss: 0.029114\n",
      "Train Epoch: 99 [8320/14860 (56%)]\tLoss: 0.014950\n",
      "Train Epoch: 99 [8448/14860 (56%)]\tLoss: 0.025116\n",
      "Train Epoch: 99 [8576/14860 (57%)]\tLoss: 0.025701\n",
      "Train Epoch: 99 [8704/14860 (58%)]\tLoss: 0.018172\n",
      "Train Epoch: 99 [8832/14860 (59%)]\tLoss: 0.021770\n",
      "Train Epoch: 99 [8960/14860 (60%)]\tLoss: 0.022702\n",
      "Train Epoch: 99 [9088/14860 (61%)]\tLoss: 0.020649\n",
      "Train Epoch: 99 [9216/14860 (62%)]\tLoss: 0.023423\n",
      "Train Epoch: 99 [9344/14860 (62%)]\tLoss: 0.028512\n",
      "Train Epoch: 99 [9472/14860 (63%)]\tLoss: 0.013962\n",
      "Train Epoch: 99 [9600/14860 (64%)]\tLoss: 0.013871\n",
      "Train Epoch: 99 [9728/14860 (65%)]\tLoss: 0.026572\n",
      "Train Epoch: 99 [9856/14860 (66%)]\tLoss: 0.018620\n",
      "Train Epoch: 99 [9984/14860 (67%)]\tLoss: 0.022349\n",
      "Train Epoch: 99 [10112/14860 (68%)]\tLoss: 0.020333\n",
      "Train Epoch: 99 [10240/14860 (68%)]\tLoss: 0.018237\n",
      "Train Epoch: 99 [10368/14860 (69%)]\tLoss: 0.019209\n",
      "Train Epoch: 99 [10496/14860 (70%)]\tLoss: 0.015139\n",
      "Train Epoch: 99 [10624/14860 (71%)]\tLoss: 0.019893\n",
      "Train Epoch: 99 [10752/14860 (72%)]\tLoss: 0.022710\n",
      "Train Epoch: 99 [10880/14860 (73%)]\tLoss: 0.019688\n",
      "Train Epoch: 99 [11008/14860 (74%)]\tLoss: 0.013295\n",
      "Train Epoch: 99 [11136/14860 (74%)]\tLoss: 0.024811\n",
      "Train Epoch: 99 [11264/14860 (75%)]\tLoss: 0.022606\n",
      "Train Epoch: 99 [11392/14860 (76%)]\tLoss: 0.020043\n",
      "Train Epoch: 99 [11520/14860 (77%)]\tLoss: 0.026880\n",
      "Train Epoch: 99 [11648/14860 (78%)]\tLoss: 0.024866\n",
      "Train Epoch: 99 [11776/14860 (79%)]\tLoss: 0.016415\n",
      "Train Epoch: 99 [11904/14860 (79%)]\tLoss: 0.013376\n",
      "Train Epoch: 99 [12032/14860 (80%)]\tLoss: 0.018919\n",
      "Train Epoch: 99 [12160/14860 (81%)]\tLoss: 0.023085\n",
      "Train Epoch: 99 [12288/14860 (82%)]\tLoss: 0.017528\n",
      "Train Epoch: 99 [12416/14860 (83%)]\tLoss: 0.022167\n",
      "Train Epoch: 99 [12544/14860 (84%)]\tLoss: 0.016028\n",
      "Train Epoch: 99 [12672/14860 (85%)]\tLoss: 0.018048\n",
      "Train Epoch: 99 [12800/14860 (85%)]\tLoss: 0.018781\n",
      "Train Epoch: 99 [12928/14860 (86%)]\tLoss: 0.028267\n",
      "Train Epoch: 99 [13056/14860 (87%)]\tLoss: 0.011846\n",
      "Train Epoch: 99 [13184/14860 (88%)]\tLoss: 0.018401\n",
      "Train Epoch: 99 [13312/14860 (89%)]\tLoss: 0.019113\n",
      "Train Epoch: 99 [13440/14860 (90%)]\tLoss: 0.025941\n",
      "Train Epoch: 99 [13568/14860 (91%)]\tLoss: 0.017186\n",
      "Train Epoch: 99 [13696/14860 (91%)]\tLoss: 0.014233\n",
      "Train Epoch: 99 [13824/14860 (92%)]\tLoss: 0.022288\n",
      "Train Epoch: 99 [13952/14860 (93%)]\tLoss: 0.023694\n",
      "Train Epoch: 99 [14080/14860 (94%)]\tLoss: 0.023948\n",
      "Train Epoch: 99 [14208/14860 (95%)]\tLoss: 0.025603\n",
      "Train Epoch: 99 [14336/14860 (96%)]\tLoss: 0.015286\n",
      "Train Epoch: 99 [14464/14860 (97%)]\tLoss: 0.023285\n",
      "Train Epoch: 99 [14592/14860 (97%)]\tLoss: 0.011348\n",
      "Train Epoch: 99 [14720/14860 (98%)]\tLoss: 0.030298\n",
      "Train Epoch: 99 [1392/14860 (99%)]\tLoss: 0.012943\n",
      "epoch 99 training loss: 0.0211514161231044\n",
      "epoch 99 validation loss: 0.02178845653811032\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 100):    \n",
    "    \n",
    "    loss_train=train(model, optimizer, dataloader_train, device, epoch)    \n",
    "    loss_train_list.append(loss_train)\n",
    "    print('epoch', epoch, 'training loss:', loss_train)\n",
    "    \n",
    "   \n",
    "    loss_val, mae_val,mape_test = test(model, dataloader_val, device)\n",
    "    loss_val_list.append(loss_val)\n",
    "    mae_val_list.append(mae_val)\n",
    "    print('epoch', epoch, 'validation loss:', loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yp_test=[]\n",
    "with torch.no_grad(): # tell Pytorch not to build graph in the 'with' section\n",
    "    for batch_idx, (X, Y) in enumerate(dataloader_test):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        Yp = model(X)#forward pass\n",
    "        Yp_test.append(Yp.detach().cpu().numpy())\n",
    "Yp_test=np.concatenate(Yp_test, axis=0).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate model on testing set\n",
      "MSE= 0.020354695314931316\n",
      "MAE= 0.09834716988857402\n",
      "MAPE= 0.27234372057655987\n"
     ]
    }
   ],
   "source": [
    "print('Evaluate model on testing set')\n",
    "mse_test, mae_test,mape_test = test(model, dataloader_test, device)\n",
    "print('MSE=', mse_test)\n",
    "print('MAE=', mae_test)\n",
    "print('MAPE=', mape_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "ax.plot(np.arange(0,len(mae_val_list)), mae_val_list, '-r', label='validation accuracy')\n",
    "ax.set_xlabel('epoch',fontsize=16)\n",
    "ax.legend(fontsize=16)\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity_&lt;1H OCEAN</th>\n",
       "      <th>ocean_proximity_INLAND</th>\n",
       "      <th>ocean_proximity_ISLAND</th>\n",
       "      <th>ocean_proximity_NEAR BAY</th>\n",
       "      <th>ocean_proximity_NEAR OCEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  ocean_proximity_<1H OCEAN  \\\n",
       "0       322.0       126.0         8.3252                          0   \n",
       "1      2401.0      1138.0         8.3014                          0   \n",
       "2       496.0       177.0         7.2574                          0   \n",
       "3       558.0       219.0         5.6431                          0   \n",
       "4       565.0       259.0         3.8462                          0   \n",
       "\n",
       "   ocean_proximity_INLAND  ocean_proximity_ISLAND  ocean_proximity_NEAR BAY  \\\n",
       "0                       0                       0                         1   \n",
       "1                       0                       0                         1   \n",
       "2                       0                       0                         1   \n",
       "3                       0                       0                         1   \n",
       "4                       0                       0                         1   \n",
       "\n",
       "   ocean_proximity_NEAR OCEAN  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=housing.drop(['median_house_value'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    452600.0\n",
       "1    358500.0\n",
       "2    352100.0\n",
       "3    341300.0\n",
       "4    342200.0\n",
       "Name: median_house_value, dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=housing['median_house_value']\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pandas dataframe/series to numpy array\n",
    "# sklearn functions may not work well with pandas data types\n",
    "X_columns=X.columns #store the column names\n",
    "X=X.values\n",
    "Y=Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (14860, 13) (14860,)\n",
      "validation: (1652, 13) (1652,)\n",
      "test: (4128, 13) (4128,)\n"
     ]
    }
   ],
   "source": [
    "#trainnig, validation, testing split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "#split X_train and Y_train into a 'pure' training set and a validation set\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=0)\n",
    "print('train:', X_train.shape, Y_train.shape)\n",
    "print('validation:', X_val.shape, Y_val.shape)\n",
    "print('test:', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply feature normalization to training, validation and test sets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(X_train) # think about why fit to X_train, not X ?\n",
    "X_train=scaler.transform(X_train)\n",
    "X_val=scaler.transform(X_val)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "import xgboost as xgb\n",
    "model = xgb.XGBClassifier(n_estimators=20, random_state=0, objective='reg:squarederror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth=30\n",
    "\n",
    "max_depth_list=np.arange(1,max_depth+1)\n",
    "\n",
    "max_depth_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_train_list=[]\n",
    "MAE_val_list=[]\n",
    "\n",
    "for k in max_depth_list:\n",
    "    model=xgb.XGBRegressor(n_estimators=20,max_depth=k,random_state=0, objective='reg:squarederror')\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    Y_val_pred=model.predict(X_val)\n",
    "    MAE_val = np.mean(np.abs(Y_val - Y_val_pred))\n",
    "    \n",
    "    Y_train_pred=model.predict(X_train)\n",
    "    MAE_training = np.mean(np.abs(Y_train - Y_train_pred))\n",
    "\n",
    "    MAE_train_list.append(MAE_training)\n",
    "    MAE_val_list.append(MAE_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(10,6))\n",
    "ax[0].plot(max_depth_list, MAE_train_list, 'b')\n",
    "ax[0].set_xlabel('max_depth')\n",
    "ax[0].set_ylabel('training accuracy')\n",
    "ax[0].set_title('max_depth v.s. training accuracy')\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].plot(max_depth_list, MAE_val_list, 'r')\n",
    "ax[1].set_xlabel('max_depth')\n",
    "ax[1].set_ylabel('validation accuracy')\n",
    "ax[1].set_title('max_depth v.s. validation accuracy')\n",
    "ax[1].grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Temp1 = np.argmin(MAE_val_list,axis=0) \n",
    "max_depth_best =(max_depth_list[Temp1])\n",
    "max_depth_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate model on traning set\n",
      "MSE= 311695561.7753502\n",
      "MAE= 12119.912758007024\n",
      "Evaluate model on testing set\n",
      "MSE= 2292813525.478662\n",
      "MAE= 32029.049320191378\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(n_estimators=20,max_depth=max_depth_best,random_state=0, objective='reg:squarederror')\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_train_pred = model.predict(X_train)\n",
    "Y_test_pred = model.predict(X_test)\n",
    "\n",
    "print('Evaluate model on traning set')\n",
    "MSE_XGBoost = np.mean((Y_train - Y_train_pred)**2)\n",
    "MAE_XGBoost= np.mean(np.abs(Y_train - Y_train_pred))\n",
    "MAPE_XGBoost =  np.mean(np.abs(Y_train - Y_train_pred)/Y_train)\n",
    "print('MSE=', MSE_XGBoost )\n",
    "print('MAE=', MAE_XGBoost)\n",
    "\n",
    "\n",
    "print('Evaluate model on testing set')\n",
    "MSE_XGBoost = np.mean((Y_test - Y_test_pred)**2)\n",
    "MAE_XGBoost= np.mean(np.abs(Y_test - Y_test_pred))\n",
    "MAPE_XGBoost =  np.mean(np.abs(Y_test - Y_test_pred)/Y_test)\n",
    "print('MSE=', MSE_XGBoost)\n",
    "print('MAE=', MAE_XGBoost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared MSE/MAE value of MLP model with XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model MSE= 0.020354695 MAE= 0.09834717 MAPE= 0.27234372\n",
      "XGBoost   MSE= 2292813525.478662 MAE= 32029.049320191378 MAPE= 0.1788979515255204\n"
     ]
    }
   ],
   "source": [
    "print('MLP model', 'MSE=',round(mse_test,9),'MAE=',round(mae_test,8), 'MAPE=',round(mape_test,8))\n",
    "print('XGBoost  ', 'MSE=',MSE_XGBoost, 'MAE=',MAE_XGBoost, 'MAPE=',MAPE_XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared accurancy value of MLP model with XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model 0.12089415534645247\n",
      "XGBoost 33383.13865532309\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "print('MLP model',statistics.mean(mae_val_list))\n",
    "\n",
    "print('XGBoost',MAE_val_list[max_depth_best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, I build a MLP model that includes 4 layers and nonlinear activation (Sigmoid)\n",
    "#Second, I compared MLP model with XGBoost model, and use evaluation index (MSE, MAE, accurancy) \n",
    "#Finally, I found the results as follows.\n",
    "\n",
    "#Conclusion:\n",
    "# 1. Based on the result, we can find that the MSE/ MAE/ MAPE of the MLP model are 0.020, 0.098. The MSE/ MAE of \n",
    "#    XGBoost are 22928, 32029. Therefore, the method of MLP model is better than  the method of XGBoost.\n",
    "# 2. About accurency, the MLP model is 0.12. The XGBoost is 33383. Therefore, the accurncy of MLP model is also better than \n",
    "#   the accurncy of XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
